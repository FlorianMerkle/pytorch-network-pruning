{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.models import ResNet, MNIST_CNN, CIFAR_CNN\n",
    "from src.helpers import evaluate_rob_accuracy, evaluate_clean_accuracy, load_model, safe_model,_evaluate_model\n",
    "from src.data_loader import load_torchvision_dataset, load_imagenette\n",
    "#from src.pruning import identify_layers, _evaluate_sparsity\n",
    "\n",
    "import time\n",
    "\n",
    "#device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n"
     ]
    }
   ],
   "source": [
    "#model = ResNet()\n",
    "#model = MNIST_CNN()\n",
    "model = CIFAR_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = load_torchvision_dataset('CIFAR10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './saved-models/CIFAR-baseline-150-epochs.pth'\n",
    "model = load_model(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_clean_accuracy(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_rob_accuracy(model, test_loader, device, epsilon=8/255, attack='FGSM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_clean_accuracy(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rob_accuracy(model, test_loader, device, epsilon=8/255, attack='FGSM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.autograd import Variable\n",
    "import time \n",
    "\n",
    "\n",
    "def fit_free(model, train_loader, val_loader , epochs, device, number_of_replays=3, eps = 16/255):\n",
    "    mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "    mean = torch.tensor(mean).view(3,1,1).expand(3,32,32)\n",
    "    std = torch.tensor(std).view(3,1,1).expand(3,32,32)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    pert_storage = torch.zeros((512,3,32,32))\n",
    "    \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        t0 = time.time()\n",
    "        running_loss, acc_epoch_loss, avg_epoch_loss, epoch_accuracy, acc_epoch_accuracy = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        #pert_storage = torch.zeros([512, 3, 32,32])\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            mini_batch_loss = 0.0\n",
    "            mini_batch_acc = 0.0\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            no_of_samples_in_batch = inputs.shape[0]\n",
    "            \n",
    "\n",
    "            # Mini Batch Replays\n",
    "            for j in range(number_of_replays):\n",
    "                noise_batch = pert_storage[:no_of_samples_in_batch].detach().clone().requires_grad_(True)\n",
    "                adv_input = inputs+noise_batch[:no_of_samples_in_batch]\n",
    "                \n",
    "                adv_input.clamp_(0, 1.0)\n",
    "                adv_input.sub_(mean).div_(std)\n",
    "                \n",
    "                #print(adv_input[0])\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = model(adv_input)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                \n",
    "                #craft adv pert\n",
    "                pert = fgsm(noise_batch.grad)\n",
    "                \n",
    "                pert_storage[0:no_of_samples_in_batch] += pert\n",
    "                pert_storage.clamp_(-eps, eps)\n",
    "                #update weights\n",
    "                optimizer.step()\n",
    "\n",
    "                    # print statistics\n",
    "                accuracy = get_accuracy(labels, outputs)\n",
    "                mini_batch_loss += loss.item()\n",
    "                mini_batch_acc += accuracy\n",
    "                acc_loss += mini_batch_loss\n",
    "                acc_accuracy += mini_batch_acc\n",
    "                \n",
    "        avg_mini_batch_accuracy = mini_batch_acc / number_of_replays    \n",
    "        avg_mini_batch_loss = mini_batch_loss / number_of_replays\n",
    "        \n",
    "            if i%1 == 0:\n",
    "                print('[%d, %5d] loss: %.5f, train_accuracy: %.2f' %(epoch + 1, i + 1, avg_mini_batch_loss, avg_mini_batch_accuracy))\n",
    "            running_loss = 0.0\n",
    "        avg_epoch_accuracy = acc_epoch_accuracy / (i+1)*number_of_replays    \n",
    "        avg_epoch_loss = acc_epoch_loss / (i+1)*number_of_replays\n",
    "        t1 = time.time()\n",
    "        accuracy, loss = _evaluate_model(model, val_loader, device, criterion)\n",
    "        print('duration:', t1-t0,'- train loss: ',avg_epoch_loss,' - train accuracy: ',avg_epoch_accuracy,' - validation accuracy: ', accuracy,' - validation loss: ', loss)\n",
    "        print('duration: %d s - train loss: %.5f - train accuracy: %.2f - validation loss: %.2f - validation accuracy: %.2f ' %(t1-t0, avg_epoch_loss, avg_epoch_accuracy, loss, accuracy))\n",
    "        \n",
    "    print('Finished Training')\n",
    "    return {\n",
    "        'criterion': criterion,\n",
    "        'optimizer': optimizer,\n",
    "        'hist': 'Not implemented',\n",
    "        'val_accuracy': accuracy\n",
    "    }\n",
    "\n",
    "def get_accuracy(labels, outputs):\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def fgsm(gradients, step_size=.05):\n",
    "    return step_size*torch.sign(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_free(model, train_loader, test_loader, 5, device, number_of_replays=3, eps = 16/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_fast(model, train_loader, val_loader , epochs, device, eps = 8/255):\n",
    "    mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "    mean = torch.tensor(mean).view(3,1,1).expand(3,32,32)\n",
    "    std = torch.tensor(std).view(3,1,1).expand(3,32,32)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    for epoch in range(epochs):\n",
    "        t0 = time.time()\n",
    "        running_loss, acc_epoch_loss, avg_epoch_loss, epoch_accuracy, acc_epoch_accuracy = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        \n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            pert = torch.rand_like(inputs, requires_grad=True)\n",
    "            adv_inputs = inputs + pert\n",
    "            adv_inputs.clamp_(0, 1.0)\n",
    "            adv_inputs.sub_(mean).div_(std)\n",
    "            #clip 0,1\n",
    "            \n",
    "            # first backwards pass to perform fgsm\n",
    "            outputs = model(adv_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            pert = pert + (eps * pert.grad)\n",
    "            pert.clamp_(-eps, eps)\n",
    "            adv_inputs = inputs + pert\n",
    "            \n",
    "            # second backwards pass to update weights on adv.\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(adv_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            accuracy = get_accuracy(labels, outputs)\n",
    "            acc_epoch_loss += loss.item() \n",
    "            avg_epoch_loss = acc_epoch_loss / (i+1)\n",
    "            acc_epoch_accuracy += accuracy\n",
    "            avg_epoch_accuracy = acc_epoch_accuracy / (i+1)\n",
    "            if i%1 == 0:\n",
    "                print('[%d, %5d] loss: %.5f, train_accuracy: %.2f' %(epoch + 1, i + 1, loss.item(), accuracy))\n",
    "\n",
    "        t1 = time.time()\n",
    "        accuracy, loss = _evaluate_model(model, val_loader, device, criterion)\n",
    "\n",
    "        print('duration: %d s - train loss: %.5f - train accuracy: %.2f - validation loss: %.5f - validation accuracy: %.2f ' %(t1-t0, avg_epoch_loss, avg_epoch_accuracy, loss, accuracy))\n",
    "\n",
    "def get_accuracy(labels, outputs):\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.71994, train_accuracy: 10.94\n",
      "[1,     2] loss: 2.61876, train_accuracy: 11.52\n",
      "[1,     3] loss: 2.53445, train_accuracy: 14.45\n",
      "[1,     4] loss: 2.59530, train_accuracy: 14.65\n",
      "[1,     5] loss: 2.36077, train_accuracy: 16.21\n",
      "[1,     6] loss: 2.42841, train_accuracy: 18.36\n",
      "[1,     7] loss: 2.32086, train_accuracy: 18.95\n",
      "[1,     8] loss: 2.23608, train_accuracy: 19.14\n",
      "[1,     9] loss: 2.29884, train_accuracy: 20.51\n",
      "[1,    10] loss: 2.16112, train_accuracy: 22.46\n",
      "[1,    11] loss: 2.22307, train_accuracy: 22.27\n",
      "[1,    12] loss: 2.22280, train_accuracy: 21.88\n",
      "[1,    13] loss: 2.20852, train_accuracy: 23.63\n",
      "[1,    14] loss: 2.12756, train_accuracy: 23.05\n",
      "[1,    15] loss: 2.12157, train_accuracy: 22.27\n",
      "[1,    16] loss: 2.08616, train_accuracy: 23.05\n",
      "[1,    17] loss: 2.03543, train_accuracy: 26.56\n",
      "[1,    18] loss: 2.10694, train_accuracy: 23.63\n",
      "[1,    19] loss: 2.14892, train_accuracy: 22.07\n",
      "[1,    20] loss: 2.06685, train_accuracy: 26.76\n",
      "[1,    21] loss: 2.14502, train_accuracy: 23.24\n",
      "[1,    22] loss: 2.08352, train_accuracy: 24.41\n",
      "[1,    23] loss: 2.07990, train_accuracy: 26.56\n",
      "[1,    24] loss: 2.11090, train_accuracy: 22.66\n",
      "[1,    25] loss: 2.14669, train_accuracy: 26.37\n",
      "[1,    26] loss: 2.06254, train_accuracy: 27.15\n",
      "[1,    27] loss: 1.99116, train_accuracy: 27.93\n",
      "[1,    28] loss: 2.02295, train_accuracy: 24.80\n",
      "[1,    29] loss: 1.99923, train_accuracy: 24.80\n",
      "[1,    30] loss: 2.02303, train_accuracy: 25.00\n",
      "[1,    31] loss: 1.97037, train_accuracy: 26.56\n",
      "[1,    32] loss: 2.02454, train_accuracy: 25.78\n",
      "[1,    33] loss: 1.99914, train_accuracy: 27.15\n",
      "[1,    34] loss: 1.96992, train_accuracy: 25.98\n",
      "[1,    35] loss: 2.02969, train_accuracy: 28.71\n",
      "[1,    36] loss: 1.94087, train_accuracy: 31.84\n",
      "[1,    37] loss: 2.01323, train_accuracy: 26.37\n",
      "[1,    38] loss: 2.00773, train_accuracy: 28.32\n",
      "[1,    39] loss: 2.02693, train_accuracy: 27.73\n",
      "[1,    40] loss: 1.98264, train_accuracy: 29.10\n",
      "[1,    41] loss: 1.96932, train_accuracy: 27.54\n",
      "[1,    42] loss: 1.92415, train_accuracy: 30.66\n",
      "[1,    43] loss: 1.96412, train_accuracy: 28.52\n",
      "[1,    44] loss: 2.05468, train_accuracy: 25.59\n",
      "[1,    45] loss: 1.98435, train_accuracy: 28.52\n",
      "[1,    46] loss: 2.02819, train_accuracy: 25.39\n",
      "[1,    47] loss: 1.95902, train_accuracy: 27.73\n",
      "[1,    48] loss: 1.92427, train_accuracy: 32.03\n",
      "[1,    49] loss: 1.97677, train_accuracy: 27.15\n",
      "[1,    50] loss: 1.97271, train_accuracy: 30.47\n",
      "[1,    51] loss: 1.89327, train_accuracy: 32.42\n",
      "[1,    52] loss: 1.92489, train_accuracy: 30.08\n",
      "[1,    53] loss: 1.93676, train_accuracy: 26.95\n",
      "[1,    54] loss: 1.99423, train_accuracy: 25.98\n",
      "[1,    55] loss: 1.85923, train_accuracy: 31.45\n",
      "[1,    56] loss: 1.93656, train_accuracy: 28.52\n",
      "[1,    57] loss: 1.97328, train_accuracy: 27.93\n",
      "[1,    58] loss: 1.93073, train_accuracy: 27.73\n",
      "[1,    59] loss: 1.89544, train_accuracy: 26.76\n",
      "[1,    60] loss: 1.95332, train_accuracy: 28.71\n",
      "[1,    61] loss: 1.93733, train_accuracy: 30.47\n",
      "[1,    62] loss: 2.02578, train_accuracy: 26.95\n",
      "[1,    63] loss: 1.89432, train_accuracy: 28.52\n",
      "[1,    64] loss: 1.94225, train_accuracy: 30.08\n",
      "[1,    65] loss: 1.98158, train_accuracy: 29.10\n",
      "[1,    66] loss: 1.93077, train_accuracy: 29.49\n",
      "[1,    67] loss: 1.94856, train_accuracy: 26.17\n",
      "[1,    68] loss: 1.91124, train_accuracy: 27.93\n",
      "[1,    69] loss: 1.92833, train_accuracy: 30.08\n",
      "[1,    70] loss: 1.95060, train_accuracy: 32.62\n",
      "[1,    71] loss: 1.96887, train_accuracy: 26.17\n",
      "[1,    72] loss: 1.91778, train_accuracy: 31.64\n",
      "[1,    73] loss: 1.96353, train_accuracy: 29.49\n",
      "[1,    74] loss: 1.97570, train_accuracy: 28.71\n",
      "[1,    75] loss: 1.94703, train_accuracy: 31.64\n",
      "[1,    76] loss: 1.93615, train_accuracy: 29.30\n",
      "[1,    77] loss: 1.92014, train_accuracy: 29.69\n",
      "[1,    78] loss: 1.88212, train_accuracy: 30.66\n",
      "[1,    79] loss: 1.89806, train_accuracy: 28.91\n",
      "[1,    80] loss: 1.95154, train_accuracy: 28.12\n",
      "[1,    81] loss: 1.88109, train_accuracy: 33.20\n",
      "[1,    82] loss: 2.05202, train_accuracy: 24.61\n",
      "[1,    83] loss: 1.86330, train_accuracy: 34.18\n",
      "[1,    84] loss: 1.86356, train_accuracy: 31.25\n",
      "[1,    85] loss: 1.87894, train_accuracy: 31.84\n",
      "[1,    86] loss: 1.92386, train_accuracy: 29.10\n",
      "[1,    87] loss: 1.88918, train_accuracy: 28.91\n",
      "[1,    88] loss: 1.95165, train_accuracy: 30.66\n",
      "[1,    89] loss: 1.87950, train_accuracy: 28.12\n",
      "[1,    90] loss: 1.80581, train_accuracy: 34.18\n",
      "[1,    91] loss: 1.92107, train_accuracy: 30.27\n",
      "[1,    92] loss: 1.92357, train_accuracy: 28.12\n",
      "[1,    93] loss: 1.98631, train_accuracy: 28.52\n",
      "[1,    94] loss: 1.87470, train_accuracy: 32.03\n",
      "[1,    95] loss: 1.87512, train_accuracy: 31.64\n",
      "[1,    96] loss: 1.89697, train_accuracy: 30.47\n",
      "[1,    97] loss: 1.87164, train_accuracy: 31.05\n",
      "[1,    98] loss: 1.89064, train_accuracy: 30.65\n",
      "duration: 314 s - train loss: 2.02396 - train accuracy: 26.91 - validation loss: 1.67351 - validation accuracy: 38.69 \n",
      "[2,     1] loss: 1.90515, train_accuracy: 29.10\n",
      "[2,     2] loss: 1.80779, train_accuracy: 30.08\n",
      "[2,     3] loss: 1.95823, train_accuracy: 29.49\n",
      "[2,     4] loss: 1.84575, train_accuracy: 32.42\n",
      "[2,     5] loss: 1.91343, train_accuracy: 28.91\n",
      "[2,     6] loss: 1.87253, train_accuracy: 29.49\n",
      "[2,     7] loss: 1.90067, train_accuracy: 30.47\n",
      "[2,     8] loss: 1.83465, train_accuracy: 33.40\n",
      "[2,     9] loss: 1.84437, train_accuracy: 29.49\n",
      "[2,    10] loss: 1.85103, train_accuracy: 32.23\n",
      "[2,    11] loss: 1.87958, train_accuracy: 32.42\n",
      "[2,    12] loss: 1.83356, train_accuracy: 32.42\n",
      "[2,    13] loss: 1.88456, train_accuracy: 32.62\n",
      "[2,    14] loss: 1.91390, train_accuracy: 30.86\n",
      "[2,    15] loss: 1.85368, train_accuracy: 33.01\n",
      "[2,    16] loss: 1.79700, train_accuracy: 33.40\n",
      "[2,    17] loss: 1.76908, train_accuracy: 35.55\n",
      "[2,    18] loss: 1.84734, train_accuracy: 32.81\n",
      "[2,    19] loss: 1.83250, train_accuracy: 32.81\n",
      "[2,    20] loss: 1.85853, train_accuracy: 34.57\n",
      "[2,    21] loss: 1.79025, train_accuracy: 35.74\n",
      "[2,    22] loss: 1.83541, train_accuracy: 31.45\n",
      "[2,    23] loss: 1.81980, train_accuracy: 34.18\n",
      "[2,    24] loss: 1.91899, train_accuracy: 28.71\n",
      "[2,    25] loss: 1.90018, train_accuracy: 31.05\n",
      "[2,    26] loss: 1.85568, train_accuracy: 31.25\n",
      "[2,    27] loss: 1.85922, train_accuracy: 32.42\n",
      "[2,    28] loss: 1.77824, train_accuracy: 36.13\n",
      "[2,    29] loss: 1.81397, train_accuracy: 32.23\n",
      "[2,    30] loss: 1.91640, train_accuracy: 33.01\n",
      "[2,    31] loss: 1.83499, train_accuracy: 33.59\n",
      "[2,    32] loss: 1.82370, train_accuracy: 32.42\n",
      "[2,    33] loss: 1.88734, train_accuracy: 29.10\n",
      "[2,    34] loss: 1.79983, train_accuracy: 31.64\n",
      "[2,    35] loss: 1.76927, train_accuracy: 35.55\n",
      "[2,    36] loss: 1.86358, train_accuracy: 31.45\n",
      "[2,    37] loss: 1.81788, train_accuracy: 33.20\n",
      "[2,    38] loss: 1.87817, train_accuracy: 30.47\n",
      "[2,    39] loss: 1.91522, train_accuracy: 33.79\n",
      "[2,    40] loss: 1.76360, train_accuracy: 35.94\n",
      "[2,    41] loss: 1.80447, train_accuracy: 32.23\n",
      "[2,    42] loss: 1.81514, train_accuracy: 33.01\n",
      "[2,    43] loss: 1.80872, train_accuracy: 34.77\n",
      "[2,    44] loss: 1.82631, train_accuracy: 34.18\n",
      "[2,    45] loss: 1.86828, train_accuracy: 32.62\n",
      "[2,    46] loss: 1.81133, train_accuracy: 34.96\n",
      "[2,    47] loss: 1.90444, train_accuracy: 31.84\n",
      "[2,    48] loss: 1.79914, train_accuracy: 33.79\n",
      "[2,    49] loss: 1.85867, train_accuracy: 29.49\n",
      "[2,    50] loss: 1.80404, train_accuracy: 33.98\n",
      "[2,    51] loss: 1.79965, train_accuracy: 34.77\n",
      "[2,    52] loss: 1.83802, train_accuracy: 29.10\n",
      "[2,    53] loss: 1.88421, train_accuracy: 28.71\n",
      "[2,    54] loss: 1.78964, train_accuracy: 34.18\n",
      "[2,    55] loss: 1.82810, train_accuracy: 32.03\n",
      "[2,    56] loss: 1.81527, train_accuracy: 37.30\n",
      "[2,    57] loss: 1.78711, train_accuracy: 34.57\n",
      "[2,    58] loss: 1.84725, train_accuracy: 33.01\n",
      "[2,    59] loss: 1.76059, train_accuracy: 34.18\n",
      "[2,    60] loss: 1.83817, train_accuracy: 32.62\n",
      "[2,    61] loss: 1.76227, train_accuracy: 35.16\n",
      "[2,    62] loss: 1.83530, train_accuracy: 34.57\n",
      "[2,    63] loss: 1.83629, train_accuracy: 33.20\n",
      "[2,    64] loss: 1.82931, train_accuracy: 31.05\n",
      "[2,    65] loss: 1.93546, train_accuracy: 30.86\n",
      "[2,    66] loss: 1.80322, train_accuracy: 35.35\n",
      "[2,    67] loss: 1.85583, train_accuracy: 32.23\n",
      "[2,    68] loss: 1.79281, train_accuracy: 32.81\n",
      "[2,    69] loss: 1.81987, train_accuracy: 33.01\n",
      "[2,    70] loss: 1.88570, train_accuracy: 32.03\n",
      "[2,    71] loss: 1.84314, train_accuracy: 33.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    72] loss: 1.76227, train_accuracy: 38.09\n",
      "[2,    73] loss: 1.86249, train_accuracy: 30.86\n",
      "[2,    74] loss: 1.81873, train_accuracy: 32.62\n",
      "[2,    75] loss: 1.85440, train_accuracy: 33.98\n",
      "[2,    76] loss: 1.83829, train_accuracy: 30.66\n",
      "[2,    77] loss: 1.81324, train_accuracy: 34.18\n",
      "[2,    78] loss: 1.81008, train_accuracy: 31.64\n",
      "[2,    79] loss: 1.84453, train_accuracy: 33.59\n",
      "[2,    80] loss: 1.80842, train_accuracy: 33.20\n",
      "[2,    81] loss: 1.85633, train_accuracy: 33.59\n",
      "[2,    82] loss: 1.81781, train_accuracy: 31.25\n",
      "[2,    83] loss: 1.81516, train_accuracy: 36.52\n",
      "[2,    84] loss: 1.78259, train_accuracy: 39.06\n",
      "[2,    85] loss: 1.76345, train_accuracy: 34.38\n",
      "[2,    86] loss: 1.74368, train_accuracy: 35.55\n",
      "[2,    87] loss: 1.81582, train_accuracy: 33.98\n",
      "[2,    88] loss: 1.70904, train_accuracy: 37.11\n",
      "[2,    89] loss: 1.81688, train_accuracy: 33.20\n",
      "[2,    90] loss: 1.83271, train_accuracy: 33.20\n",
      "[2,    91] loss: 1.73621, train_accuracy: 37.11\n",
      "[2,    92] loss: 1.87143, train_accuracy: 30.86\n",
      "[2,    93] loss: 1.81633, train_accuracy: 34.96\n",
      "[2,    94] loss: 1.74789, train_accuracy: 35.35\n",
      "[2,    95] loss: 1.81061, train_accuracy: 35.16\n",
      "[2,    96] loss: 1.76466, train_accuracy: 36.52\n",
      "[2,    97] loss: 1.81418, train_accuracy: 34.57\n",
      "[2,    98] loss: 1.75810, train_accuracy: 34.82\n",
      "duration: 268 s - train loss: 1.83080 - train accuracy: 33.06 - validation loss: 1.55681 - validation accuracy: 43.39 \n",
      "[3,     1] loss: 1.88543, train_accuracy: 34.18\n",
      "[3,     2] loss: 1.84031, train_accuracy: 33.20\n",
      "[3,     3] loss: 1.79706, train_accuracy: 33.98\n",
      "[3,     4] loss: 1.77658, train_accuracy: 34.96\n",
      "[3,     5] loss: 1.79855, train_accuracy: 38.09\n",
      "[3,     6] loss: 1.81528, train_accuracy: 35.35\n",
      "[3,     7] loss: 1.78250, train_accuracy: 34.38\n",
      "[3,     8] loss: 1.82732, train_accuracy: 29.88\n",
      "[3,     9] loss: 1.74805, train_accuracy: 34.77\n",
      "[3,    10] loss: 1.76868, train_accuracy: 37.30\n",
      "[3,    11] loss: 1.78528, train_accuracy: 31.84\n",
      "[3,    12] loss: 1.79215, train_accuracy: 35.16\n",
      "[3,    13] loss: 1.74283, train_accuracy: 33.40\n",
      "[3,    14] loss: 1.87572, train_accuracy: 29.10\n",
      "[3,    15] loss: 1.78370, train_accuracy: 35.35\n",
      "[3,    16] loss: 1.70836, train_accuracy: 36.33\n",
      "[3,    17] loss: 1.77990, train_accuracy: 34.18\n",
      "[3,    18] loss: 1.77397, train_accuracy: 34.57\n",
      "[3,    19] loss: 1.72976, train_accuracy: 39.84\n",
      "[3,    20] loss: 1.74060, train_accuracy: 34.57\n",
      "[3,    21] loss: 1.77296, train_accuracy: 39.06\n",
      "[3,    22] loss: 1.76871, train_accuracy: 38.28\n",
      "[3,    23] loss: 1.80122, train_accuracy: 36.72\n",
      "[3,    24] loss: 1.72287, train_accuracy: 37.11\n",
      "[3,    25] loss: 1.81119, train_accuracy: 35.94\n",
      "[3,    26] loss: 1.70511, train_accuracy: 38.09\n",
      "[3,    27] loss: 1.74511, train_accuracy: 36.13\n",
      "[3,    28] loss: 1.75254, train_accuracy: 32.42\n",
      "[3,    29] loss: 1.84691, train_accuracy: 32.03\n",
      "[3,    30] loss: 1.71831, train_accuracy: 35.16\n",
      "[3,    31] loss: 1.71436, train_accuracy: 37.11\n",
      "[3,    32] loss: 1.73031, train_accuracy: 36.91\n",
      "[3,    33] loss: 1.73270, train_accuracy: 38.48\n",
      "[3,    34] loss: 1.76693, train_accuracy: 35.16\n",
      "[3,    35] loss: 1.73574, train_accuracy: 36.72\n",
      "[3,    36] loss: 1.74401, train_accuracy: 35.16\n",
      "[3,    37] loss: 1.71259, train_accuracy: 35.74\n",
      "[3,    38] loss: 1.74035, train_accuracy: 41.21\n",
      "[3,    39] loss: 1.85106, train_accuracy: 31.45\n",
      "[3,    40] loss: 1.72405, train_accuracy: 38.48\n",
      "[3,    41] loss: 1.73922, train_accuracy: 37.70\n",
      "[3,    42] loss: 1.70379, train_accuracy: 36.33\n",
      "[3,    43] loss: 1.69969, train_accuracy: 37.70\n",
      "[3,    44] loss: 1.77510, train_accuracy: 34.77\n",
      "[3,    45] loss: 1.70970, train_accuracy: 38.67\n",
      "[3,    46] loss: 1.78897, train_accuracy: 35.94\n",
      "[3,    47] loss: 1.76900, train_accuracy: 35.74\n",
      "[3,    48] loss: 1.65454, train_accuracy: 40.62\n",
      "[3,    49] loss: 1.74527, train_accuracy: 41.02\n",
      "[3,    50] loss: 1.77016, train_accuracy: 34.38\n",
      "[3,    51] loss: 1.77781, train_accuracy: 34.77\n",
      "[3,    52] loss: 1.73309, train_accuracy: 40.43\n",
      "[3,    53] loss: 1.70396, train_accuracy: 37.70\n",
      "[3,    54] loss: 1.74256, train_accuracy: 36.72\n",
      "[3,    55] loss: 1.69790, train_accuracy: 36.52\n",
      "[3,    56] loss: 1.77322, train_accuracy: 35.16\n",
      "[3,    57] loss: 1.75645, train_accuracy: 38.28\n",
      "[3,    58] loss: 1.78763, train_accuracy: 34.57\n",
      "[3,    59] loss: 1.72563, train_accuracy: 39.65\n",
      "[3,    60] loss: 1.79782, train_accuracy: 30.86\n",
      "[3,    61] loss: 1.80069, train_accuracy: 35.94\n",
      "[3,    62] loss: 1.77442, train_accuracy: 35.74\n",
      "[3,    63] loss: 1.74630, train_accuracy: 36.13\n",
      "[3,    64] loss: 1.73092, train_accuracy: 39.06\n",
      "[3,    65] loss: 1.68389, train_accuracy: 37.50\n",
      "[3,    66] loss: 1.81793, train_accuracy: 36.13\n",
      "[3,    67] loss: 1.75581, train_accuracy: 34.96\n",
      "[3,    68] loss: 1.72678, train_accuracy: 37.89\n",
      "[3,    69] loss: 1.70528, train_accuracy: 37.50\n",
      "[3,    70] loss: 1.78071, train_accuracy: 34.77\n",
      "[3,    71] loss: 1.76956, train_accuracy: 35.35\n",
      "[3,    72] loss: 1.68376, train_accuracy: 36.52\n",
      "[3,    73] loss: 1.66722, train_accuracy: 36.52\n",
      "[3,    74] loss: 1.81757, train_accuracy: 32.81\n",
      "[3,    75] loss: 1.76322, train_accuracy: 35.74\n",
      "[3,    76] loss: 1.70487, train_accuracy: 41.21\n",
      "[3,    77] loss: 1.75132, train_accuracy: 34.77\n",
      "[3,    78] loss: 1.75101, train_accuracy: 37.30\n",
      "[3,    79] loss: 1.85053, train_accuracy: 30.27\n",
      "[3,    80] loss: 1.81644, train_accuracy: 33.40\n",
      "[3,    81] loss: 1.86165, train_accuracy: 33.79\n",
      "[3,    82] loss: 1.68935, train_accuracy: 37.50\n",
      "[3,    83] loss: 1.69772, train_accuracy: 39.45\n",
      "[3,    84] loss: 1.70763, train_accuracy: 39.65\n",
      "[3,    85] loss: 1.70684, train_accuracy: 38.48\n",
      "[3,    86] loss: 1.69574, train_accuracy: 39.26\n",
      "[3,    87] loss: 1.66098, train_accuracy: 40.04\n",
      "[3,    88] loss: 1.76211, train_accuracy: 33.01\n",
      "[3,    89] loss: 1.74699, train_accuracy: 37.70\n",
      "[3,    90] loss: 1.77251, train_accuracy: 35.35\n",
      "[3,    91] loss: 1.70039, train_accuracy: 40.62\n",
      "[3,    92] loss: 1.77434, train_accuracy: 30.47\n",
      "[3,    93] loss: 1.66751, train_accuracy: 39.65\n",
      "[3,    94] loss: 1.84485, train_accuracy: 32.42\n",
      "[3,    95] loss: 1.78275, train_accuracy: 37.11\n",
      "[3,    96] loss: 1.77489, train_accuracy: 34.57\n",
      "[3,    97] loss: 1.67335, train_accuracy: 38.09\n",
      "[3,    98] loss: 1.68414, train_accuracy: 41.07\n",
      "duration: 280 s - train loss: 1.75513 - train accuracy: 36.15 - validation loss: 1.45721 - validation accuracy: 47.54 \n",
      "[4,     1] loss: 1.75656, train_accuracy: 36.91\n",
      "[4,     2] loss: 1.68589, train_accuracy: 38.87\n",
      "[4,     3] loss: 1.65483, train_accuracy: 40.82\n",
      "[4,     4] loss: 1.69975, train_accuracy: 37.89\n",
      "[4,     5] loss: 1.69439, train_accuracy: 40.82\n",
      "[4,     6] loss: 1.70955, train_accuracy: 38.09\n",
      "[4,     7] loss: 1.70893, train_accuracy: 35.55\n",
      "[4,     8] loss: 1.75698, train_accuracy: 37.30\n",
      "[4,     9] loss: 1.78073, train_accuracy: 33.40\n",
      "[4,    10] loss: 1.73142, train_accuracy: 36.33\n",
      "[4,    11] loss: 1.66276, train_accuracy: 40.04\n",
      "[4,    12] loss: 1.74977, train_accuracy: 39.06\n",
      "[4,    13] loss: 1.71352, train_accuracy: 35.74\n",
      "[4,    14] loss: 1.80670, train_accuracy: 36.33\n",
      "[4,    15] loss: 1.72782, train_accuracy: 37.11\n",
      "[4,    16] loss: 1.77021, train_accuracy: 33.40\n",
      "[4,    17] loss: 1.63707, train_accuracy: 40.62\n",
      "[4,    18] loss: 1.77746, train_accuracy: 34.96\n",
      "[4,    19] loss: 1.70851, train_accuracy: 39.45\n",
      "[4,    20] loss: 1.65728, train_accuracy: 40.04\n",
      "[4,    21] loss: 1.67198, train_accuracy: 38.87\n",
      "[4,    22] loss: 1.83304, train_accuracy: 32.81\n",
      "[4,    23] loss: 1.74026, train_accuracy: 37.11\n",
      "[4,    24] loss: 1.74151, train_accuracy: 36.52\n",
      "[4,    25] loss: 1.72713, train_accuracy: 41.80\n",
      "[4,    26] loss: 1.74357, train_accuracy: 34.77\n",
      "[4,    27] loss: 1.82344, train_accuracy: 33.01\n",
      "[4,    28] loss: 1.75866, train_accuracy: 39.84\n",
      "[4,    29] loss: 1.74490, train_accuracy: 35.55\n",
      "[4,    30] loss: 1.68635, train_accuracy: 41.41\n",
      "[4,    31] loss: 1.74469, train_accuracy: 36.91\n",
      "[4,    32] loss: 1.67793, train_accuracy: 39.26\n",
      "[4,    33] loss: 1.76004, train_accuracy: 34.57\n",
      "[4,    34] loss: 1.74432, train_accuracy: 37.89\n",
      "[4,    35] loss: 1.70937, train_accuracy: 37.70\n",
      "[4,    36] loss: 1.67715, train_accuracy: 42.19\n",
      "[4,    37] loss: 1.67163, train_accuracy: 39.84\n",
      "[4,    38] loss: 1.73835, train_accuracy: 39.06\n",
      "[4,    39] loss: 1.74077, train_accuracy: 38.09\n",
      "[4,    40] loss: 1.71723, train_accuracy: 33.98\n",
      "[4,    41] loss: 1.72026, train_accuracy: 38.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,    42] loss: 1.73618, train_accuracy: 39.26\n",
      "[4,    43] loss: 1.76022, train_accuracy: 35.55\n",
      "[4,    44] loss: 1.68306, train_accuracy: 38.87\n",
      "[4,    45] loss: 1.71588, train_accuracy: 36.91\n",
      "[4,    46] loss: 1.74166, train_accuracy: 36.33\n",
      "[4,    47] loss: 1.71446, train_accuracy: 36.72\n",
      "[4,    48] loss: 1.74213, train_accuracy: 38.87\n",
      "[4,    49] loss: 1.69143, train_accuracy: 36.52\n",
      "[4,    50] loss: 1.68440, train_accuracy: 38.48\n",
      "[4,    51] loss: 1.69154, train_accuracy: 35.94\n",
      "[4,    52] loss: 1.69785, train_accuracy: 38.09\n",
      "[4,    53] loss: 1.74708, train_accuracy: 39.06\n",
      "[4,    54] loss: 1.75130, train_accuracy: 36.91\n",
      "[4,    55] loss: 1.66772, train_accuracy: 40.43\n",
      "[4,    56] loss: 1.66232, train_accuracy: 38.28\n",
      "[4,    57] loss: 1.68866, train_accuracy: 38.87\n",
      "[4,    58] loss: 1.69049, train_accuracy: 38.48\n",
      "[4,    59] loss: 1.68906, train_accuracy: 41.02\n",
      "[4,    60] loss: 1.67436, train_accuracy: 39.65\n",
      "[4,    61] loss: 1.73356, train_accuracy: 39.26\n",
      "[4,    62] loss: 1.69483, train_accuracy: 37.30\n",
      "[4,    63] loss: 1.75813, train_accuracy: 35.94\n",
      "[4,    64] loss: 1.68905, train_accuracy: 41.02\n",
      "[4,    65] loss: 1.72749, train_accuracy: 37.70\n",
      "[4,    66] loss: 1.66144, train_accuracy: 40.82\n",
      "[4,    67] loss: 1.78507, train_accuracy: 36.52\n",
      "[4,    68] loss: 1.66791, train_accuracy: 39.65\n",
      "[4,    69] loss: 1.66117, train_accuracy: 38.09\n",
      "[4,    70] loss: 1.73634, train_accuracy: 37.11\n",
      "[4,    71] loss: 1.64227, train_accuracy: 40.43\n",
      "[4,    72] loss: 1.76118, train_accuracy: 37.11\n",
      "[4,    73] loss: 1.65591, train_accuracy: 40.62\n",
      "[4,    74] loss: 1.73653, train_accuracy: 39.06\n",
      "[4,    75] loss: 1.66420, train_accuracy: 40.23\n",
      "[4,    76] loss: 1.69461, train_accuracy: 38.67\n",
      "[4,    77] loss: 1.67738, train_accuracy: 38.09\n",
      "[4,    78] loss: 1.65547, train_accuracy: 41.80\n",
      "[4,    79] loss: 1.73685, train_accuracy: 33.59\n",
      "[4,    80] loss: 1.62799, train_accuracy: 41.21\n",
      "[4,    81] loss: 1.67431, train_accuracy: 39.26\n",
      "[4,    82] loss: 1.71135, train_accuracy: 37.70\n",
      "[4,    83] loss: 1.68722, train_accuracy: 38.09\n",
      "[4,    84] loss: 1.66376, train_accuracy: 39.06\n",
      "[4,    85] loss: 1.70090, train_accuracy: 40.23\n",
      "[4,    86] loss: 1.73450, train_accuracy: 37.70\n",
      "[4,    87] loss: 1.58584, train_accuracy: 41.02\n",
      "[4,    88] loss: 1.72515, train_accuracy: 36.72\n",
      "[4,    89] loss: 1.69870, train_accuracy: 37.11\n",
      "[4,    90] loss: 1.64350, train_accuracy: 41.41\n",
      "[4,    91] loss: 1.74711, train_accuracy: 39.84\n",
      "[4,    92] loss: 1.69523, train_accuracy: 39.26\n",
      "[4,    93] loss: 1.68570, train_accuracy: 39.65\n",
      "[4,    94] loss: 1.70036, train_accuracy: 36.33\n",
      "[4,    95] loss: 1.74762, train_accuracy: 37.11\n",
      "[4,    96] loss: 1.72788, train_accuracy: 35.94\n",
      "[4,    97] loss: 1.69246, train_accuracy: 36.72\n",
      "[4,    98] loss: 1.68049, train_accuracy: 38.39\n",
      "duration: 286 s - train loss: 1.71084 - train accuracy: 38.08 - validation loss: 1.41144 - validation accuracy: 49.92 \n",
      "[5,     1] loss: 1.60904, train_accuracy: 40.23\n",
      "[5,     2] loss: 1.75656, train_accuracy: 37.11\n",
      "[5,     3] loss: 1.63109, train_accuracy: 39.65\n",
      "[5,     4] loss: 1.72421, train_accuracy: 36.52\n",
      "[5,     5] loss: 1.67024, train_accuracy: 39.26\n",
      "[5,     6] loss: 1.66590, train_accuracy: 36.13\n",
      "[5,     7] loss: 1.73323, train_accuracy: 36.52\n",
      "[5,     8] loss: 1.67267, train_accuracy: 40.04\n",
      "[5,     9] loss: 1.68628, train_accuracy: 37.70\n",
      "[5,    10] loss: 1.61631, train_accuracy: 40.62\n",
      "[5,    11] loss: 1.74795, train_accuracy: 37.11\n",
      "[5,    12] loss: 1.67782, train_accuracy: 37.30\n",
      "[5,    13] loss: 1.64625, train_accuracy: 39.26\n",
      "[5,    14] loss: 1.60065, train_accuracy: 42.77\n",
      "[5,    15] loss: 1.60570, train_accuracy: 38.87\n",
      "[5,    16] loss: 1.60077, train_accuracy: 40.04\n",
      "[5,    17] loss: 1.68729, train_accuracy: 37.89\n",
      "[5,    18] loss: 1.60011, train_accuracy: 41.80\n",
      "[5,    19] loss: 1.65655, train_accuracy: 38.87\n",
      "[5,    20] loss: 1.75853, train_accuracy: 38.87\n",
      "[5,    21] loss: 1.69490, train_accuracy: 38.09\n",
      "[5,    22] loss: 1.70367, train_accuracy: 37.70\n",
      "[5,    23] loss: 1.55708, train_accuracy: 43.16\n",
      "[5,    24] loss: 1.61159, train_accuracy: 42.38\n",
      "[5,    25] loss: 1.62228, train_accuracy: 40.23\n",
      "[5,    26] loss: 1.62403, train_accuracy: 38.87\n",
      "[5,    27] loss: 1.61042, train_accuracy: 44.92\n",
      "[5,    28] loss: 1.65530, train_accuracy: 39.45\n",
      "[5,    29] loss: 1.73555, train_accuracy: 36.72\n",
      "[5,    30] loss: 1.67764, train_accuracy: 37.70\n",
      "[5,    31] loss: 1.63852, train_accuracy: 41.02\n",
      "[5,    32] loss: 1.64755, train_accuracy: 41.21\n",
      "[5,    33] loss: 1.67853, train_accuracy: 38.28\n",
      "[5,    34] loss: 1.67286, train_accuracy: 38.09\n",
      "[5,    35] loss: 1.65099, train_accuracy: 43.95\n",
      "[5,    36] loss: 1.68454, train_accuracy: 41.60\n",
      "[5,    37] loss: 1.70797, train_accuracy: 39.06\n",
      "[5,    38] loss: 1.63854, train_accuracy: 40.23\n",
      "[5,    39] loss: 1.60531, train_accuracy: 40.43\n",
      "[5,    40] loss: 1.66402, train_accuracy: 40.04\n",
      "[5,    41] loss: 1.66858, train_accuracy: 40.82\n",
      "[5,    42] loss: 1.66621, train_accuracy: 42.19\n",
      "[5,    43] loss: 1.65070, train_accuracy: 37.89\n",
      "[5,    44] loss: 1.63760, train_accuracy: 44.73\n",
      "[5,    45] loss: 1.68194, train_accuracy: 39.26\n",
      "[5,    46] loss: 1.68141, train_accuracy: 39.65\n",
      "[5,    47] loss: 1.70969, train_accuracy: 37.11\n",
      "[5,    48] loss: 1.59913, train_accuracy: 41.99\n",
      "[5,    49] loss: 1.70022, train_accuracy: 40.82\n",
      "[5,    50] loss: 1.76473, train_accuracy: 35.35\n",
      "[5,    51] loss: 1.66814, train_accuracy: 38.67\n",
      "[5,    52] loss: 1.64824, train_accuracy: 39.06\n",
      "[5,    53] loss: 1.65123, train_accuracy: 42.97\n",
      "[5,    54] loss: 1.64595, train_accuracy: 41.60\n",
      "[5,    55] loss: 1.62156, train_accuracy: 42.19\n",
      "[5,    56] loss: 1.62904, train_accuracy: 42.77\n",
      "[5,    57] loss: 1.61417, train_accuracy: 44.14\n",
      "[5,    58] loss: 1.65022, train_accuracy: 38.67\n",
      "[5,    59] loss: 1.63777, train_accuracy: 38.87\n",
      "[5,    60] loss: 1.70597, train_accuracy: 39.45\n",
      "[5,    61] loss: 1.72269, train_accuracy: 38.87\n",
      "[5,    62] loss: 1.56199, train_accuracy: 44.34\n",
      "[5,    63] loss: 1.65949, train_accuracy: 36.91\n",
      "[5,    64] loss: 1.68175, train_accuracy: 39.84\n",
      "[5,    65] loss: 1.65660, train_accuracy: 39.06\n",
      "[5,    66] loss: 1.71745, train_accuracy: 36.33\n",
      "[5,    67] loss: 1.64085, train_accuracy: 44.53\n",
      "[5,    68] loss: 1.69535, train_accuracy: 37.50\n",
      "[5,    69] loss: 1.62046, train_accuracy: 38.87\n",
      "[5,    70] loss: 1.63751, train_accuracy: 40.23\n",
      "[5,    71] loss: 1.64784, train_accuracy: 40.43\n",
      "[5,    72] loss: 1.66981, train_accuracy: 38.09\n",
      "[5,    73] loss: 1.67986, train_accuracy: 38.09\n",
      "[5,    74] loss: 1.66784, train_accuracy: 36.72\n",
      "[5,    75] loss: 1.71624, train_accuracy: 37.70\n",
      "[5,    76] loss: 1.60996, train_accuracy: 41.41\n",
      "[5,    77] loss: 1.64669, train_accuracy: 38.87\n",
      "[5,    78] loss: 1.60578, train_accuracy: 41.41\n",
      "[5,    79] loss: 1.73607, train_accuracy: 37.30\n",
      "[5,    80] loss: 1.71105, train_accuracy: 40.43\n",
      "[5,    81] loss: 1.62864, train_accuracy: 40.82\n",
      "[5,    82] loss: 1.68057, train_accuracy: 39.06\n",
      "[5,    83] loss: 1.65626, train_accuracy: 41.41\n",
      "[5,    84] loss: 1.62362, train_accuracy: 42.77\n",
      "[5,    85] loss: 1.63222, train_accuracy: 41.41\n",
      "[5,    86] loss: 1.60512, train_accuracy: 45.12\n",
      "[5,    87] loss: 1.69088, train_accuracy: 38.09\n",
      "[5,    88] loss: 1.57082, train_accuracy: 45.12\n",
      "[5,    89] loss: 1.68686, train_accuracy: 40.43\n",
      "[5,    90] loss: 1.61594, train_accuracy: 39.45\n",
      "[5,    91] loss: 1.60997, train_accuracy: 42.58\n",
      "[5,    92] loss: 1.72940, train_accuracy: 33.59\n",
      "[5,    93] loss: 1.66760, train_accuracy: 40.82\n",
      "[5,    94] loss: 1.60250, train_accuracy: 41.21\n",
      "[5,    95] loss: 1.68628, train_accuracy: 39.26\n",
      "[5,    96] loss: 1.66649, train_accuracy: 40.82\n",
      "[5,    97] loss: 1.58744, train_accuracy: 41.60\n",
      "[5,    98] loss: 1.63969, train_accuracy: 41.67\n",
      "duration: 288 s - train loss: 1.65843 - train accuracy: 39.90 - validation loss: 1.37342 - validation accuracy: 51.03 \n",
      "[6,     1] loss: 1.64602, train_accuracy: 42.77\n",
      "[6,     2] loss: 1.66030, train_accuracy: 39.65\n",
      "[6,     3] loss: 1.67656, train_accuracy: 39.45\n",
      "[6,     4] loss: 1.68774, train_accuracy: 39.45\n",
      "[6,     5] loss: 1.61921, train_accuracy: 41.80\n",
      "[6,     6] loss: 1.62441, train_accuracy: 41.80\n",
      "[6,     7] loss: 1.61983, train_accuracy: 42.77\n",
      "[6,     8] loss: 1.65916, train_accuracy: 42.19\n",
      "[6,     9] loss: 1.64216, train_accuracy: 36.72\n",
      "[6,    10] loss: 1.58926, train_accuracy: 42.77\n",
      "[6,    11] loss: 1.66263, train_accuracy: 40.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    12] loss: 1.58701, train_accuracy: 44.14\n",
      "[6,    13] loss: 1.61550, train_accuracy: 41.02\n",
      "[6,    14] loss: 1.64899, train_accuracy: 43.55\n",
      "[6,    15] loss: 1.63424, train_accuracy: 39.84\n",
      "[6,    16] loss: 1.58944, train_accuracy: 44.14\n",
      "[6,    17] loss: 1.63284, train_accuracy: 42.58\n",
      "[6,    18] loss: 1.68672, train_accuracy: 39.26\n",
      "[6,    19] loss: 1.70584, train_accuracy: 37.11\n",
      "[6,    20] loss: 1.59851, train_accuracy: 42.97\n",
      "[6,    21] loss: 1.62118, train_accuracy: 40.23\n",
      "[6,    22] loss: 1.69037, train_accuracy: 36.91\n",
      "[6,    23] loss: 1.60955, train_accuracy: 41.41\n",
      "[6,    24] loss: 1.64143, train_accuracy: 41.02\n",
      "[6,    25] loss: 1.69225, train_accuracy: 39.26\n",
      "[6,    26] loss: 1.63175, train_accuracy: 40.43\n",
      "[6,    27] loss: 1.68015, train_accuracy: 40.43\n",
      "[6,    28] loss: 1.58959, train_accuracy: 41.41\n",
      "[6,    29] loss: 1.64923, train_accuracy: 42.38\n",
      "[6,    30] loss: 1.58470, train_accuracy: 44.14\n",
      "[6,    31] loss: 1.66978, train_accuracy: 39.45\n",
      "[6,    32] loss: 1.58536, train_accuracy: 41.99\n",
      "[6,    33] loss: 1.58564, train_accuracy: 39.84\n",
      "[6,    34] loss: 1.61781, train_accuracy: 41.41\n",
      "[6,    35] loss: 1.56350, train_accuracy: 43.36\n",
      "[6,    36] loss: 1.67114, train_accuracy: 40.43\n",
      "[6,    37] loss: 1.56877, train_accuracy: 42.58\n",
      "[6,    38] loss: 1.49962, train_accuracy: 44.14\n",
      "[6,    39] loss: 1.62555, train_accuracy: 41.02\n",
      "[6,    40] loss: 1.62525, train_accuracy: 41.02\n",
      "[6,    41] loss: 1.68691, train_accuracy: 36.72\n",
      "[6,    42] loss: 1.66159, train_accuracy: 40.62\n",
      "[6,    43] loss: 1.67479, train_accuracy: 40.04\n",
      "[6,    44] loss: 1.65452, train_accuracy: 39.45\n",
      "[6,    45] loss: 1.70491, train_accuracy: 41.80\n",
      "[6,    46] loss: 1.60873, train_accuracy: 42.97\n",
      "[6,    47] loss: 1.69337, train_accuracy: 40.23\n",
      "[6,    48] loss: 1.56957, train_accuracy: 41.80\n",
      "[6,    49] loss: 1.60835, train_accuracy: 39.45\n",
      "[6,    50] loss: 1.60389, train_accuracy: 41.02\n",
      "[6,    51] loss: 1.57692, train_accuracy: 42.58\n",
      "[6,    52] loss: 1.55660, train_accuracy: 46.09\n",
      "[6,    53] loss: 1.64579, train_accuracy: 43.16\n",
      "[6,    54] loss: 1.74124, train_accuracy: 39.65\n",
      "[6,    55] loss: 1.65044, train_accuracy: 40.23\n",
      "[6,    56] loss: 1.59018, train_accuracy: 43.36\n",
      "[6,    57] loss: 1.58923, train_accuracy: 39.45\n",
      "[6,    58] loss: 1.67710, train_accuracy: 37.11\n",
      "[6,    59] loss: 1.62009, train_accuracy: 40.43\n",
      "[6,    60] loss: 1.46341, train_accuracy: 46.09\n",
      "[6,    61] loss: 1.61156, train_accuracy: 41.80\n",
      "[6,    62] loss: 1.61705, train_accuracy: 41.60\n",
      "[6,    63] loss: 1.59088, train_accuracy: 40.43\n",
      "[6,    64] loss: 1.71112, train_accuracy: 38.48\n",
      "[6,    65] loss: 1.65671, train_accuracy: 39.45\n",
      "[6,    66] loss: 1.63369, train_accuracy: 41.02\n",
      "[6,    67] loss: 1.66076, train_accuracy: 38.28\n",
      "[6,    68] loss: 1.57326, train_accuracy: 43.36\n",
      "[6,    69] loss: 1.62816, train_accuracy: 42.19\n",
      "[6,    70] loss: 1.61896, train_accuracy: 43.75\n",
      "[6,    71] loss: 1.64732, train_accuracy: 38.87\n",
      "[6,    72] loss: 1.68713, train_accuracy: 40.82\n",
      "[6,    73] loss: 1.51622, train_accuracy: 44.53\n",
      "[6,    74] loss: 1.68209, train_accuracy: 38.67\n",
      "[6,    75] loss: 1.64400, train_accuracy: 38.09\n",
      "[6,    76] loss: 1.54321, train_accuracy: 43.55\n",
      "[6,    77] loss: 1.58164, train_accuracy: 42.77\n",
      "[6,    78] loss: 1.59579, train_accuracy: 39.45\n",
      "[6,    79] loss: 1.62446, train_accuracy: 40.62\n",
      "[6,    80] loss: 1.59981, train_accuracy: 42.38\n",
      "[6,    81] loss: 1.59662, train_accuracy: 41.02\n",
      "[6,    82] loss: 1.61845, train_accuracy: 41.21\n",
      "[6,    83] loss: 1.60511, train_accuracy: 43.95\n",
      "[6,    84] loss: 1.56607, train_accuracy: 41.21\n",
      "[6,    85] loss: 1.61525, train_accuracy: 43.55\n",
      "[6,    86] loss: 1.65343, train_accuracy: 40.04\n",
      "[6,    87] loss: 1.56288, train_accuracy: 41.21\n",
      "[6,    88] loss: 1.57564, train_accuracy: 42.58\n",
      "[6,    89] loss: 1.68615, train_accuracy: 38.48\n",
      "[6,    90] loss: 1.58369, train_accuracy: 44.53\n",
      "[6,    91] loss: 1.69171, train_accuracy: 35.35\n",
      "[6,    92] loss: 1.59871, train_accuracy: 40.62\n",
      "[6,    93] loss: 1.59398, train_accuracy: 42.77\n",
      "[6,    94] loss: 1.61105, train_accuracy: 41.02\n",
      "[6,    95] loss: 1.55857, train_accuracy: 45.31\n",
      "[6,    96] loss: 1.59275, train_accuracy: 41.99\n",
      "[6,    97] loss: 1.62388, train_accuracy: 39.84\n",
      "[6,    98] loss: 1.70386, train_accuracy: 36.90\n",
      "duration: 323 s - train loss: 1.62478 - train accuracy: 41.13 - validation loss: 1.34106 - validation accuracy: 52.26 \n",
      "[7,     1] loss: 1.54845, train_accuracy: 44.92\n",
      "[7,     2] loss: 1.58730, train_accuracy: 41.80\n",
      "[7,     3] loss: 1.59843, train_accuracy: 42.58\n",
      "[7,     4] loss: 1.53430, train_accuracy: 44.34\n",
      "[7,     5] loss: 1.63698, train_accuracy: 39.65\n",
      "[7,     6] loss: 1.65531, train_accuracy: 40.82\n",
      "[7,     7] loss: 1.71816, train_accuracy: 36.72\n",
      "[7,     8] loss: 1.61046, train_accuracy: 43.36\n",
      "[7,     9] loss: 1.57517, train_accuracy: 43.75\n",
      "[7,    10] loss: 1.62118, train_accuracy: 42.19\n",
      "[7,    11] loss: 1.63111, train_accuracy: 38.87\n",
      "[7,    12] loss: 1.56928, train_accuracy: 43.55\n",
      "[7,    13] loss: 1.59383, train_accuracy: 43.36\n",
      "[7,    14] loss: 1.58776, train_accuracy: 42.77\n",
      "[7,    15] loss: 1.56422, train_accuracy: 43.75\n",
      "[7,    16] loss: 1.61268, train_accuracy: 41.80\n",
      "[7,    17] loss: 1.63195, train_accuracy: 41.41\n",
      "[7,    18] loss: 1.59737, train_accuracy: 45.90\n",
      "[7,    19] loss: 1.62708, train_accuracy: 41.41\n",
      "[7,    20] loss: 1.57449, train_accuracy: 44.14\n",
      "[7,    21] loss: 1.55344, train_accuracy: 44.92\n",
      "[7,    22] loss: 1.56765, train_accuracy: 43.55\n",
      "[7,    23] loss: 1.65895, train_accuracy: 40.23\n",
      "[7,    24] loss: 1.61032, train_accuracy: 42.19\n",
      "[7,    25] loss: 1.55078, train_accuracy: 44.92\n",
      "[7,    26] loss: 1.64118, train_accuracy: 40.23\n",
      "[7,    27] loss: 1.66674, train_accuracy: 40.43\n",
      "[7,    28] loss: 1.67949, train_accuracy: 38.28\n",
      "[7,    29] loss: 1.66563, train_accuracy: 40.04\n",
      "[7,    30] loss: 1.59490, train_accuracy: 45.31\n",
      "[7,    31] loss: 1.64906, train_accuracy: 41.41\n",
      "[7,    32] loss: 1.62696, train_accuracy: 41.80\n",
      "[7,    33] loss: 1.58054, train_accuracy: 44.73\n",
      "[7,    34] loss: 1.61928, train_accuracy: 43.16\n",
      "[7,    35] loss: 1.58075, train_accuracy: 44.53\n",
      "[7,    36] loss: 1.55810, train_accuracy: 41.41\n",
      "[7,    37] loss: 1.51874, train_accuracy: 46.29\n",
      "[7,    38] loss: 1.55338, train_accuracy: 44.34\n",
      "[7,    39] loss: 1.62581, train_accuracy: 40.23\n",
      "[7,    40] loss: 1.63856, train_accuracy: 40.62\n",
      "[7,    41] loss: 1.50187, train_accuracy: 49.41\n",
      "[7,    42] loss: 1.66104, train_accuracy: 42.58\n",
      "[7,    43] loss: 1.66338, train_accuracy: 38.67\n",
      "[7,    44] loss: 1.60108, train_accuracy: 41.21\n",
      "[7,    45] loss: 1.65874, train_accuracy: 41.21\n",
      "[7,    46] loss: 1.59245, train_accuracy: 41.99\n",
      "[7,    47] loss: 1.66514, train_accuracy: 41.99\n",
      "[7,    48] loss: 1.56242, train_accuracy: 43.36\n",
      "[7,    49] loss: 1.56482, train_accuracy: 42.77\n",
      "[7,    50] loss: 1.57622, train_accuracy: 43.16\n",
      "[7,    51] loss: 1.51831, train_accuracy: 43.16\n",
      "[7,    52] loss: 1.62432, train_accuracy: 43.16\n",
      "[7,    53] loss: 1.58372, train_accuracy: 40.82\n",
      "[7,    54] loss: 1.57226, train_accuracy: 43.16\n",
      "[7,    55] loss: 1.48166, train_accuracy: 46.48\n",
      "[7,    56] loss: 1.61329, train_accuracy: 42.77\n",
      "[7,    57] loss: 1.62196, train_accuracy: 41.99\n",
      "[7,    58] loss: 1.56251, train_accuracy: 43.55\n",
      "[7,    59] loss: 1.62443, train_accuracy: 44.14\n",
      "[7,    60] loss: 1.51843, train_accuracy: 45.70\n",
      "[7,    61] loss: 1.52997, train_accuracy: 46.88\n",
      "[7,    62] loss: 1.53585, train_accuracy: 40.62\n",
      "[7,    63] loss: 1.68822, train_accuracy: 40.43\n",
      "[7,    64] loss: 1.59378, train_accuracy: 43.16\n",
      "[7,    65] loss: 1.55888, train_accuracy: 43.95\n",
      "[7,    66] loss: 1.54705, train_accuracy: 44.14\n",
      "[7,    67] loss: 1.57337, train_accuracy: 42.38\n",
      "[7,    68] loss: 1.53951, train_accuracy: 44.73\n",
      "[7,    69] loss: 1.58735, train_accuracy: 41.21\n",
      "[7,    70] loss: 1.52704, train_accuracy: 45.12\n",
      "[7,    71] loss: 1.53528, train_accuracy: 44.73\n",
      "[7,    72] loss: 1.58845, train_accuracy: 42.58\n",
      "[7,    73] loss: 1.60229, train_accuracy: 44.34\n",
      "[7,    74] loss: 1.59448, train_accuracy: 40.43\n",
      "[7,    75] loss: 1.58270, train_accuracy: 45.51\n",
      "[7,    76] loss: 1.56483, train_accuracy: 42.58\n",
      "[7,    77] loss: 1.63267, train_accuracy: 40.23\n",
      "[7,    78] loss: 1.63980, train_accuracy: 42.77\n",
      "[7,    79] loss: 1.61366, train_accuracy: 41.21\n",
      "[7,    80] loss: 1.55669, train_accuracy: 45.70\n",
      "[7,    81] loss: 1.62187, train_accuracy: 40.04\n",
      "[7,    82] loss: 1.57819, train_accuracy: 43.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,    83] loss: 1.53868, train_accuracy: 44.92\n",
      "[7,    84] loss: 1.56656, train_accuracy: 44.34\n",
      "[7,    85] loss: 1.59706, train_accuracy: 42.38\n",
      "[7,    86] loss: 1.57147, train_accuracy: 41.41\n",
      "[7,    87] loss: 1.67428, train_accuracy: 40.43\n",
      "[7,    88] loss: 1.55674, train_accuracy: 44.34\n",
      "[7,    89] loss: 1.59070, train_accuracy: 41.80\n",
      "[7,    90] loss: 1.55652, train_accuracy: 45.12\n",
      "[7,    91] loss: 1.55550, train_accuracy: 40.82\n",
      "[7,    92] loss: 1.56896, train_accuracy: 42.19\n",
      "[7,    93] loss: 1.55221, train_accuracy: 44.92\n",
      "[7,    94] loss: 1.65357, train_accuracy: 42.97\n",
      "[7,    95] loss: 1.65610, train_accuracy: 41.99\n",
      "[7,    96] loss: 1.56854, train_accuracy: 45.90\n",
      "[7,    97] loss: 1.54567, train_accuracy: 44.34\n",
      "[7,    98] loss: 1.58721, train_accuracy: 43.15\n",
      "duration: 311 s - train loss: 1.59302 - train accuracy: 42.80 - validation loss: 1.30843 - validation accuracy: 53.80 \n",
      "[8,     1] loss: 1.62711, train_accuracy: 43.55\n",
      "[8,     2] loss: 1.55907, train_accuracy: 45.12\n",
      "[8,     3] loss: 1.58970, train_accuracy: 43.55\n",
      "[8,     4] loss: 1.53724, train_accuracy: 44.14\n",
      "[8,     5] loss: 1.50164, train_accuracy: 45.51\n",
      "[8,     6] loss: 1.67157, train_accuracy: 39.65\n",
      "[8,     7] loss: 1.60808, train_accuracy: 41.60\n",
      "[8,     8] loss: 1.62442, train_accuracy: 42.77\n",
      "[8,     9] loss: 1.57558, train_accuracy: 44.14\n",
      "[8,    10] loss: 1.55235, train_accuracy: 45.70\n",
      "[8,    11] loss: 1.53534, train_accuracy: 44.92\n",
      "[8,    12] loss: 1.64932, train_accuracy: 42.97\n",
      "[8,    13] loss: 1.57369, train_accuracy: 45.31\n",
      "[8,    14] loss: 1.52538, train_accuracy: 43.75\n",
      "[8,    15] loss: 1.56920, train_accuracy: 41.60\n",
      "[8,    16] loss: 1.60830, train_accuracy: 41.80\n",
      "[8,    17] loss: 1.60498, train_accuracy: 42.38\n",
      "[8,    18] loss: 1.58039, train_accuracy: 41.60\n",
      "[8,    19] loss: 1.58986, train_accuracy: 40.04\n",
      "[8,    20] loss: 1.66101, train_accuracy: 42.19\n",
      "[8,    21] loss: 1.64578, train_accuracy: 42.97\n",
      "[8,    22] loss: 1.59859, train_accuracy: 41.80\n",
      "[8,    23] loss: 1.51756, train_accuracy: 45.90\n",
      "[8,    24] loss: 1.61571, train_accuracy: 40.82\n",
      "[8,    25] loss: 1.61982, train_accuracy: 43.95\n",
      "[8,    26] loss: 1.60178, train_accuracy: 44.14\n",
      "[8,    27] loss: 1.57969, train_accuracy: 41.99\n",
      "[8,    28] loss: 1.61177, train_accuracy: 42.19\n",
      "[8,    29] loss: 1.44940, train_accuracy: 46.48\n",
      "[8,    30] loss: 1.52087, train_accuracy: 45.51\n",
      "[8,    31] loss: 1.52218, train_accuracy: 43.75\n",
      "[8,    32] loss: 1.54053, train_accuracy: 46.68\n",
      "[8,    33] loss: 1.56202, train_accuracy: 45.12\n",
      "[8,    34] loss: 1.54346, train_accuracy: 44.73\n",
      "[8,    35] loss: 1.59282, train_accuracy: 44.14\n",
      "[8,    36] loss: 1.58044, train_accuracy: 43.95\n",
      "[8,    37] loss: 1.59748, train_accuracy: 43.95\n",
      "[8,    38] loss: 1.56894, train_accuracy: 41.41\n",
      "[8,    39] loss: 1.56879, train_accuracy: 42.38\n",
      "[8,    40] loss: 1.54538, train_accuracy: 44.53\n",
      "[8,    41] loss: 1.61003, train_accuracy: 43.95\n",
      "[8,    42] loss: 1.60424, train_accuracy: 41.80\n",
      "[8,    43] loss: 1.59731, train_accuracy: 44.73\n",
      "[8,    44] loss: 1.52438, train_accuracy: 45.90\n",
      "[8,    45] loss: 1.61806, train_accuracy: 41.80\n",
      "[8,    46] loss: 1.62632, train_accuracy: 41.99\n",
      "[8,    47] loss: 1.55205, train_accuracy: 44.34\n",
      "[8,    48] loss: 1.59395, train_accuracy: 42.58\n",
      "[8,    49] loss: 1.56924, train_accuracy: 45.90\n",
      "[8,    50] loss: 1.55348, train_accuracy: 45.12\n",
      "[8,    51] loss: 1.61835, train_accuracy: 42.38\n",
      "[8,    52] loss: 1.55222, train_accuracy: 46.88\n",
      "[8,    53] loss: 1.55684, train_accuracy: 42.19\n",
      "[8,    54] loss: 1.63236, train_accuracy: 38.09\n",
      "[8,    55] loss: 1.52660, train_accuracy: 45.31\n",
      "[8,    56] loss: 1.53775, train_accuracy: 45.31\n",
      "[8,    57] loss: 1.51487, train_accuracy: 44.53\n",
      "[8,    58] loss: 1.51632, train_accuracy: 44.34\n",
      "[8,    59] loss: 1.53698, train_accuracy: 44.14\n",
      "[8,    60] loss: 1.52668, train_accuracy: 45.51\n",
      "[8,    61] loss: 1.48491, train_accuracy: 43.95\n",
      "[8,    62] loss: 1.62487, train_accuracy: 41.80\n",
      "[8,    63] loss: 1.52440, train_accuracy: 46.09\n",
      "[8,    64] loss: 1.59008, train_accuracy: 43.75\n",
      "[8,    65] loss: 1.58309, train_accuracy: 47.27\n",
      "[8,    66] loss: 1.50855, train_accuracy: 46.29\n",
      "[8,    67] loss: 1.54843, train_accuracy: 44.14\n",
      "[8,    68] loss: 1.66470, train_accuracy: 41.60\n",
      "[8,    69] loss: 1.60013, train_accuracy: 42.97\n",
      "[8,    70] loss: 1.52381, train_accuracy: 43.55\n",
      "[8,    71] loss: 1.61771, train_accuracy: 41.80\n",
      "[8,    72] loss: 1.59910, train_accuracy: 45.90\n",
      "[8,    73] loss: 1.54791, train_accuracy: 45.51\n",
      "[8,    74] loss: 1.51744, train_accuracy: 45.51\n",
      "[8,    75] loss: 1.64633, train_accuracy: 42.19\n",
      "[8,    76] loss: 1.53820, train_accuracy: 42.38\n",
      "[8,    77] loss: 1.58819, train_accuracy: 41.21\n",
      "[8,    78] loss: 1.58248, train_accuracy: 44.92\n",
      "[8,    79] loss: 1.51300, train_accuracy: 45.70\n",
      "[8,    80] loss: 1.52254, train_accuracy: 47.27\n",
      "[8,    81] loss: 1.46257, train_accuracy: 43.55\n",
      "[8,    82] loss: 1.57107, train_accuracy: 43.16\n",
      "[8,    83] loss: 1.50680, train_accuracy: 45.51\n",
      "[8,    84] loss: 1.60419, train_accuracy: 43.95\n",
      "[8,    85] loss: 1.53282, train_accuracy: 44.14\n",
      "[8,    86] loss: 1.54745, train_accuracy: 44.92\n",
      "[8,    87] loss: 1.58888, train_accuracy: 42.97\n",
      "[8,    88] loss: 1.53094, train_accuracy: 45.51\n",
      "[8,    89] loss: 1.53880, train_accuracy: 42.77\n",
      "[8,    90] loss: 1.53191, train_accuracy: 45.31\n",
      "[8,    91] loss: 1.62752, train_accuracy: 39.26\n",
      "[8,    92] loss: 1.61394, train_accuracy: 43.95\n",
      "[8,    93] loss: 1.65357, train_accuracy: 42.19\n",
      "[8,    94] loss: 1.49867, train_accuracy: 44.53\n",
      "[8,    95] loss: 1.55081, train_accuracy: 43.75\n",
      "[8,    96] loss: 1.51840, train_accuracy: 47.85\n",
      "[8,    97] loss: 1.64977, train_accuracy: 38.48\n",
      "[8,    98] loss: 1.42080, train_accuracy: 48.51\n",
      "duration: 334 s - train loss: 1.56908 - train accuracy: 43.77 - validation loss: 1.28378 - validation accuracy: 54.95 \n",
      "[9,     1] loss: 1.47597, train_accuracy: 45.90\n",
      "[9,     2] loss: 1.56123, train_accuracy: 43.75\n",
      "[9,     3] loss: 1.57430, train_accuracy: 42.77\n",
      "[9,     4] loss: 1.52585, train_accuracy: 45.31\n",
      "[9,     5] loss: 1.41215, train_accuracy: 48.24\n",
      "[9,     6] loss: 1.56414, train_accuracy: 43.75\n",
      "[9,     7] loss: 1.57803, train_accuracy: 42.97\n",
      "[9,     8] loss: 1.60488, train_accuracy: 41.41\n",
      "[9,     9] loss: 1.49650, train_accuracy: 47.66\n",
      "[9,    10] loss: 1.59939, train_accuracy: 44.14\n",
      "[9,    11] loss: 1.47483, train_accuracy: 46.48\n",
      "[9,    12] loss: 1.52612, train_accuracy: 44.92\n",
      "[9,    13] loss: 1.58269, train_accuracy: 42.19\n",
      "[9,    14] loss: 1.51210, train_accuracy: 47.66\n",
      "[9,    15] loss: 1.56450, train_accuracy: 41.60\n",
      "[9,    16] loss: 1.53515, train_accuracy: 47.66\n",
      "[9,    17] loss: 1.55651, train_accuracy: 43.55\n",
      "[9,    18] loss: 1.53428, train_accuracy: 45.12\n",
      "[9,    19] loss: 1.56992, train_accuracy: 45.12\n",
      "[9,    20] loss: 1.48935, train_accuracy: 49.22\n",
      "[9,    21] loss: 1.48741, train_accuracy: 46.48\n",
      "[9,    22] loss: 1.49725, train_accuracy: 47.85\n",
      "[9,    23] loss: 1.60483, train_accuracy: 44.53\n",
      "[9,    24] loss: 1.57335, train_accuracy: 42.19\n",
      "[9,    25] loss: 1.56951, train_accuracy: 42.38\n",
      "[9,    26] loss: 1.54521, train_accuracy: 46.48\n",
      "[9,    27] loss: 1.52283, train_accuracy: 46.88\n",
      "[9,    28] loss: 1.55714, train_accuracy: 46.88\n",
      "[9,    29] loss: 1.56330, train_accuracy: 43.75\n",
      "[9,    30] loss: 1.59270, train_accuracy: 43.75\n",
      "[9,    31] loss: 1.61458, train_accuracy: 39.45\n",
      "[9,    32] loss: 1.59850, train_accuracy: 45.12\n",
      "[9,    33] loss: 1.51516, train_accuracy: 46.88\n",
      "[9,    34] loss: 1.51360, train_accuracy: 46.48\n",
      "[9,    35] loss: 1.47716, train_accuracy: 47.46\n",
      "[9,    36] loss: 1.54954, train_accuracy: 41.99\n",
      "[9,    37] loss: 1.53669, train_accuracy: 45.51\n",
      "[9,    38] loss: 1.52092, train_accuracy: 46.09\n",
      "[9,    39] loss: 1.57931, train_accuracy: 43.36\n",
      "[9,    40] loss: 1.51115, train_accuracy: 43.75\n",
      "[9,    41] loss: 1.49480, train_accuracy: 46.68\n",
      "[9,    42] loss: 1.62212, train_accuracy: 40.82\n",
      "[9,    43] loss: 1.59285, train_accuracy: 41.21\n",
      "[9,    44] loss: 1.52204, train_accuracy: 44.14\n",
      "[9,    45] loss: 1.50755, train_accuracy: 45.31\n",
      "[9,    46] loss: 1.52811, train_accuracy: 46.88\n",
      "[9,    47] loss: 1.57038, train_accuracy: 43.55\n",
      "[9,    48] loss: 1.48767, train_accuracy: 45.12\n",
      "[9,    49] loss: 1.55895, train_accuracy: 46.68\n",
      "[9,    50] loss: 1.50639, train_accuracy: 44.14\n",
      "[9,    51] loss: 1.55060, train_accuracy: 43.16\n",
      "[9,    52] loss: 1.57395, train_accuracy: 44.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,    53] loss: 1.52709, train_accuracy: 47.07\n",
      "[9,    54] loss: 1.53556, train_accuracy: 42.97\n",
      "[9,    55] loss: 1.45234, train_accuracy: 49.02\n",
      "[9,    56] loss: 1.65688, train_accuracy: 40.62\n",
      "[9,    57] loss: 1.47487, train_accuracy: 45.90\n",
      "[9,    58] loss: 1.50177, train_accuracy: 44.92\n",
      "[9,    59] loss: 1.56171, train_accuracy: 45.31\n",
      "[9,    60] loss: 1.61408, train_accuracy: 40.04\n",
      "[9,    61] loss: 1.53746, train_accuracy: 45.12\n",
      "[9,    62] loss: 1.52420, train_accuracy: 45.51\n",
      "[9,    63] loss: 1.56056, train_accuracy: 47.07\n",
      "[9,    64] loss: 1.56901, train_accuracy: 42.58\n",
      "[9,    65] loss: 1.45738, train_accuracy: 45.90\n",
      "[9,    66] loss: 1.52738, train_accuracy: 46.29\n",
      "[9,    67] loss: 1.53548, train_accuracy: 44.92\n",
      "[9,    68] loss: 1.57493, train_accuracy: 43.55\n",
      "[9,    69] loss: 1.59838, train_accuracy: 43.55\n",
      "[9,    70] loss: 1.55435, train_accuracy: 44.92\n",
      "[9,    71] loss: 1.55522, train_accuracy: 45.51\n",
      "[9,    72] loss: 1.52632, train_accuracy: 47.27\n",
      "[9,    73] loss: 1.42662, train_accuracy: 50.20\n",
      "[9,    74] loss: 1.57444, train_accuracy: 43.55\n",
      "[9,    75] loss: 1.49001, train_accuracy: 46.88\n",
      "[9,    76] loss: 1.58247, train_accuracy: 42.58\n",
      "[9,    77] loss: 1.50543, train_accuracy: 44.14\n",
      "[9,    78] loss: 1.54612, train_accuracy: 44.34\n",
      "[9,    79] loss: 1.47686, train_accuracy: 47.07\n",
      "[9,    80] loss: 1.53702, train_accuracy: 44.73\n",
      "[9,    81] loss: 1.60223, train_accuracy: 41.02\n",
      "[9,    82] loss: 1.55205, train_accuracy: 43.16\n",
      "[9,    83] loss: 1.57573, train_accuracy: 43.16\n",
      "[9,    84] loss: 1.51222, train_accuracy: 45.90\n",
      "[9,    85] loss: 1.51530, train_accuracy: 49.41\n",
      "[9,    86] loss: 1.54058, train_accuracy: 41.99\n",
      "[9,    87] loss: 1.52500, train_accuracy: 43.75\n",
      "[9,    88] loss: 1.52966, train_accuracy: 46.09\n",
      "[9,    89] loss: 1.64701, train_accuracy: 39.26\n",
      "[9,    90] loss: 1.51397, train_accuracy: 46.88\n",
      "[9,    91] loss: 1.60517, train_accuracy: 40.23\n",
      "[9,    92] loss: 1.59952, train_accuracy: 39.65\n",
      "[9,    93] loss: 1.61447, train_accuracy: 42.19\n",
      "[9,    94] loss: 1.49204, train_accuracy: 46.29\n",
      "[9,    95] loss: 1.51119, train_accuracy: 44.92\n",
      "[9,    96] loss: 1.46909, train_accuracy: 47.46\n",
      "[9,    97] loss: 1.48853, train_accuracy: 47.66\n",
      "[9,    98] loss: 1.56858, train_accuracy: 44.05\n",
      "duration: 257 s - train loss: 1.54112 - train accuracy: 44.73 - validation loss: 1.25797 - validation accuracy: 55.73 \n",
      "[10,     1] loss: 1.52145, train_accuracy: 44.73\n",
      "[10,     2] loss: 1.50509, train_accuracy: 46.68\n",
      "[10,     3] loss: 1.56715, train_accuracy: 43.36\n",
      "[10,     4] loss: 1.59822, train_accuracy: 42.38\n",
      "[10,     5] loss: 1.48091, train_accuracy: 48.24\n",
      "[10,     6] loss: 1.51332, train_accuracy: 46.88\n",
      "[10,     7] loss: 1.53783, train_accuracy: 41.41\n",
      "[10,     8] loss: 1.60076, train_accuracy: 42.77\n",
      "[10,     9] loss: 1.57843, train_accuracy: 43.55\n",
      "[10,    10] loss: 1.59461, train_accuracy: 42.77\n",
      "[10,    11] loss: 1.47165, train_accuracy: 45.12\n",
      "[10,    12] loss: 1.60043, train_accuracy: 40.62\n",
      "[10,    13] loss: 1.50015, train_accuracy: 43.95\n",
      "[10,    14] loss: 1.53733, train_accuracy: 43.36\n",
      "[10,    15] loss: 1.53071, train_accuracy: 45.31\n",
      "[10,    16] loss: 1.53931, train_accuracy: 43.55\n",
      "[10,    17] loss: 1.43466, train_accuracy: 50.00\n",
      "[10,    18] loss: 1.53295, train_accuracy: 42.77\n",
      "[10,    19] loss: 1.58051, train_accuracy: 44.34\n",
      "[10,    20] loss: 1.56289, train_accuracy: 44.14\n",
      "[10,    21] loss: 1.48291, train_accuracy: 49.61\n",
      "[10,    22] loss: 1.60254, train_accuracy: 46.88\n",
      "[10,    23] loss: 1.55305, train_accuracy: 45.51\n",
      "[10,    24] loss: 1.55139, train_accuracy: 44.34\n",
      "[10,    25] loss: 1.51678, train_accuracy: 44.92\n",
      "[10,    26] loss: 1.47893, train_accuracy: 45.90\n",
      "[10,    27] loss: 1.51710, train_accuracy: 44.14\n",
      "[10,    28] loss: 1.52421, train_accuracy: 43.36\n",
      "[10,    29] loss: 1.55317, train_accuracy: 43.75\n",
      "[10,    30] loss: 1.48204, train_accuracy: 45.90\n",
      "[10,    31] loss: 1.51126, train_accuracy: 47.46\n",
      "[10,    32] loss: 1.57980, train_accuracy: 42.77\n",
      "[10,    33] loss: 1.47579, train_accuracy: 45.12\n",
      "[10,    34] loss: 1.56407, train_accuracy: 44.34\n",
      "[10,    35] loss: 1.47546, train_accuracy: 50.78\n",
      "[10,    36] loss: 1.53869, train_accuracy: 45.51\n",
      "[10,    37] loss: 1.53053, train_accuracy: 43.55\n",
      "[10,    38] loss: 1.55835, train_accuracy: 44.92\n",
      "[10,    39] loss: 1.48923, train_accuracy: 46.48\n",
      "[10,    40] loss: 1.56404, train_accuracy: 42.38\n",
      "[10,    41] loss: 1.45743, train_accuracy: 46.48\n",
      "[10,    42] loss: 1.50443, train_accuracy: 45.51\n",
      "[10,    43] loss: 1.51427, train_accuracy: 45.90\n",
      "[10,    44] loss: 1.45728, train_accuracy: 53.52\n",
      "[10,    45] loss: 1.61917, train_accuracy: 41.80\n",
      "[10,    46] loss: 1.46961, train_accuracy: 46.68\n",
      "[10,    47] loss: 1.44709, train_accuracy: 46.29\n",
      "[10,    48] loss: 1.47325, train_accuracy: 47.85\n",
      "[10,    49] loss: 1.56498, train_accuracy: 45.90\n",
      "[10,    50] loss: 1.56599, train_accuracy: 42.77\n",
      "[10,    51] loss: 1.61659, train_accuracy: 41.41\n",
      "[10,    52] loss: 1.61313, train_accuracy: 40.23\n",
      "[10,    53] loss: 1.66131, train_accuracy: 41.99\n",
      "[10,    54] loss: 1.59507, train_accuracy: 45.51\n",
      "[10,    55] loss: 1.45417, train_accuracy: 48.24\n",
      "[10,    56] loss: 1.46114, train_accuracy: 46.29\n",
      "[10,    57] loss: 1.53878, train_accuracy: 45.51\n",
      "[10,    58] loss: 1.52192, train_accuracy: 43.16\n",
      "[10,    59] loss: 1.51863, train_accuracy: 44.14\n",
      "[10,    60] loss: 1.52558, train_accuracy: 44.92\n",
      "[10,    61] loss: 1.46109, train_accuracy: 47.85\n",
      "[10,    62] loss: 1.45320, train_accuracy: 50.39\n",
      "[10,    63] loss: 1.42297, train_accuracy: 51.17\n",
      "[10,    64] loss: 1.52699, train_accuracy: 48.44\n",
      "[10,    65] loss: 1.54654, train_accuracy: 44.53\n",
      "[10,    66] loss: 1.49620, train_accuracy: 48.05\n",
      "[10,    67] loss: 1.54576, train_accuracy: 42.19\n",
      "[10,    68] loss: 1.59326, train_accuracy: 39.65\n",
      "[10,    69] loss: 1.51894, train_accuracy: 45.12\n",
      "[10,    70] loss: 1.47353, train_accuracy: 49.80\n",
      "[10,    71] loss: 1.58179, train_accuracy: 42.58\n",
      "[10,    72] loss: 1.52229, train_accuracy: 47.07\n",
      "[10,    73] loss: 1.52050, train_accuracy: 44.14\n",
      "[10,    74] loss: 1.53513, train_accuracy: 44.14\n",
      "[10,    75] loss: 1.47245, train_accuracy: 48.83\n",
      "[10,    76] loss: 1.48987, train_accuracy: 47.66\n",
      "[10,    77] loss: 1.55356, train_accuracy: 45.12\n",
      "[10,    78] loss: 1.52315, train_accuracy: 49.22\n",
      "[10,    79] loss: 1.49428, train_accuracy: 48.24\n",
      "[10,    80] loss: 1.51081, train_accuracy: 44.53\n",
      "[10,    81] loss: 1.53904, train_accuracy: 41.60\n",
      "[10,    82] loss: 1.53797, train_accuracy: 44.14\n",
      "[10,    83] loss: 1.53344, train_accuracy: 44.92\n",
      "[10,    84] loss: 1.56582, train_accuracy: 44.53\n",
      "[10,    85] loss: 1.49933, train_accuracy: 44.92\n",
      "[10,    86] loss: 1.49125, train_accuracy: 46.88\n",
      "[10,    87] loss: 1.52677, train_accuracy: 47.46\n",
      "[10,    88] loss: 1.51599, train_accuracy: 45.51\n",
      "[10,    89] loss: 1.48837, train_accuracy: 45.31\n",
      "[10,    90] loss: 1.54394, train_accuracy: 44.92\n",
      "[10,    91] loss: 1.59366, train_accuracy: 46.68\n",
      "[10,    92] loss: 1.56503, train_accuracy: 41.99\n",
      "[10,    93] loss: 1.48715, train_accuracy: 44.53\n",
      "[10,    94] loss: 1.53310, train_accuracy: 41.80\n",
      "[10,    95] loss: 1.45184, train_accuracy: 45.90\n",
      "[10,    96] loss: 1.64667, train_accuracy: 40.82\n",
      "[10,    97] loss: 1.56488, train_accuracy: 42.58\n",
      "[10,    98] loss: 1.54390, train_accuracy: 43.75\n",
      "duration: 242 s - train loss: 1.52845 - train accuracy: 45.15 - validation loss: 1.24098 - validation accuracy: 56.38 \n",
      "[11,     1] loss: 1.49955, train_accuracy: 47.66\n",
      "[11,     2] loss: 1.59987, train_accuracy: 42.77\n",
      "[11,     3] loss: 1.48211, train_accuracy: 45.31\n",
      "[11,     4] loss: 1.48340, train_accuracy: 47.27\n",
      "[11,     5] loss: 1.48186, train_accuracy: 45.31\n",
      "[11,     6] loss: 1.45956, train_accuracy: 48.44\n",
      "[11,     7] loss: 1.58643, train_accuracy: 44.34\n",
      "[11,     8] loss: 1.55067, train_accuracy: 43.36\n",
      "[11,     9] loss: 1.56306, train_accuracy: 42.19\n",
      "[11,    10] loss: 1.55293, train_accuracy: 44.73\n",
      "[11,    11] loss: 1.50051, train_accuracy: 46.88\n",
      "[11,    12] loss: 1.59463, train_accuracy: 44.92\n",
      "[11,    13] loss: 1.48207, train_accuracy: 47.85\n",
      "[11,    14] loss: 1.52610, train_accuracy: 43.95\n",
      "[11,    15] loss: 1.44255, train_accuracy: 46.29\n",
      "[11,    16] loss: 1.53446, train_accuracy: 43.16\n",
      "[11,    17] loss: 1.46321, train_accuracy: 47.07\n",
      "[11,    18] loss: 1.51615, train_accuracy: 48.24\n",
      "[11,    19] loss: 1.48054, train_accuracy: 49.02\n",
      "[11,    20] loss: 1.55156, train_accuracy: 41.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,    21] loss: 1.47770, train_accuracy: 44.73\n",
      "[11,    22] loss: 1.55279, train_accuracy: 42.38\n",
      "[11,    23] loss: 1.52089, train_accuracy: 47.85\n",
      "[11,    24] loss: 1.53443, train_accuracy: 42.38\n",
      "[11,    25] loss: 1.53428, train_accuracy: 42.19\n",
      "[11,    26] loss: 1.51575, train_accuracy: 45.31\n",
      "[11,    27] loss: 1.50365, train_accuracy: 49.22\n",
      "[11,    28] loss: 1.52067, train_accuracy: 44.53\n",
      "[11,    29] loss: 1.43697, train_accuracy: 46.68\n",
      "[11,    30] loss: 1.48955, train_accuracy: 47.85\n",
      "[11,    31] loss: 1.52549, train_accuracy: 45.51\n",
      "[11,    32] loss: 1.46419, train_accuracy: 48.05\n",
      "[11,    33] loss: 1.48341, train_accuracy: 48.44\n",
      "[11,    34] loss: 1.50194, train_accuracy: 46.29\n",
      "[11,    35] loss: 1.50634, train_accuracy: 44.92\n",
      "[11,    36] loss: 1.49921, train_accuracy: 43.75\n",
      "[11,    37] loss: 1.52623, train_accuracy: 46.48\n",
      "[11,    38] loss: 1.51475, train_accuracy: 42.58\n",
      "[11,    39] loss: 1.68965, train_accuracy: 39.26\n",
      "[11,    40] loss: 1.57328, train_accuracy: 41.80\n",
      "[11,    41] loss: 1.56641, train_accuracy: 45.12\n",
      "[11,    42] loss: 1.49938, train_accuracy: 46.09\n",
      "[11,    43] loss: 1.51030, train_accuracy: 45.31\n",
      "[11,    44] loss: 1.44864, train_accuracy: 45.12\n",
      "[11,    45] loss: 1.59326, train_accuracy: 43.75\n",
      "[11,    46] loss: 1.44817, train_accuracy: 49.02\n",
      "[11,    47] loss: 1.56550, train_accuracy: 43.36\n",
      "[11,    48] loss: 1.51987, train_accuracy: 44.73\n",
      "[11,    49] loss: 1.46718, train_accuracy: 45.90\n",
      "[11,    50] loss: 1.43662, train_accuracy: 49.61\n",
      "[11,    51] loss: 1.56844, train_accuracy: 41.02\n",
      "[11,    52] loss: 1.45696, train_accuracy: 46.68\n",
      "[11,    53] loss: 1.53245, train_accuracy: 44.14\n",
      "[11,    54] loss: 1.53910, train_accuracy: 43.16\n",
      "[11,    55] loss: 1.54830, train_accuracy: 44.92\n",
      "[11,    56] loss: 1.55066, train_accuracy: 44.53\n",
      "[11,    57] loss: 1.46995, train_accuracy: 48.44\n",
      "[11,    58] loss: 1.44084, train_accuracy: 48.63\n",
      "[11,    59] loss: 1.38651, train_accuracy: 51.37\n",
      "[11,    60] loss: 1.50749, train_accuracy: 46.68\n",
      "[11,    61] loss: 1.52139, train_accuracy: 44.73\n",
      "[11,    62] loss: 1.51539, train_accuracy: 46.09\n",
      "[11,    63] loss: 1.50279, train_accuracy: 44.92\n",
      "[11,    64] loss: 1.46595, train_accuracy: 49.41\n",
      "[11,    65] loss: 1.51095, train_accuracy: 45.70\n",
      "[11,    66] loss: 1.44778, train_accuracy: 48.83\n",
      "[11,    67] loss: 1.47566, train_accuracy: 46.09\n",
      "[11,    68] loss: 1.52537, train_accuracy: 45.12\n",
      "[11,    69] loss: 1.48414, train_accuracy: 47.07\n",
      "[11,    70] loss: 1.50645, train_accuracy: 45.70\n",
      "[11,    71] loss: 1.52257, train_accuracy: 46.88\n",
      "[11,    72] loss: 1.51869, train_accuracy: 43.95\n",
      "[11,    73] loss: 1.45760, train_accuracy: 50.20\n",
      "[11,    74] loss: 1.55374, train_accuracy: 43.36\n",
      "[11,    75] loss: 1.48860, train_accuracy: 44.73\n",
      "[11,    76] loss: 1.38660, train_accuracy: 50.78\n",
      "[11,    77] loss: 1.49810, train_accuracy: 46.68\n",
      "[11,    78] loss: 1.44053, train_accuracy: 49.22\n",
      "[11,    79] loss: 1.46850, train_accuracy: 46.29\n",
      "[11,    80] loss: 1.57439, train_accuracy: 40.23\n",
      "[11,    81] loss: 1.48876, train_accuracy: 44.73\n",
      "[11,    82] loss: 1.52205, train_accuracy: 42.97\n",
      "[11,    83] loss: 1.59460, train_accuracy: 44.14\n",
      "[11,    84] loss: 1.53295, train_accuracy: 44.92\n",
      "[11,    85] loss: 1.47998, train_accuracy: 47.46\n",
      "[11,    86] loss: 1.46117, train_accuracy: 47.66\n",
      "[11,    87] loss: 1.48938, train_accuracy: 45.12\n",
      "[11,    88] loss: 1.44278, train_accuracy: 49.41\n",
      "[11,    89] loss: 1.47447, train_accuracy: 47.85\n",
      "[11,    90] loss: 1.40391, train_accuracy: 48.44\n",
      "[11,    91] loss: 1.49416, train_accuracy: 44.92\n",
      "[11,    92] loss: 1.54079, train_accuracy: 44.73\n",
      "[11,    93] loss: 1.46279, train_accuracy: 45.90\n",
      "[11,    94] loss: 1.51359, train_accuracy: 45.90\n",
      "[11,    95] loss: 1.42257, train_accuracy: 48.24\n",
      "[11,    96] loss: 1.51854, train_accuracy: 45.90\n",
      "[11,    97] loss: 1.48989, train_accuracy: 48.05\n",
      "[11,    98] loss: 1.43556, train_accuracy: 49.40\n",
      "duration: 251 s - train loss: 1.50420 - train accuracy: 45.82 - validation loss: 1.21257 - validation accuracy: 57.63 \n",
      "[12,     1] loss: 1.52996, train_accuracy: 46.09\n",
      "[12,     2] loss: 1.51914, train_accuracy: 44.34\n",
      "[12,     3] loss: 1.46428, train_accuracy: 48.63\n",
      "[12,     4] loss: 1.55481, train_accuracy: 45.31\n",
      "[12,     5] loss: 1.52604, train_accuracy: 47.46\n",
      "[12,     6] loss: 1.48508, train_accuracy: 45.51\n",
      "[12,     7] loss: 1.48771, train_accuracy: 46.09\n",
      "[12,     8] loss: 1.45278, train_accuracy: 49.22\n",
      "[12,     9] loss: 1.57560, train_accuracy: 42.38\n",
      "[12,    10] loss: 1.45858, train_accuracy: 43.36\n",
      "[12,    11] loss: 1.45266, train_accuracy: 47.46\n",
      "[12,    12] loss: 1.52819, train_accuracy: 44.14\n",
      "[12,    13] loss: 1.57024, train_accuracy: 41.99\n",
      "[12,    14] loss: 1.48997, train_accuracy: 45.90\n",
      "[12,    15] loss: 1.53236, train_accuracy: 46.48\n",
      "[12,    16] loss: 1.48033, train_accuracy: 48.24\n",
      "[12,    17] loss: 1.52921, train_accuracy: 43.95\n",
      "[12,    18] loss: 1.41569, train_accuracy: 50.20\n",
      "[12,    19] loss: 1.48729, train_accuracy: 47.07\n",
      "[12,    20] loss: 1.51719, train_accuracy: 46.09\n",
      "[12,    21] loss: 1.45623, train_accuracy: 48.63\n",
      "[12,    22] loss: 1.45299, train_accuracy: 48.44\n",
      "[12,    23] loss: 1.52822, train_accuracy: 45.70\n",
      "[12,    24] loss: 1.44020, train_accuracy: 46.68\n",
      "[12,    25] loss: 1.48369, train_accuracy: 48.24\n",
      "[12,    26] loss: 1.48155, train_accuracy: 48.83\n",
      "[12,    27] loss: 1.44605, train_accuracy: 49.41\n",
      "[12,    28] loss: 1.54715, train_accuracy: 42.19\n",
      "[12,    29] loss: 1.46070, train_accuracy: 47.46\n",
      "[12,    30] loss: 1.52537, train_accuracy: 43.36\n",
      "[12,    31] loss: 1.51397, train_accuracy: 45.51\n",
      "[12,    32] loss: 1.55990, train_accuracy: 41.41\n",
      "[12,    33] loss: 1.45640, train_accuracy: 47.85\n",
      "[12,    34] loss: 1.44031, train_accuracy: 49.02\n",
      "[12,    35] loss: 1.53544, train_accuracy: 46.88\n",
      "[12,    36] loss: 1.56300, train_accuracy: 47.07\n",
      "[12,    37] loss: 1.49955, train_accuracy: 47.85\n",
      "[12,    38] loss: 1.46114, train_accuracy: 49.02\n",
      "[12,    39] loss: 1.43464, train_accuracy: 48.83\n",
      "[12,    40] loss: 1.51979, train_accuracy: 45.31\n",
      "[12,    41] loss: 1.50812, train_accuracy: 47.07\n",
      "[12,    42] loss: 1.45534, train_accuracy: 48.05\n",
      "[12,    43] loss: 1.47496, train_accuracy: 46.68\n",
      "[12,    44] loss: 1.49006, train_accuracy: 48.44\n",
      "[12,    45] loss: 1.51880, train_accuracy: 43.75\n",
      "[12,    46] loss: 1.38891, train_accuracy: 50.78\n",
      "[12,    47] loss: 1.50547, train_accuracy: 45.12\n",
      "[12,    48] loss: 1.51302, train_accuracy: 47.07\n",
      "[12,    49] loss: 1.49287, train_accuracy: 45.70\n",
      "[12,    50] loss: 1.49468, train_accuracy: 46.68\n",
      "[12,    51] loss: 1.44363, train_accuracy: 46.48\n",
      "[12,    52] loss: 1.46672, train_accuracy: 45.90\n",
      "[12,    53] loss: 1.41990, train_accuracy: 47.07\n",
      "[12,    54] loss: 1.41996, train_accuracy: 48.83\n",
      "[12,    55] loss: 1.48159, train_accuracy: 46.68\n",
      "[12,    56] loss: 1.47921, train_accuracy: 46.09\n",
      "[12,    57] loss: 1.58065, train_accuracy: 46.88\n",
      "[12,    58] loss: 1.42566, train_accuracy: 46.68\n",
      "[12,    59] loss: 1.50974, train_accuracy: 44.73\n",
      "[12,    60] loss: 1.48493, train_accuracy: 45.51\n",
      "[12,    61] loss: 1.53294, train_accuracy: 42.38\n",
      "[12,    62] loss: 1.55317, train_accuracy: 42.97\n",
      "[12,    63] loss: 1.47890, train_accuracy: 46.29\n",
      "[12,    64] loss: 1.48682, train_accuracy: 47.07\n",
      "[12,    65] loss: 1.48093, train_accuracy: 46.48\n",
      "[12,    66] loss: 1.45336, train_accuracy: 47.27\n",
      "[12,    67] loss: 1.53406, train_accuracy: 45.31\n",
      "[12,    68] loss: 1.44383, train_accuracy: 49.41\n",
      "[12,    69] loss: 1.41837, train_accuracy: 47.27\n",
      "[12,    70] loss: 1.45817, train_accuracy: 47.85\n",
      "[12,    71] loss: 1.48541, train_accuracy: 46.68\n",
      "[12,    72] loss: 1.53431, train_accuracy: 43.95\n",
      "[12,    73] loss: 1.43752, train_accuracy: 46.68\n",
      "[12,    74] loss: 1.51909, train_accuracy: 44.92\n",
      "[12,    75] loss: 1.53737, train_accuracy: 44.92\n",
      "[12,    76] loss: 1.51508, train_accuracy: 44.92\n",
      "[12,    77] loss: 1.42509, train_accuracy: 47.46\n",
      "[12,    78] loss: 1.58918, train_accuracy: 40.04\n",
      "[12,    79] loss: 1.38321, train_accuracy: 50.59\n",
      "[12,    80] loss: 1.57665, train_accuracy: 41.41\n",
      "[12,    81] loss: 1.47790, train_accuracy: 46.29\n",
      "[12,    82] loss: 1.50387, train_accuracy: 48.05\n",
      "[12,    83] loss: 1.50750, train_accuracy: 46.29\n",
      "[12,    84] loss: 1.42018, train_accuracy: 51.17\n",
      "[12,    85] loss: 1.51079, train_accuracy: 46.09\n",
      "[12,    86] loss: 1.46806, train_accuracy: 47.07\n",
      "[12,    87] loss: 1.47786, train_accuracy: 44.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,    88] loss: 1.48327, train_accuracy: 49.02\n",
      "[12,    89] loss: 1.53877, train_accuracy: 43.75\n",
      "[12,    90] loss: 1.42880, train_accuracy: 47.27\n",
      "[12,    91] loss: 1.47767, train_accuracy: 45.70\n",
      "[12,    92] loss: 1.53381, train_accuracy: 44.73\n",
      "[12,    93] loss: 1.46201, train_accuracy: 48.44\n",
      "[12,    94] loss: 1.42248, train_accuracy: 49.61\n",
      "[12,    95] loss: 1.54301, train_accuracy: 46.68\n",
      "[12,    96] loss: 1.55282, train_accuracy: 43.95\n",
      "[12,    97] loss: 1.45085, train_accuracy: 48.63\n",
      "[12,    98] loss: 1.54800, train_accuracy: 40.48\n",
      "duration: 248 s - train loss: 1.49050 - train accuracy: 46.36 - validation loss: 1.21115 - validation accuracy: 57.74 \n",
      "[13,     1] loss: 1.50183, train_accuracy: 44.92\n",
      "[13,     2] loss: 1.45920, train_accuracy: 45.51\n",
      "[13,     3] loss: 1.53477, train_accuracy: 43.55\n",
      "[13,     4] loss: 1.53524, train_accuracy: 43.36\n",
      "[13,     5] loss: 1.52964, train_accuracy: 44.34\n",
      "[13,     6] loss: 1.55263, train_accuracy: 45.31\n",
      "[13,     7] loss: 1.44774, train_accuracy: 48.24\n",
      "[13,     8] loss: 1.46936, train_accuracy: 48.05\n",
      "[13,     9] loss: 1.54097, train_accuracy: 44.92\n",
      "[13,    10] loss: 1.48369, train_accuracy: 45.51\n",
      "[13,    11] loss: 1.45270, train_accuracy: 49.22\n",
      "[13,    12] loss: 1.49642, train_accuracy: 50.39\n",
      "[13,    13] loss: 1.43249, train_accuracy: 50.59\n",
      "[13,    14] loss: 1.47433, train_accuracy: 49.02\n",
      "[13,    15] loss: 1.46238, train_accuracy: 49.41\n",
      "[13,    16] loss: 1.46324, train_accuracy: 48.63\n",
      "[13,    17] loss: 1.49693, train_accuracy: 50.20\n",
      "[13,    18] loss: 1.49829, train_accuracy: 44.14\n",
      "[13,    19] loss: 1.47428, train_accuracy: 48.05\n",
      "[13,    20] loss: 1.49190, train_accuracy: 46.29\n",
      "[13,    21] loss: 1.63166, train_accuracy: 39.84\n",
      "[13,    22] loss: 1.49214, train_accuracy: 48.83\n",
      "[13,    23] loss: 1.46710, train_accuracy: 45.70\n",
      "[13,    24] loss: 1.47240, train_accuracy: 48.83\n",
      "[13,    25] loss: 1.41880, train_accuracy: 49.80\n",
      "[13,    26] loss: 1.37050, train_accuracy: 51.37\n",
      "[13,    27] loss: 1.47718, train_accuracy: 46.29\n",
      "[13,    28] loss: 1.55247, train_accuracy: 42.19\n",
      "[13,    29] loss: 1.37172, train_accuracy: 50.78\n",
      "[13,    30] loss: 1.44286, train_accuracy: 49.22\n",
      "[13,    31] loss: 1.49603, train_accuracy: 44.92\n",
      "[13,    32] loss: 1.51477, train_accuracy: 46.68\n",
      "[13,    33] loss: 1.44728, train_accuracy: 49.61\n",
      "[13,    34] loss: 1.42599, train_accuracy: 52.15\n",
      "[13,    35] loss: 1.40332, train_accuracy: 47.66\n",
      "[13,    36] loss: 1.52080, train_accuracy: 44.92\n",
      "[13,    37] loss: 1.32463, train_accuracy: 52.34\n",
      "[13,    38] loss: 1.48130, train_accuracy: 45.31\n",
      "[13,    39] loss: 1.51227, train_accuracy: 44.73\n",
      "[13,    40] loss: 1.42421, train_accuracy: 48.63\n",
      "[13,    41] loss: 1.54411, train_accuracy: 46.09\n",
      "[13,    42] loss: 1.37630, train_accuracy: 49.02\n",
      "[13,    43] loss: 1.50468, train_accuracy: 44.53\n",
      "[13,    44] loss: 1.46287, train_accuracy: 47.66\n",
      "[13,    45] loss: 1.50655, train_accuracy: 47.66\n",
      "[13,    46] loss: 1.49256, train_accuracy: 46.88\n",
      "[13,    47] loss: 1.51655, train_accuracy: 43.36\n",
      "[13,    48] loss: 1.45411, train_accuracy: 47.85\n",
      "[13,    49] loss: 1.43411, train_accuracy: 47.46\n",
      "[13,    50] loss: 1.53883, train_accuracy: 43.55\n",
      "[13,    51] loss: 1.53875, train_accuracy: 45.51\n",
      "[13,    52] loss: 1.45545, train_accuracy: 47.66\n",
      "[13,    53] loss: 1.46323, train_accuracy: 44.73\n",
      "[13,    54] loss: 1.51368, train_accuracy: 44.34\n",
      "[13,    55] loss: 1.41891, train_accuracy: 48.44\n",
      "[13,    56] loss: 1.38455, train_accuracy: 50.00\n",
      "[13,    57] loss: 1.41741, train_accuracy: 48.44\n",
      "[13,    58] loss: 1.46459, train_accuracy: 47.27\n",
      "[13,    59] loss: 1.49367, train_accuracy: 47.66\n",
      "[13,    60] loss: 1.47615, train_accuracy: 49.02\n",
      "[13,    61] loss: 1.48243, train_accuracy: 47.66\n",
      "[13,    62] loss: 1.44656, train_accuracy: 47.07\n",
      "[13,    63] loss: 1.38722, train_accuracy: 46.09\n",
      "[13,    64] loss: 1.45418, train_accuracy: 45.90\n",
      "[13,    65] loss: 1.40491, train_accuracy: 46.48\n",
      "[13,    66] loss: 1.54149, train_accuracy: 47.27\n",
      "[13,    67] loss: 1.50628, train_accuracy: 45.31\n",
      "[13,    68] loss: 1.48692, train_accuracy: 46.88\n",
      "[13,    69] loss: 1.52054, train_accuracy: 45.70\n",
      "[13,    70] loss: 1.51505, train_accuracy: 44.92\n",
      "[13,    71] loss: 1.48427, train_accuracy: 45.70\n",
      "[13,    72] loss: 1.50255, train_accuracy: 44.14\n",
      "[13,    73] loss: 1.46273, train_accuracy: 48.63\n",
      "[13,    74] loss: 1.42560, train_accuracy: 49.61\n",
      "[13,    75] loss: 1.44817, train_accuracy: 47.66\n",
      "[13,    76] loss: 1.50617, train_accuracy: 46.88\n",
      "[13,    77] loss: 1.38943, train_accuracy: 50.98\n",
      "[13,    78] loss: 1.41507, train_accuracy: 51.56\n",
      "[13,    79] loss: 1.49506, train_accuracy: 43.75\n",
      "[13,    80] loss: 1.43195, train_accuracy: 47.66\n",
      "[13,    81] loss: 1.46094, train_accuracy: 46.48\n",
      "[13,    82] loss: 1.46959, train_accuracy: 45.31\n",
      "[13,    83] loss: 1.53570, train_accuracy: 46.29\n",
      "[13,    84] loss: 1.50387, train_accuracy: 41.41\n",
      "[13,    85] loss: 1.43422, train_accuracy: 48.63\n",
      "[13,    86] loss: 1.44256, train_accuracy: 52.54\n",
      "[13,    87] loss: 1.50593, train_accuracy: 44.92\n",
      "[13,    88] loss: 1.52590, train_accuracy: 45.90\n",
      "[13,    89] loss: 1.54921, train_accuracy: 46.29\n",
      "[13,    90] loss: 1.40733, train_accuracy: 49.80\n",
      "[13,    91] loss: 1.53799, train_accuracy: 44.14\n",
      "[13,    92] loss: 1.53274, train_accuracy: 44.53\n",
      "[13,    93] loss: 1.50458, train_accuracy: 44.73\n",
      "[13,    94] loss: 1.49262, train_accuracy: 43.55\n",
      "[13,    95] loss: 1.45703, train_accuracy: 48.63\n",
      "[13,    96] loss: 1.42740, train_accuracy: 46.48\n",
      "[13,    97] loss: 1.48727, train_accuracy: 46.88\n",
      "[13,    98] loss: 1.40395, train_accuracy: 49.11\n",
      "duration: 221 s - train loss: 1.47437 - train accuracy: 46.96 - validation loss: 1.17822 - validation accuracy: 58.72 \n",
      "[14,     1] loss: 1.45028, train_accuracy: 45.12\n",
      "[14,     2] loss: 1.47348, train_accuracy: 44.34\n",
      "[14,     3] loss: 1.37711, train_accuracy: 51.37\n",
      "[14,     4] loss: 1.47066, train_accuracy: 47.66\n",
      "[14,     5] loss: 1.54403, train_accuracy: 44.53\n",
      "[14,     6] loss: 1.35059, train_accuracy: 50.39\n",
      "[14,     7] loss: 1.39992, train_accuracy: 49.61\n",
      "[14,     8] loss: 1.52590, train_accuracy: 45.31\n",
      "[14,     9] loss: 1.46862, train_accuracy: 48.44\n",
      "[14,    10] loss: 1.38946, train_accuracy: 49.41\n",
      "[14,    11] loss: 1.40799, train_accuracy: 50.00\n",
      "[14,    12] loss: 1.46225, train_accuracy: 49.02\n",
      "[14,    13] loss: 1.48524, train_accuracy: 46.09\n",
      "[14,    14] loss: 1.50017, train_accuracy: 46.68\n",
      "[14,    15] loss: 1.43013, train_accuracy: 46.29\n",
      "[14,    16] loss: 1.43570, train_accuracy: 50.39\n",
      "[14,    17] loss: 1.46859, train_accuracy: 45.12\n",
      "[14,    18] loss: 1.35072, train_accuracy: 52.34\n",
      "[14,    19] loss: 1.46633, train_accuracy: 47.66\n",
      "[14,    20] loss: 1.48425, train_accuracy: 44.34\n",
      "[14,    21] loss: 1.47999, train_accuracy: 48.44\n",
      "[14,    22] loss: 1.42052, train_accuracy: 49.02\n",
      "[14,    23] loss: 1.44059, train_accuracy: 46.68\n",
      "[14,    24] loss: 1.53693, train_accuracy: 46.48\n",
      "[14,    25] loss: 1.51420, train_accuracy: 45.31\n",
      "[14,    26] loss: 1.54767, train_accuracy: 45.90\n",
      "[14,    27] loss: 1.47411, train_accuracy: 46.29\n",
      "[14,    28] loss: 1.51846, train_accuracy: 47.07\n",
      "[14,    29] loss: 1.45792, train_accuracy: 48.05\n",
      "[14,    30] loss: 1.50709, train_accuracy: 43.55\n",
      "[14,    31] loss: 1.52875, train_accuracy: 45.12\n",
      "[14,    32] loss: 1.46528, train_accuracy: 47.66\n",
      "[14,    33] loss: 1.51936, train_accuracy: 44.92\n",
      "[14,    34] loss: 1.45061, train_accuracy: 46.68\n",
      "[14,    35] loss: 1.48989, train_accuracy: 49.41\n",
      "[14,    36] loss: 1.49393, train_accuracy: 45.31\n",
      "[14,    37] loss: 1.42268, train_accuracy: 51.76\n",
      "[14,    38] loss: 1.40740, train_accuracy: 49.41\n",
      "[14,    39] loss: 1.40326, train_accuracy: 50.00\n",
      "[14,    40] loss: 1.52771, train_accuracy: 43.16\n",
      "[14,    41] loss: 1.45089, train_accuracy: 46.68\n",
      "[14,    42] loss: 1.43323, train_accuracy: 49.41\n",
      "[14,    43] loss: 1.48004, train_accuracy: 45.70\n",
      "[14,    44] loss: 1.54906, train_accuracy: 44.92\n",
      "[14,    45] loss: 1.50867, train_accuracy: 44.14\n",
      "[14,    46] loss: 1.49487, train_accuracy: 46.88\n",
      "[14,    47] loss: 1.54307, train_accuracy: 44.73\n",
      "[14,    48] loss: 1.46320, train_accuracy: 48.24\n",
      "[14,    49] loss: 1.46149, train_accuracy: 49.02\n",
      "[14,    50] loss: 1.43190, train_accuracy: 48.44\n",
      "[14,    51] loss: 1.46143, train_accuracy: 49.22\n",
      "[14,    52] loss: 1.42636, train_accuracy: 50.98\n",
      "[14,    53] loss: 1.46858, train_accuracy: 46.68\n",
      "[14,    54] loss: 1.45883, train_accuracy: 48.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,    55] loss: 1.44709, train_accuracy: 48.24\n",
      "[14,    56] loss: 1.50530, train_accuracy: 48.24\n",
      "[14,    57] loss: 1.44458, train_accuracy: 50.00\n",
      "[14,    58] loss: 1.47619, train_accuracy: 48.24\n",
      "[14,    59] loss: 1.49019, train_accuracy: 47.07\n",
      "[14,    60] loss: 1.48553, train_accuracy: 45.70\n",
      "[14,    61] loss: 1.44604, train_accuracy: 48.44\n",
      "[14,    62] loss: 1.46936, train_accuracy: 49.22\n",
      "[14,    63] loss: 1.44202, train_accuracy: 49.61\n",
      "[14,    64] loss: 1.53113, train_accuracy: 44.73\n",
      "[14,    65] loss: 1.44732, train_accuracy: 49.80\n",
      "[14,    66] loss: 1.47255, train_accuracy: 46.48\n",
      "[14,    67] loss: 1.42806, train_accuracy: 48.83\n",
      "[14,    68] loss: 1.46718, train_accuracy: 47.85\n",
      "[14,    69] loss: 1.44826, train_accuracy: 48.24\n",
      "[14,    70] loss: 1.47909, train_accuracy: 44.14\n",
      "[14,    71] loss: 1.49136, train_accuracy: 47.46\n",
      "[14,    72] loss: 1.42486, train_accuracy: 48.83\n",
      "[14,    73] loss: 1.45955, train_accuracy: 48.05\n",
      "[14,    74] loss: 1.55220, train_accuracy: 43.75\n",
      "[14,    75] loss: 1.43143, train_accuracy: 48.24\n",
      "[14,    76] loss: 1.42536, train_accuracy: 49.02\n",
      "[14,    77] loss: 1.39094, train_accuracy: 49.41\n",
      "[14,    78] loss: 1.47496, train_accuracy: 48.05\n",
      "[14,    79] loss: 1.33910, train_accuracy: 51.37\n",
      "[14,    80] loss: 1.40408, train_accuracy: 49.41\n",
      "[14,    81] loss: 1.41532, train_accuracy: 48.44\n",
      "[14,    82] loss: 1.43090, train_accuracy: 48.44\n",
      "[14,    83] loss: 1.50089, train_accuracy: 45.51\n",
      "[14,    84] loss: 1.43507, train_accuracy: 48.05\n",
      "[14,    85] loss: 1.47031, train_accuracy: 46.88\n",
      "[14,    86] loss: 1.49440, train_accuracy: 44.53\n",
      "[14,    87] loss: 1.40935, train_accuracy: 49.22\n",
      "[14,    88] loss: 1.47587, train_accuracy: 45.12\n",
      "[14,    89] loss: 1.40578, train_accuracy: 47.46\n",
      "[14,    90] loss: 1.37438, train_accuracy: 50.00\n",
      "[14,    91] loss: 1.45237, train_accuracy: 49.61\n",
      "[14,    92] loss: 1.42345, train_accuracy: 47.66\n",
      "[14,    93] loss: 1.47806, train_accuracy: 47.66\n",
      "[14,    94] loss: 1.45746, train_accuracy: 50.20\n",
      "[14,    95] loss: 1.42441, train_accuracy: 48.24\n",
      "[14,    96] loss: 1.40538, train_accuracy: 51.56\n",
      "[14,    97] loss: 1.51957, train_accuracy: 44.34\n",
      "[14,    98] loss: 1.49973, train_accuracy: 43.45\n",
      "duration: 220 s - train loss: 1.46047 - train accuracy: 47.58 - validation loss: 1.17182 - validation accuracy: 58.41 \n",
      "[15,     1] loss: 1.53005, train_accuracy: 41.80\n",
      "[15,     2] loss: 1.42825, train_accuracy: 48.44\n",
      "[15,     3] loss: 1.40592, train_accuracy: 51.17\n",
      "[15,     4] loss: 1.43814, train_accuracy: 50.20\n",
      "[15,     5] loss: 1.50453, train_accuracy: 47.07\n",
      "[15,     6] loss: 1.45205, train_accuracy: 49.22\n",
      "[15,     7] loss: 1.48400, train_accuracy: 44.34\n",
      "[15,     8] loss: 1.38045, train_accuracy: 50.39\n",
      "[15,     9] loss: 1.47946, train_accuracy: 46.09\n",
      "[15,    10] loss: 1.35698, train_accuracy: 51.37\n",
      "[15,    11] loss: 1.47702, train_accuracy: 45.70\n",
      "[15,    12] loss: 1.45702, train_accuracy: 47.85\n",
      "[15,    13] loss: 1.46305, train_accuracy: 45.51\n",
      "[15,    14] loss: 1.49119, train_accuracy: 45.90\n",
      "[15,    15] loss: 1.43878, train_accuracy: 48.63\n",
      "[15,    16] loss: 1.35403, train_accuracy: 52.73\n",
      "[15,    17] loss: 1.52730, train_accuracy: 46.48\n",
      "[15,    18] loss: 1.43588, train_accuracy: 47.46\n",
      "[15,    19] loss: 1.46070, train_accuracy: 47.85\n",
      "[15,    20] loss: 1.50433, train_accuracy: 46.48\n",
      "[15,    21] loss: 1.48030, train_accuracy: 46.09\n",
      "[15,    22] loss: 1.51390, train_accuracy: 41.99\n",
      "[15,    23] loss: 1.41548, train_accuracy: 47.85\n",
      "[15,    24] loss: 1.40403, train_accuracy: 50.20\n",
      "[15,    25] loss: 1.50874, train_accuracy: 43.95\n",
      "[15,    26] loss: 1.47066, train_accuracy: 47.27\n",
      "[15,    27] loss: 1.48980, train_accuracy: 45.31\n",
      "[15,    28] loss: 1.43741, train_accuracy: 49.22\n",
      "[15,    29] loss: 1.52738, train_accuracy: 45.51\n",
      "[15,    30] loss: 1.42804, train_accuracy: 49.61\n",
      "[15,    31] loss: 1.46195, train_accuracy: 47.85\n",
      "[15,    32] loss: 1.49830, train_accuracy: 46.68\n",
      "[15,    33] loss: 1.46913, train_accuracy: 45.70\n",
      "[15,    34] loss: 1.42278, train_accuracy: 46.09\n",
      "[15,    35] loss: 1.40596, train_accuracy: 49.61\n",
      "[15,    36] loss: 1.44886, train_accuracy: 44.92\n",
      "[15,    37] loss: 1.53219, train_accuracy: 46.09\n",
      "[15,    38] loss: 1.60503, train_accuracy: 43.55\n",
      "[15,    39] loss: 1.41392, train_accuracy: 50.78\n",
      "[15,    40] loss: 1.51446, train_accuracy: 47.46\n",
      "[15,    41] loss: 1.49037, train_accuracy: 47.07\n",
      "[15,    42] loss: 1.41543, train_accuracy: 47.46\n",
      "[15,    43] loss: 1.47936, train_accuracy: 47.07\n",
      "[15,    44] loss: 1.44039, train_accuracy: 45.70\n",
      "[15,    45] loss: 1.45712, train_accuracy: 48.05\n",
      "[15,    46] loss: 1.47846, train_accuracy: 45.51\n",
      "[15,    47] loss: 1.43299, train_accuracy: 49.02\n",
      "[15,    48] loss: 1.36174, train_accuracy: 52.15\n",
      "[15,    49] loss: 1.45161, train_accuracy: 49.61\n",
      "[15,    50] loss: 1.44588, train_accuracy: 50.39\n",
      "[15,    51] loss: 1.48575, train_accuracy: 46.68\n",
      "[15,    52] loss: 1.45611, train_accuracy: 48.83\n",
      "[15,    53] loss: 1.44841, train_accuracy: 46.88\n",
      "[15,    54] loss: 1.41129, train_accuracy: 49.80\n",
      "[15,    55] loss: 1.49707, train_accuracy: 45.90\n",
      "[15,    56] loss: 1.48356, train_accuracy: 43.36\n",
      "[15,    57] loss: 1.40976, train_accuracy: 49.02\n",
      "[15,    58] loss: 1.46416, train_accuracy: 48.44\n",
      "[15,    59] loss: 1.40707, train_accuracy: 50.00\n",
      "[15,    60] loss: 1.50051, train_accuracy: 47.07\n",
      "[15,    61] loss: 1.42345, train_accuracy: 46.68\n",
      "[15,    62] loss: 1.42475, train_accuracy: 48.05\n",
      "[15,    63] loss: 1.48497, train_accuracy: 46.09\n",
      "[15,    64] loss: 1.47278, train_accuracy: 49.61\n",
      "[15,    65] loss: 1.50862, train_accuracy: 43.16\n",
      "[15,    66] loss: 1.47881, train_accuracy: 46.88\n",
      "[15,    67] loss: 1.48674, train_accuracy: 46.09\n",
      "[15,    68] loss: 1.43577, train_accuracy: 48.44\n",
      "[15,    69] loss: 1.43250, train_accuracy: 47.85\n",
      "[15,    70] loss: 1.40498, train_accuracy: 50.20\n",
      "[15,    71] loss: 1.43116, train_accuracy: 48.63\n",
      "[15,    72] loss: 1.47146, train_accuracy: 46.29\n",
      "[15,    73] loss: 1.54825, train_accuracy: 43.36\n",
      "[15,    74] loss: 1.44924, train_accuracy: 46.29\n",
      "[15,    75] loss: 1.40465, train_accuracy: 50.59\n",
      "[15,    76] loss: 1.49908, train_accuracy: 46.09\n",
      "[15,    77] loss: 1.51499, train_accuracy: 45.51\n",
      "[15,    78] loss: 1.47849, train_accuracy: 47.07\n",
      "[15,    79] loss: 1.49771, train_accuracy: 45.12\n",
      "[15,    80] loss: 1.35653, train_accuracy: 52.73\n",
      "[15,    81] loss: 1.41292, train_accuracy: 50.78\n",
      "[15,    82] loss: 1.42235, train_accuracy: 51.17\n",
      "[15,    83] loss: 1.42251, train_accuracy: 48.44\n",
      "[15,    84] loss: 1.47277, train_accuracy: 49.02\n",
      "[15,    85] loss: 1.32762, train_accuracy: 52.34\n",
      "[15,    86] loss: 1.47608, train_accuracy: 49.02\n",
      "[15,    87] loss: 1.42810, train_accuracy: 50.98\n",
      "[15,    88] loss: 1.50303, train_accuracy: 44.92\n",
      "[15,    89] loss: 1.44593, train_accuracy: 47.85\n",
      "[15,    90] loss: 1.43064, train_accuracy: 46.68\n",
      "[15,    91] loss: 1.46844, train_accuracy: 48.24\n",
      "[15,    92] loss: 1.48739, train_accuracy: 43.75\n",
      "[15,    93] loss: 1.40550, train_accuracy: 50.39\n",
      "[15,    94] loss: 1.46848, train_accuracy: 47.27\n",
      "[15,    95] loss: 1.41475, train_accuracy: 47.85\n",
      "[15,    96] loss: 1.41184, train_accuracy: 48.44\n",
      "[15,    97] loss: 1.50283, train_accuracy: 44.73\n",
      "[15,    98] loss: 1.41246, train_accuracy: 52.98\n",
      "duration: 262 s - train loss: 1.45564 - train accuracy: 47.63 - validation loss: 1.17526 - validation accuracy: 58.70 \n",
      "[16,     1] loss: 1.41718, train_accuracy: 47.46\n",
      "[16,     2] loss: 1.43465, train_accuracy: 47.07\n",
      "[16,     3] loss: 1.43506, train_accuracy: 47.85\n",
      "[16,     4] loss: 1.45733, train_accuracy: 48.44\n",
      "[16,     5] loss: 1.52719, train_accuracy: 45.51\n",
      "[16,     6] loss: 1.40286, train_accuracy: 49.80\n",
      "[16,     7] loss: 1.48426, train_accuracy: 46.68\n",
      "[16,     8] loss: 1.43499, train_accuracy: 48.44\n",
      "[16,     9] loss: 1.40500, train_accuracy: 49.61\n",
      "[16,    10] loss: 1.46892, train_accuracy: 47.07\n",
      "[16,    11] loss: 1.42237, train_accuracy: 50.39\n",
      "[16,    12] loss: 1.48152, train_accuracy: 43.55\n",
      "[16,    13] loss: 1.47245, train_accuracy: 50.00\n",
      "[16,    14] loss: 1.46412, train_accuracy: 47.27\n",
      "[16,    15] loss: 1.40791, train_accuracy: 48.44\n",
      "[16,    16] loss: 1.45517, train_accuracy: 48.05\n",
      "[16,    17] loss: 1.44323, train_accuracy: 50.20\n",
      "[16,    18] loss: 1.53072, train_accuracy: 47.46\n",
      "[16,    19] loss: 1.53849, train_accuracy: 45.51\n",
      "[16,    20] loss: 1.45860, train_accuracy: 48.24\n",
      "[16,    21] loss: 1.46941, train_accuracy: 47.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,    22] loss: 1.51048, train_accuracy: 45.70\n",
      "[16,    23] loss: 1.43940, train_accuracy: 49.22\n",
      "[16,    24] loss: 1.47919, train_accuracy: 49.02\n",
      "[16,    25] loss: 1.40866, train_accuracy: 47.85\n",
      "[16,    26] loss: 1.40640, train_accuracy: 50.98\n",
      "[16,    27] loss: 1.40383, train_accuracy: 49.61\n",
      "[16,    28] loss: 1.45240, train_accuracy: 49.22\n",
      "[16,    29] loss: 1.46592, train_accuracy: 48.05\n",
      "[16,    30] loss: 1.48962, train_accuracy: 44.53\n",
      "[16,    31] loss: 1.35672, train_accuracy: 49.41\n",
      "[16,    32] loss: 1.43077, train_accuracy: 48.24\n",
      "[16,    33] loss: 1.35557, train_accuracy: 53.52\n",
      "[16,    34] loss: 1.38205, train_accuracy: 49.61\n",
      "[16,    35] loss: 1.36384, train_accuracy: 50.78\n",
      "[16,    36] loss: 1.40021, train_accuracy: 48.63\n",
      "[16,    37] loss: 1.41831, train_accuracy: 49.02\n",
      "[16,    38] loss: 1.38891, train_accuracy: 49.02\n",
      "[16,    39] loss: 1.49110, train_accuracy: 46.48\n",
      "[16,    40] loss: 1.50119, train_accuracy: 45.12\n",
      "[16,    41] loss: 1.40189, train_accuracy: 49.80\n",
      "[16,    42] loss: 1.45657, train_accuracy: 47.27\n",
      "[16,    43] loss: 1.49316, train_accuracy: 44.53\n",
      "[16,    44] loss: 1.39482, train_accuracy: 48.63\n",
      "[16,    45] loss: 1.40081, train_accuracy: 49.41\n",
      "[16,    46] loss: 1.46155, train_accuracy: 47.27\n",
      "[16,    47] loss: 1.44912, train_accuracy: 48.05\n",
      "[16,    48] loss: 1.42126, train_accuracy: 48.44\n",
      "[16,    49] loss: 1.47092, train_accuracy: 45.12\n",
      "[16,    50] loss: 1.43144, train_accuracy: 49.80\n",
      "[16,    51] loss: 1.49947, train_accuracy: 46.09\n",
      "[16,    52] loss: 1.52783, train_accuracy: 47.66\n",
      "[16,    53] loss: 1.43759, train_accuracy: 50.20\n",
      "[16,    54] loss: 1.53866, train_accuracy: 43.75\n",
      "[16,    55] loss: 1.37307, train_accuracy: 52.73\n",
      "[16,    56] loss: 1.39806, train_accuracy: 50.20\n",
      "[16,    57] loss: 1.51920, train_accuracy: 47.46\n",
      "[16,    58] loss: 1.39768, train_accuracy: 49.41\n",
      "[16,    59] loss: 1.41395, train_accuracy: 49.41\n",
      "[16,    60] loss: 1.48031, train_accuracy: 50.59\n",
      "[16,    61] loss: 1.57960, train_accuracy: 47.27\n",
      "[16,    62] loss: 1.39189, train_accuracy: 46.09\n",
      "[16,    63] loss: 1.49533, train_accuracy: 46.29\n",
      "[16,    64] loss: 1.44336, train_accuracy: 47.85\n",
      "[16,    65] loss: 1.40026, train_accuracy: 50.39\n",
      "[16,    66] loss: 1.48851, train_accuracy: 47.46\n",
      "[16,    67] loss: 1.33356, train_accuracy: 54.69\n",
      "[16,    68] loss: 1.36795, train_accuracy: 51.95\n",
      "[16,    69] loss: 1.45505, train_accuracy: 50.00\n",
      "[16,    70] loss: 1.40574, train_accuracy: 48.83\n",
      "[16,    71] loss: 1.39061, train_accuracy: 50.59\n",
      "[16,    72] loss: 1.52682, train_accuracy: 45.70\n",
      "[16,    73] loss: 1.48333, train_accuracy: 48.44\n",
      "[16,    74] loss: 1.42610, train_accuracy: 48.24\n",
      "[16,    75] loss: 1.44763, train_accuracy: 48.63\n",
      "[16,    76] loss: 1.36719, train_accuracy: 51.17\n",
      "[16,    77] loss: 1.45634, train_accuracy: 48.44\n",
      "[16,    78] loss: 1.48810, train_accuracy: 47.46\n",
      "[16,    79] loss: 1.50495, train_accuracy: 47.07\n",
      "[16,    80] loss: 1.49301, train_accuracy: 47.27\n",
      "[16,    81] loss: 1.42971, train_accuracy: 48.24\n",
      "[16,    82] loss: 1.38208, train_accuracy: 49.02\n",
      "[16,    83] loss: 1.48329, train_accuracy: 47.07\n",
      "[16,    84] loss: 1.41895, train_accuracy: 48.44\n",
      "[16,    85] loss: 1.41983, train_accuracy: 48.63\n",
      "[16,    86] loss: 1.44654, train_accuracy: 50.59\n",
      "[16,    87] loss: 1.40709, train_accuracy: 51.95\n",
      "[16,    88] loss: 1.41659, train_accuracy: 47.85\n",
      "[16,    89] loss: 1.38000, train_accuracy: 49.02\n",
      "[16,    90] loss: 1.42355, train_accuracy: 48.05\n",
      "[16,    91] loss: 1.44439, train_accuracy: 50.00\n",
      "[16,    92] loss: 1.47439, train_accuracy: 46.48\n",
      "[16,    93] loss: 1.37106, train_accuracy: 51.17\n",
      "[16,    94] loss: 1.39735, train_accuracy: 50.00\n",
      "[16,    95] loss: 1.48549, train_accuracy: 46.09\n",
      "[16,    96] loss: 1.42756, train_accuracy: 50.20\n",
      "[16,    97] loss: 1.36991, train_accuracy: 51.76\n",
      "[16,    98] loss: 1.50801, train_accuracy: 43.15\n",
      "duration: 240 s - train loss: 1.44239 - train accuracy: 48.43 - validation loss: 1.14981 - validation accuracy: 59.53 \n",
      "[17,     1] loss: 1.46704, train_accuracy: 46.68\n",
      "[17,     2] loss: 1.41519, train_accuracy: 50.78\n",
      "[17,     3] loss: 1.46174, train_accuracy: 48.24\n",
      "[17,     4] loss: 1.41416, train_accuracy: 48.05\n",
      "[17,     5] loss: 1.45040, train_accuracy: 49.80\n",
      "[17,     6] loss: 1.37069, train_accuracy: 52.54\n",
      "[17,     7] loss: 1.39174, train_accuracy: 49.22\n",
      "[17,     8] loss: 1.52936, train_accuracy: 46.09\n",
      "[17,     9] loss: 1.44077, train_accuracy: 48.63\n",
      "[17,    10] loss: 1.38185, train_accuracy: 49.61\n",
      "[17,    11] loss: 1.43433, train_accuracy: 48.83\n",
      "[17,    12] loss: 1.46814, train_accuracy: 46.09\n",
      "[17,    13] loss: 1.41750, train_accuracy: 47.27\n",
      "[17,    14] loss: 1.42963, train_accuracy: 47.85\n",
      "[17,    15] loss: 1.36485, train_accuracy: 50.78\n",
      "[17,    16] loss: 1.47078, train_accuracy: 47.27\n",
      "[17,    17] loss: 1.39144, train_accuracy: 49.61\n",
      "[17,    18] loss: 1.41050, train_accuracy: 50.00\n",
      "[17,    19] loss: 1.50095, train_accuracy: 46.48\n",
      "[17,    20] loss: 1.41305, train_accuracy: 48.05\n",
      "[17,    21] loss: 1.46000, train_accuracy: 47.85\n",
      "[17,    22] loss: 1.40653, train_accuracy: 47.85\n",
      "[17,    23] loss: 1.39371, train_accuracy: 48.44\n",
      "[17,    24] loss: 1.46238, train_accuracy: 46.09\n",
      "[17,    25] loss: 1.35208, train_accuracy: 49.80\n",
      "[17,    26] loss: 1.44749, train_accuracy: 48.05\n",
      "[17,    27] loss: 1.47905, train_accuracy: 48.05\n",
      "[17,    28] loss: 1.50300, train_accuracy: 46.09\n",
      "[17,    29] loss: 1.43474, train_accuracy: 48.05\n",
      "[17,    30] loss: 1.40947, train_accuracy: 49.41\n",
      "[17,    31] loss: 1.42349, train_accuracy: 48.83\n",
      "[17,    32] loss: 1.43185, train_accuracy: 48.24\n",
      "[17,    33] loss: 1.44810, train_accuracy: 50.39\n",
      "[17,    34] loss: 1.43750, train_accuracy: 50.59\n",
      "[17,    35] loss: 1.46924, train_accuracy: 46.68\n",
      "[17,    36] loss: 1.42100, train_accuracy: 47.66\n",
      "[17,    37] loss: 1.43485, train_accuracy: 50.39\n",
      "[17,    38] loss: 1.49079, train_accuracy: 46.68\n",
      "[17,    39] loss: 1.48296, train_accuracy: 47.66\n",
      "[17,    40] loss: 1.43974, train_accuracy: 49.02\n",
      "[17,    41] loss: 1.44616, train_accuracy: 47.27\n",
      "[17,    42] loss: 1.35691, train_accuracy: 51.95\n",
      "[17,    43] loss: 1.47809, train_accuracy: 46.29\n",
      "[17,    44] loss: 1.47527, train_accuracy: 46.88\n",
      "[17,    45] loss: 1.43332, train_accuracy: 49.80\n",
      "[17,    46] loss: 1.35323, train_accuracy: 52.15\n",
      "[17,    47] loss: 1.37654, train_accuracy: 49.22\n",
      "[17,    48] loss: 1.34203, train_accuracy: 55.47\n",
      "[17,    49] loss: 1.35795, train_accuracy: 50.59\n",
      "[17,    50] loss: 1.44440, train_accuracy: 49.80\n",
      "[17,    51] loss: 1.42103, train_accuracy: 50.59\n",
      "[17,    52] loss: 1.43086, train_accuracy: 47.46\n",
      "[17,    53] loss: 1.46066, train_accuracy: 49.02\n",
      "[17,    54] loss: 1.46454, train_accuracy: 48.44\n",
      "[17,    55] loss: 1.37880, train_accuracy: 53.32\n",
      "[17,    56] loss: 1.43056, train_accuracy: 47.66\n",
      "[17,    57] loss: 1.37165, train_accuracy: 48.63\n",
      "[17,    58] loss: 1.43535, train_accuracy: 50.00\n",
      "[17,    59] loss: 1.38676, train_accuracy: 50.00\n",
      "[17,    60] loss: 1.42752, train_accuracy: 50.20\n",
      "[17,    61] loss: 1.40017, train_accuracy: 50.59\n",
      "[17,    62] loss: 1.42522, train_accuracy: 48.83\n",
      "[17,    63] loss: 1.47007, train_accuracy: 46.09\n",
      "[17,    64] loss: 1.34753, train_accuracy: 51.56\n",
      "[17,    65] loss: 1.41675, train_accuracy: 48.44\n",
      "[17,    66] loss: 1.50885, train_accuracy: 47.27\n",
      "[17,    67] loss: 1.42149, train_accuracy: 48.44\n",
      "[17,    68] loss: 1.42122, train_accuracy: 48.83\n",
      "[17,    69] loss: 1.37559, train_accuracy: 51.17\n",
      "[17,    70] loss: 1.39390, train_accuracy: 47.66\n",
      "[17,    71] loss: 1.33201, train_accuracy: 53.32\n",
      "[17,    72] loss: 1.50958, train_accuracy: 46.88\n",
      "[17,    73] loss: 1.42318, train_accuracy: 48.83\n",
      "[17,    74] loss: 1.46243, train_accuracy: 48.83\n",
      "[17,    75] loss: 1.43768, train_accuracy: 50.00\n",
      "[17,    76] loss: 1.43233, train_accuracy: 48.63\n",
      "[17,    77] loss: 1.41391, train_accuracy: 50.20\n",
      "[17,    78] loss: 1.44410, train_accuracy: 48.24\n",
      "[17,    79] loss: 1.42682, train_accuracy: 50.20\n",
      "[17,    80] loss: 1.46533, train_accuracy: 46.09\n",
      "[17,    81] loss: 1.41147, train_accuracy: 51.17\n",
      "[17,    82] loss: 1.51169, train_accuracy: 44.34\n",
      "[17,    83] loss: 1.38259, train_accuracy: 51.76\n",
      "[17,    84] loss: 1.46588, train_accuracy: 44.53\n",
      "[17,    85] loss: 1.39056, train_accuracy: 51.37\n",
      "[17,    86] loss: 1.50400, train_accuracy: 43.95\n",
      "[17,    87] loss: 1.41729, train_accuracy: 47.66\n",
      "[17,    88] loss: 1.43406, train_accuracy: 50.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17,    89] loss: 1.43328, train_accuracy: 49.22\n",
      "[17,    90] loss: 1.48703, train_accuracy: 45.51\n",
      "[17,    91] loss: 1.42229, train_accuracy: 45.70\n",
      "[17,    92] loss: 1.47844, train_accuracy: 44.53\n",
      "[17,    93] loss: 1.38381, train_accuracy: 49.80\n",
      "[17,    94] loss: 1.46234, train_accuracy: 48.63\n",
      "[17,    95] loss: 1.48034, train_accuracy: 46.29\n",
      "[17,    96] loss: 1.40007, train_accuracy: 47.27\n",
      "[17,    97] loss: 1.35713, train_accuracy: 51.56\n",
      "[17,    98] loss: 1.36535, train_accuracy: 50.60\n",
      "duration: 206 s - train loss: 1.42897 - train accuracy: 48.74 - validation loss: 1.16103 - validation accuracy: 59.60 \n",
      "[18,     1] loss: 1.49609, train_accuracy: 44.14\n",
      "[18,     2] loss: 1.41737, train_accuracy: 50.59\n",
      "[18,     3] loss: 1.37069, train_accuracy: 50.20\n",
      "[18,     4] loss: 1.40700, train_accuracy: 50.00\n",
      "[18,     5] loss: 1.46402, train_accuracy: 48.05\n",
      "[18,     6] loss: 1.44220, train_accuracy: 47.85\n",
      "[18,     7] loss: 1.49557, train_accuracy: 46.88\n",
      "[18,     8] loss: 1.42554, train_accuracy: 46.68\n",
      "[18,     9] loss: 1.34061, train_accuracy: 53.71\n",
      "[18,    10] loss: 1.44929, train_accuracy: 47.27\n",
      "[18,    11] loss: 1.45310, train_accuracy: 49.41\n",
      "[18,    12] loss: 1.40877, train_accuracy: 49.02\n",
      "[18,    13] loss: 1.42722, train_accuracy: 50.98\n",
      "[18,    14] loss: 1.41141, train_accuracy: 51.17\n",
      "[18,    15] loss: 1.43822, train_accuracy: 49.61\n",
      "[18,    16] loss: 1.37437, train_accuracy: 50.39\n",
      "[18,    17] loss: 1.38049, train_accuracy: 52.15\n",
      "[18,    18] loss: 1.33216, train_accuracy: 47.85\n",
      "[18,    19] loss: 1.42308, train_accuracy: 49.22\n",
      "[18,    20] loss: 1.45095, train_accuracy: 46.68\n",
      "[18,    21] loss: 1.42057, train_accuracy: 46.48\n",
      "[18,    22] loss: 1.52412, train_accuracy: 44.53\n",
      "[18,    23] loss: 1.36429, train_accuracy: 51.37\n",
      "[18,    24] loss: 1.42907, train_accuracy: 49.02\n",
      "[18,    25] loss: 1.49554, train_accuracy: 45.90\n",
      "[18,    26] loss: 1.35209, train_accuracy: 51.37\n",
      "[18,    27] loss: 1.41260, train_accuracy: 50.20\n",
      "[18,    28] loss: 1.37974, train_accuracy: 49.41\n",
      "[18,    29] loss: 1.43309, train_accuracy: 50.78\n",
      "[18,    30] loss: 1.45212, train_accuracy: 48.05\n",
      "[18,    31] loss: 1.38092, train_accuracy: 51.17\n",
      "[18,    32] loss: 1.44574, train_accuracy: 47.85\n",
      "[18,    33] loss: 1.47483, train_accuracy: 44.92\n",
      "[18,    34] loss: 1.42175, train_accuracy: 46.48\n",
      "[18,    35] loss: 1.40777, train_accuracy: 49.22\n",
      "[18,    36] loss: 1.37513, train_accuracy: 47.46\n",
      "[18,    37] loss: 1.53576, train_accuracy: 47.46\n",
      "[18,    38] loss: 1.42359, train_accuracy: 50.78\n",
      "[18,    39] loss: 1.44732, train_accuracy: 46.09\n",
      "[18,    40] loss: 1.38636, train_accuracy: 50.00\n",
      "[18,    41] loss: 1.38527, train_accuracy: 49.80\n",
      "[18,    42] loss: 1.45142, train_accuracy: 46.88\n",
      "[18,    43] loss: 1.42103, train_accuracy: 49.41\n",
      "[18,    44] loss: 1.54887, train_accuracy: 46.68\n",
      "[18,    45] loss: 1.37389, train_accuracy: 51.76\n",
      "[18,    46] loss: 1.39171, train_accuracy: 51.56\n",
      "[18,    47] loss: 1.42417, train_accuracy: 50.39\n",
      "[18,    48] loss: 1.37515, train_accuracy: 50.59\n",
      "[18,    49] loss: 1.46032, train_accuracy: 45.70\n",
      "[18,    50] loss: 1.43354, train_accuracy: 48.44\n",
      "[18,    51] loss: 1.51297, train_accuracy: 46.48\n",
      "[18,    52] loss: 1.36318, train_accuracy: 51.56\n",
      "[18,    53] loss: 1.42980, train_accuracy: 51.95\n",
      "[18,    54] loss: 1.32449, train_accuracy: 52.54\n",
      "[18,    55] loss: 1.41409, train_accuracy: 51.76\n",
      "[18,    56] loss: 1.39201, train_accuracy: 51.17\n",
      "[18,    57] loss: 1.46271, train_accuracy: 48.05\n",
      "[18,    58] loss: 1.41159, train_accuracy: 49.22\n",
      "[18,    59] loss: 1.40738, train_accuracy: 47.07\n",
      "[18,    60] loss: 1.40112, train_accuracy: 50.78\n",
      "[18,    61] loss: 1.44435, train_accuracy: 48.24\n",
      "[18,    62] loss: 1.36135, train_accuracy: 54.69\n",
      "[18,    63] loss: 1.45979, train_accuracy: 47.85\n",
      "[18,    64] loss: 1.39645, train_accuracy: 48.83\n",
      "[18,    65] loss: 1.46121, train_accuracy: 47.85\n",
      "[18,    66] loss: 1.41399, train_accuracy: 51.37\n",
      "[18,    67] loss: 1.41576, train_accuracy: 50.00\n",
      "[18,    68] loss: 1.36358, train_accuracy: 50.20\n",
      "[18,    69] loss: 1.39752, train_accuracy: 51.95\n",
      "[18,    70] loss: 1.44040, train_accuracy: 46.48\n",
      "[18,    71] loss: 1.49435, train_accuracy: 50.20\n",
      "[18,    72] loss: 1.38147, train_accuracy: 46.88\n",
      "[18,    73] loss: 1.46209, train_accuracy: 47.46\n",
      "[18,    74] loss: 1.33872, train_accuracy: 52.15\n",
      "[18,    75] loss: 1.44978, train_accuracy: 48.24\n",
      "[18,    76] loss: 1.31158, train_accuracy: 54.88\n",
      "[18,    77] loss: 1.43662, train_accuracy: 49.61\n",
      "[18,    78] loss: 1.42052, train_accuracy: 48.63\n",
      "[18,    79] loss: 1.32651, train_accuracy: 50.39\n",
      "[18,    80] loss: 1.39801, train_accuracy: 50.78\n",
      "[18,    81] loss: 1.32282, train_accuracy: 52.54\n",
      "[18,    82] loss: 1.49723, train_accuracy: 47.07\n",
      "[18,    83] loss: 1.36201, train_accuracy: 52.54\n",
      "[18,    84] loss: 1.40325, train_accuracy: 48.44\n",
      "[18,    85] loss: 1.40317, train_accuracy: 49.22\n",
      "[18,    86] loss: 1.47723, train_accuracy: 47.27\n",
      "[18,    87] loss: 1.40538, train_accuracy: 50.00\n",
      "[18,    88] loss: 1.43907, train_accuracy: 48.63\n",
      "[18,    89] loss: 1.41677, train_accuracy: 49.02\n",
      "[18,    90] loss: 1.39648, train_accuracy: 50.39\n",
      "[18,    91] loss: 1.39486, train_accuracy: 51.17\n",
      "[18,    92] loss: 1.42830, train_accuracy: 47.66\n",
      "[18,    93] loss: 1.42703, train_accuracy: 49.61\n",
      "[18,    94] loss: 1.35007, train_accuracy: 51.76\n",
      "[18,    95] loss: 1.36617, train_accuracy: 50.98\n",
      "[18,    96] loss: 1.44884, train_accuracy: 48.24\n",
      "[18,    97] loss: 1.41441, train_accuracy: 49.41\n",
      "[18,    98] loss: 1.46532, train_accuracy: 49.11\n",
      "duration: 204 s - train loss: 1.41783 - train accuracy: 49.31 - validation loss: 1.13711 - validation accuracy: 60.04 \n",
      "[19,     1] loss: 1.39289, train_accuracy: 50.59\n",
      "[19,     2] loss: 1.42371, train_accuracy: 45.31\n",
      "[19,     3] loss: 1.43664, train_accuracy: 47.66\n",
      "[19,     4] loss: 1.42290, train_accuracy: 50.00\n",
      "[19,     5] loss: 1.36723, train_accuracy: 50.00\n",
      "[19,     6] loss: 1.45025, train_accuracy: 47.27\n",
      "[19,     7] loss: 1.38480, train_accuracy: 51.37\n",
      "[19,     8] loss: 1.48843, train_accuracy: 45.70\n",
      "[19,     9] loss: 1.39130, train_accuracy: 49.41\n",
      "[19,    10] loss: 1.41223, train_accuracy: 50.20\n",
      "[19,    11] loss: 1.40737, train_accuracy: 51.37\n",
      "[19,    12] loss: 1.41687, train_accuracy: 47.66\n",
      "[19,    13] loss: 1.37535, train_accuracy: 49.61\n",
      "[19,    14] loss: 1.39309, train_accuracy: 50.20\n",
      "[19,    15] loss: 1.45955, train_accuracy: 46.48\n",
      "[19,    16] loss: 1.41441, train_accuracy: 50.98\n",
      "[19,    17] loss: 1.38792, train_accuracy: 49.80\n",
      "[19,    18] loss: 1.45862, train_accuracy: 49.61\n",
      "[19,    19] loss: 1.34702, train_accuracy: 52.73\n",
      "[19,    20] loss: 1.39297, train_accuracy: 51.76\n",
      "[19,    21] loss: 1.42666, train_accuracy: 50.59\n",
      "[19,    22] loss: 1.42164, train_accuracy: 49.22\n",
      "[19,    23] loss: 1.38006, train_accuracy: 51.56\n",
      "[19,    24] loss: 1.41045, train_accuracy: 48.44\n",
      "[19,    25] loss: 1.34702, train_accuracy: 52.54\n",
      "[19,    26] loss: 1.42734, train_accuracy: 47.85\n",
      "[19,    27] loss: 1.43800, train_accuracy: 49.22\n",
      "[19,    28] loss: 1.38753, train_accuracy: 46.68\n",
      "[19,    29] loss: 1.36305, train_accuracy: 51.95\n",
      "[19,    30] loss: 1.46102, train_accuracy: 47.66\n",
      "[19,    31] loss: 1.40777, train_accuracy: 49.02\n",
      "[19,    32] loss: 1.41543, train_accuracy: 49.61\n",
      "[19,    33] loss: 1.44483, train_accuracy: 50.78\n",
      "[19,    34] loss: 1.47319, train_accuracy: 48.05\n",
      "[19,    35] loss: 1.35871, train_accuracy: 52.93\n",
      "[19,    36] loss: 1.43534, train_accuracy: 51.17\n",
      "[19,    37] loss: 1.44700, train_accuracy: 49.61\n",
      "[19,    38] loss: 1.39519, train_accuracy: 49.22\n",
      "[19,    39] loss: 1.40371, train_accuracy: 50.20\n",
      "[19,    40] loss: 1.44522, train_accuracy: 48.44\n",
      "[19,    41] loss: 1.34072, train_accuracy: 50.98\n",
      "[19,    42] loss: 1.44453, train_accuracy: 46.09\n",
      "[19,    43] loss: 1.48042, train_accuracy: 46.48\n",
      "[19,    44] loss: 1.49238, train_accuracy: 45.90\n",
      "[19,    45] loss: 1.34618, train_accuracy: 53.52\n",
      "[19,    46] loss: 1.46443, train_accuracy: 47.07\n",
      "[19,    47] loss: 1.36977, train_accuracy: 50.98\n",
      "[19,    48] loss: 1.35935, train_accuracy: 51.56\n",
      "[19,    49] loss: 1.35859, train_accuracy: 51.37\n",
      "[19,    50] loss: 1.34685, train_accuracy: 49.80\n",
      "[19,    51] loss: 1.33258, train_accuracy: 52.34\n",
      "[19,    52] loss: 1.46946, train_accuracy: 47.46\n",
      "[19,    53] loss: 1.34920, train_accuracy: 49.02\n",
      "[19,    54] loss: 1.44155, train_accuracy: 49.22\n",
      "[19,    55] loss: 1.45347, train_accuracy: 47.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19,    56] loss: 1.41390, train_accuracy: 49.22\n",
      "[19,    57] loss: 1.32802, train_accuracy: 53.71\n",
      "[19,    58] loss: 1.51096, train_accuracy: 43.95\n",
      "[19,    59] loss: 1.42181, train_accuracy: 48.05\n",
      "[19,    60] loss: 1.38823, train_accuracy: 50.78\n",
      "[19,    61] loss: 1.42689, train_accuracy: 49.80\n",
      "[19,    62] loss: 1.33178, train_accuracy: 53.12\n",
      "[19,    63] loss: 1.47310, train_accuracy: 46.88\n",
      "[19,    64] loss: 1.38703, train_accuracy: 52.54\n",
      "[19,    65] loss: 1.40486, train_accuracy: 51.76\n",
      "[19,    66] loss: 1.51451, train_accuracy: 44.53\n",
      "[19,    67] loss: 1.38968, train_accuracy: 52.34\n",
      "[19,    68] loss: 1.44401, train_accuracy: 49.41\n",
      "[19,    69] loss: 1.37541, train_accuracy: 50.98\n",
      "[19,    70] loss: 1.40527, train_accuracy: 50.00\n",
      "[19,    71] loss: 1.38859, train_accuracy: 48.44\n",
      "[19,    72] loss: 1.47928, train_accuracy: 49.41\n",
      "[19,    73] loss: 1.40956, train_accuracy: 50.98\n",
      "[19,    74] loss: 1.50131, train_accuracy: 48.44\n",
      "[19,    75] loss: 1.37557, train_accuracy: 52.34\n",
      "[19,    76] loss: 1.44010, train_accuracy: 47.85\n",
      "[19,    77] loss: 1.44611, train_accuracy: 46.48\n",
      "[19,    78] loss: 1.47239, train_accuracy: 46.48\n",
      "[19,    79] loss: 1.36847, train_accuracy: 52.15\n",
      "[19,    80] loss: 1.29645, train_accuracy: 52.34\n",
      "[19,    81] loss: 1.38935, train_accuracy: 50.20\n",
      "[19,    82] loss: 1.42107, train_accuracy: 48.24\n",
      "[19,    83] loss: 1.43501, train_accuracy: 47.46\n",
      "[19,    84] loss: 1.38836, train_accuracy: 51.56\n",
      "[19,    85] loss: 1.38612, train_accuracy: 51.17\n",
      "[19,    86] loss: 1.29895, train_accuracy: 56.05\n",
      "[19,    87] loss: 1.41168, train_accuracy: 49.80\n",
      "[19,    88] loss: 1.37743, train_accuracy: 50.59\n",
      "[19,    89] loss: 1.43320, train_accuracy: 51.17\n",
      "[19,    90] loss: 1.37922, train_accuracy: 51.56\n",
      "[19,    91] loss: 1.44376, train_accuracy: 47.85\n",
      "[19,    92] loss: 1.29966, train_accuracy: 52.73\n",
      "[19,    93] loss: 1.37826, train_accuracy: 52.34\n",
      "[19,    94] loss: 1.45430, train_accuracy: 51.95\n",
      "[19,    95] loss: 1.40134, train_accuracy: 51.37\n",
      "[19,    96] loss: 1.39586, train_accuracy: 51.56\n",
      "[19,    97] loss: 1.44107, train_accuracy: 46.88\n",
      "[19,    98] loss: 1.49889, train_accuracy: 48.81\n",
      "duration: 204 s - train loss: 1.41009 - train accuracy: 49.74 - validation loss: 1.11877 - validation accuracy: 60.85 \n",
      "[20,     1] loss: 1.48768, train_accuracy: 49.80\n",
      "[20,     2] loss: 1.35290, train_accuracy: 50.00\n",
      "[20,     3] loss: 1.38256, train_accuracy: 50.20\n",
      "[20,     4] loss: 1.47051, train_accuracy: 49.22\n",
      "[20,     5] loss: 1.36121, train_accuracy: 50.20\n",
      "[20,     6] loss: 1.45594, train_accuracy: 46.68\n",
      "[20,     7] loss: 1.43662, train_accuracy: 48.24\n",
      "[20,     8] loss: 1.32385, train_accuracy: 54.49\n",
      "[20,     9] loss: 1.43471, train_accuracy: 50.00\n",
      "[20,    10] loss: 1.40725, train_accuracy: 49.02\n",
      "[20,    11] loss: 1.36009, train_accuracy: 50.78\n",
      "[20,    12] loss: 1.39324, train_accuracy: 51.56\n",
      "[20,    13] loss: 1.49177, train_accuracy: 45.31\n",
      "[20,    14] loss: 1.48331, train_accuracy: 47.46\n",
      "[20,    15] loss: 1.42096, train_accuracy: 49.41\n",
      "[20,    16] loss: 1.42251, train_accuracy: 49.22\n",
      "[20,    17] loss: 1.44328, train_accuracy: 47.66\n",
      "[20,    18] loss: 1.47278, train_accuracy: 45.90\n",
      "[20,    19] loss: 1.39268, train_accuracy: 47.85\n",
      "[20,    20] loss: 1.39283, train_accuracy: 51.17\n",
      "[20,    21] loss: 1.40560, train_accuracy: 48.44\n",
      "[20,    22] loss: 1.35045, train_accuracy: 52.73\n",
      "[20,    23] loss: 1.41953, train_accuracy: 50.59\n",
      "[20,    24] loss: 1.42343, train_accuracy: 49.61\n",
      "[20,    25] loss: 1.38213, train_accuracy: 50.39\n",
      "[20,    26] loss: 1.36451, train_accuracy: 51.37\n",
      "[20,    27] loss: 1.37978, train_accuracy: 49.02\n",
      "[20,    28] loss: 1.38456, train_accuracy: 49.02\n",
      "[20,    29] loss: 1.45956, train_accuracy: 49.22\n",
      "[20,    30] loss: 1.39686, train_accuracy: 51.95\n",
      "[20,    31] loss: 1.42582, train_accuracy: 47.66\n",
      "[20,    32] loss: 1.39792, train_accuracy: 51.76\n",
      "[20,    33] loss: 1.39526, train_accuracy: 52.15\n",
      "[20,    34] loss: 1.43423, train_accuracy: 49.80\n",
      "[20,    35] loss: 1.36785, train_accuracy: 51.95\n",
      "[20,    36] loss: 1.39886, train_accuracy: 49.02\n",
      "[20,    37] loss: 1.34352, train_accuracy: 50.78\n",
      "[20,    38] loss: 1.37825, train_accuracy: 49.22\n",
      "[20,    39] loss: 1.41888, train_accuracy: 47.27\n",
      "[20,    40] loss: 1.46700, train_accuracy: 48.44\n",
      "[20,    41] loss: 1.47215, train_accuracy: 46.09\n",
      "[20,    42] loss: 1.37203, train_accuracy: 51.37\n",
      "[20,    43] loss: 1.53327, train_accuracy: 44.34\n",
      "[20,    44] loss: 1.35153, train_accuracy: 50.78\n",
      "[20,    45] loss: 1.36200, train_accuracy: 50.78\n",
      "[20,    46] loss: 1.44090, train_accuracy: 47.85\n",
      "[20,    47] loss: 1.51453, train_accuracy: 46.68\n",
      "[20,    48] loss: 1.32470, train_accuracy: 51.37\n",
      "[20,    49] loss: 1.37437, train_accuracy: 50.00\n",
      "[20,    50] loss: 1.43034, train_accuracy: 47.27\n",
      "[20,    51] loss: 1.43301, train_accuracy: 50.20\n",
      "[20,    52] loss: 1.29381, train_accuracy: 54.69\n",
      "[20,    53] loss: 1.46348, train_accuracy: 47.27\n",
      "[20,    54] loss: 1.46687, train_accuracy: 48.24\n",
      "[20,    55] loss: 1.44553, train_accuracy: 49.22\n",
      "[20,    56] loss: 1.43074, train_accuracy: 50.39\n",
      "[20,    57] loss: 1.43692, train_accuracy: 49.02\n",
      "[20,    58] loss: 1.38840, train_accuracy: 49.80\n",
      "[20,    59] loss: 1.45139, train_accuracy: 46.29\n",
      "[20,    60] loss: 1.43544, train_accuracy: 46.68\n",
      "[20,    61] loss: 1.38160, train_accuracy: 50.39\n",
      "[20,    62] loss: 1.38032, train_accuracy: 50.59\n",
      "[20,    63] loss: 1.43709, train_accuracy: 50.78\n",
      "[20,    64] loss: 1.40575, train_accuracy: 51.17\n",
      "[20,    65] loss: 1.31671, train_accuracy: 53.52\n",
      "[20,    66] loss: 1.37204, train_accuracy: 53.32\n",
      "[20,    67] loss: 1.33497, train_accuracy: 51.37\n",
      "[20,    68] loss: 1.43874, train_accuracy: 49.61\n",
      "[20,    69] loss: 1.40925, train_accuracy: 49.02\n",
      "[20,    70] loss: 1.42590, train_accuracy: 50.00\n",
      "[20,    71] loss: 1.32895, train_accuracy: 49.80\n",
      "[20,    72] loss: 1.41323, train_accuracy: 52.54\n",
      "[20,    73] loss: 1.43420, train_accuracy: 49.41\n",
      "[20,    74] loss: 1.39700, train_accuracy: 48.44\n",
      "[20,    75] loss: 1.43052, train_accuracy: 50.78\n",
      "[20,    76] loss: 1.48941, train_accuracy: 48.44\n",
      "[20,    77] loss: 1.41880, train_accuracy: 50.39\n",
      "[20,    78] loss: 1.41682, train_accuracy: 50.20\n",
      "[20,    79] loss: 1.42280, train_accuracy: 50.20\n",
      "[20,    80] loss: 1.36384, train_accuracy: 49.80\n",
      "[20,    81] loss: 1.47670, train_accuracy: 47.27\n",
      "[20,    82] loss: 1.42481, train_accuracy: 48.63\n",
      "[20,    83] loss: 1.38973, train_accuracy: 49.41\n",
      "[20,    84] loss: 1.42886, train_accuracy: 49.80\n",
      "[20,    85] loss: 1.42206, train_accuracy: 49.61\n",
      "[20,    86] loss: 1.44388, train_accuracy: 49.22\n",
      "[20,    87] loss: 1.39781, train_accuracy: 51.56\n",
      "[20,    88] loss: 1.38066, train_accuracy: 50.59\n",
      "[20,    89] loss: 1.40207, train_accuracy: 51.56\n",
      "[20,    90] loss: 1.34582, train_accuracy: 50.98\n",
      "[20,    91] loss: 1.41163, train_accuracy: 48.63\n",
      "[20,    92] loss: 1.43387, train_accuracy: 49.41\n",
      "[20,    93] loss: 1.38067, train_accuracy: 49.22\n",
      "[20,    94] loss: 1.41611, train_accuracy: 47.07\n",
      "[20,    95] loss: 1.37294, train_accuracy: 50.59\n",
      "[20,    96] loss: 1.40005, train_accuracy: 48.83\n",
      "[20,    97] loss: 1.47406, train_accuracy: 47.46\n",
      "[20,    98] loss: 1.38144, train_accuracy: 52.38\n",
      "duration: 204 s - train loss: 1.41024 - train accuracy: 49.64 - validation loss: 1.10647 - validation accuracy: 61.59 \n",
      "[21,     1] loss: 1.38777, train_accuracy: 49.02\n",
      "[21,     2] loss: 1.46437, train_accuracy: 45.51\n",
      "[21,     3] loss: 1.31616, train_accuracy: 51.17\n",
      "[21,     4] loss: 1.41504, train_accuracy: 51.37\n",
      "[21,     5] loss: 1.31874, train_accuracy: 53.52\n",
      "[21,     6] loss: 1.37810, train_accuracy: 52.93\n",
      "[21,     7] loss: 1.44749, train_accuracy: 47.27\n",
      "[21,     8] loss: 1.34649, train_accuracy: 53.71\n",
      "[21,     9] loss: 1.42506, train_accuracy: 49.02\n",
      "[21,    10] loss: 1.34786, train_accuracy: 51.76\n",
      "[21,    11] loss: 1.44229, train_accuracy: 48.63\n",
      "[21,    12] loss: 1.40605, train_accuracy: 49.22\n",
      "[21,    13] loss: 1.28814, train_accuracy: 55.27\n",
      "[21,    14] loss: 1.36118, train_accuracy: 50.39\n",
      "[21,    15] loss: 1.37658, train_accuracy: 52.54\n",
      "[21,    16] loss: 1.44957, train_accuracy: 52.15\n",
      "[21,    17] loss: 1.40088, train_accuracy: 49.22\n",
      "[21,    18] loss: 1.39327, train_accuracy: 50.98\n",
      "[21,    19] loss: 1.50658, train_accuracy: 48.83\n",
      "[21,    20] loss: 1.41313, train_accuracy: 48.44\n",
      "[21,    21] loss: 1.40742, train_accuracy: 49.80\n",
      "[21,    22] loss: 1.34674, train_accuracy: 52.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21,    23] loss: 1.39318, train_accuracy: 51.56\n",
      "[21,    24] loss: 1.34784, train_accuracy: 51.17\n",
      "[21,    25] loss: 1.36889, train_accuracy: 49.80\n",
      "[21,    26] loss: 1.31355, train_accuracy: 53.32\n",
      "[21,    27] loss: 1.50495, train_accuracy: 44.53\n",
      "[21,    28] loss: 1.37583, train_accuracy: 50.78\n",
      "[21,    29] loss: 1.42740, train_accuracy: 50.59\n",
      "[21,    30] loss: 1.40718, train_accuracy: 50.59\n",
      "[21,    31] loss: 1.38395, train_accuracy: 49.80\n",
      "[21,    32] loss: 1.39858, train_accuracy: 50.78\n",
      "[21,    33] loss: 1.36348, train_accuracy: 51.37\n",
      "[21,    34] loss: 1.41605, train_accuracy: 49.41\n",
      "[21,    35] loss: 1.37295, train_accuracy: 52.73\n",
      "[21,    36] loss: 1.53956, train_accuracy: 44.73\n",
      "[21,    37] loss: 1.35611, train_accuracy: 49.02\n",
      "[21,    38] loss: 1.39824, train_accuracy: 49.41\n",
      "[21,    39] loss: 1.37087, train_accuracy: 50.39\n",
      "[21,    40] loss: 1.44813, train_accuracy: 48.83\n",
      "[21,    41] loss: 1.37327, train_accuracy: 49.80\n",
      "[21,    42] loss: 1.37024, train_accuracy: 48.24\n",
      "[21,    43] loss: 1.36482, train_accuracy: 52.15\n",
      "[21,    44] loss: 1.31183, train_accuracy: 52.34\n",
      "[21,    45] loss: 1.43202, train_accuracy: 49.80\n",
      "[21,    46] loss: 1.39772, train_accuracy: 50.39\n",
      "[21,    47] loss: 1.38368, train_accuracy: 50.20\n",
      "[21,    48] loss: 1.32560, train_accuracy: 54.49\n",
      "[21,    49] loss: 1.44423, train_accuracy: 49.80\n",
      "[21,    50] loss: 1.41722, train_accuracy: 50.00\n",
      "[21,    51] loss: 1.39616, train_accuracy: 48.05\n",
      "[21,    52] loss: 1.46228, train_accuracy: 48.24\n",
      "[21,    53] loss: 1.43606, train_accuracy: 49.02\n",
      "[21,    54] loss: 1.37711, train_accuracy: 52.54\n",
      "[21,    55] loss: 1.41441, train_accuracy: 47.27\n",
      "[21,    56] loss: 1.38029, train_accuracy: 51.17\n",
      "[21,    57] loss: 1.41362, train_accuracy: 47.07\n",
      "[21,    58] loss: 1.43652, train_accuracy: 47.07\n",
      "[21,    59] loss: 1.42121, train_accuracy: 51.17\n",
      "[21,    60] loss: 1.43284, train_accuracy: 47.85\n",
      "[21,    61] loss: 1.40881, train_accuracy: 50.59\n",
      "[21,    62] loss: 1.42975, train_accuracy: 48.63\n",
      "[21,    63] loss: 1.30027, train_accuracy: 52.73\n",
      "[21,    64] loss: 1.30837, train_accuracy: 56.84\n",
      "[21,    65] loss: 1.41863, train_accuracy: 50.00\n",
      "[21,    66] loss: 1.41715, train_accuracy: 48.05\n",
      "[21,    67] loss: 1.41873, train_accuracy: 49.02\n",
      "[21,    68] loss: 1.39766, train_accuracy: 49.41\n",
      "[21,    69] loss: 1.39460, train_accuracy: 48.63\n",
      "[21,    70] loss: 1.37542, train_accuracy: 51.76\n",
      "[21,    71] loss: 1.42671, train_accuracy: 48.24\n",
      "[21,    72] loss: 1.37437, train_accuracy: 52.73\n",
      "[21,    73] loss: 1.41837, train_accuracy: 50.00\n",
      "[21,    74] loss: 1.44281, train_accuracy: 50.20\n",
      "[21,    75] loss: 1.42057, train_accuracy: 51.37\n",
      "[21,    76] loss: 1.43606, train_accuracy: 47.85\n",
      "[21,    77] loss: 1.41112, train_accuracy: 48.63\n",
      "[21,    78] loss: 1.32752, train_accuracy: 51.95\n",
      "[21,    79] loss: 1.37512, train_accuracy: 48.24\n",
      "[21,    80] loss: 1.39057, train_accuracy: 51.17\n",
      "[21,    81] loss: 1.40400, train_accuracy: 48.83\n",
      "[21,    82] loss: 1.46135, train_accuracy: 47.85\n",
      "[21,    83] loss: 1.32931, train_accuracy: 51.76\n",
      "[21,    84] loss: 1.41403, train_accuracy: 48.05\n",
      "[21,    85] loss: 1.43863, train_accuracy: 50.20\n",
      "[21,    86] loss: 1.47414, train_accuracy: 47.27\n",
      "[21,    87] loss: 1.38987, train_accuracy: 50.59\n",
      "[21,    88] loss: 1.42816, train_accuracy: 49.22\n",
      "[21,    89] loss: 1.38412, train_accuracy: 52.54\n",
      "[21,    90] loss: 1.38030, train_accuracy: 50.00\n",
      "[21,    91] loss: 1.37902, train_accuracy: 51.95\n",
      "[21,    92] loss: 1.42241, train_accuracy: 48.05\n",
      "[21,    93] loss: 1.42046, train_accuracy: 50.00\n",
      "[21,    94] loss: 1.41341, train_accuracy: 50.59\n",
      "[21,    95] loss: 1.36573, train_accuracy: 50.20\n",
      "[21,    96] loss: 1.46940, train_accuracy: 47.27\n",
      "[21,    97] loss: 1.34048, train_accuracy: 54.69\n",
      "[21,    98] loss: 1.37147, train_accuracy: 50.00\n",
      "duration: 213 s - train loss: 1.39792 - train accuracy: 50.14 - validation loss: 1.09771 - validation accuracy: 61.67 \n",
      "[22,     1] loss: 1.39559, train_accuracy: 52.73\n",
      "[22,     2] loss: 1.30739, train_accuracy: 54.30\n",
      "[22,     3] loss: 1.32401, train_accuracy: 51.56\n",
      "[22,     4] loss: 1.36745, train_accuracy: 50.39\n",
      "[22,     5] loss: 1.39698, train_accuracy: 48.63\n",
      "[22,     6] loss: 1.41452, train_accuracy: 48.63\n",
      "[22,     7] loss: 1.40357, train_accuracy: 46.68\n",
      "[22,     8] loss: 1.36091, train_accuracy: 51.37\n",
      "[22,     9] loss: 1.36059, train_accuracy: 50.39\n",
      "[22,    10] loss: 1.40546, train_accuracy: 49.22\n",
      "[22,    11] loss: 1.30953, train_accuracy: 53.91\n",
      "[22,    12] loss: 1.31174, train_accuracy: 55.86\n",
      "[22,    13] loss: 1.40977, train_accuracy: 45.90\n",
      "[22,    14] loss: 1.41040, train_accuracy: 51.37\n",
      "[22,    15] loss: 1.42021, train_accuracy: 50.78\n",
      "[22,    16] loss: 1.37885, train_accuracy: 51.56\n",
      "[22,    17] loss: 1.36911, train_accuracy: 49.61\n",
      "[22,    18] loss: 1.34583, train_accuracy: 51.95\n",
      "[22,    19] loss: 1.34490, train_accuracy: 49.61\n",
      "[22,    20] loss: 1.41277, train_accuracy: 50.00\n",
      "[22,    21] loss: 1.37338, train_accuracy: 52.15\n",
      "[22,    22] loss: 1.40627, train_accuracy: 52.15\n",
      "[22,    23] loss: 1.37081, train_accuracy: 50.20\n",
      "[22,    24] loss: 1.34995, train_accuracy: 51.95\n",
      "[22,    25] loss: 1.45326, train_accuracy: 50.20\n",
      "[22,    26] loss: 1.32247, train_accuracy: 53.32\n",
      "[22,    27] loss: 1.45985, train_accuracy: 46.88\n",
      "[22,    28] loss: 1.37678, train_accuracy: 50.98\n",
      "[22,    29] loss: 1.35420, train_accuracy: 51.37\n",
      "[22,    30] loss: 1.30722, train_accuracy: 54.88\n",
      "[22,    31] loss: 1.40027, train_accuracy: 50.00\n",
      "[22,    32] loss: 1.42292, train_accuracy: 47.07\n",
      "[22,    33] loss: 1.37162, train_accuracy: 50.39\n",
      "[22,    34] loss: 1.40963, train_accuracy: 49.41\n",
      "[22,    35] loss: 1.36692, train_accuracy: 48.44\n",
      "[22,    36] loss: 1.39328, train_accuracy: 47.85\n",
      "[22,    37] loss: 1.36916, train_accuracy: 49.22\n",
      "[22,    38] loss: 1.46033, train_accuracy: 47.27\n",
      "[22,    39] loss: 1.31835, train_accuracy: 53.71\n",
      "[22,    40] loss: 1.44843, train_accuracy: 46.29\n",
      "[22,    41] loss: 1.34710, train_accuracy: 50.39\n",
      "[22,    42] loss: 1.34803, train_accuracy: 52.15\n",
      "[22,    43] loss: 1.40530, train_accuracy: 51.95\n",
      "[22,    44] loss: 1.37874, train_accuracy: 52.34\n",
      "[22,    45] loss: 1.38368, train_accuracy: 51.17\n",
      "[22,    46] loss: 1.41238, train_accuracy: 46.68\n",
      "[22,    47] loss: 1.34368, train_accuracy: 49.41\n",
      "[22,    48] loss: 1.31838, train_accuracy: 52.73\n",
      "[22,    49] loss: 1.43610, train_accuracy: 49.02\n",
      "[22,    50] loss: 1.42279, train_accuracy: 49.02\n",
      "[22,    51] loss: 1.40935, train_accuracy: 50.59\n",
      "[22,    52] loss: 1.40267, train_accuracy: 49.22\n",
      "[22,    53] loss: 1.32037, train_accuracy: 52.15\n",
      "[22,    54] loss: 1.41874, train_accuracy: 48.63\n",
      "[22,    55] loss: 1.35954, train_accuracy: 51.95\n",
      "[22,    56] loss: 1.41459, train_accuracy: 48.63\n",
      "[22,    57] loss: 1.37096, train_accuracy: 49.61\n",
      "[22,    58] loss: 1.44124, train_accuracy: 51.56\n",
      "[22,    59] loss: 1.34571, train_accuracy: 52.34\n",
      "[22,    60] loss: 1.47539, train_accuracy: 46.48\n",
      "[22,    61] loss: 1.29235, train_accuracy: 53.32\n",
      "[22,    62] loss: 1.42059, train_accuracy: 46.09\n",
      "[22,    63] loss: 1.43097, train_accuracy: 49.22\n",
      "[22,    64] loss: 1.43730, train_accuracy: 47.66\n",
      "[22,    65] loss: 1.45058, train_accuracy: 50.78\n",
      "[22,    66] loss: 1.37521, train_accuracy: 49.02\n",
      "[22,    67] loss: 1.30542, train_accuracy: 52.34\n",
      "[22,    68] loss: 1.30591, train_accuracy: 52.93\n",
      "[22,    69] loss: 1.36174, train_accuracy: 53.52\n",
      "[22,    70] loss: 1.37441, train_accuracy: 51.95\n",
      "[22,    71] loss: 1.37770, train_accuracy: 50.59\n",
      "[22,    72] loss: 1.50896, train_accuracy: 45.31\n",
      "[22,    73] loss: 1.40219, train_accuracy: 50.00\n",
      "[22,    74] loss: 1.30549, train_accuracy: 52.34\n",
      "[22,    75] loss: 1.31277, train_accuracy: 53.12\n",
      "[22,    76] loss: 1.37412, train_accuracy: 51.17\n",
      "[22,    77] loss: 1.32591, train_accuracy: 50.00\n",
      "[22,    78] loss: 1.39510, train_accuracy: 49.41\n",
      "[22,    79] loss: 1.34261, train_accuracy: 53.32\n",
      "[22,    80] loss: 1.38134, train_accuracy: 50.98\n",
      "[22,    81] loss: 1.35523, train_accuracy: 52.34\n",
      "[22,    82] loss: 1.39511, train_accuracy: 51.17\n",
      "[22,    83] loss: 1.36068, train_accuracy: 51.37\n",
      "[22,    84] loss: 1.51315, train_accuracy: 47.27\n",
      "[22,    85] loss: 1.37888, train_accuracy: 51.56\n",
      "[22,    86] loss: 1.39820, train_accuracy: 50.39\n",
      "[22,    87] loss: 1.37831, train_accuracy: 54.30\n",
      "[22,    88] loss: 1.48777, train_accuracy: 42.97\n",
      "[22,    89] loss: 1.47857, train_accuracy: 46.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22,    90] loss: 1.37420, train_accuracy: 51.56\n",
      "[22,    91] loss: 1.43241, train_accuracy: 47.27\n",
      "[22,    92] loss: 1.37250, train_accuracy: 51.56\n",
      "[22,    93] loss: 1.41650, train_accuracy: 48.05\n",
      "[22,    94] loss: 1.35650, train_accuracy: 52.34\n",
      "[22,    95] loss: 1.34330, train_accuracy: 54.88\n",
      "[22,    96] loss: 1.37999, train_accuracy: 49.02\n",
      "[22,    97] loss: 1.34616, train_accuracy: 49.61\n",
      "[22,    98] loss: 1.53462, train_accuracy: 46.13\n",
      "duration: 247 s - train loss: 1.38492 - train accuracy: 50.37 - validation loss: 1.09739 - validation accuracy: 61.75 \n",
      "[23,     1] loss: 1.37841, train_accuracy: 50.20\n",
      "[23,     2] loss: 1.36544, train_accuracy: 52.15\n",
      "[23,     3] loss: 1.34147, train_accuracy: 53.91\n",
      "[23,     4] loss: 1.37322, train_accuracy: 51.76\n",
      "[23,     5] loss: 1.39601, train_accuracy: 52.54\n",
      "[23,     6] loss: 1.35780, train_accuracy: 52.54\n",
      "[23,     7] loss: 1.46345, train_accuracy: 48.63\n",
      "[23,     8] loss: 1.40890, train_accuracy: 49.41\n",
      "[23,     9] loss: 1.30874, train_accuracy: 53.52\n",
      "[23,    10] loss: 1.44312, train_accuracy: 46.09\n",
      "[23,    11] loss: 1.40497, train_accuracy: 51.56\n",
      "[23,    12] loss: 1.44117, train_accuracy: 44.34\n",
      "[23,    13] loss: 1.39684, train_accuracy: 51.37\n",
      "[23,    14] loss: 1.38444, train_accuracy: 47.85\n",
      "[23,    15] loss: 1.41346, train_accuracy: 49.80\n",
      "[23,    16] loss: 1.40414, train_accuracy: 48.44\n",
      "[23,    17] loss: 1.39057, train_accuracy: 51.17\n",
      "[23,    18] loss: 1.40928, train_accuracy: 51.76\n",
      "[23,    19] loss: 1.40136, train_accuracy: 49.80\n",
      "[23,    20] loss: 1.36250, train_accuracy: 51.37\n",
      "[23,    21] loss: 1.41668, train_accuracy: 51.37\n",
      "[23,    22] loss: 1.41867, train_accuracy: 48.44\n",
      "[23,    23] loss: 1.46949, train_accuracy: 46.29\n",
      "[23,    24] loss: 1.40334, train_accuracy: 50.59\n",
      "[23,    25] loss: 1.33341, train_accuracy: 51.37\n",
      "[23,    26] loss: 1.37185, train_accuracy: 50.20\n",
      "[23,    27] loss: 1.40538, train_accuracy: 47.46\n",
      "[23,    28] loss: 1.45233, train_accuracy: 45.70\n",
      "[23,    29] loss: 1.43961, train_accuracy: 49.22\n",
      "[23,    30] loss: 1.38625, train_accuracy: 50.98\n",
      "[23,    31] loss: 1.26331, train_accuracy: 54.69\n",
      "[23,    32] loss: 1.37381, train_accuracy: 49.80\n",
      "[23,    33] loss: 1.45313, train_accuracy: 49.61\n",
      "[23,    34] loss: 1.35876, train_accuracy: 52.93\n",
      "[23,    35] loss: 1.38474, train_accuracy: 50.20\n",
      "[23,    36] loss: 1.34315, train_accuracy: 51.76\n",
      "[23,    37] loss: 1.30795, train_accuracy: 54.10\n",
      "[23,    38] loss: 1.38895, train_accuracy: 52.15\n",
      "[23,    39] loss: 1.33722, train_accuracy: 51.95\n",
      "[23,    40] loss: 1.34956, train_accuracy: 52.15\n",
      "[23,    41] loss: 1.42842, train_accuracy: 50.20\n",
      "[23,    42] loss: 1.36431, train_accuracy: 51.95\n",
      "[23,    43] loss: 1.40797, train_accuracy: 47.85\n",
      "[23,    44] loss: 1.40323, train_accuracy: 49.80\n",
      "[23,    45] loss: 1.40069, train_accuracy: 50.78\n",
      "[23,    46] loss: 1.45047, train_accuracy: 52.93\n",
      "[23,    47] loss: 1.39860, train_accuracy: 51.17\n",
      "[23,    48] loss: 1.34376, train_accuracy: 51.95\n",
      "[23,    49] loss: 1.39954, train_accuracy: 50.98\n",
      "[23,    50] loss: 1.42265, train_accuracy: 46.88\n",
      "[23,    51] loss: 1.40527, train_accuracy: 48.05\n",
      "[23,    52] loss: 1.40850, train_accuracy: 48.44\n",
      "[23,    53] loss: 1.35584, train_accuracy: 54.69\n",
      "[23,    54] loss: 1.41701, train_accuracy: 49.02\n",
      "[23,    55] loss: 1.31739, train_accuracy: 52.54\n",
      "[23,    56] loss: 1.40762, train_accuracy: 52.73\n",
      "[23,    57] loss: 1.35561, train_accuracy: 53.91\n",
      "[23,    58] loss: 1.48814, train_accuracy: 46.88\n",
      "[23,    59] loss: 1.31529, train_accuracy: 52.34\n",
      "[23,    60] loss: 1.35476, train_accuracy: 50.78\n",
      "[23,    61] loss: 1.36965, train_accuracy: 50.39\n",
      "[23,    62] loss: 1.23122, train_accuracy: 58.20\n",
      "[23,    63] loss: 1.31038, train_accuracy: 50.78\n",
      "[23,    64] loss: 1.41258, train_accuracy: 51.17\n",
      "[23,    65] loss: 1.38263, train_accuracy: 51.76\n",
      "[23,    66] loss: 1.41825, train_accuracy: 48.05\n",
      "[23,    67] loss: 1.34176, train_accuracy: 51.37\n",
      "[23,    68] loss: 1.41882, train_accuracy: 49.22\n",
      "[23,    69] loss: 1.43032, train_accuracy: 48.44\n",
      "[23,    70] loss: 1.23552, train_accuracy: 57.62\n",
      "[23,    71] loss: 1.36066, train_accuracy: 53.32\n",
      "[23,    72] loss: 1.34735, train_accuracy: 51.56\n",
      "[23,    73] loss: 1.42202, train_accuracy: 48.83\n",
      "[23,    74] loss: 1.31770, train_accuracy: 54.49\n",
      "[23,    75] loss: 1.40704, train_accuracy: 50.00\n",
      "[23,    76] loss: 1.39939, train_accuracy: 52.15\n",
      "[23,    77] loss: 1.36899, train_accuracy: 48.83\n",
      "[23,    78] loss: 1.38327, train_accuracy: 51.95\n",
      "[23,    79] loss: 1.35843, train_accuracy: 52.54\n",
      "[23,    80] loss: 1.39989, train_accuracy: 50.39\n",
      "[23,    81] loss: 1.32058, train_accuracy: 51.95\n",
      "[23,    82] loss: 1.43327, train_accuracy: 50.00\n",
      "[23,    83] loss: 1.45113, train_accuracy: 50.39\n",
      "[23,    84] loss: 1.36795, train_accuracy: 50.78\n",
      "[23,    85] loss: 1.25163, train_accuracy: 57.81\n",
      "[23,    86] loss: 1.37582, train_accuracy: 50.78\n",
      "[23,    87] loss: 1.46570, train_accuracy: 46.48\n",
      "[23,    88] loss: 1.32899, train_accuracy: 51.37\n",
      "[23,    89] loss: 1.41005, train_accuracy: 48.63\n",
      "[23,    90] loss: 1.33427, train_accuracy: 50.00\n",
      "[23,    91] loss: 1.44448, train_accuracy: 50.00\n",
      "[23,    92] loss: 1.40595, train_accuracy: 49.80\n",
      "[23,    93] loss: 1.40420, train_accuracy: 50.20\n",
      "[23,    94] loss: 1.35041, train_accuracy: 53.12\n",
      "[23,    95] loss: 1.33499, train_accuracy: 50.78\n",
      "[23,    96] loss: 1.40601, train_accuracy: 51.37\n",
      "[23,    97] loss: 1.35814, train_accuracy: 51.37\n",
      "[23,    98] loss: 1.40542, train_accuracy: 51.49\n",
      "duration: 237 s - train loss: 1.38278 - train accuracy: 50.82 - validation loss: 1.08671 - validation accuracy: 62.40 \n",
      "[24,     1] loss: 1.33051, train_accuracy: 51.76\n",
      "[24,     2] loss: 1.37915, train_accuracy: 51.95\n",
      "[24,     3] loss: 1.36092, train_accuracy: 50.98\n",
      "[24,     4] loss: 1.32709, train_accuracy: 52.93\n",
      "[24,     5] loss: 1.31538, train_accuracy: 52.15\n",
      "[24,     6] loss: 1.36699, train_accuracy: 52.15\n",
      "[24,     7] loss: 1.32127, train_accuracy: 51.76\n",
      "[24,     8] loss: 1.42096, train_accuracy: 47.27\n",
      "[24,     9] loss: 1.35205, train_accuracy: 50.59\n",
      "[24,    10] loss: 1.39020, train_accuracy: 50.20\n",
      "[24,    11] loss: 1.33611, train_accuracy: 52.93\n",
      "[24,    12] loss: 1.35833, train_accuracy: 51.17\n",
      "[24,    13] loss: 1.48802, train_accuracy: 47.46\n",
      "[24,    14] loss: 1.37222, train_accuracy: 50.00\n",
      "[24,    15] loss: 1.35124, train_accuracy: 53.32\n",
      "[24,    16] loss: 1.33700, train_accuracy: 51.17\n",
      "[24,    17] loss: 1.45783, train_accuracy: 48.83\n",
      "[24,    18] loss: 1.33156, train_accuracy: 55.27\n",
      "[24,    19] loss: 1.33089, train_accuracy: 54.49\n",
      "[24,    20] loss: 1.49458, train_accuracy: 44.34\n",
      "[24,    21] loss: 1.45157, train_accuracy: 48.44\n",
      "[24,    22] loss: 1.30816, train_accuracy: 52.93\n",
      "[24,    23] loss: 1.29571, train_accuracy: 55.27\n",
      "[24,    24] loss: 1.31328, train_accuracy: 52.73\n",
      "[24,    25] loss: 1.36071, train_accuracy: 52.15\n",
      "[24,    26] loss: 1.43907, train_accuracy: 48.24\n",
      "[24,    27] loss: 1.32100, train_accuracy: 52.93\n",
      "[24,    28] loss: 1.36000, train_accuracy: 52.34\n",
      "[24,    29] loss: 1.39836, train_accuracy: 50.78\n",
      "[24,    30] loss: 1.32776, train_accuracy: 53.32\n",
      "[24,    31] loss: 1.33996, train_accuracy: 54.49\n",
      "[24,    32] loss: 1.35399, train_accuracy: 52.34\n",
      "[24,    33] loss: 1.42647, train_accuracy: 49.80\n",
      "[24,    34] loss: 1.34708, train_accuracy: 51.17\n",
      "[24,    35] loss: 1.37479, train_accuracy: 49.02\n",
      "[24,    36] loss: 1.33656, train_accuracy: 50.78\n",
      "[24,    37] loss: 1.45554, train_accuracy: 49.61\n",
      "[24,    38] loss: 1.38889, train_accuracy: 51.17\n",
      "[24,    39] loss: 1.35058, train_accuracy: 52.73\n",
      "[24,    40] loss: 1.37321, train_accuracy: 51.76\n",
      "[24,    41] loss: 1.39418, train_accuracy: 51.56\n",
      "[24,    42] loss: 1.32378, train_accuracy: 54.49\n",
      "[24,    43] loss: 1.33999, train_accuracy: 53.52\n",
      "[24,    44] loss: 1.35661, train_accuracy: 51.37\n",
      "[24,    45] loss: 1.39528, train_accuracy: 51.17\n",
      "[24,    46] loss: 1.30863, train_accuracy: 52.34\n",
      "[24,    47] loss: 1.45477, train_accuracy: 50.59\n",
      "[24,    48] loss: 1.34025, train_accuracy: 51.56\n",
      "[24,    49] loss: 1.35080, train_accuracy: 49.80\n",
      "[24,    50] loss: 1.35976, train_accuracy: 52.73\n",
      "[24,    51] loss: 1.39104, train_accuracy: 50.39\n",
      "[24,    52] loss: 1.44274, train_accuracy: 49.61\n",
      "[24,    53] loss: 1.35072, train_accuracy: 50.20\n",
      "[24,    54] loss: 1.38477, train_accuracy: 50.20\n",
      "[24,    55] loss: 1.35395, train_accuracy: 52.54\n",
      "[24,    56] loss: 1.37409, train_accuracy: 50.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24,    57] loss: 1.36182, train_accuracy: 48.05\n",
      "[24,    58] loss: 1.39581, train_accuracy: 51.56\n",
      "[24,    59] loss: 1.44826, train_accuracy: 48.63\n",
      "[24,    60] loss: 1.47228, train_accuracy: 49.41\n",
      "[24,    61] loss: 1.37938, train_accuracy: 50.78\n",
      "[24,    62] loss: 1.47112, train_accuracy: 46.09\n",
      "[24,    63] loss: 1.38379, train_accuracy: 52.93\n",
      "[24,    64] loss: 1.38299, train_accuracy: 49.02\n",
      "[24,    65] loss: 1.43811, train_accuracy: 49.02\n",
      "[24,    66] loss: 1.35885, train_accuracy: 52.34\n",
      "[24,    67] loss: 1.39705, train_accuracy: 49.61\n",
      "[24,    68] loss: 1.45891, train_accuracy: 47.07\n",
      "[24,    69] loss: 1.42565, train_accuracy: 50.00\n",
      "[24,    70] loss: 1.36252, train_accuracy: 48.05\n",
      "[24,    71] loss: 1.37556, train_accuracy: 50.59\n",
      "[24,    72] loss: 1.35249, train_accuracy: 51.37\n",
      "[24,    73] loss: 1.37189, train_accuracy: 50.00\n",
      "[24,    74] loss: 1.40233, train_accuracy: 53.52\n",
      "[24,    75] loss: 1.33488, train_accuracy: 54.10\n",
      "[24,    76] loss: 1.39068, train_accuracy: 50.20\n",
      "[24,    77] loss: 1.34622, train_accuracy: 51.37\n",
      "[24,    78] loss: 1.25820, train_accuracy: 54.69\n",
      "[24,    79] loss: 1.37364, train_accuracy: 50.78\n",
      "[24,    80] loss: 1.45415, train_accuracy: 50.20\n",
      "[24,    81] loss: 1.33492, train_accuracy: 50.78\n",
      "[24,    82] loss: 1.35330, train_accuracy: 50.98\n",
      "[24,    83] loss: 1.28612, train_accuracy: 52.73\n",
      "[24,    84] loss: 1.46394, train_accuracy: 48.05\n",
      "[24,    85] loss: 1.38564, train_accuracy: 52.34\n",
      "[24,    86] loss: 1.38619, train_accuracy: 49.61\n",
      "[24,    87] loss: 1.32374, train_accuracy: 52.73\n",
      "[24,    88] loss: 1.39042, train_accuracy: 48.44\n",
      "[24,    89] loss: 1.32066, train_accuracy: 52.15\n",
      "[24,    90] loss: 1.44199, train_accuracy: 47.85\n",
      "[24,    91] loss: 1.44631, train_accuracy: 48.63\n",
      "[24,    92] loss: 1.37353, train_accuracy: 54.88\n",
      "[24,    93] loss: 1.32356, train_accuracy: 52.54\n",
      "[24,    94] loss: 1.34807, train_accuracy: 51.17\n",
      "[24,    95] loss: 1.37801, train_accuracy: 50.00\n",
      "[24,    96] loss: 1.36217, train_accuracy: 50.39\n",
      "[24,    97] loss: 1.38398, train_accuracy: 49.22\n",
      "[24,    98] loss: 1.42177, train_accuracy: 47.02\n",
      "duration: 216 s - train loss: 1.37538 - train accuracy: 50.96 - validation loss: 1.07580 - validation accuracy: 62.32 \n",
      "[25,     1] loss: 1.33229, train_accuracy: 50.59\n",
      "[25,     2] loss: 1.41421, train_accuracy: 49.80\n",
      "[25,     3] loss: 1.43807, train_accuracy: 47.66\n",
      "[25,     4] loss: 1.32189, train_accuracy: 53.12\n",
      "[25,     5] loss: 1.30830, train_accuracy: 53.91\n",
      "[25,     6] loss: 1.41073, train_accuracy: 51.76\n",
      "[25,     7] loss: 1.38677, train_accuracy: 53.52\n",
      "[25,     8] loss: 1.40454, train_accuracy: 49.22\n",
      "[25,     9] loss: 1.31967, train_accuracy: 53.52\n",
      "[25,    10] loss: 1.30385, train_accuracy: 51.76\n",
      "[25,    11] loss: 1.37554, train_accuracy: 52.15\n",
      "[25,    12] loss: 1.33173, train_accuracy: 52.73\n",
      "[25,    13] loss: 1.36312, train_accuracy: 50.78\n",
      "[25,    14] loss: 1.40598, train_accuracy: 50.98\n",
      "[25,    15] loss: 1.31323, train_accuracy: 52.73\n",
      "[25,    16] loss: 1.34396, train_accuracy: 48.24\n",
      "[25,    17] loss: 1.34533, train_accuracy: 48.24\n",
      "[25,    18] loss: 1.36417, train_accuracy: 50.78\n",
      "[25,    19] loss: 1.39634, train_accuracy: 51.76\n",
      "[25,    20] loss: 1.35403, train_accuracy: 54.88\n",
      "[25,    21] loss: 1.28743, train_accuracy: 56.45\n",
      "[25,    22] loss: 1.38627, train_accuracy: 49.41\n",
      "[25,    23] loss: 1.36751, train_accuracy: 50.39\n",
      "[25,    24] loss: 1.40292, train_accuracy: 50.39\n",
      "[25,    25] loss: 1.42806, train_accuracy: 49.61\n",
      "[25,    26] loss: 1.31490, train_accuracy: 52.93\n",
      "[25,    27] loss: 1.28897, train_accuracy: 52.34\n",
      "[25,    28] loss: 1.42922, train_accuracy: 47.46\n",
      "[25,    29] loss: 1.44732, train_accuracy: 47.07\n",
      "[25,    30] loss: 1.35491, train_accuracy: 51.56\n",
      "[25,    31] loss: 1.29630, train_accuracy: 52.73\n",
      "[25,    32] loss: 1.30307, train_accuracy: 53.12\n",
      "[25,    33] loss: 1.39132, train_accuracy: 51.17\n",
      "[25,    34] loss: 1.35215, train_accuracy: 50.20\n",
      "[25,    35] loss: 1.37714, train_accuracy: 52.15\n",
      "[25,    36] loss: 1.34263, train_accuracy: 53.91\n",
      "[25,    37] loss: 1.33068, train_accuracy: 53.52\n",
      "[25,    38] loss: 1.31492, train_accuracy: 52.93\n",
      "[25,    39] loss: 1.27086, train_accuracy: 53.52\n",
      "[25,    40] loss: 1.40571, train_accuracy: 50.59\n",
      "[25,    41] loss: 1.42081, train_accuracy: 51.95\n",
      "[25,    42] loss: 1.31610, train_accuracy: 53.32\n",
      "[25,    43] loss: 1.51608, train_accuracy: 44.73\n",
      "[25,    44] loss: 1.47490, train_accuracy: 45.31\n",
      "[25,    45] loss: 1.41517, train_accuracy: 48.44\n",
      "[25,    46] loss: 1.27608, train_accuracy: 54.10\n",
      "[25,    47] loss: 1.34306, train_accuracy: 52.15\n",
      "[25,    48] loss: 1.39119, train_accuracy: 50.78\n",
      "[25,    49] loss: 1.26938, train_accuracy: 54.88\n",
      "[25,    50] loss: 1.39676, train_accuracy: 52.54\n",
      "[25,    51] loss: 1.38638, train_accuracy: 49.41\n",
      "[25,    52] loss: 1.39830, train_accuracy: 49.22\n",
      "[25,    53] loss: 1.35445, train_accuracy: 54.69\n",
      "[25,    54] loss: 1.27323, train_accuracy: 54.10\n",
      "[25,    55] loss: 1.32580, train_accuracy: 52.54\n",
      "[25,    56] loss: 1.33761, train_accuracy: 56.45\n",
      "[25,    57] loss: 1.38409, train_accuracy: 50.98\n",
      "[25,    58] loss: 1.41286, train_accuracy: 51.17\n",
      "[25,    59] loss: 1.46233, train_accuracy: 46.48\n",
      "[25,    60] loss: 1.34204, train_accuracy: 51.17\n",
      "[25,    61] loss: 1.33478, train_accuracy: 51.17\n",
      "[25,    62] loss: 1.47330, train_accuracy: 47.66\n",
      "[25,    63] loss: 1.41709, train_accuracy: 50.59\n",
      "[25,    64] loss: 1.33410, train_accuracy: 51.56\n",
      "[25,    65] loss: 1.36907, train_accuracy: 53.52\n",
      "[25,    66] loss: 1.37119, train_accuracy: 48.05\n",
      "[25,    67] loss: 1.40929, train_accuracy: 48.63\n",
      "[25,    68] loss: 1.38103, train_accuracy: 53.91\n",
      "[25,    69] loss: 1.38035, train_accuracy: 50.00\n",
      "[25,    70] loss: 1.40145, train_accuracy: 48.24\n",
      "[25,    71] loss: 1.25517, train_accuracy: 52.93\n",
      "[25,    72] loss: 1.33950, train_accuracy: 49.41\n",
      "[25,    73] loss: 1.30688, train_accuracy: 54.49\n",
      "[25,    74] loss: 1.36169, train_accuracy: 50.00\n",
      "[25,    75] loss: 1.37970, train_accuracy: 50.39\n",
      "[25,    76] loss: 1.31704, train_accuracy: 51.37\n",
      "[25,    77] loss: 1.39953, train_accuracy: 48.44\n",
      "[25,    78] loss: 1.36701, train_accuracy: 48.44\n",
      "[25,    79] loss: 1.39640, train_accuracy: 50.78\n",
      "[25,    80] loss: 1.32901, train_accuracy: 50.98\n",
      "[25,    81] loss: 1.25910, train_accuracy: 54.69\n",
      "[25,    82] loss: 1.39157, train_accuracy: 50.20\n",
      "[25,    83] loss: 1.30747, train_accuracy: 55.08\n",
      "[25,    84] loss: 1.34329, train_accuracy: 54.49\n",
      "[25,    85] loss: 1.36347, train_accuracy: 51.37\n",
      "[25,    86] loss: 1.37556, train_accuracy: 50.98\n",
      "[25,    87] loss: 1.31562, train_accuracy: 54.49\n",
      "[25,    88] loss: 1.42070, train_accuracy: 51.17\n",
      "[25,    89] loss: 1.39416, train_accuracy: 50.00\n",
      "[25,    90] loss: 1.33738, train_accuracy: 50.78\n",
      "[25,    91] loss: 1.40838, train_accuracy: 49.61\n",
      "[25,    92] loss: 1.37451, train_accuracy: 52.15\n",
      "[25,    93] loss: 1.34953, train_accuracy: 52.34\n",
      "[25,    94] loss: 1.36599, train_accuracy: 48.24\n",
      "[25,    95] loss: 1.37921, train_accuracy: 47.46\n",
      "[25,    96] loss: 1.32006, train_accuracy: 53.71\n",
      "[25,    97] loss: 1.36879, train_accuracy: 48.83\n",
      "[25,    98] loss: 1.39832, train_accuracy: 50.30\n",
      "duration: 217 s - train loss: 1.36346 - train accuracy: 51.23 - validation loss: 1.07390 - validation accuracy: 62.56 \n",
      "[26,     1] loss: 1.38808, train_accuracy: 51.56\n",
      "[26,     2] loss: 1.35785, train_accuracy: 49.22\n",
      "[26,     3] loss: 1.34883, train_accuracy: 50.78\n",
      "[26,     4] loss: 1.36729, train_accuracy: 48.83\n",
      "[26,     5] loss: 1.30681, train_accuracy: 51.37\n",
      "[26,     6] loss: 1.47408, train_accuracy: 49.22\n",
      "[26,     7] loss: 1.37614, train_accuracy: 51.56\n",
      "[26,     8] loss: 1.32169, train_accuracy: 54.30\n",
      "[26,     9] loss: 1.34308, train_accuracy: 51.56\n",
      "[26,    10] loss: 1.28100, train_accuracy: 53.71\n",
      "[26,    11] loss: 1.40419, train_accuracy: 50.59\n",
      "[26,    12] loss: 1.32537, train_accuracy: 53.71\n",
      "[26,    13] loss: 1.38233, train_accuracy: 49.41\n",
      "[26,    14] loss: 1.28592, train_accuracy: 54.49\n",
      "[26,    15] loss: 1.39848, train_accuracy: 49.41\n",
      "[26,    16] loss: 1.35220, train_accuracy: 51.95\n",
      "[26,    17] loss: 1.37896, train_accuracy: 50.78\n",
      "[26,    18] loss: 1.34817, train_accuracy: 50.59\n",
      "[26,    19] loss: 1.27432, train_accuracy: 57.42\n",
      "[26,    20] loss: 1.32614, train_accuracy: 50.00\n",
      "[26,    21] loss: 1.38828, train_accuracy: 50.20\n",
      "[26,    22] loss: 1.42353, train_accuracy: 48.83\n",
      "[26,    23] loss: 1.30267, train_accuracy: 53.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26,    24] loss: 1.36204, train_accuracy: 51.37\n",
      "[26,    25] loss: 1.41128, train_accuracy: 48.83\n",
      "[26,    26] loss: 1.27991, train_accuracy: 53.71\n",
      "[26,    27] loss: 1.39686, train_accuracy: 48.83\n",
      "[26,    28] loss: 1.25301, train_accuracy: 57.62\n",
      "[26,    29] loss: 1.36480, train_accuracy: 52.54\n",
      "[26,    30] loss: 1.38644, train_accuracy: 52.73\n",
      "[26,    31] loss: 1.30292, train_accuracy: 55.86\n",
      "[26,    32] loss: 1.33502, train_accuracy: 51.76\n",
      "[26,    33] loss: 1.39540, train_accuracy: 50.39\n",
      "[26,    34] loss: 1.37006, train_accuracy: 49.02\n",
      "[26,    35] loss: 1.41497, train_accuracy: 50.98\n",
      "[26,    36] loss: 1.27069, train_accuracy: 52.93\n",
      "[26,    37] loss: 1.43153, train_accuracy: 49.80\n",
      "[26,    38] loss: 1.32576, train_accuracy: 55.27\n",
      "[26,    39] loss: 1.35966, train_accuracy: 52.73\n",
      "[26,    40] loss: 1.43597, train_accuracy: 50.39\n",
      "[26,    41] loss: 1.32622, train_accuracy: 54.69\n",
      "[26,    42] loss: 1.40067, train_accuracy: 50.20\n",
      "[26,    43] loss: 1.38353, train_accuracy: 49.41\n",
      "[26,    44] loss: 1.36550, train_accuracy: 52.54\n",
      "[26,    45] loss: 1.30584, train_accuracy: 51.76\n",
      "[26,    46] loss: 1.34114, train_accuracy: 50.00\n",
      "[26,    47] loss: 1.35183, train_accuracy: 51.76\n",
      "[26,    48] loss: 1.35337, train_accuracy: 51.76\n",
      "[26,    49] loss: 1.38521, train_accuracy: 52.15\n",
      "[26,    50] loss: 1.37269, train_accuracy: 52.15\n",
      "[26,    51] loss: 1.26094, train_accuracy: 56.45\n",
      "[26,    52] loss: 1.30899, train_accuracy: 52.73\n",
      "[26,    53] loss: 1.38964, train_accuracy: 50.39\n",
      "[26,    54] loss: 1.38935, train_accuracy: 51.56\n",
      "[26,    55] loss: 1.26052, train_accuracy: 55.66\n",
      "[26,    56] loss: 1.36500, train_accuracy: 50.59\n",
      "[26,    57] loss: 1.45912, train_accuracy: 46.68\n",
      "[26,    58] loss: 1.36505, train_accuracy: 52.34\n",
      "[26,    59] loss: 1.41208, train_accuracy: 47.46\n",
      "[26,    60] loss: 1.38263, train_accuracy: 47.27\n",
      "[26,    61] loss: 1.38787, train_accuracy: 51.56\n",
      "[26,    62] loss: 1.37787, train_accuracy: 51.37\n",
      "[26,    63] loss: 1.36224, train_accuracy: 51.76\n",
      "[26,    64] loss: 1.38466, train_accuracy: 45.70\n",
      "[26,    65] loss: 1.45705, train_accuracy: 49.80\n",
      "[26,    66] loss: 1.41448, train_accuracy: 49.02\n",
      "[26,    67] loss: 1.44231, train_accuracy: 48.24\n",
      "[26,    68] loss: 1.34052, train_accuracy: 51.37\n",
      "[26,    69] loss: 1.34367, train_accuracy: 49.80\n",
      "[26,    70] loss: 1.32461, train_accuracy: 54.10\n",
      "[26,    71] loss: 1.33172, train_accuracy: 50.59\n",
      "[26,    72] loss: 1.32583, train_accuracy: 53.91\n",
      "[26,    73] loss: 1.36876, train_accuracy: 50.98\n",
      "[26,    74] loss: 1.34877, train_accuracy: 50.20\n",
      "[26,    75] loss: 1.36961, train_accuracy: 48.05\n",
      "[26,    76] loss: 1.34505, train_accuracy: 53.12\n",
      "[26,    77] loss: 1.28446, train_accuracy: 53.71\n",
      "[26,    78] loss: 1.39030, train_accuracy: 48.83\n",
      "[26,    79] loss: 1.38202, train_accuracy: 49.41\n",
      "[26,    80] loss: 1.38581, train_accuracy: 48.83\n",
      "[26,    81] loss: 1.40061, train_accuracy: 50.98\n",
      "[26,    82] loss: 1.43419, train_accuracy: 48.05\n",
      "[26,    83] loss: 1.42592, train_accuracy: 47.66\n",
      "[26,    84] loss: 1.38187, train_accuracy: 49.61\n",
      "[26,    85] loss: 1.38573, train_accuracy: 51.56\n",
      "[26,    86] loss: 1.40302, train_accuracy: 51.95\n",
      "[26,    87] loss: 1.36814, train_accuracy: 50.20\n",
      "[26,    88] loss: 1.48959, train_accuracy: 46.48\n",
      "[26,    89] loss: 1.30556, train_accuracy: 52.93\n",
      "[26,    90] loss: 1.41018, train_accuracy: 50.20\n",
      "[26,    91] loss: 1.38792, train_accuracy: 54.10\n",
      "[26,    92] loss: 1.35381, train_accuracy: 51.76\n",
      "[26,    93] loss: 1.38487, train_accuracy: 48.63\n",
      "[26,    94] loss: 1.33858, train_accuracy: 50.78\n",
      "[26,    95] loss: 1.34004, train_accuracy: 51.37\n",
      "[26,    96] loss: 1.33078, train_accuracy: 51.17\n",
      "[26,    97] loss: 1.37033, train_accuracy: 50.59\n",
      "[26,    98] loss: 1.40544, train_accuracy: 50.00\n",
      "duration: 256 s - train loss: 1.36444 - train accuracy: 51.16 - validation loss: 1.06172 - validation accuracy: 62.99 \n",
      "[27,     1] loss: 1.34591, train_accuracy: 51.76\n",
      "[27,     2] loss: 1.35023, train_accuracy: 53.32\n",
      "[27,     3] loss: 1.38959, train_accuracy: 52.73\n",
      "[27,     4] loss: 1.38842, train_accuracy: 49.61\n",
      "[27,     5] loss: 1.31037, train_accuracy: 52.73\n",
      "[27,     6] loss: 1.26280, train_accuracy: 55.66\n",
      "[27,     7] loss: 1.38143, train_accuracy: 51.37\n",
      "[27,     8] loss: 1.32091, train_accuracy: 54.88\n",
      "[27,     9] loss: 1.29597, train_accuracy: 55.47\n",
      "[27,    10] loss: 1.40205, train_accuracy: 47.66\n",
      "[27,    11] loss: 1.43560, train_accuracy: 50.98\n",
      "[27,    12] loss: 1.33501, train_accuracy: 52.34\n",
      "[27,    13] loss: 1.42771, train_accuracy: 49.02\n",
      "[27,    14] loss: 1.37183, train_accuracy: 54.49\n",
      "[27,    15] loss: 1.38570, train_accuracy: 49.22\n",
      "[27,    16] loss: 1.26989, train_accuracy: 54.10\n",
      "[27,    17] loss: 1.32767, train_accuracy: 52.93\n",
      "[27,    18] loss: 1.29020, train_accuracy: 53.71\n",
      "[27,    19] loss: 1.35252, train_accuracy: 53.91\n",
      "[27,    20] loss: 1.38446, train_accuracy: 53.32\n",
      "[27,    21] loss: 1.39638, train_accuracy: 50.59\n",
      "[27,    22] loss: 1.30916, train_accuracy: 54.69\n",
      "[27,    23] loss: 1.37602, train_accuracy: 49.61\n",
      "[27,    24] loss: 1.38225, train_accuracy: 50.39\n",
      "[27,    25] loss: 1.25529, train_accuracy: 54.49\n",
      "[27,    26] loss: 1.35823, train_accuracy: 51.76\n",
      "[27,    27] loss: 1.43445, train_accuracy: 47.46\n",
      "[27,    28] loss: 1.41795, train_accuracy: 48.05\n",
      "[27,    29] loss: 1.34954, train_accuracy: 52.73\n",
      "[27,    30] loss: 1.40424, train_accuracy: 49.41\n",
      "[27,    31] loss: 1.35937, train_accuracy: 52.34\n",
      "[27,    32] loss: 1.32910, train_accuracy: 50.98\n",
      "[27,    33] loss: 1.40652, train_accuracy: 46.29\n",
      "[27,    34] loss: 1.38678, train_accuracy: 49.41\n",
      "[27,    35] loss: 1.27641, train_accuracy: 54.10\n",
      "[27,    36] loss: 1.36676, train_accuracy: 50.59\n",
      "[27,    37] loss: 1.32535, train_accuracy: 50.00\n",
      "[27,    38] loss: 1.30474, train_accuracy: 54.49\n",
      "[27,    39] loss: 1.29427, train_accuracy: 53.52\n",
      "[27,    40] loss: 1.33632, train_accuracy: 52.15\n",
      "[27,    41] loss: 1.43675, train_accuracy: 48.63\n",
      "[27,    42] loss: 1.27433, train_accuracy: 54.10\n",
      "[27,    43] loss: 1.35532, train_accuracy: 49.22\n",
      "[27,    44] loss: 1.30281, train_accuracy: 55.27\n",
      "[27,    45] loss: 1.31963, train_accuracy: 52.15\n",
      "[27,    46] loss: 1.28906, train_accuracy: 55.27\n",
      "[27,    47] loss: 1.35188, train_accuracy: 52.34\n",
      "[27,    48] loss: 1.37964, train_accuracy: 51.17\n",
      "[27,    49] loss: 1.28833, train_accuracy: 56.64\n",
      "[27,    50] loss: 1.38009, train_accuracy: 51.95\n",
      "[27,    51] loss: 1.42796, train_accuracy: 50.20\n",
      "[27,    52] loss: 1.35831, train_accuracy: 49.80\n",
      "[27,    53] loss: 1.35087, train_accuracy: 50.78\n",
      "[27,    54] loss: 1.31941, train_accuracy: 51.95\n",
      "[27,    55] loss: 1.35419, train_accuracy: 51.17\n",
      "[27,    56] loss: 1.31658, train_accuracy: 55.27\n",
      "[27,    57] loss: 1.35227, train_accuracy: 51.76\n",
      "[27,    58] loss: 1.30491, train_accuracy: 56.64\n",
      "[27,    59] loss: 1.37591, train_accuracy: 48.83\n",
      "[27,    60] loss: 1.35328, train_accuracy: 52.73\n",
      "[27,    61] loss: 1.28805, train_accuracy: 54.49\n",
      "[27,    62] loss: 1.41363, train_accuracy: 49.22\n",
      "[27,    63] loss: 1.35531, train_accuracy: 50.78\n",
      "[27,    64] loss: 1.40011, train_accuracy: 52.93\n",
      "[27,    65] loss: 1.42626, train_accuracy: 47.66\n",
      "[27,    66] loss: 1.34447, train_accuracy: 53.32\n",
      "[27,    67] loss: 1.37317, train_accuracy: 49.80\n",
      "[27,    68] loss: 1.34658, train_accuracy: 53.52\n",
      "[27,    69] loss: 1.30973, train_accuracy: 51.56\n",
      "[27,    70] loss: 1.39705, train_accuracy: 49.61\n",
      "[27,    71] loss: 1.39603, train_accuracy: 50.98\n",
      "[27,    72] loss: 1.38447, train_accuracy: 50.59\n",
      "[27,    73] loss: 1.38770, train_accuracy: 51.76\n",
      "[27,    74] loss: 1.44638, train_accuracy: 51.56\n",
      "[27,    75] loss: 1.40686, train_accuracy: 50.20\n",
      "[27,    76] loss: 1.45011, train_accuracy: 47.66\n",
      "[27,    77] loss: 1.35563, train_accuracy: 51.37\n",
      "[27,    78] loss: 1.30629, train_accuracy: 53.12\n",
      "[27,    79] loss: 1.45629, train_accuracy: 48.05\n",
      "[27,    80] loss: 1.28818, train_accuracy: 55.47\n",
      "[27,    81] loss: 1.33668, train_accuracy: 51.56\n",
      "[27,    82] loss: 1.41331, train_accuracy: 50.20\n",
      "[27,    83] loss: 1.36341, train_accuracy: 50.00\n",
      "[27,    84] loss: 1.34783, train_accuracy: 52.93\n",
      "[27,    85] loss: 1.38254, train_accuracy: 50.20\n",
      "[27,    86] loss: 1.34137, train_accuracy: 49.41\n",
      "[27,    87] loss: 1.40589, train_accuracy: 49.61\n",
      "[27,    88] loss: 1.34987, train_accuracy: 48.63\n",
      "[27,    89] loss: 1.32469, train_accuracy: 55.47\n",
      "[27,    90] loss: 1.30047, train_accuracy: 51.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27,    91] loss: 1.26440, train_accuracy: 55.66\n",
      "[27,    92] loss: 1.39946, train_accuracy: 51.56\n",
      "[27,    93] loss: 1.37328, train_accuracy: 51.37\n",
      "[27,    94] loss: 1.36164, train_accuracy: 54.10\n",
      "[27,    95] loss: 1.41173, train_accuracy: 50.59\n",
      "[27,    96] loss: 1.47326, train_accuracy: 47.46\n",
      "[27,    97] loss: 1.39184, train_accuracy: 50.78\n",
      "[27,    98] loss: 1.44490, train_accuracy: 44.94\n",
      "duration: 436 s - train loss: 1.35926 - train accuracy: 51.61 - validation loss: 1.06289 - validation accuracy: 63.40 \n",
      "[28,     1] loss: 1.35943, train_accuracy: 50.78\n",
      "[28,     2] loss: 1.37766, train_accuracy: 52.93\n",
      "[28,     3] loss: 1.37782, train_accuracy: 50.59\n",
      "[28,     4] loss: 1.39367, train_accuracy: 49.80\n",
      "[28,     5] loss: 1.37050, train_accuracy: 50.59\n",
      "[28,     6] loss: 1.31929, train_accuracy: 50.59\n",
      "[28,     7] loss: 1.34752, train_accuracy: 49.80\n",
      "[28,     8] loss: 1.30646, train_accuracy: 52.73\n",
      "[28,     9] loss: 1.31796, train_accuracy: 55.08\n",
      "[28,    10] loss: 1.25061, train_accuracy: 52.93\n",
      "[28,    11] loss: 1.38449, train_accuracy: 51.37\n",
      "[28,    12] loss: 1.33787, train_accuracy: 54.69\n",
      "[28,    13] loss: 1.39874, train_accuracy: 48.24\n",
      "[28,    14] loss: 1.32478, train_accuracy: 53.71\n",
      "[28,    15] loss: 1.34617, train_accuracy: 51.17\n",
      "[28,    16] loss: 1.35723, train_accuracy: 53.32\n",
      "[28,    17] loss: 1.29205, train_accuracy: 50.78\n",
      "[28,    18] loss: 1.42566, train_accuracy: 48.24\n",
      "[28,    19] loss: 1.29663, train_accuracy: 54.30\n",
      "[28,    20] loss: 1.30416, train_accuracy: 53.52\n",
      "[28,    21] loss: 1.40077, train_accuracy: 50.39\n",
      "[28,    22] loss: 1.33397, train_accuracy: 53.12\n",
      "[28,    23] loss: 1.33975, train_accuracy: 51.17\n",
      "[28,    24] loss: 1.42223, train_accuracy: 50.00\n",
      "[28,    25] loss: 1.34011, train_accuracy: 52.15\n",
      "[28,    26] loss: 1.28192, train_accuracy: 52.93\n",
      "[28,    27] loss: 1.33462, train_accuracy: 54.49\n",
      "[28,    28] loss: 1.34083, train_accuracy: 52.93\n",
      "[28,    29] loss: 1.33542, train_accuracy: 52.54\n",
      "[28,    30] loss: 1.33424, train_accuracy: 51.56\n",
      "[28,    31] loss: 1.38891, train_accuracy: 49.22\n",
      "[28,    32] loss: 1.44398, train_accuracy: 48.24\n",
      "[28,    33] loss: 1.36915, train_accuracy: 49.80\n",
      "[28,    34] loss: 1.44309, train_accuracy: 49.61\n",
      "[28,    35] loss: 1.41054, train_accuracy: 50.78\n",
      "[28,    36] loss: 1.40468, train_accuracy: 50.78\n",
      "[28,    37] loss: 1.36218, train_accuracy: 50.00\n",
      "[28,    38] loss: 1.32511, train_accuracy: 52.54\n",
      "[28,    39] loss: 1.40039, train_accuracy: 50.00\n",
      "[28,    40] loss: 1.35026, train_accuracy: 52.34\n",
      "[28,    41] loss: 1.34247, train_accuracy: 50.78\n",
      "[28,    42] loss: 1.37723, train_accuracy: 52.54\n",
      "[28,    43] loss: 1.39162, train_accuracy: 50.20\n",
      "[28,    44] loss: 1.28344, train_accuracy: 54.88\n",
      "[28,    45] loss: 1.36691, train_accuracy: 51.76\n",
      "[28,    46] loss: 1.30764, train_accuracy: 53.12\n",
      "[28,    47] loss: 1.39499, train_accuracy: 53.12\n",
      "[28,    48] loss: 1.33106, train_accuracy: 50.78\n",
      "[28,    49] loss: 1.39500, train_accuracy: 50.20\n",
      "[28,    50] loss: 1.39249, train_accuracy: 50.20\n",
      "[28,    51] loss: 1.38178, train_accuracy: 52.34\n",
      "[28,    52] loss: 1.33796, train_accuracy: 52.34\n",
      "[28,    53] loss: 1.40876, train_accuracy: 50.20\n",
      "[28,    54] loss: 1.40489, train_accuracy: 49.22\n",
      "[28,    55] loss: 1.36235, train_accuracy: 48.24\n",
      "[28,    56] loss: 1.39520, train_accuracy: 49.41\n",
      "[28,    57] loss: 1.32906, train_accuracy: 49.61\n",
      "[28,    58] loss: 1.22118, train_accuracy: 54.69\n",
      "[28,    59] loss: 1.39982, train_accuracy: 53.71\n",
      "[28,    60] loss: 1.29239, train_accuracy: 54.69\n",
      "[28,    61] loss: 1.36773, train_accuracy: 50.39\n",
      "[28,    62] loss: 1.35635, train_accuracy: 50.98\n",
      "[28,    63] loss: 1.35143, train_accuracy: 48.63\n",
      "[28,    64] loss: 1.37340, train_accuracy: 51.37\n",
      "[28,    65] loss: 1.27640, train_accuracy: 55.27\n",
      "[28,    66] loss: 1.36988, train_accuracy: 48.05\n",
      "[28,    67] loss: 1.33546, train_accuracy: 55.08\n",
      "[28,    68] loss: 1.47237, train_accuracy: 48.24\n",
      "[28,    69] loss: 1.40956, train_accuracy: 50.00\n",
      "[28,    70] loss: 1.32802, train_accuracy: 51.17\n",
      "[28,    71] loss: 1.33426, train_accuracy: 55.27\n",
      "[28,    72] loss: 1.31800, train_accuracy: 55.08\n",
      "[28,    73] loss: 1.31433, train_accuracy: 51.95\n",
      "[28,    74] loss: 1.29875, train_accuracy: 54.69\n",
      "[28,    75] loss: 1.41000, train_accuracy: 51.95\n",
      "[28,    76] loss: 1.34530, train_accuracy: 51.17\n",
      "[28,    77] loss: 1.37042, train_accuracy: 52.15\n",
      "[28,    78] loss: 1.41176, train_accuracy: 50.78\n",
      "[28,    79] loss: 1.27122, train_accuracy: 55.47\n",
      "[28,    80] loss: 1.40225, train_accuracy: 48.24\n",
      "[28,    81] loss: 1.38729, train_accuracy: 49.22\n",
      "[28,    82] loss: 1.47175, train_accuracy: 48.63\n",
      "[28,    83] loss: 1.30219, train_accuracy: 52.15\n",
      "[28,    84] loss: 1.43689, train_accuracy: 51.17\n",
      "[28,    85] loss: 1.32876, train_accuracy: 51.37\n",
      "[28,    86] loss: 1.34355, train_accuracy: 50.20\n",
      "[28,    87] loss: 1.34490, train_accuracy: 50.00\n",
      "[28,    88] loss: 1.36401, train_accuracy: 49.41\n",
      "[28,    89] loss: 1.41028, train_accuracy: 47.85\n",
      "[28,    90] loss: 1.39021, train_accuracy: 48.44\n",
      "[28,    91] loss: 1.37524, train_accuracy: 49.22\n",
      "[28,    92] loss: 1.35080, train_accuracy: 52.34\n",
      "[28,    93] loss: 1.33467, train_accuracy: 55.86\n",
      "[28,    94] loss: 1.38438, train_accuracy: 52.34\n",
      "[28,    95] loss: 1.30161, train_accuracy: 52.73\n",
      "[28,    96] loss: 1.31166, train_accuracy: 54.30\n",
      "[28,    97] loss: 1.31171, train_accuracy: 54.10\n",
      "[28,    98] loss: 1.43984, train_accuracy: 47.62\n",
      "duration: 294 s - train loss: 1.35790 - train accuracy: 51.48 - validation loss: 1.05698 - validation accuracy: 63.40 \n",
      "[29,     1] loss: 1.33820, train_accuracy: 51.37\n",
      "[29,     2] loss: 1.35582, train_accuracy: 53.71\n",
      "[29,     3] loss: 1.24855, train_accuracy: 54.30\n",
      "[29,     4] loss: 1.36556, train_accuracy: 50.98\n",
      "[29,     5] loss: 1.34314, train_accuracy: 51.76\n",
      "[29,     6] loss: 1.41928, train_accuracy: 49.22\n",
      "[29,     7] loss: 1.32538, train_accuracy: 52.15\n",
      "[29,     8] loss: 1.40229, train_accuracy: 48.05\n",
      "[29,     9] loss: 1.34412, train_accuracy: 52.15\n",
      "[29,    10] loss: 1.32797, train_accuracy: 54.10\n",
      "[29,    11] loss: 1.28453, train_accuracy: 55.86\n",
      "[29,    12] loss: 1.41725, train_accuracy: 51.17\n",
      "[29,    13] loss: 1.40163, train_accuracy: 50.20\n",
      "[29,    14] loss: 1.33014, train_accuracy: 52.54\n",
      "[29,    15] loss: 1.34496, train_accuracy: 55.66\n",
      "[29,    16] loss: 1.30973, train_accuracy: 54.10\n",
      "[29,    17] loss: 1.32482, train_accuracy: 51.17\n",
      "[29,    18] loss: 1.33842, train_accuracy: 56.84\n",
      "[29,    19] loss: 1.24020, train_accuracy: 54.30\n",
      "[29,    20] loss: 1.33013, train_accuracy: 50.39\n",
      "[29,    21] loss: 1.29602, train_accuracy: 51.95\n",
      "[29,    22] loss: 1.37774, train_accuracy: 49.61\n",
      "[29,    23] loss: 1.37083, train_accuracy: 50.78\n",
      "[29,    24] loss: 1.29670, train_accuracy: 53.52\n",
      "[29,    25] loss: 1.34963, train_accuracy: 49.41\n",
      "[29,    26] loss: 1.40913, train_accuracy: 50.39\n",
      "[29,    27] loss: 1.41423, train_accuracy: 48.44\n",
      "[29,    28] loss: 1.33036, train_accuracy: 53.32\n",
      "[29,    29] loss: 1.25306, train_accuracy: 55.08\n",
      "[29,    30] loss: 1.37358, train_accuracy: 50.00\n",
      "[29,    31] loss: 1.37854, train_accuracy: 48.83\n",
      "[29,    32] loss: 1.35901, train_accuracy: 53.52\n",
      "[29,    33] loss: 1.34755, train_accuracy: 48.83\n",
      "[29,    34] loss: 1.32543, train_accuracy: 52.73\n",
      "[29,    35] loss: 1.34944, train_accuracy: 50.98\n",
      "[29,    36] loss: 1.34886, train_accuracy: 53.32\n",
      "[29,    37] loss: 1.34646, train_accuracy: 52.54\n",
      "[29,    38] loss: 1.43758, train_accuracy: 49.41\n",
      "[29,    39] loss: 1.38332, train_accuracy: 50.78\n",
      "[29,    40] loss: 1.38523, train_accuracy: 50.00\n",
      "[29,    41] loss: 1.36921, train_accuracy: 50.98\n",
      "[29,    42] loss: 1.26316, train_accuracy: 55.08\n",
      "[29,    43] loss: 1.35472, train_accuracy: 52.34\n",
      "[29,    44] loss: 1.30020, train_accuracy: 52.73\n",
      "[29,    45] loss: 1.43054, train_accuracy: 48.05\n",
      "[29,    46] loss: 1.30937, train_accuracy: 50.78\n",
      "[29,    47] loss: 1.38668, train_accuracy: 48.83\n",
      "[29,    48] loss: 1.38644, train_accuracy: 51.56\n",
      "[29,    49] loss: 1.38231, train_accuracy: 51.95\n",
      "[29,    50] loss: 1.42164, train_accuracy: 49.02\n",
      "[29,    51] loss: 1.30733, train_accuracy: 53.12\n",
      "[29,    52] loss: 1.23030, train_accuracy: 53.91\n",
      "[29,    53] loss: 1.32700, train_accuracy: 55.27\n",
      "[29,    54] loss: 1.38351, train_accuracy: 49.22\n",
      "[29,    55] loss: 1.35196, train_accuracy: 48.63\n",
      "[29,    56] loss: 1.41427, train_accuracy: 51.17\n",
      "[29,    57] loss: 1.35429, train_accuracy: 53.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29,    58] loss: 1.32113, train_accuracy: 52.73\n",
      "[29,    59] loss: 1.33966, train_accuracy: 54.30\n",
      "[29,    60] loss: 1.33541, train_accuracy: 53.12\n",
      "[29,    61] loss: 1.36433, train_accuracy: 49.61\n",
      "[29,    62] loss: 1.34924, train_accuracy: 54.10\n",
      "[29,    63] loss: 1.32799, train_accuracy: 52.34\n",
      "[29,    64] loss: 1.33186, train_accuracy: 53.32\n",
      "[29,    65] loss: 1.32990, train_accuracy: 51.37\n",
      "[29,    66] loss: 1.34630, train_accuracy: 53.12\n",
      "[29,    67] loss: 1.37193, train_accuracy: 49.41\n",
      "[29,    68] loss: 1.38159, train_accuracy: 48.24\n",
      "[29,    69] loss: 1.34957, train_accuracy: 52.34\n",
      "[29,    70] loss: 1.31529, train_accuracy: 50.00\n",
      "[29,    71] loss: 1.43074, train_accuracy: 49.80\n",
      "[29,    72] loss: 1.33828, train_accuracy: 51.56\n",
      "[29,    73] loss: 1.34556, train_accuracy: 53.12\n",
      "[29,    74] loss: 1.39359, train_accuracy: 50.98\n",
      "[29,    75] loss: 1.36077, train_accuracy: 50.00\n",
      "[29,    76] loss: 1.40180, train_accuracy: 50.39\n",
      "[29,    77] loss: 1.34148, train_accuracy: 52.73\n",
      "[29,    78] loss: 1.33516, train_accuracy: 49.61\n",
      "[29,    79] loss: 1.35664, train_accuracy: 50.39\n",
      "[29,    80] loss: 1.31303, train_accuracy: 52.34\n",
      "[29,    81] loss: 1.34080, train_accuracy: 52.34\n",
      "[29,    82] loss: 1.37528, train_accuracy: 50.39\n",
      "[29,    83] loss: 1.30962, train_accuracy: 53.52\n",
      "[29,    84] loss: 1.27472, train_accuracy: 54.49\n",
      "[29,    85] loss: 1.41041, train_accuracy: 48.83\n",
      "[29,    86] loss: 1.34934, train_accuracy: 51.76\n",
      "[29,    87] loss: 1.35987, train_accuracy: 50.00\n",
      "[29,    88] loss: 1.41088, train_accuracy: 48.63\n",
      "[29,    89] loss: 1.29079, train_accuracy: 52.15\n",
      "[29,    90] loss: 1.30335, train_accuracy: 56.45\n",
      "[29,    91] loss: 1.41190, train_accuracy: 49.41\n",
      "[29,    92] loss: 1.35249, train_accuracy: 51.76\n",
      "[29,    93] loss: 1.38761, train_accuracy: 49.22\n",
      "[29,    94] loss: 1.25875, train_accuracy: 55.27\n",
      "[29,    95] loss: 1.26486, train_accuracy: 54.49\n",
      "[29,    96] loss: 1.31276, train_accuracy: 54.49\n",
      "[29,    97] loss: 1.32789, train_accuracy: 51.56\n",
      "[29,    98] loss: 1.31895, train_accuracy: 53.57\n",
      "duration: 240 s - train loss: 1.34734 - train accuracy: 51.76 - validation loss: 1.05154 - validation accuracy: 63.27 \n",
      "[30,     1] loss: 1.30139, train_accuracy: 54.49\n",
      "[30,     2] loss: 1.32537, train_accuracy: 53.91\n",
      "[30,     3] loss: 1.36214, train_accuracy: 53.12\n",
      "[30,     4] loss: 1.38583, train_accuracy: 52.93\n",
      "[30,     5] loss: 1.31114, train_accuracy: 53.91\n",
      "[30,     6] loss: 1.36016, train_accuracy: 51.17\n",
      "[30,     7] loss: 1.25956, train_accuracy: 55.47\n",
      "[30,     8] loss: 1.30625, train_accuracy: 53.71\n",
      "[30,     9] loss: 1.35313, train_accuracy: 53.52\n",
      "[30,    10] loss: 1.37559, train_accuracy: 51.17\n",
      "[30,    11] loss: 1.29563, train_accuracy: 55.08\n",
      "[30,    12] loss: 1.38594, train_accuracy: 48.44\n",
      "[30,    13] loss: 1.40688, train_accuracy: 50.00\n",
      "[30,    14] loss: 1.32173, train_accuracy: 54.88\n",
      "[30,    15] loss: 1.25091, train_accuracy: 54.10\n",
      "[30,    16] loss: 1.30351, train_accuracy: 54.30\n",
      "[30,    17] loss: 1.35066, train_accuracy: 55.27\n",
      "[30,    18] loss: 1.32956, train_accuracy: 51.76\n",
      "[30,    19] loss: 1.35116, train_accuracy: 52.34\n",
      "[30,    20] loss: 1.38952, train_accuracy: 50.00\n",
      "[30,    21] loss: 1.23495, train_accuracy: 56.25\n",
      "[30,    22] loss: 1.34743, train_accuracy: 52.93\n",
      "[30,    23] loss: 1.37041, train_accuracy: 49.80\n",
      "[30,    24] loss: 1.37710, train_accuracy: 49.41\n",
      "[30,    25] loss: 1.38885, train_accuracy: 51.76\n",
      "[30,    26] loss: 1.37080, train_accuracy: 52.15\n",
      "[30,    27] loss: 1.30360, train_accuracy: 55.08\n",
      "[30,    28] loss: 1.36879, train_accuracy: 51.37\n",
      "[30,    29] loss: 1.36095, train_accuracy: 53.52\n",
      "[30,    30] loss: 1.41164, train_accuracy: 50.78\n",
      "[30,    31] loss: 1.25539, train_accuracy: 57.03\n",
      "[30,    32] loss: 1.37917, train_accuracy: 50.98\n",
      "[30,    33] loss: 1.32336, train_accuracy: 51.95\n",
      "[30,    34] loss: 1.38636, train_accuracy: 50.20\n",
      "[30,    35] loss: 1.36392, train_accuracy: 52.34\n",
      "[30,    36] loss: 1.34090, train_accuracy: 54.88\n",
      "[30,    37] loss: 1.42454, train_accuracy: 50.39\n",
      "[30,    38] loss: 1.39488, train_accuracy: 50.20\n",
      "[30,    39] loss: 1.30510, train_accuracy: 52.54\n",
      "[30,    40] loss: 1.39377, train_accuracy: 51.37\n",
      "[30,    41] loss: 1.34803, train_accuracy: 53.91\n",
      "[30,    42] loss: 1.35050, train_accuracy: 50.20\n",
      "[30,    43] loss: 1.34047, train_accuracy: 50.78\n",
      "[30,    44] loss: 1.32808, train_accuracy: 53.52\n",
      "[30,    45] loss: 1.31201, train_accuracy: 50.78\n",
      "[30,    46] loss: 1.23833, train_accuracy: 58.98\n",
      "[30,    47] loss: 1.36237, train_accuracy: 52.93\n",
      "[30,    48] loss: 1.33320, train_accuracy: 51.76\n",
      "[30,    49] loss: 1.43375, train_accuracy: 50.98\n",
      "[30,    50] loss: 1.33534, train_accuracy: 52.73\n",
      "[30,    51] loss: 1.30694, train_accuracy: 53.71\n",
      "[30,    52] loss: 1.32077, train_accuracy: 54.49\n",
      "[30,    53] loss: 1.35648, train_accuracy: 53.32\n",
      "[30,    54] loss: 1.28574, train_accuracy: 54.30\n",
      "[30,    55] loss: 1.35838, train_accuracy: 50.98\n",
      "[30,    56] loss: 1.34802, train_accuracy: 52.15\n",
      "[30,    57] loss: 1.30900, train_accuracy: 52.73\n",
      "[30,    58] loss: 1.39452, train_accuracy: 50.59\n",
      "[30,    59] loss: 1.30183, train_accuracy: 55.47\n",
      "[30,    60] loss: 1.35275, train_accuracy: 51.95\n",
      "[30,    61] loss: 1.41942, train_accuracy: 52.15\n",
      "[30,    62] loss: 1.41393, train_accuracy: 49.80\n",
      "[30,    63] loss: 1.44806, train_accuracy: 49.02\n",
      "[30,    64] loss: 1.39159, train_accuracy: 53.32\n",
      "[30,    65] loss: 1.35968, train_accuracy: 52.15\n",
      "[30,    66] loss: 1.30187, train_accuracy: 54.88\n",
      "[30,    67] loss: 1.34952, train_accuracy: 53.32\n",
      "[30,    68] loss: 1.38901, train_accuracy: 49.02\n",
      "[30,    69] loss: 1.36955, train_accuracy: 48.24\n",
      "[30,    70] loss: 1.23665, train_accuracy: 57.62\n",
      "[30,    71] loss: 1.34677, train_accuracy: 51.76\n",
      "[30,    72] loss: 1.31777, train_accuracy: 54.49\n",
      "[30,    73] loss: 1.41261, train_accuracy: 48.83\n",
      "[30,    74] loss: 1.36105, train_accuracy: 51.37\n",
      "[30,    75] loss: 1.36153, train_accuracy: 51.37\n",
      "[30,    76] loss: 1.32457, train_accuracy: 54.69\n",
      "[30,    77] loss: 1.32780, train_accuracy: 53.71\n",
      "[30,    78] loss: 1.32440, train_accuracy: 53.91\n",
      "[30,    79] loss: 1.25162, train_accuracy: 55.66\n",
      "[30,    80] loss: 1.29862, train_accuracy: 54.10\n",
      "[30,    81] loss: 1.33371, train_accuracy: 55.66\n",
      "[30,    82] loss: 1.38940, train_accuracy: 51.95\n",
      "[30,    83] loss: 1.31337, train_accuracy: 54.10\n",
      "[30,    84] loss: 1.45507, train_accuracy: 49.80\n",
      "[30,    85] loss: 1.42468, train_accuracy: 49.41\n",
      "[30,    86] loss: 1.39940, train_accuracy: 50.20\n",
      "[30,    87] loss: 1.40977, train_accuracy: 47.27\n",
      "[30,    88] loss: 1.32775, train_accuracy: 53.12\n",
      "[30,    89] loss: 1.40020, train_accuracy: 49.80\n",
      "[30,    90] loss: 1.40741, train_accuracy: 49.80\n",
      "[30,    91] loss: 1.30974, train_accuracy: 52.15\n",
      "[30,    92] loss: 1.25847, train_accuracy: 56.25\n",
      "[30,    93] loss: 1.32543, train_accuracy: 53.52\n",
      "[30,    94] loss: 1.31556, train_accuracy: 52.73\n",
      "[30,    95] loss: 1.39533, train_accuracy: 51.95\n",
      "[30,    96] loss: 1.30085, train_accuracy: 53.32\n",
      "[30,    97] loss: 1.35632, train_accuracy: 54.10\n",
      "[30,    98] loss: 1.32353, train_accuracy: 50.30\n",
      "duration: 231 s - train loss: 1.34690 - train accuracy: 52.51 - validation loss: 1.04914 - validation accuracy: 63.77 \n"
     ]
    }
   ],
   "source": [
    "fit_fast(model, train_loader, test_loader, 30, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63.87, 0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_clean_accuracy(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rob_accuracy(model, test_loader, device, epsilon=8/255, attack='PGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_fast_with_double_update(model, train_loader, val_loader , epochs, device, number_of_replays=3, eps = 16/255):\n",
    "    mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "    mean = torch.tensor(mean).view(3,1,1).expand(3,32,32)\n",
    "    std = torch.tensor(std).view(3,1,1).expand(3,32,32)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    for epoch in range(epochs):\n",
    "        t0 = time.time()\n",
    "        running_loss, acc_epoch_loss, avg_epoch_loss, epoch_accuracy, acc_epoch_accuracy = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        \n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            pert = torch.rand_like(inputs, requires_grad=True)\n",
    "            adv_inputs = inputs + pert\n",
    "            adv_inputs.clamp_(0, 1.0)\n",
    "            adv_inputs.sub_(mean).div_(std)\n",
    "            #clip 0,1\n",
    "            \n",
    "            # first backwards pass to perform fgsm\n",
    "            outputs = model(adv_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            pert = pert + (eps * pert.grad)\n",
    "            pert.clamp_(-eps, eps)\n",
    "            adv_inputs = inputs + pert\n",
    "            optimizer.step()\n",
    "            \n",
    "            # second backwards pass to update weights on adv.\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(adv_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            accuracy = get_accuracy(labels, outputs)\n",
    "            acc_epoch_loss += loss.item() \n",
    "            avg_epoch_loss = acc_epoch_loss / (i+1)\n",
    "            acc_epoch_accuracy += accuracy\n",
    "            avg_epoch_accuracy = acc_epoch_accuracy / (i+1)\n",
    "            if i%1 == 0:\n",
    "                print('[%d, %5d] loss: %.5f, train_accuracy: %.2f' %(epoch + 1, i + 1, loss.item(), accuracy))\n",
    "\n",
    "        t1 = time.time()\n",
    "        accuracy, loss = _evaluate_model(model, val_loader, device, criterion)\n",
    "\n",
    "        print('duration: %d s - train loss: %.5f - train accuracy: %.2f - validation loss: %.5f - validation accuracy: %.2f ' %(t1-t0, avg_epoch_loss, avg_epoch_accuracy, loss, accuracy))\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.66116, train_accuracy: 12.11\n",
      "[1,     2] loss: 2.55891, train_accuracy: 19.14\n",
      "[1,     3] loss: 2.44707, train_accuracy: 18.75\n",
      "[1,     4] loss: 2.29412, train_accuracy: 21.88\n",
      "[1,     5] loss: 2.28044, train_accuracy: 21.29\n",
      "[1,     6] loss: 2.23886, train_accuracy: 20.31\n",
      "[1,     7] loss: 2.13059, train_accuracy: 24.61\n",
      "[1,     8] loss: 2.27068, train_accuracy: 23.63\n",
      "[1,     9] loss: 2.13736, train_accuracy: 26.17\n",
      "[1,    10] loss: 2.14453, train_accuracy: 24.41\n",
      "[1,    11] loss: 2.19443, train_accuracy: 23.63\n",
      "[1,    12] loss: 2.08948, train_accuracy: 27.34\n",
      "[1,    13] loss: 2.10452, train_accuracy: 23.05\n",
      "[1,    14] loss: 2.00129, train_accuracy: 30.08\n",
      "[1,    15] loss: 2.02556, train_accuracy: 25.98\n",
      "[1,    16] loss: 2.09792, train_accuracy: 26.37\n",
      "[1,    17] loss: 2.06948, train_accuracy: 23.83\n",
      "[1,    18] loss: 1.96625, train_accuracy: 29.49\n",
      "[1,    19] loss: 1.99748, train_accuracy: 26.17\n",
      "[1,    20] loss: 2.05507, train_accuracy: 26.37\n",
      "[1,    21] loss: 2.07647, train_accuracy: 24.41\n",
      "[1,    22] loss: 1.99043, train_accuracy: 27.15\n",
      "[1,    23] loss: 1.93009, train_accuracy: 28.91\n",
      "[1,    24] loss: 2.01446, train_accuracy: 28.12\n",
      "[1,    25] loss: 1.95269, train_accuracy: 30.86\n",
      "[1,    26] loss: 2.03932, train_accuracy: 24.41\n",
      "[1,    27] loss: 1.98517, train_accuracy: 25.98\n",
      "[1,    28] loss: 2.03242, train_accuracy: 25.39\n",
      "[1,    29] loss: 2.02398, train_accuracy: 26.37\n",
      "[1,    30] loss: 1.96200, train_accuracy: 27.34\n",
      "[1,    31] loss: 1.96975, train_accuracy: 28.91\n",
      "[1,    32] loss: 2.02372, train_accuracy: 30.27\n",
      "[1,    33] loss: 1.95969, train_accuracy: 30.08\n",
      "[1,    34] loss: 2.01718, train_accuracy: 27.93\n",
      "[1,    35] loss: 1.99737, train_accuracy: 25.98\n",
      "[1,    36] loss: 1.87172, train_accuracy: 31.64\n",
      "[1,    37] loss: 1.94574, train_accuracy: 29.49\n",
      "[1,    38] loss: 1.91374, train_accuracy: 31.25\n",
      "[1,    39] loss: 1.93039, train_accuracy: 30.27\n",
      "[1,    40] loss: 1.95073, train_accuracy: 30.08\n",
      "[1,    41] loss: 1.91182, train_accuracy: 32.03\n",
      "[1,    42] loss: 1.85572, train_accuracy: 31.05\n",
      "[1,    43] loss: 1.85136, train_accuracy: 30.86\n",
      "[1,    44] loss: 1.88897, train_accuracy: 34.38\n",
      "[1,    45] loss: 1.95890, train_accuracy: 29.30\n",
      "[1,    46] loss: 1.97143, train_accuracy: 27.15\n",
      "[1,    47] loss: 1.77886, train_accuracy: 36.33\n",
      "[1,    48] loss: 1.85717, train_accuracy: 30.86\n",
      "[1,    49] loss: 1.95480, train_accuracy: 33.01\n",
      "[1,    50] loss: 1.79635, train_accuracy: 31.84\n",
      "[1,    51] loss: 1.91960, train_accuracy: 27.93\n",
      "[1,    52] loss: 1.88188, train_accuracy: 30.86\n",
      "[1,    53] loss: 1.88419, train_accuracy: 32.42\n",
      "[1,    54] loss: 1.84247, train_accuracy: 34.38\n",
      "[1,    55] loss: 1.84648, train_accuracy: 33.20\n",
      "[1,    56] loss: 1.90753, train_accuracy: 33.20\n",
      "[1,    57] loss: 1.81831, train_accuracy: 31.05\n",
      "[1,    58] loss: 1.90331, train_accuracy: 28.32\n",
      "[1,    59] loss: 1.87632, train_accuracy: 33.59\n",
      "[1,    60] loss: 1.96782, train_accuracy: 29.30\n",
      "[1,    61] loss: 1.87826, train_accuracy: 31.05\n",
      "[1,    62] loss: 1.90752, train_accuracy: 28.91\n",
      "[1,    63] loss: 1.90017, train_accuracy: 29.88\n",
      "[1,    64] loss: 1.83555, train_accuracy: 31.64\n",
      "[1,    65] loss: 1.84331, train_accuracy: 37.11\n",
      "[1,    66] loss: 1.84223, train_accuracy: 32.03\n",
      "[1,    67] loss: 1.85200, train_accuracy: 30.47\n",
      "[1,    68] loss: 1.87997, train_accuracy: 30.27\n",
      "[1,    69] loss: 1.88688, train_accuracy: 31.45\n",
      "[1,    70] loss: 1.87760, train_accuracy: 35.16\n",
      "[1,    71] loss: 1.88775, train_accuracy: 32.81\n",
      "[1,    72] loss: 1.85572, train_accuracy: 31.64\n",
      "[1,    73] loss: 1.89820, train_accuracy: 29.30\n",
      "[1,    74] loss: 1.80986, train_accuracy: 33.79\n",
      "[1,    75] loss: 1.86366, train_accuracy: 36.33\n",
      "[1,    76] loss: 1.84241, train_accuracy: 31.25\n",
      "[1,    77] loss: 1.88176, train_accuracy: 32.81\n",
      "[1,    78] loss: 1.82231, train_accuracy: 32.42\n",
      "[1,    79] loss: 1.75849, train_accuracy: 35.74\n",
      "[1,    80] loss: 1.87775, train_accuracy: 33.40\n",
      "[1,    81] loss: 1.82629, train_accuracy: 35.55\n",
      "[1,    82] loss: 1.79085, train_accuracy: 34.77\n",
      "[1,    83] loss: 1.87373, train_accuracy: 29.49\n",
      "[1,    84] loss: 1.86880, train_accuracy: 33.40\n",
      "[1,    85] loss: 1.77869, train_accuracy: 34.38\n",
      "[1,    86] loss: 1.78483, train_accuracy: 36.72\n",
      "[1,    87] loss: 1.79314, train_accuracy: 35.16\n",
      "[1,    88] loss: 1.75887, train_accuracy: 39.26\n",
      "[1,    89] loss: 1.87395, train_accuracy: 37.11\n",
      "[1,    90] loss: 1.86102, train_accuracy: 29.49\n",
      "[1,    91] loss: 1.78118, train_accuracy: 35.16\n",
      "[1,    92] loss: 1.81348, train_accuracy: 35.74\n",
      "[1,    93] loss: 1.84736, train_accuracy: 32.23\n",
      "[1,    94] loss: 1.77045, train_accuracy: 37.50\n",
      "[1,    95] loss: 1.83705, train_accuracy: 32.42\n",
      "[1,    96] loss: 1.69668, train_accuracy: 36.33\n",
      "[1,    97] loss: 1.74520, train_accuracy: 37.11\n",
      "[1,    98] loss: 1.61823, train_accuracy: 43.15\n",
      "duration: 293 s - train loss: 1.94435 - train accuracy: 30.13 - validation loss: 1.56449 - validation accuracy: 42.67 \n",
      "[2,     1] loss: 1.82461, train_accuracy: 34.18\n",
      "[2,     2] loss: 1.83276, train_accuracy: 31.64\n",
      "[2,     3] loss: 1.81625, train_accuracy: 30.66\n",
      "[2,     4] loss: 1.73220, train_accuracy: 37.11\n",
      "[2,     5] loss: 1.78308, train_accuracy: 34.38\n",
      "[2,     6] loss: 1.80401, train_accuracy: 36.52\n",
      "[2,     7] loss: 1.76395, train_accuracy: 33.98\n",
      "[2,     8] loss: 1.73524, train_accuracy: 36.13\n",
      "[2,     9] loss: 1.86141, train_accuracy: 31.45\n",
      "[2,    10] loss: 1.75108, train_accuracy: 37.70\n",
      "[2,    11] loss: 1.76444, train_accuracy: 35.74\n",
      "[2,    12] loss: 1.77592, train_accuracy: 35.16\n",
      "[2,    13] loss: 1.85857, train_accuracy: 30.86\n",
      "[2,    14] loss: 1.77339, train_accuracy: 35.35\n",
      "[2,    15] loss: 1.82286, train_accuracy: 38.09\n",
      "[2,    16] loss: 1.80192, train_accuracy: 33.79\n",
      "[2,    17] loss: 1.77402, train_accuracy: 35.74\n",
      "[2,    18] loss: 1.78136, train_accuracy: 36.52\n",
      "[2,    19] loss: 1.70704, train_accuracy: 35.94\n",
      "[2,    20] loss: 1.78618, train_accuracy: 34.57\n",
      "[2,    21] loss: 1.77747, train_accuracy: 35.94\n",
      "[2,    22] loss: 1.80975, train_accuracy: 34.38\n",
      "[2,    23] loss: 1.75765, train_accuracy: 33.40\n",
      "[2,    24] loss: 1.75739, train_accuracy: 38.87\n",
      "[2,    25] loss: 1.78448, train_accuracy: 35.35\n",
      "[2,    26] loss: 1.76383, train_accuracy: 38.87\n",
      "[2,    27] loss: 1.73467, train_accuracy: 37.30\n",
      "[2,    28] loss: 1.78191, train_accuracy: 34.77\n",
      "[2,    29] loss: 1.69496, train_accuracy: 38.67\n",
      "[2,    30] loss: 1.80811, train_accuracy: 35.16\n",
      "[2,    31] loss: 1.80227, train_accuracy: 34.77\n",
      "[2,    32] loss: 1.79521, train_accuracy: 35.35\n",
      "[2,    33] loss: 1.70493, train_accuracy: 37.89\n",
      "[2,    34] loss: 1.75734, train_accuracy: 38.67\n",
      "[2,    35] loss: 1.84589, train_accuracy: 33.98\n",
      "[2,    36] loss: 1.72498, train_accuracy: 37.89\n",
      "[2,    37] loss: 1.72591, train_accuracy: 35.94\n",
      "[2,    38] loss: 1.77185, train_accuracy: 37.89\n",
      "[2,    39] loss: 1.84052, train_accuracy: 33.98\n",
      "[2,    40] loss: 1.73184, train_accuracy: 36.13\n",
      "[2,    41] loss: 1.71456, train_accuracy: 36.33\n",
      "[2,    42] loss: 1.75650, train_accuracy: 33.20\n",
      "[2,    43] loss: 1.75437, train_accuracy: 36.52\n",
      "[2,    44] loss: 1.80791, train_accuracy: 35.94\n",
      "[2,    45] loss: 1.73135, train_accuracy: 36.72\n",
      "[2,    46] loss: 1.79282, train_accuracy: 33.01\n",
      "[2,    47] loss: 1.77685, train_accuracy: 35.35\n",
      "[2,    48] loss: 1.77460, train_accuracy: 36.52\n",
      "[2,    49] loss: 1.70510, train_accuracy: 36.52\n",
      "[2,    50] loss: 1.80074, train_accuracy: 37.89\n",
      "[2,    51] loss: 1.69808, train_accuracy: 40.43\n",
      "[2,    52] loss: 1.73512, train_accuracy: 36.52\n",
      "[2,    53] loss: 1.75724, train_accuracy: 35.94\n",
      "[2,    54] loss: 1.77669, train_accuracy: 35.16\n",
      "[2,    55] loss: 1.71242, train_accuracy: 37.50\n",
      "[2,    56] loss: 1.70510, train_accuracy: 39.26\n",
      "[2,    57] loss: 1.80220, train_accuracy: 34.38\n",
      "[2,    58] loss: 1.78042, train_accuracy: 35.35\n",
      "[2,    59] loss: 1.74347, train_accuracy: 36.72\n",
      "[2,    60] loss: 1.78540, train_accuracy: 32.62\n",
      "[2,    61] loss: 1.79664, train_accuracy: 34.57\n",
      "[2,    62] loss: 1.73883, train_accuracy: 38.09\n",
      "[2,    63] loss: 1.65507, train_accuracy: 37.89\n",
      "[2,    64] loss: 1.67742, train_accuracy: 38.48\n",
      "[2,    65] loss: 1.71154, train_accuracy: 38.48\n",
      "[2,    66] loss: 1.79384, train_accuracy: 33.59\n",
      "[2,    67] loss: 1.71282, train_accuracy: 38.28\n",
      "[2,    68] loss: 1.71457, train_accuracy: 37.70\n",
      "[2,    69] loss: 1.70597, train_accuracy: 37.89\n",
      "[2,    70] loss: 1.70202, train_accuracy: 37.50\n",
      "[2,    71] loss: 1.73111, train_accuracy: 37.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    72] loss: 1.67464, train_accuracy: 38.87\n",
      "[2,    73] loss: 1.67981, train_accuracy: 40.04\n",
      "[2,    74] loss: 1.66716, train_accuracy: 37.30\n",
      "[2,    75] loss: 1.77758, train_accuracy: 35.55\n",
      "[2,    76] loss: 1.74583, train_accuracy: 37.50\n",
      "[2,    77] loss: 1.67587, train_accuracy: 37.89\n",
      "[2,    78] loss: 1.74530, train_accuracy: 37.70\n",
      "[2,    79] loss: 1.74576, train_accuracy: 36.13\n",
      "[2,    80] loss: 1.67584, train_accuracy: 35.94\n",
      "[2,    81] loss: 1.74719, train_accuracy: 40.23\n",
      "[2,    82] loss: 1.70323, train_accuracy: 39.84\n",
      "[2,    83] loss: 1.67273, train_accuracy: 38.09\n",
      "[2,    84] loss: 1.77330, train_accuracy: 34.57\n",
      "[2,    85] loss: 1.71300, train_accuracy: 38.87\n",
      "[2,    86] loss: 1.71906, train_accuracy: 37.11\n",
      "[2,    87] loss: 1.68709, train_accuracy: 40.43\n",
      "[2,    88] loss: 1.71389, train_accuracy: 37.50\n",
      "[2,    89] loss: 1.71178, train_accuracy: 34.77\n",
      "[2,    90] loss: 1.74080, train_accuracy: 38.09\n",
      "[2,    91] loss: 1.71875, train_accuracy: 38.28\n",
      "[2,    92] loss: 1.71261, train_accuracy: 36.72\n",
      "[2,    93] loss: 1.70975, train_accuracy: 37.11\n",
      "[2,    94] loss: 1.70709, train_accuracy: 37.89\n",
      "[2,    95] loss: 1.77120, train_accuracy: 36.91\n",
      "[2,    96] loss: 1.80562, train_accuracy: 37.70\n",
      "[2,    97] loss: 1.66820, train_accuracy: 39.65\n",
      "[2,    98] loss: 1.76015, train_accuracy: 34.82\n",
      "duration: 216 s - train loss: 1.75097 - train accuracy: 36.41 - validation loss: 1.44628 - validation accuracy: 48.01 \n",
      "[3,     1] loss: 1.76109, train_accuracy: 37.70\n",
      "[3,     2] loss: 1.69329, train_accuracy: 36.52\n",
      "[3,     3] loss: 1.67356, train_accuracy: 36.91\n",
      "[3,     4] loss: 1.74268, train_accuracy: 36.91\n",
      "[3,     5] loss: 1.67824, train_accuracy: 38.87\n",
      "[3,     6] loss: 1.78713, train_accuracy: 37.11\n",
      "[3,     7] loss: 1.67615, train_accuracy: 40.62\n",
      "[3,     8] loss: 1.75017, train_accuracy: 37.11\n",
      "[3,     9] loss: 1.68020, train_accuracy: 39.26\n",
      "[3,    10] loss: 1.67328, train_accuracy: 39.45\n",
      "[3,    11] loss: 1.75511, train_accuracy: 37.70\n",
      "[3,    12] loss: 1.67842, train_accuracy: 40.62\n",
      "[3,    13] loss: 1.63923, train_accuracy: 40.82\n",
      "[3,    14] loss: 1.70324, train_accuracy: 37.70\n",
      "[3,    15] loss: 1.68617, train_accuracy: 39.06\n",
      "[3,    16] loss: 1.72868, train_accuracy: 34.96\n",
      "[3,    17] loss: 1.71101, train_accuracy: 38.09\n",
      "[3,    18] loss: 1.71902, train_accuracy: 37.89\n",
      "[3,    19] loss: 1.65250, train_accuracy: 40.43\n",
      "[3,    20] loss: 1.73739, train_accuracy: 36.33\n",
      "[3,    21] loss: 1.72279, train_accuracy: 35.74\n",
      "[3,    22] loss: 1.82442, train_accuracy: 34.18\n",
      "[3,    23] loss: 1.71673, train_accuracy: 33.79\n",
      "[3,    24] loss: 1.68384, train_accuracy: 39.06\n",
      "[3,    25] loss: 1.75673, train_accuracy: 35.74\n",
      "[3,    26] loss: 1.65332, train_accuracy: 41.60\n",
      "[3,    27] loss: 1.70356, train_accuracy: 37.70\n",
      "[3,    28] loss: 1.70956, train_accuracy: 35.35\n",
      "[3,    29] loss: 1.60433, train_accuracy: 41.02\n",
      "[3,    30] loss: 1.74658, train_accuracy: 36.72\n",
      "[3,    31] loss: 1.63357, train_accuracy: 42.19\n",
      "[3,    32] loss: 1.67843, train_accuracy: 38.28\n",
      "[3,    33] loss: 1.69477, train_accuracy: 40.23\n",
      "[3,    34] loss: 1.66209, train_accuracy: 38.48\n",
      "[3,    35] loss: 1.62851, train_accuracy: 38.09\n",
      "[3,    36] loss: 1.69999, train_accuracy: 37.30\n",
      "[3,    37] loss: 1.68925, train_accuracy: 40.82\n",
      "[3,    38] loss: 1.67515, train_accuracy: 37.89\n",
      "[3,    39] loss: 1.69314, train_accuracy: 37.70\n",
      "[3,    40] loss: 1.71375, train_accuracy: 37.89\n",
      "[3,    41] loss: 1.72077, train_accuracy: 36.91\n",
      "[3,    42] loss: 1.70187, train_accuracy: 40.62\n",
      "[3,    43] loss: 1.65948, train_accuracy: 38.67\n",
      "[3,    44] loss: 1.65008, train_accuracy: 40.62\n",
      "[3,    45] loss: 1.63088, train_accuracy: 41.80\n",
      "[3,    46] loss: 1.77236, train_accuracy: 34.96\n",
      "[3,    47] loss: 1.67759, train_accuracy: 39.06\n",
      "[3,    48] loss: 1.66933, train_accuracy: 41.02\n",
      "[3,    49] loss: 1.70484, train_accuracy: 40.62\n",
      "[3,    50] loss: 1.62408, train_accuracy: 42.58\n",
      "[3,    51] loss: 1.69981, train_accuracy: 37.30\n",
      "[3,    52] loss: 1.72215, train_accuracy: 39.65\n",
      "[3,    53] loss: 1.66668, train_accuracy: 40.43\n",
      "[3,    54] loss: 1.69569, train_accuracy: 39.84\n",
      "[3,    55] loss: 1.60874, train_accuracy: 40.43\n",
      "[3,    56] loss: 1.63962, train_accuracy: 39.65\n",
      "[3,    57] loss: 1.68379, train_accuracy: 39.26\n",
      "[3,    58] loss: 1.62115, train_accuracy: 40.82\n",
      "[3,    59] loss: 1.73204, train_accuracy: 35.74\n",
      "[3,    60] loss: 1.73697, train_accuracy: 35.74\n",
      "[3,    61] loss: 1.64357, train_accuracy: 38.67\n",
      "[3,    62] loss: 1.61403, train_accuracy: 42.58\n",
      "[3,    63] loss: 1.71218, train_accuracy: 37.11\n",
      "[3,    64] loss: 1.64087, train_accuracy: 39.45\n",
      "[3,    65] loss: 1.58057, train_accuracy: 42.58\n",
      "[3,    66] loss: 1.64463, train_accuracy: 39.65\n",
      "[3,    67] loss: 1.59042, train_accuracy: 39.65\n",
      "[3,    68] loss: 1.69472, train_accuracy: 36.52\n",
      "[3,    69] loss: 1.72374, train_accuracy: 36.91\n",
      "[3,    70] loss: 1.68275, train_accuracy: 37.11\n",
      "[3,    71] loss: 1.61839, train_accuracy: 39.84\n",
      "[3,    72] loss: 1.71609, train_accuracy: 40.23\n",
      "[3,    73] loss: 1.68480, train_accuracy: 39.06\n",
      "[3,    74] loss: 1.64663, train_accuracy: 40.43\n",
      "[3,    75] loss: 1.68449, train_accuracy: 41.02\n",
      "[3,    76] loss: 1.70394, train_accuracy: 41.21\n",
      "[3,    77] loss: 1.69791, train_accuracy: 37.70\n",
      "[3,    78] loss: 1.61576, train_accuracy: 40.04\n",
      "[3,    79] loss: 1.65576, train_accuracy: 41.21\n",
      "[3,    80] loss: 1.65231, train_accuracy: 39.84\n",
      "[3,    81] loss: 1.67349, train_accuracy: 38.28\n",
      "[3,    82] loss: 1.59159, train_accuracy: 39.06\n",
      "[3,    83] loss: 1.68045, train_accuracy: 38.87\n",
      "[3,    84] loss: 1.70756, train_accuracy: 37.70\n",
      "[3,    85] loss: 1.63028, train_accuracy: 40.82\n",
      "[3,    86] loss: 1.66246, train_accuracy: 40.04\n",
      "[3,    87] loss: 1.65006, train_accuracy: 41.21\n",
      "[3,    88] loss: 1.55582, train_accuracy: 41.21\n",
      "[3,    89] loss: 1.68445, train_accuracy: 37.70\n",
      "[3,    90] loss: 1.67512, train_accuracy: 40.23\n",
      "[3,    91] loss: 1.62143, train_accuracy: 40.23\n",
      "[3,    92] loss: 1.71082, train_accuracy: 40.43\n",
      "[3,    93] loss: 1.59408, train_accuracy: 41.21\n",
      "[3,    94] loss: 1.68431, train_accuracy: 40.23\n",
      "[3,    95] loss: 1.66069, train_accuracy: 39.06\n",
      "[3,    96] loss: 1.71526, train_accuracy: 38.48\n",
      "[3,    97] loss: 1.68169, train_accuracy: 42.19\n",
      "[3,    98] loss: 1.69516, train_accuracy: 42.26\n",
      "duration: 228 s - train loss: 1.68075 - train accuracy: 38.98 - validation loss: 1.42220 - validation accuracy: 48.82 \n",
      "[4,     1] loss: 1.66916, train_accuracy: 40.82\n",
      "[4,     2] loss: 1.71237, train_accuracy: 37.50\n",
      "[4,     3] loss: 1.66734, train_accuracy: 41.99\n",
      "[4,     4] loss: 1.63137, train_accuracy: 42.19\n",
      "[4,     5] loss: 1.68245, train_accuracy: 37.30\n",
      "[4,     6] loss: 1.68968, train_accuracy: 38.28\n",
      "[4,     7] loss: 1.58298, train_accuracy: 40.82\n",
      "[4,     8] loss: 1.69739, train_accuracy: 37.70\n",
      "[4,     9] loss: 1.69223, train_accuracy: 39.06\n",
      "[4,    10] loss: 1.66036, train_accuracy: 39.65\n",
      "[4,    11] loss: 1.61257, train_accuracy: 40.04\n",
      "[4,    12] loss: 1.63552, train_accuracy: 40.43\n",
      "[4,    13] loss: 1.63379, train_accuracy: 38.67\n",
      "[4,    14] loss: 1.62844, train_accuracy: 41.99\n",
      "[4,    15] loss: 1.68476, train_accuracy: 37.30\n",
      "[4,    16] loss: 1.68048, train_accuracy: 38.28\n",
      "[4,    17] loss: 1.60456, train_accuracy: 41.02\n",
      "[4,    18] loss: 1.63444, train_accuracy: 37.89\n",
      "[4,    19] loss: 1.64327, train_accuracy: 42.19\n",
      "[4,    20] loss: 1.63016, train_accuracy: 39.84\n",
      "[4,    21] loss: 1.66284, train_accuracy: 39.26\n",
      "[4,    22] loss: 1.56796, train_accuracy: 44.73\n",
      "[4,    23] loss: 1.70183, train_accuracy: 40.43\n",
      "[4,    24] loss: 1.65177, train_accuracy: 40.62\n",
      "[4,    25] loss: 1.59421, train_accuracy: 42.77\n",
      "[4,    26] loss: 1.72198, train_accuracy: 36.72\n",
      "[4,    27] loss: 1.67186, train_accuracy: 39.45\n",
      "[4,    28] loss: 1.58926, train_accuracy: 45.31\n",
      "[4,    29] loss: 1.64619, train_accuracy: 40.23\n",
      "[4,    30] loss: 1.64767, train_accuracy: 36.72\n",
      "[4,    31] loss: 1.61687, train_accuracy: 39.84\n",
      "[4,    32] loss: 1.62723, train_accuracy: 41.80\n",
      "[4,    33] loss: 1.63027, train_accuracy: 38.67\n",
      "[4,    34] loss: 1.59975, train_accuracy: 40.82\n",
      "[4,    35] loss: 1.64978, train_accuracy: 40.62\n",
      "[4,    36] loss: 1.63402, train_accuracy: 38.48\n",
      "[4,    37] loss: 1.57704, train_accuracy: 44.73\n",
      "[4,    38] loss: 1.62566, train_accuracy: 43.36\n",
      "[4,    39] loss: 1.67315, train_accuracy: 39.06\n",
      "[4,    40] loss: 1.64095, train_accuracy: 40.82\n",
      "[4,    41] loss: 1.66815, train_accuracy: 40.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,    42] loss: 1.70110, train_accuracy: 38.09\n",
      "[4,    43] loss: 1.63171, train_accuracy: 43.55\n",
      "[4,    44] loss: 1.68387, train_accuracy: 38.28\n",
      "[4,    45] loss: 1.60345, train_accuracy: 41.99\n",
      "[4,    46] loss: 1.61998, train_accuracy: 37.89\n",
      "[4,    47] loss: 1.62594, train_accuracy: 40.43\n",
      "[4,    48] loss: 1.72208, train_accuracy: 38.67\n",
      "[4,    49] loss: 1.56524, train_accuracy: 42.19\n",
      "[4,    50] loss: 1.61532, train_accuracy: 42.77\n",
      "[4,    51] loss: 1.65125, train_accuracy: 39.84\n",
      "[4,    52] loss: 1.67315, train_accuracy: 38.87\n",
      "[4,    53] loss: 1.70330, train_accuracy: 38.09\n",
      "[4,    54] loss: 1.69604, train_accuracy: 39.06\n",
      "[4,    55] loss: 1.57728, train_accuracy: 41.99\n",
      "[4,    56] loss: 1.64115, train_accuracy: 38.87\n",
      "[4,    57] loss: 1.53323, train_accuracy: 45.12\n",
      "[4,    58] loss: 1.63504, train_accuracy: 40.23\n",
      "[4,    59] loss: 1.61329, train_accuracy: 41.02\n",
      "[4,    60] loss: 1.62497, train_accuracy: 40.43\n",
      "[4,    61] loss: 1.63985, train_accuracy: 41.41\n",
      "[4,    62] loss: 1.66023, train_accuracy: 39.06\n",
      "[4,    63] loss: 1.65473, train_accuracy: 39.45\n",
      "[4,    64] loss: 1.69614, train_accuracy: 38.09\n",
      "[4,    65] loss: 1.63245, train_accuracy: 41.80\n",
      "[4,    66] loss: 1.67682, train_accuracy: 41.21\n",
      "[4,    67] loss: 1.62457, train_accuracy: 40.04\n",
      "[4,    68] loss: 1.56462, train_accuracy: 43.36\n",
      "[4,    69] loss: 1.65200, train_accuracy: 40.62\n",
      "[4,    70] loss: 1.65250, train_accuracy: 38.67\n",
      "[4,    71] loss: 1.65831, train_accuracy: 41.02\n",
      "[4,    72] loss: 1.57380, train_accuracy: 41.80\n",
      "[4,    73] loss: 1.69381, train_accuracy: 39.65\n",
      "[4,    74] loss: 1.65928, train_accuracy: 40.04\n",
      "[4,    75] loss: 1.63564, train_accuracy: 41.02\n",
      "[4,    76] loss: 1.68556, train_accuracy: 39.06\n",
      "[4,    77] loss: 1.62783, train_accuracy: 39.65\n",
      "[4,    78] loss: 1.61172, train_accuracy: 41.80\n",
      "[4,    79] loss: 1.54095, train_accuracy: 44.73\n",
      "[4,    80] loss: 1.55259, train_accuracy: 44.53\n",
      "[4,    81] loss: 1.66076, train_accuracy: 40.82\n",
      "[4,    82] loss: 1.64918, train_accuracy: 39.26\n",
      "[4,    83] loss: 1.60318, train_accuracy: 40.43\n",
      "[4,    84] loss: 1.63510, train_accuracy: 41.60\n",
      "[4,    85] loss: 1.57928, train_accuracy: 42.19\n",
      "[4,    86] loss: 1.58563, train_accuracy: 43.16\n",
      "[4,    87] loss: 1.64943, train_accuracy: 40.04\n",
      "[4,    88] loss: 1.66274, train_accuracy: 40.23\n",
      "[4,    89] loss: 1.67340, train_accuracy: 38.48\n",
      "[4,    90] loss: 1.68399, train_accuracy: 38.67\n",
      "[4,    91] loss: 1.60797, train_accuracy: 42.38\n",
      "[4,    92] loss: 1.60381, train_accuracy: 41.80\n",
      "[4,    93] loss: 1.55684, train_accuracy: 42.58\n",
      "[4,    94] loss: 1.54364, train_accuracy: 44.14\n",
      "[4,    95] loss: 1.63433, train_accuracy: 40.23\n",
      "[4,    96] loss: 1.66979, train_accuracy: 39.84\n",
      "[4,    97] loss: 1.61346, train_accuracy: 44.14\n",
      "[4,    98] loss: 1.65696, train_accuracy: 42.56\n",
      "duration: 234 s - train loss: 1.63829 - train accuracy: 40.56 - validation loss: 1.34519 - validation accuracy: 52.13 \n",
      "[5,     1] loss: 1.66458, train_accuracy: 39.26\n",
      "[5,     2] loss: 1.67023, train_accuracy: 37.70\n",
      "[5,     3] loss: 1.64712, train_accuracy: 40.43\n",
      "[5,     4] loss: 1.60767, train_accuracy: 43.75\n",
      "[5,     5] loss: 1.58671, train_accuracy: 42.77\n",
      "[5,     6] loss: 1.58189, train_accuracy: 44.34\n",
      "[5,     7] loss: 1.60686, train_accuracy: 41.99\n",
      "[5,     8] loss: 1.65470, train_accuracy: 42.77\n",
      "[5,     9] loss: 1.64683, train_accuracy: 39.84\n",
      "[5,    10] loss: 1.62833, train_accuracy: 39.84\n",
      "[5,    11] loss: 1.56693, train_accuracy: 43.55\n",
      "[5,    12] loss: 1.67765, train_accuracy: 41.99\n",
      "[5,    13] loss: 1.63122, train_accuracy: 41.80\n",
      "[5,    14] loss: 1.65993, train_accuracy: 40.43\n",
      "[5,    15] loss: 1.67859, train_accuracy: 39.84\n",
      "[5,    16] loss: 1.64412, train_accuracy: 40.43\n",
      "[5,    17] loss: 1.62784, train_accuracy: 40.43\n",
      "[5,    18] loss: 1.62761, train_accuracy: 41.02\n",
      "[5,    19] loss: 1.62667, train_accuracy: 42.58\n",
      "[5,    20] loss: 1.54656, train_accuracy: 43.95\n",
      "[5,    21] loss: 1.59797, train_accuracy: 44.14\n",
      "[5,    22] loss: 1.58009, train_accuracy: 44.92\n",
      "[5,    23] loss: 1.56478, train_accuracy: 41.80\n",
      "[5,    24] loss: 1.64396, train_accuracy: 38.87\n",
      "[5,    25] loss: 1.66546, train_accuracy: 40.62\n",
      "[5,    26] loss: 1.54182, train_accuracy: 46.88\n",
      "[5,    27] loss: 1.68256, train_accuracy: 36.91\n",
      "[5,    28] loss: 1.55559, train_accuracy: 42.58\n",
      "[5,    29] loss: 1.60701, train_accuracy: 41.80\n",
      "[5,    30] loss: 1.63417, train_accuracy: 37.89\n",
      "[5,    31] loss: 1.62184, train_accuracy: 41.02\n",
      "[5,    32] loss: 1.59566, train_accuracy: 41.41\n",
      "[5,    33] loss: 1.58170, train_accuracy: 40.82\n",
      "[5,    34] loss: 1.67325, train_accuracy: 40.04\n",
      "[5,    35] loss: 1.56109, train_accuracy: 45.70\n",
      "[5,    36] loss: 1.62290, train_accuracy: 41.99\n",
      "[5,    37] loss: 1.65607, train_accuracy: 36.72\n",
      "[5,    38] loss: 1.63608, train_accuracy: 37.70\n",
      "[5,    39] loss: 1.57666, train_accuracy: 44.92\n",
      "[5,    40] loss: 1.63987, train_accuracy: 41.60\n",
      "[5,    41] loss: 1.58657, train_accuracy: 42.77\n",
      "[5,    42] loss: 1.55857, train_accuracy: 43.95\n",
      "[5,    43] loss: 1.63351, train_accuracy: 41.02\n",
      "[5,    44] loss: 1.66648, train_accuracy: 41.99\n",
      "[5,    45] loss: 1.57857, train_accuracy: 43.95\n",
      "[5,    46] loss: 1.57444, train_accuracy: 45.31\n",
      "[5,    47] loss: 1.59091, train_accuracy: 42.97\n",
      "[5,    48] loss: 1.64283, train_accuracy: 38.67\n",
      "[5,    49] loss: 1.57964, train_accuracy: 41.60\n",
      "[5,    50] loss: 1.64310, train_accuracy: 43.16\n",
      "[5,    51] loss: 1.67569, train_accuracy: 41.60\n",
      "[5,    52] loss: 1.61906, train_accuracy: 40.23\n",
      "[5,    53] loss: 1.66939, train_accuracy: 39.26\n",
      "[5,    54] loss: 1.50530, train_accuracy: 45.51\n",
      "[5,    55] loss: 1.65755, train_accuracy: 39.84\n",
      "[5,    56] loss: 1.60904, train_accuracy: 42.38\n",
      "[5,    57] loss: 1.57312, train_accuracy: 41.99\n",
      "[5,    58] loss: 1.62388, train_accuracy: 40.82\n",
      "[5,    59] loss: 1.60154, train_accuracy: 44.34\n",
      "[5,    60] loss: 1.59824, train_accuracy: 43.36\n",
      "[5,    61] loss: 1.58140, train_accuracy: 42.38\n",
      "[5,    62] loss: 1.55866, train_accuracy: 42.58\n",
      "[5,    63] loss: 1.63968, train_accuracy: 39.26\n",
      "[5,    64] loss: 1.59718, train_accuracy: 43.55\n",
      "[5,    65] loss: 1.61734, train_accuracy: 39.65\n",
      "[5,    66] loss: 1.58728, train_accuracy: 41.02\n",
      "[5,    67] loss: 1.60919, train_accuracy: 43.95\n",
      "[5,    68] loss: 1.65196, train_accuracy: 44.14\n",
      "[5,    69] loss: 1.59082, train_accuracy: 43.95\n",
      "[5,    70] loss: 1.59870, train_accuracy: 41.80\n",
      "[5,    71] loss: 1.62215, train_accuracy: 40.23\n",
      "[5,    72] loss: 1.51822, train_accuracy: 41.99\n",
      "[5,    73] loss: 1.60952, train_accuracy: 43.75\n",
      "[5,    74] loss: 1.62870, train_accuracy: 42.38\n",
      "[5,    75] loss: 1.61859, train_accuracy: 40.43\n",
      "[5,    76] loss: 1.53677, train_accuracy: 42.77\n",
      "[5,    77] loss: 1.59479, train_accuracy: 42.97\n",
      "[5,    78] loss: 1.62832, train_accuracy: 38.87\n",
      "[5,    79] loss: 1.62798, train_accuracy: 40.43\n",
      "[5,    80] loss: 1.59288, train_accuracy: 41.60\n",
      "[5,    81] loss: 1.57872, train_accuracy: 45.51\n",
      "[5,    82] loss: 1.54819, train_accuracy: 44.92\n",
      "[5,    83] loss: 1.52272, train_accuracy: 46.48\n",
      "[5,    84] loss: 1.57371, train_accuracy: 40.62\n",
      "[5,    85] loss: 1.55115, train_accuracy: 42.58\n",
      "[5,    86] loss: 1.65778, train_accuracy: 38.48\n",
      "[5,    87] loss: 1.67439, train_accuracy: 37.70\n",
      "[5,    88] loss: 1.54807, train_accuracy: 43.16\n",
      "[5,    89] loss: 1.62654, train_accuracy: 41.60\n",
      "[5,    90] loss: 1.50986, train_accuracy: 43.55\n",
      "[5,    91] loss: 1.60148, train_accuracy: 42.58\n",
      "[5,    92] loss: 1.56835, train_accuracy: 41.60\n",
      "[5,    93] loss: 1.60664, train_accuracy: 43.95\n",
      "[5,    94] loss: 1.57596, train_accuracy: 42.19\n",
      "[5,    95] loss: 1.61976, train_accuracy: 43.75\n",
      "[5,    96] loss: 1.62072, train_accuracy: 38.67\n",
      "[5,    97] loss: 1.54190, train_accuracy: 44.92\n",
      "[5,    98] loss: 1.57118, train_accuracy: 41.37\n",
      "duration: 233 s - train loss: 1.60730 - train accuracy: 41.87 - validation loss: 1.31664 - validation accuracy: 52.68 \n",
      "[6,     1] loss: 1.62754, train_accuracy: 40.43\n",
      "[6,     2] loss: 1.57469, train_accuracy: 46.09\n",
      "[6,     3] loss: 1.59882, train_accuracy: 40.23\n",
      "[6,     4] loss: 1.56993, train_accuracy: 44.53\n",
      "[6,     5] loss: 1.55852, train_accuracy: 41.60\n",
      "[6,     6] loss: 1.55702, train_accuracy: 44.92\n",
      "[6,     7] loss: 1.53604, train_accuracy: 45.31\n",
      "[6,     8] loss: 1.57707, train_accuracy: 45.31\n",
      "[6,     9] loss: 1.54211, train_accuracy: 44.53\n",
      "[6,    10] loss: 1.59562, train_accuracy: 41.21\n",
      "[6,    11] loss: 1.56219, train_accuracy: 42.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    12] loss: 1.57309, train_accuracy: 43.36\n",
      "[6,    13] loss: 1.58494, train_accuracy: 40.43\n",
      "[6,    14] loss: 1.59600, train_accuracy: 39.65\n",
      "[6,    15] loss: 1.58176, train_accuracy: 43.55\n",
      "[6,    16] loss: 1.57007, train_accuracy: 39.65\n",
      "[6,    17] loss: 1.53633, train_accuracy: 45.51\n",
      "[6,    18] loss: 1.58099, train_accuracy: 42.77\n",
      "[6,    19] loss: 1.59369, train_accuracy: 44.14\n",
      "[6,    20] loss: 1.56602, train_accuracy: 42.38\n",
      "[6,    21] loss: 1.58460, train_accuracy: 44.34\n",
      "[6,    22] loss: 1.56109, train_accuracy: 44.34\n",
      "[6,    23] loss: 1.57402, train_accuracy: 46.48\n",
      "[6,    24] loss: 1.59129, train_accuracy: 42.58\n",
      "[6,    25] loss: 1.61645, train_accuracy: 42.58\n",
      "[6,    26] loss: 1.59020, train_accuracy: 42.38\n",
      "[6,    27] loss: 1.57079, train_accuracy: 43.75\n",
      "[6,    28] loss: 1.57358, train_accuracy: 43.55\n",
      "[6,    29] loss: 1.58544, train_accuracy: 42.97\n",
      "[6,    30] loss: 1.58424, train_accuracy: 40.04\n",
      "[6,    31] loss: 1.60268, train_accuracy: 41.02\n",
      "[6,    32] loss: 1.66935, train_accuracy: 41.21\n",
      "[6,    33] loss: 1.57759, train_accuracy: 42.19\n",
      "[6,    34] loss: 1.61499, train_accuracy: 41.80\n",
      "[6,    35] loss: 1.54772, train_accuracy: 45.70\n",
      "[6,    36] loss: 1.60006, train_accuracy: 41.02\n",
      "[6,    37] loss: 1.49732, train_accuracy: 46.68\n",
      "[6,    38] loss: 1.63469, train_accuracy: 39.26\n",
      "[6,    39] loss: 1.59402, train_accuracy: 42.19\n",
      "[6,    40] loss: 1.61709, train_accuracy: 40.62\n",
      "[6,    41] loss: 1.63567, train_accuracy: 41.80\n",
      "[6,    42] loss: 1.58759, train_accuracy: 44.14\n",
      "[6,    43] loss: 1.66646, train_accuracy: 40.23\n",
      "[6,    44] loss: 1.62186, train_accuracy: 42.58\n",
      "[6,    45] loss: 1.54598, train_accuracy: 44.92\n",
      "[6,    46] loss: 1.57553, train_accuracy: 44.73\n",
      "[6,    47] loss: 1.59766, train_accuracy: 42.58\n",
      "[6,    48] loss: 1.60790, train_accuracy: 41.21\n",
      "[6,    49] loss: 1.66770, train_accuracy: 41.80\n",
      "[6,    50] loss: 1.58883, train_accuracy: 43.75\n",
      "[6,    51] loss: 1.60927, train_accuracy: 40.82\n",
      "[6,    52] loss: 1.65752, train_accuracy: 41.41\n",
      "[6,    53] loss: 1.57715, train_accuracy: 40.62\n",
      "[6,    54] loss: 1.55035, train_accuracy: 44.92\n",
      "[6,    55] loss: 1.59165, train_accuracy: 44.34\n",
      "[6,    56] loss: 1.67830, train_accuracy: 42.58\n",
      "[6,    57] loss: 1.54790, train_accuracy: 41.41\n",
      "[6,    58] loss: 1.57404, train_accuracy: 41.60\n",
      "[6,    59] loss: 1.65976, train_accuracy: 40.62\n",
      "[6,    60] loss: 1.67927, train_accuracy: 40.04\n",
      "[6,    61] loss: 1.57688, train_accuracy: 42.58\n",
      "[6,    62] loss: 1.61014, train_accuracy: 41.99\n",
      "[6,    63] loss: 1.61201, train_accuracy: 41.60\n",
      "[6,    64] loss: 1.57308, train_accuracy: 41.80\n",
      "[6,    65] loss: 1.52851, train_accuracy: 44.73\n",
      "[6,    66] loss: 1.65821, train_accuracy: 41.21\n",
      "[6,    67] loss: 1.60116, train_accuracy: 41.02\n",
      "[6,    68] loss: 1.60924, train_accuracy: 42.97\n",
      "[6,    69] loss: 1.55265, train_accuracy: 43.55\n",
      "[6,    70] loss: 1.61929, train_accuracy: 43.55\n",
      "[6,    71] loss: 1.47673, train_accuracy: 46.88\n",
      "[6,    72] loss: 1.52313, train_accuracy: 45.51\n",
      "[6,    73] loss: 1.54392, train_accuracy: 44.73\n",
      "[6,    74] loss: 1.56237, train_accuracy: 41.41\n",
      "[6,    75] loss: 1.64450, train_accuracy: 41.02\n",
      "[6,    76] loss: 1.48638, train_accuracy: 46.48\n",
      "[6,    77] loss: 1.52186, train_accuracy: 44.73\n",
      "[6,    78] loss: 1.57067, train_accuracy: 45.70\n",
      "[6,    79] loss: 1.51342, train_accuracy: 44.34\n",
      "[6,    80] loss: 1.58361, train_accuracy: 43.36\n",
      "[6,    81] loss: 1.53630, train_accuracy: 44.34\n",
      "[6,    82] loss: 1.55812, train_accuracy: 45.12\n",
      "[6,    83] loss: 1.48022, train_accuracy: 49.02\n",
      "[6,    84] loss: 1.59667, train_accuracy: 40.62\n",
      "[6,    85] loss: 1.47198, train_accuracy: 46.88\n",
      "[6,    86] loss: 1.64729, train_accuracy: 42.19\n",
      "[6,    87] loss: 1.50855, train_accuracy: 43.55\n",
      "[6,    88] loss: 1.67917, train_accuracy: 38.28\n",
      "[6,    89] loss: 1.59024, train_accuracy: 42.19\n",
      "[6,    90] loss: 1.59925, train_accuracy: 44.92\n",
      "[6,    91] loss: 1.47385, train_accuracy: 45.51\n",
      "[6,    92] loss: 1.59620, train_accuracy: 43.95\n",
      "[6,    93] loss: 1.56470, train_accuracy: 43.95\n",
      "[6,    94] loss: 1.55385, train_accuracy: 44.73\n",
      "[6,    95] loss: 1.58394, train_accuracy: 43.55\n",
      "[6,    96] loss: 1.50346, train_accuracy: 46.48\n",
      "[6,    97] loss: 1.63373, train_accuracy: 40.43\n",
      "[6,    98] loss: 1.59055, train_accuracy: 41.96\n",
      "duration: 226 s - train loss: 1.58190 - train accuracy: 43.02 - validation loss: 1.28252 - validation accuracy: 54.90 \n",
      "[7,     1] loss: 1.56372, train_accuracy: 43.95\n",
      "[7,     2] loss: 1.49922, train_accuracy: 48.05\n",
      "[7,     3] loss: 1.52388, train_accuracy: 47.85\n",
      "[7,     4] loss: 1.55805, train_accuracy: 43.75\n",
      "[7,     5] loss: 1.56713, train_accuracy: 41.99\n",
      "[7,     6] loss: 1.54498, train_accuracy: 42.38\n",
      "[7,     7] loss: 1.51761, train_accuracy: 42.38\n",
      "[7,     8] loss: 1.44849, train_accuracy: 49.02\n",
      "[7,     9] loss: 1.57017, train_accuracy: 44.73\n",
      "[7,    10] loss: 1.57622, train_accuracy: 43.75\n",
      "[7,    11] loss: 1.58537, train_accuracy: 41.60\n",
      "[7,    12] loss: 1.60410, train_accuracy: 43.95\n",
      "[7,    13] loss: 1.62101, train_accuracy: 43.16\n",
      "[7,    14] loss: 1.56134, train_accuracy: 42.58\n",
      "[7,    15] loss: 1.61975, train_accuracy: 40.62\n",
      "[7,    16] loss: 1.47789, train_accuracy: 44.34\n",
      "[7,    17] loss: 1.65249, train_accuracy: 39.45\n",
      "[7,    18] loss: 1.54581, train_accuracy: 44.34\n",
      "[7,    19] loss: 1.55238, train_accuracy: 45.31\n",
      "[7,    20] loss: 1.56216, train_accuracy: 44.73\n",
      "[7,    21] loss: 1.59276, train_accuracy: 43.16\n",
      "[7,    22] loss: 1.55659, train_accuracy: 43.16\n",
      "[7,    23] loss: 1.52942, train_accuracy: 45.51\n",
      "[7,    24] loss: 1.57736, train_accuracy: 43.95\n",
      "[7,    25] loss: 1.62067, train_accuracy: 41.99\n",
      "[7,    26] loss: 1.53196, train_accuracy: 43.36\n",
      "[7,    27] loss: 1.52587, train_accuracy: 44.53\n",
      "[7,    28] loss: 1.56910, train_accuracy: 41.99\n",
      "[7,    29] loss: 1.54641, train_accuracy: 44.34\n",
      "[7,    30] loss: 1.56537, train_accuracy: 44.92\n",
      "[7,    31] loss: 1.57043, train_accuracy: 41.99\n",
      "[7,    32] loss: 1.50467, train_accuracy: 47.85\n",
      "[7,    33] loss: 1.58252, train_accuracy: 43.16\n",
      "[7,    34] loss: 1.55363, train_accuracy: 44.14\n",
      "[7,    35] loss: 1.62537, train_accuracy: 44.14\n",
      "[7,    36] loss: 1.60113, train_accuracy: 45.51\n",
      "[7,    37] loss: 1.43409, train_accuracy: 48.63\n",
      "[7,    38] loss: 1.55664, train_accuracy: 44.73\n",
      "[7,    39] loss: 1.61372, train_accuracy: 42.77\n",
      "[7,    40] loss: 1.56654, train_accuracy: 42.97\n",
      "[7,    41] loss: 1.60034, train_accuracy: 42.38\n",
      "[7,    42] loss: 1.54066, train_accuracy: 42.97\n",
      "[7,    43] loss: 1.60793, train_accuracy: 40.23\n",
      "[7,    44] loss: 1.54609, train_accuracy: 44.53\n",
      "[7,    45] loss: 1.61998, train_accuracy: 41.02\n",
      "[7,    46] loss: 1.54998, train_accuracy: 44.53\n",
      "[7,    47] loss: 1.55967, train_accuracy: 44.73\n",
      "[7,    48] loss: 1.52147, train_accuracy: 47.46\n",
      "[7,    49] loss: 1.53228, train_accuracy: 44.14\n",
      "[7,    50] loss: 1.65502, train_accuracy: 40.82\n",
      "[7,    51] loss: 1.51845, train_accuracy: 45.12\n",
      "[7,    52] loss: 1.58897, train_accuracy: 44.14\n",
      "[7,    53] loss: 1.54308, train_accuracy: 43.95\n",
      "[7,    54] loss: 1.50494, train_accuracy: 43.75\n",
      "[7,    55] loss: 1.65066, train_accuracy: 40.04\n",
      "[7,    56] loss: 1.59346, train_accuracy: 41.99\n",
      "[7,    57] loss: 1.53510, train_accuracy: 43.16\n",
      "[7,    58] loss: 1.57244, train_accuracy: 44.73\n",
      "[7,    59] loss: 1.61453, train_accuracy: 41.02\n",
      "[7,    60] loss: 1.63245, train_accuracy: 41.02\n",
      "[7,    61] loss: 1.54122, train_accuracy: 43.75\n",
      "[7,    62] loss: 1.50364, train_accuracy: 45.51\n",
      "[7,    63] loss: 1.53714, train_accuracy: 48.44\n",
      "[7,    64] loss: 1.56787, train_accuracy: 43.75\n",
      "[7,    65] loss: 1.53741, train_accuracy: 46.09\n",
      "[7,    66] loss: 1.56708, train_accuracy: 44.73\n",
      "[7,    67] loss: 1.51938, train_accuracy: 44.14\n",
      "[7,    68] loss: 1.59428, train_accuracy: 42.58\n",
      "[7,    69] loss: 1.53422, train_accuracy: 45.12\n",
      "[7,    70] loss: 1.55247, train_accuracy: 42.58\n",
      "[7,    71] loss: 1.54998, train_accuracy: 43.75\n",
      "[7,    72] loss: 1.55269, train_accuracy: 40.62\n",
      "[7,    73] loss: 1.55709, train_accuracy: 43.36\n",
      "[7,    74] loss: 1.52772, train_accuracy: 44.53\n",
      "[7,    75] loss: 1.56604, train_accuracy: 45.90\n",
      "[7,    76] loss: 1.54000, train_accuracy: 44.53\n",
      "[7,    77] loss: 1.50605, train_accuracy: 44.73\n",
      "[7,    78] loss: 1.50479, train_accuracy: 44.73\n",
      "[7,    79] loss: 1.58741, train_accuracy: 42.19\n",
      "[7,    80] loss: 1.50346, train_accuracy: 46.48\n",
      "[7,    81] loss: 1.47730, train_accuracy: 45.31\n",
      "[7,    82] loss: 1.54331, train_accuracy: 43.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,    83] loss: 1.49397, train_accuracy: 44.34\n",
      "[7,    84] loss: 1.61261, train_accuracy: 44.14\n",
      "[7,    85] loss: 1.50340, train_accuracy: 44.53\n",
      "[7,    86] loss: 1.52804, train_accuracy: 43.36\n",
      "[7,    87] loss: 1.52560, train_accuracy: 44.73\n",
      "[7,    88] loss: 1.51971, train_accuracy: 44.53\n",
      "[7,    89] loss: 1.53020, train_accuracy: 45.51\n",
      "[7,    90] loss: 1.56188, train_accuracy: 45.31\n",
      "[7,    91] loss: 1.49510, train_accuracy: 47.07\n",
      "[7,    92] loss: 1.55821, train_accuracy: 43.75\n",
      "[7,    93] loss: 1.53873, train_accuracy: 44.34\n",
      "[7,    94] loss: 1.56778, train_accuracy: 45.51\n",
      "[7,    95] loss: 1.49413, train_accuracy: 45.51\n",
      "[7,    96] loss: 1.61250, train_accuracy: 40.43\n",
      "[7,    97] loss: 1.51507, train_accuracy: 45.12\n",
      "[7,    98] loss: 1.51362, train_accuracy: 46.13\n",
      "duration: 207 s - train loss: 1.55413 - train accuracy: 44.01 - validation loss: 1.26015 - validation accuracy: 55.56 \n",
      "[8,     1] loss: 1.49023, train_accuracy: 47.46\n",
      "[8,     2] loss: 1.49632, train_accuracy: 46.09\n",
      "[8,     3] loss: 1.47710, train_accuracy: 47.46\n",
      "[8,     4] loss: 1.49718, train_accuracy: 45.90\n",
      "[8,     5] loss: 1.58088, train_accuracy: 42.38\n",
      "[8,     6] loss: 1.53644, train_accuracy: 43.16\n",
      "[8,     7] loss: 1.51054, train_accuracy: 43.55\n",
      "[8,     8] loss: 1.53669, train_accuracy: 44.73\n",
      "[8,     9] loss: 1.52858, train_accuracy: 41.80\n",
      "[8,    10] loss: 1.49444, train_accuracy: 48.44\n",
      "[8,    11] loss: 1.51398, train_accuracy: 48.05\n",
      "[8,    12] loss: 1.55080, train_accuracy: 46.68\n",
      "[8,    13] loss: 1.52111, train_accuracy: 42.97\n",
      "[8,    14] loss: 1.48347, train_accuracy: 48.44\n",
      "[8,    15] loss: 1.53405, train_accuracy: 44.34\n",
      "[8,    16] loss: 1.54968, train_accuracy: 46.88\n",
      "[8,    17] loss: 1.47459, train_accuracy: 47.66\n",
      "[8,    18] loss: 1.54905, train_accuracy: 45.70\n",
      "[8,    19] loss: 1.53534, train_accuracy: 44.34\n",
      "[8,    20] loss: 1.52670, train_accuracy: 43.75\n",
      "[8,    21] loss: 1.58645, train_accuracy: 42.77\n",
      "[8,    22] loss: 1.46568, train_accuracy: 50.78\n",
      "[8,    23] loss: 1.56583, train_accuracy: 45.31\n",
      "[8,    24] loss: 1.45281, train_accuracy: 46.88\n",
      "[8,    25] loss: 1.52805, train_accuracy: 46.48\n",
      "[8,    26] loss: 1.63504, train_accuracy: 44.53\n",
      "[8,    27] loss: 1.49175, train_accuracy: 46.09\n",
      "[8,    28] loss: 1.58841, train_accuracy: 43.55\n",
      "[8,    29] loss: 1.56306, train_accuracy: 43.95\n",
      "[8,    30] loss: 1.65210, train_accuracy: 40.62\n",
      "[8,    31] loss: 1.62420, train_accuracy: 39.65\n",
      "[8,    32] loss: 1.59549, train_accuracy: 44.34\n",
      "[8,    33] loss: 1.48529, train_accuracy: 50.39\n",
      "[8,    34] loss: 1.54005, train_accuracy: 44.53\n",
      "[8,    35] loss: 1.53949, train_accuracy: 43.95\n",
      "[8,    36] loss: 1.59137, train_accuracy: 42.58\n",
      "[8,    37] loss: 1.55880, train_accuracy: 43.75\n",
      "[8,    38] loss: 1.51702, train_accuracy: 44.34\n",
      "[8,    39] loss: 1.58814, train_accuracy: 39.45\n",
      "[8,    40] loss: 1.53745, train_accuracy: 45.70\n",
      "[8,    41] loss: 1.54027, train_accuracy: 46.88\n",
      "[8,    42] loss: 1.58417, train_accuracy: 43.16\n",
      "[8,    43] loss: 1.49276, train_accuracy: 48.44\n",
      "[8,    44] loss: 1.65946, train_accuracy: 42.77\n",
      "[8,    45] loss: 1.57067, train_accuracy: 42.97\n",
      "[8,    46] loss: 1.51420, train_accuracy: 48.05\n",
      "[8,    47] loss: 1.55228, train_accuracy: 41.99\n",
      "[8,    48] loss: 1.48205, train_accuracy: 43.55\n",
      "[8,    49] loss: 1.53401, train_accuracy: 42.58\n",
      "[8,    50] loss: 1.50910, train_accuracy: 43.55\n",
      "[8,    51] loss: 1.44795, train_accuracy: 47.27\n",
      "[8,    52] loss: 1.58712, train_accuracy: 41.80\n",
      "[8,    53] loss: 1.55734, train_accuracy: 43.36\n",
      "[8,    54] loss: 1.58812, train_accuracy: 41.21\n",
      "[8,    55] loss: 1.51286, train_accuracy: 47.46\n",
      "[8,    56] loss: 1.52888, train_accuracy: 43.75\n",
      "[8,    57] loss: 1.56096, train_accuracy: 39.26\n",
      "[8,    58] loss: 1.57340, train_accuracy: 42.19\n",
      "[8,    59] loss: 1.54331, train_accuracy: 43.75\n",
      "[8,    60] loss: 1.55288, train_accuracy: 43.36\n",
      "[8,    61] loss: 1.52468, train_accuracy: 44.34\n",
      "[8,    62] loss: 1.55935, train_accuracy: 44.14\n",
      "[8,    63] loss: 1.53260, train_accuracy: 43.75\n",
      "[8,    64] loss: 1.56088, train_accuracy: 43.36\n",
      "[8,    65] loss: 1.53406, train_accuracy: 46.48\n",
      "[8,    66] loss: 1.57025, train_accuracy: 41.99\n",
      "[8,    67] loss: 1.53925, train_accuracy: 45.31\n",
      "[8,    68] loss: 1.52239, train_accuracy: 43.55\n",
      "[8,    69] loss: 1.48915, train_accuracy: 44.92\n",
      "[8,    70] loss: 1.54621, train_accuracy: 45.31\n",
      "[8,    71] loss: 1.50249, train_accuracy: 41.60\n",
      "[8,    72] loss: 1.59194, train_accuracy: 41.60\n",
      "[8,    73] loss: 1.45594, train_accuracy: 47.46\n",
      "[8,    74] loss: 1.50442, train_accuracy: 46.09\n",
      "[8,    75] loss: 1.52512, train_accuracy: 42.19\n",
      "[8,    76] loss: 1.53488, train_accuracy: 44.34\n",
      "[8,    77] loss: 1.48602, train_accuracy: 47.07\n",
      "[8,    78] loss: 1.49269, train_accuracy: 47.27\n",
      "[8,    79] loss: 1.57658, train_accuracy: 42.97\n",
      "[8,    80] loss: 1.53288, train_accuracy: 42.38\n",
      "[8,    81] loss: 1.47067, train_accuracy: 47.27\n",
      "[8,    82] loss: 1.48978, train_accuracy: 43.36\n",
      "[8,    83] loss: 1.56597, train_accuracy: 44.73\n",
      "[8,    84] loss: 1.53516, train_accuracy: 43.95\n",
      "[8,    85] loss: 1.58916, train_accuracy: 43.16\n",
      "[8,    86] loss: 1.52335, train_accuracy: 44.73\n",
      "[8,    87] loss: 1.56252, train_accuracy: 44.34\n",
      "[8,    88] loss: 1.56031, train_accuracy: 43.75\n",
      "[8,    89] loss: 1.54685, train_accuracy: 44.92\n",
      "[8,    90] loss: 1.48914, train_accuracy: 47.66\n",
      "[8,    91] loss: 1.53363, train_accuracy: 41.80\n",
      "[8,    92] loss: 1.57818, train_accuracy: 43.55\n",
      "[8,    93] loss: 1.67204, train_accuracy: 41.99\n",
      "[8,    94] loss: 1.57391, train_accuracy: 45.70\n",
      "[8,    95] loss: 1.47947, train_accuracy: 44.34\n",
      "[8,    96] loss: 1.48556, train_accuracy: 48.83\n",
      "[8,    97] loss: 1.55292, train_accuracy: 42.77\n",
      "[8,    98] loss: 1.48800, train_accuracy: 48.81\n",
      "duration: 266 s - train loss: 1.53739 - train accuracy: 44.58 - validation loss: 1.24750 - validation accuracy: 55.68 \n",
      "[9,     1] loss: 1.59053, train_accuracy: 39.65\n",
      "[9,     2] loss: 1.45531, train_accuracy: 49.22\n",
      "[9,     3] loss: 1.44963, train_accuracy: 49.61\n",
      "[9,     4] loss: 1.46507, train_accuracy: 50.00\n",
      "[9,     5] loss: 1.59006, train_accuracy: 43.95\n",
      "[9,     6] loss: 1.58125, train_accuracy: 44.14\n",
      "[9,     7] loss: 1.55298, train_accuracy: 45.70\n",
      "[9,     8] loss: 1.44513, train_accuracy: 49.41\n",
      "[9,     9] loss: 1.47791, train_accuracy: 44.92\n",
      "[9,    10] loss: 1.54821, train_accuracy: 45.31\n",
      "[9,    11] loss: 1.45276, train_accuracy: 49.22\n",
      "[9,    12] loss: 1.49005, train_accuracy: 45.12\n",
      "[9,    13] loss: 1.52480, train_accuracy: 46.09\n",
      "[9,    14] loss: 1.48671, train_accuracy: 45.90\n",
      "[9,    15] loss: 1.57107, train_accuracy: 45.12\n",
      "[9,    16] loss: 1.55211, train_accuracy: 48.24\n",
      "[9,    17] loss: 1.45538, train_accuracy: 49.02\n",
      "[9,    18] loss: 1.54696, train_accuracy: 41.02\n",
      "[9,    19] loss: 1.50990, train_accuracy: 43.16\n",
      "[9,    20] loss: 1.51364, train_accuracy: 47.27\n",
      "[9,    21] loss: 1.55046, train_accuracy: 45.51\n",
      "[9,    22] loss: 1.46738, train_accuracy: 45.31\n",
      "[9,    23] loss: 1.50212, train_accuracy: 46.48\n",
      "[9,    24] loss: 1.43382, train_accuracy: 48.24\n",
      "[9,    25] loss: 1.57452, train_accuracy: 41.41\n",
      "[9,    26] loss: 1.45686, train_accuracy: 48.83\n",
      "[9,    27] loss: 1.48987, train_accuracy: 51.17\n",
      "[9,    28] loss: 1.52363, train_accuracy: 48.05\n",
      "[9,    29] loss: 1.55882, train_accuracy: 43.55\n",
      "[9,    30] loss: 1.61783, train_accuracy: 41.80\n",
      "[9,    31] loss: 1.51375, train_accuracy: 45.12\n",
      "[9,    32] loss: 1.48975, train_accuracy: 47.85\n",
      "[9,    33] loss: 1.52790, train_accuracy: 44.92\n",
      "[9,    34] loss: 1.50863, train_accuracy: 47.46\n",
      "[9,    35] loss: 1.55770, train_accuracy: 42.19\n",
      "[9,    36] loss: 1.49572, train_accuracy: 44.14\n",
      "[9,    37] loss: 1.51103, train_accuracy: 45.90\n",
      "[9,    38] loss: 1.53603, train_accuracy: 44.14\n",
      "[9,    39] loss: 1.47557, train_accuracy: 49.80\n",
      "[9,    40] loss: 1.49694, train_accuracy: 46.29\n",
      "[9,    41] loss: 1.54482, train_accuracy: 46.88\n",
      "[9,    42] loss: 1.51417, train_accuracy: 46.68\n",
      "[9,    43] loss: 1.50317, train_accuracy: 46.68\n",
      "[9,    44] loss: 1.57285, train_accuracy: 42.77\n",
      "[9,    45] loss: 1.46394, train_accuracy: 45.70\n",
      "[9,    46] loss: 1.54287, train_accuracy: 43.55\n",
      "[9,    47] loss: 1.53675, train_accuracy: 46.88\n",
      "[9,    48] loss: 1.52600, train_accuracy: 43.55\n",
      "[9,    49] loss: 1.48490, train_accuracy: 45.70\n",
      "[9,    50] loss: 1.54880, train_accuracy: 45.90\n",
      "[9,    51] loss: 1.52926, train_accuracy: 43.55\n",
      "[9,    52] loss: 1.44149, train_accuracy: 49.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,    53] loss: 1.57607, train_accuracy: 42.38\n",
      "[9,    54] loss: 1.47938, train_accuracy: 47.85\n",
      "[9,    55] loss: 1.57416, train_accuracy: 43.95\n",
      "[9,    56] loss: 1.48715, train_accuracy: 44.14\n",
      "[9,    57] loss: 1.51339, train_accuracy: 44.14\n",
      "[9,    58] loss: 1.56348, train_accuracy: 43.36\n",
      "[9,    59] loss: 1.57255, train_accuracy: 43.75\n",
      "[9,    60] loss: 1.47212, train_accuracy: 47.07\n",
      "[9,    61] loss: 1.57112, train_accuracy: 43.16\n",
      "[9,    62] loss: 1.53337, train_accuracy: 48.44\n",
      "[9,    63] loss: 1.52251, train_accuracy: 44.73\n",
      "[9,    64] loss: 1.50502, train_accuracy: 47.07\n",
      "[9,    65] loss: 1.47540, train_accuracy: 47.27\n",
      "[9,    66] loss: 1.51071, train_accuracy: 46.88\n",
      "[9,    67] loss: 1.52500, train_accuracy: 46.88\n",
      "[9,    68] loss: 1.53299, train_accuracy: 42.77\n",
      "[9,    69] loss: 1.53197, train_accuracy: 44.34\n",
      "[9,    70] loss: 1.53303, train_accuracy: 47.27\n",
      "[9,    71] loss: 1.55473, train_accuracy: 45.90\n",
      "[9,    72] loss: 1.50594, train_accuracy: 46.88\n",
      "[9,    73] loss: 1.55380, train_accuracy: 44.73\n",
      "[9,    74] loss: 1.54653, train_accuracy: 46.68\n",
      "[9,    75] loss: 1.50304, train_accuracy: 45.51\n",
      "[9,    76] loss: 1.53821, train_accuracy: 46.29\n",
      "[9,    77] loss: 1.56202, train_accuracy: 41.80\n",
      "[9,    78] loss: 1.46047, train_accuracy: 45.51\n",
      "[9,    79] loss: 1.51992, train_accuracy: 46.68\n",
      "[9,    80] loss: 1.39087, train_accuracy: 51.37\n",
      "[9,    81] loss: 1.51065, train_accuracy: 46.29\n",
      "[9,    82] loss: 1.45688, train_accuracy: 48.63\n",
      "[9,    83] loss: 1.48896, train_accuracy: 47.27\n",
      "[9,    84] loss: 1.52816, train_accuracy: 44.73\n",
      "[9,    85] loss: 1.56556, train_accuracy: 42.58\n",
      "[9,    86] loss: 1.50307, train_accuracy: 47.66\n",
      "[9,    87] loss: 1.50743, train_accuracy: 45.51\n",
      "[9,    88] loss: 1.57466, train_accuracy: 42.77\n",
      "[9,    89] loss: 1.50215, train_accuracy: 45.31\n",
      "[9,    90] loss: 1.50621, train_accuracy: 41.60\n",
      "[9,    91] loss: 1.56271, train_accuracy: 42.97\n",
      "[9,    92] loss: 1.52825, train_accuracy: 45.12\n",
      "[9,    93] loss: 1.47738, train_accuracy: 46.68\n",
      "[9,    94] loss: 1.56312, train_accuracy: 43.55\n",
      "[9,    95] loss: 1.41630, train_accuracy: 48.44\n",
      "[9,    96] loss: 1.41600, train_accuracy: 48.63\n",
      "[9,    97] loss: 1.54729, train_accuracy: 46.09\n",
      "[9,    98] loss: 1.40048, train_accuracy: 48.21\n",
      "duration: 291 s - train loss: 1.51456 - train accuracy: 45.78 - validation loss: 1.21902 - validation accuracy: 57.06 \n",
      "[10,     1] loss: 1.48334, train_accuracy: 47.46\n",
      "[10,     2] loss: 1.53143, train_accuracy: 45.51\n",
      "[10,     3] loss: 1.48789, train_accuracy: 46.09\n",
      "[10,     4] loss: 1.46202, train_accuracy: 49.61\n",
      "[10,     5] loss: 1.60700, train_accuracy: 41.80\n",
      "[10,     6] loss: 1.46222, train_accuracy: 47.27\n",
      "[10,     7] loss: 1.48219, train_accuracy: 48.05\n",
      "[10,     8] loss: 1.51782, train_accuracy: 44.14\n",
      "[10,     9] loss: 1.60738, train_accuracy: 39.06\n",
      "[10,    10] loss: 1.46048, train_accuracy: 48.05\n",
      "[10,    11] loss: 1.47426, train_accuracy: 45.12\n",
      "[10,    12] loss: 1.46141, train_accuracy: 44.92\n",
      "[10,    13] loss: 1.48268, train_accuracy: 46.68\n",
      "[10,    14] loss: 1.53129, train_accuracy: 46.09\n",
      "[10,    15] loss: 1.45792, train_accuracy: 46.88\n",
      "[10,    16] loss: 1.53260, train_accuracy: 45.90\n",
      "[10,    17] loss: 1.48368, train_accuracy: 47.46\n",
      "[10,    18] loss: 1.54185, train_accuracy: 46.09\n",
      "[10,    19] loss: 1.51539, train_accuracy: 47.27\n",
      "[10,    20] loss: 1.44595, train_accuracy: 48.44\n",
      "[10,    21] loss: 1.53546, train_accuracy: 43.36\n",
      "[10,    22] loss: 1.51677, train_accuracy: 45.90\n",
      "[10,    23] loss: 1.50028, train_accuracy: 45.51\n",
      "[10,    24] loss: 1.55660, train_accuracy: 44.53\n",
      "[10,    25] loss: 1.51444, train_accuracy: 44.34\n",
      "[10,    26] loss: 1.53022, train_accuracy: 43.55\n",
      "[10,    27] loss: 1.53096, train_accuracy: 45.51\n",
      "[10,    28] loss: 1.48208, train_accuracy: 46.68\n",
      "[10,    29] loss: 1.45735, train_accuracy: 50.39\n",
      "[10,    30] loss: 1.50840, train_accuracy: 44.92\n",
      "[10,    31] loss: 1.40913, train_accuracy: 47.85\n",
      "[10,    32] loss: 1.58168, train_accuracy: 44.14\n",
      "[10,    33] loss: 1.49275, train_accuracy: 43.95\n",
      "[10,    34] loss: 1.46000, train_accuracy: 48.44\n",
      "[10,    35] loss: 1.48939, train_accuracy: 44.92\n",
      "[10,    36] loss: 1.50399, train_accuracy: 43.75\n",
      "[10,    37] loss: 1.44375, train_accuracy: 45.90\n",
      "[10,    38] loss: 1.53354, train_accuracy: 44.53\n",
      "[10,    39] loss: 1.54415, train_accuracy: 43.55\n",
      "[10,    40] loss: 1.46304, train_accuracy: 47.66\n",
      "[10,    41] loss: 1.51832, train_accuracy: 42.19\n",
      "[10,    42] loss: 1.49843, train_accuracy: 48.44\n",
      "[10,    43] loss: 1.56699, train_accuracy: 41.60\n",
      "[10,    44] loss: 1.52033, train_accuracy: 44.92\n",
      "[10,    45] loss: 1.53210, train_accuracy: 46.29\n",
      "[10,    46] loss: 1.54587, train_accuracy: 44.73\n",
      "[10,    47] loss: 1.52561, train_accuracy: 45.31\n",
      "[10,    48] loss: 1.45359, train_accuracy: 48.05\n",
      "[10,    49] loss: 1.45917, train_accuracy: 48.44\n",
      "[10,    50] loss: 1.55793, train_accuracy: 42.58\n",
      "[10,    51] loss: 1.47739, train_accuracy: 47.07\n",
      "[10,    52] loss: 1.51497, train_accuracy: 43.95\n",
      "[10,    53] loss: 1.51458, train_accuracy: 47.85\n",
      "[10,    54] loss: 1.55919, train_accuracy: 45.12\n",
      "[10,    55] loss: 1.46968, train_accuracy: 44.14\n",
      "[10,    56] loss: 1.43017, train_accuracy: 48.63\n",
      "[10,    57] loss: 1.49138, train_accuracy: 46.68\n",
      "[10,    58] loss: 1.48671, train_accuracy: 45.31\n",
      "[10,    59] loss: 1.52664, train_accuracy: 46.68\n",
      "[10,    60] loss: 1.49036, train_accuracy: 47.66\n",
      "[10,    61] loss: 1.46623, train_accuracy: 46.09\n",
      "[10,    62] loss: 1.46494, train_accuracy: 48.63\n",
      "[10,    63] loss: 1.49606, train_accuracy: 46.88\n",
      "[10,    64] loss: 1.49959, train_accuracy: 47.07\n",
      "[10,    65] loss: 1.42078, train_accuracy: 48.05\n",
      "[10,    66] loss: 1.47121, train_accuracy: 42.97\n",
      "[10,    67] loss: 1.52779, train_accuracy: 46.29\n",
      "[10,    68] loss: 1.50728, train_accuracy: 42.77\n",
      "[10,    69] loss: 1.44136, train_accuracy: 47.27\n",
      "[10,    70] loss: 1.53038, train_accuracy: 45.12\n",
      "[10,    71] loss: 1.42552, train_accuracy: 46.09\n",
      "[10,    72] loss: 1.56810, train_accuracy: 43.16\n",
      "[10,    73] loss: 1.45598, train_accuracy: 49.61\n",
      "[10,    74] loss: 1.51741, train_accuracy: 46.48\n",
      "[10,    75] loss: 1.48249, train_accuracy: 47.27\n",
      "[10,    76] loss: 1.48767, train_accuracy: 45.90\n",
      "[10,    77] loss: 1.45019, train_accuracy: 47.07\n",
      "[10,    78] loss: 1.47441, train_accuracy: 49.61\n",
      "[10,    79] loss: 1.49511, train_accuracy: 45.12\n",
      "[10,    80] loss: 1.50957, train_accuracy: 46.48\n",
      "[10,    81] loss: 1.48949, train_accuracy: 48.24\n",
      "[10,    82] loss: 1.37662, train_accuracy: 49.02\n",
      "[10,    83] loss: 1.52681, train_accuracy: 43.75\n",
      "[10,    84] loss: 1.50199, train_accuracy: 47.66\n",
      "[10,    85] loss: 1.56018, train_accuracy: 44.14\n",
      "[10,    86] loss: 1.48918, train_accuracy: 46.88\n",
      "[10,    87] loss: 1.46738, train_accuracy: 46.88\n",
      "[10,    88] loss: 1.55253, train_accuracy: 45.90\n",
      "[10,    89] loss: 1.55297, train_accuracy: 43.75\n",
      "[10,    90] loss: 1.55225, train_accuracy: 45.90\n",
      "[10,    91] loss: 1.45392, train_accuracy: 48.05\n",
      "[10,    92] loss: 1.56134, train_accuracy: 44.34\n",
      "[10,    93] loss: 1.51702, train_accuracy: 44.73\n",
      "[10,    94] loss: 1.47975, train_accuracy: 47.27\n",
      "[10,    95] loss: 1.48635, train_accuracy: 46.68\n",
      "[10,    96] loss: 1.38245, train_accuracy: 48.63\n",
      "[10,    97] loss: 1.52403, train_accuracy: 44.92\n",
      "[10,    98] loss: 1.47904, train_accuracy: 47.02\n",
      "duration: 246 s - train loss: 1.49865 - train accuracy: 46.01 - validation loss: 1.21896 - validation accuracy: 57.61 \n",
      "[11,     1] loss: 1.43696, train_accuracy: 51.17\n",
      "[11,     2] loss: 1.42311, train_accuracy: 49.02\n",
      "[11,     3] loss: 1.42108, train_accuracy: 51.76\n",
      "[11,     4] loss: 1.52075, train_accuracy: 45.31\n",
      "[11,     5] loss: 1.48191, train_accuracy: 45.31\n",
      "[11,     6] loss: 1.50298, train_accuracy: 45.51\n",
      "[11,     7] loss: 1.42790, train_accuracy: 49.80\n",
      "[11,     8] loss: 1.52260, train_accuracy: 45.70\n",
      "[11,     9] loss: 1.51492, train_accuracy: 45.90\n",
      "[11,    10] loss: 1.51863, train_accuracy: 45.12\n",
      "[11,    11] loss: 1.47109, train_accuracy: 47.66\n",
      "[11,    12] loss: 1.48832, train_accuracy: 43.55\n",
      "[11,    13] loss: 1.47501, train_accuracy: 48.44\n",
      "[11,    14] loss: 1.53539, train_accuracy: 48.24\n",
      "[11,    15] loss: 1.38502, train_accuracy: 49.02\n",
      "[11,    16] loss: 1.46541, train_accuracy: 46.88\n",
      "[11,    17] loss: 1.45742, train_accuracy: 45.51\n",
      "[11,    18] loss: 1.48596, train_accuracy: 44.92\n",
      "[11,    19] loss: 1.59161, train_accuracy: 42.58\n",
      "[11,    20] loss: 1.50443, train_accuracy: 48.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,    21] loss: 1.48082, train_accuracy: 48.44\n",
      "[11,    22] loss: 1.43388, train_accuracy: 51.37\n",
      "[11,    23] loss: 1.42999, train_accuracy: 49.80\n",
      "[11,    24] loss: 1.45445, train_accuracy: 48.44\n",
      "[11,    25] loss: 1.46694, train_accuracy: 43.75\n",
      "[11,    26] loss: 1.49944, train_accuracy: 47.27\n",
      "[11,    27] loss: 1.49643, train_accuracy: 46.88\n",
      "[11,    28] loss: 1.46874, train_accuracy: 46.88\n",
      "[11,    29] loss: 1.51918, train_accuracy: 43.75\n",
      "[11,    30] loss: 1.58006, train_accuracy: 42.58\n",
      "[11,    31] loss: 1.38901, train_accuracy: 46.88\n",
      "[11,    32] loss: 1.45450, train_accuracy: 48.05\n",
      "[11,    33] loss: 1.40389, train_accuracy: 49.80\n",
      "[11,    34] loss: 1.49022, train_accuracy: 48.44\n",
      "[11,    35] loss: 1.47318, train_accuracy: 46.09\n",
      "[11,    36] loss: 1.51791, train_accuracy: 43.95\n",
      "[11,    37] loss: 1.46330, train_accuracy: 47.46\n",
      "[11,    38] loss: 1.45250, train_accuracy: 47.07\n",
      "[11,    39] loss: 1.50420, train_accuracy: 45.90\n",
      "[11,    40] loss: 1.43366, train_accuracy: 51.76\n",
      "[11,    41] loss: 1.45023, train_accuracy: 50.20\n",
      "[11,    42] loss: 1.54445, train_accuracy: 41.21\n",
      "[11,    43] loss: 1.44027, train_accuracy: 50.20\n",
      "[11,    44] loss: 1.42345, train_accuracy: 50.20\n",
      "[11,    45] loss: 1.57198, train_accuracy: 46.88\n",
      "[11,    46] loss: 1.49901, train_accuracy: 47.27\n",
      "[11,    47] loss: 1.49241, train_accuracy: 44.53\n",
      "[11,    48] loss: 1.45519, train_accuracy: 46.88\n",
      "[11,    49] loss: 1.41221, train_accuracy: 48.05\n",
      "[11,    50] loss: 1.48077, train_accuracy: 45.12\n",
      "[11,    51] loss: 1.51137, train_accuracy: 46.88\n",
      "[11,    52] loss: 1.45225, train_accuracy: 50.00\n",
      "[11,    53] loss: 1.53881, train_accuracy: 45.51\n",
      "[11,    54] loss: 1.47630, train_accuracy: 41.99\n",
      "[11,    55] loss: 1.45948, train_accuracy: 44.92\n",
      "[11,    56] loss: 1.41969, train_accuracy: 48.44\n",
      "[11,    57] loss: 1.44706, train_accuracy: 49.02\n",
      "[11,    58] loss: 1.54059, train_accuracy: 44.14\n",
      "[11,    59] loss: 1.48695, train_accuracy: 47.07\n",
      "[11,    60] loss: 1.47228, train_accuracy: 48.05\n",
      "[11,    61] loss: 1.43748, train_accuracy: 48.63\n",
      "[11,    62] loss: 1.50866, train_accuracy: 45.51\n",
      "[11,    63] loss: 1.46169, train_accuracy: 45.51\n",
      "[11,    64] loss: 1.45037, train_accuracy: 45.90\n",
      "[11,    65] loss: 1.44757, train_accuracy: 47.46\n",
      "[11,    66] loss: 1.45741, train_accuracy: 46.88\n",
      "[11,    67] loss: 1.46910, train_accuracy: 46.48\n",
      "[11,    68] loss: 1.58109, train_accuracy: 42.77\n",
      "[11,    69] loss: 1.48448, train_accuracy: 45.51\n",
      "[11,    70] loss: 1.47858, train_accuracy: 48.24\n",
      "[11,    71] loss: 1.40856, train_accuracy: 49.61\n",
      "[11,    72] loss: 1.55747, train_accuracy: 44.92\n",
      "[11,    73] loss: 1.56253, train_accuracy: 41.60\n",
      "[11,    74] loss: 1.42772, train_accuracy: 48.44\n",
      "[11,    75] loss: 1.43566, train_accuracy: 47.27\n",
      "[11,    76] loss: 1.52457, train_accuracy: 43.75\n",
      "[11,    77] loss: 1.51514, train_accuracy: 44.34\n",
      "[11,    78] loss: 1.52798, train_accuracy: 45.51\n",
      "[11,    79] loss: 1.46581, train_accuracy: 47.27\n",
      "[11,    80] loss: 1.41964, train_accuracy: 50.98\n",
      "[11,    81] loss: 1.42779, train_accuracy: 48.83\n",
      "[11,    82] loss: 1.44198, train_accuracy: 45.51\n",
      "[11,    83] loss: 1.47207, train_accuracy: 48.24\n",
      "[11,    84] loss: 1.44116, train_accuracy: 47.46\n",
      "[11,    85] loss: 1.48943, train_accuracy: 44.92\n",
      "[11,    86] loss: 1.51853, train_accuracy: 43.95\n",
      "[11,    87] loss: 1.39582, train_accuracy: 50.59\n",
      "[11,    88] loss: 1.48835, train_accuracy: 47.66\n",
      "[11,    89] loss: 1.44968, train_accuracy: 49.61\n",
      "[11,    90] loss: 1.47866, train_accuracy: 47.07\n",
      "[11,    91] loss: 1.51347, train_accuracy: 45.31\n",
      "[11,    92] loss: 1.50072, train_accuracy: 47.46\n",
      "[11,    93] loss: 1.54152, train_accuracy: 45.12\n",
      "[11,    94] loss: 1.53411, train_accuracy: 44.14\n",
      "[11,    95] loss: 1.50656, train_accuracy: 43.75\n",
      "[11,    96] loss: 1.52287, train_accuracy: 45.90\n",
      "[11,    97] loss: 1.55822, train_accuracy: 45.90\n",
      "[11,    98] loss: 1.48873, train_accuracy: 44.35\n",
      "duration: 238 s - train loss: 1.47968 - train accuracy: 46.77 - validation loss: 1.19725 - validation accuracy: 58.89 \n",
      "[12,     1] loss: 1.47434, train_accuracy: 48.24\n",
      "[12,     2] loss: 1.47277, train_accuracy: 48.44\n",
      "[12,     3] loss: 1.47370, train_accuracy: 47.85\n",
      "[12,     4] loss: 1.43253, train_accuracy: 47.27\n",
      "[12,     5] loss: 1.48267, train_accuracy: 46.68\n",
      "[12,     6] loss: 1.47407, train_accuracy: 47.85\n",
      "[12,     7] loss: 1.46626, train_accuracy: 49.02\n",
      "[12,     8] loss: 1.51631, train_accuracy: 47.66\n",
      "[12,     9] loss: 1.44620, train_accuracy: 47.07\n",
      "[12,    10] loss: 1.47409, train_accuracy: 47.46\n",
      "[12,    11] loss: 1.44858, train_accuracy: 47.66\n",
      "[12,    12] loss: 1.44959, train_accuracy: 49.02\n",
      "[12,    13] loss: 1.46420, train_accuracy: 47.07\n",
      "[12,    14] loss: 1.52899, train_accuracy: 46.09\n",
      "[12,    15] loss: 1.49180, train_accuracy: 46.09\n",
      "[12,    16] loss: 1.44554, train_accuracy: 45.70\n",
      "[12,    17] loss: 1.43688, train_accuracy: 48.44\n",
      "[12,    18] loss: 1.46137, train_accuracy: 49.41\n",
      "[12,    19] loss: 1.46247, train_accuracy: 47.46\n",
      "[12,    20] loss: 1.50758, train_accuracy: 45.90\n",
      "[12,    21] loss: 1.49456, train_accuracy: 45.51\n",
      "[12,    22] loss: 1.43718, train_accuracy: 48.05\n",
      "[12,    23] loss: 1.45738, train_accuracy: 46.29\n",
      "[12,    24] loss: 1.42930, train_accuracy: 45.51\n",
      "[12,    25] loss: 1.43999, train_accuracy: 47.66\n",
      "[12,    26] loss: 1.47121, train_accuracy: 48.83\n",
      "[12,    27] loss: 1.54461, train_accuracy: 43.55\n",
      "[12,    28] loss: 1.48068, train_accuracy: 45.31\n",
      "[12,    29] loss: 1.40857, train_accuracy: 47.27\n",
      "[12,    30] loss: 1.44689, train_accuracy: 49.02\n",
      "[12,    31] loss: 1.55879, train_accuracy: 43.55\n",
      "[12,    32] loss: 1.45870, train_accuracy: 47.85\n",
      "[12,    33] loss: 1.39319, train_accuracy: 47.85\n",
      "[12,    34] loss: 1.53290, train_accuracy: 44.73\n",
      "[12,    35] loss: 1.46901, train_accuracy: 49.80\n",
      "[12,    36] loss: 1.39244, train_accuracy: 46.68\n",
      "[12,    37] loss: 1.43899, train_accuracy: 48.05\n",
      "[12,    38] loss: 1.48308, train_accuracy: 43.95\n",
      "[12,    39] loss: 1.49754, train_accuracy: 47.27\n",
      "[12,    40] loss: 1.46872, train_accuracy: 48.44\n",
      "[12,    41] loss: 1.52908, train_accuracy: 47.85\n",
      "[12,    42] loss: 1.48804, train_accuracy: 47.85\n",
      "[12,    43] loss: 1.47755, train_accuracy: 48.63\n",
      "[12,    44] loss: 1.41563, train_accuracy: 48.63\n",
      "[12,    45] loss: 1.45095, train_accuracy: 48.05\n",
      "[12,    46] loss: 1.51771, train_accuracy: 44.53\n",
      "[12,    47] loss: 1.46276, train_accuracy: 48.63\n",
      "[12,    48] loss: 1.48136, train_accuracy: 47.66\n",
      "[12,    49] loss: 1.45039, train_accuracy: 48.24\n",
      "[12,    50] loss: 1.47231, train_accuracy: 48.83\n",
      "[12,    51] loss: 1.48505, train_accuracy: 44.92\n",
      "[12,    52] loss: 1.41994, train_accuracy: 49.61\n",
      "[12,    53] loss: 1.42524, train_accuracy: 52.54\n",
      "[12,    54] loss: 1.46602, train_accuracy: 46.09\n",
      "[12,    55] loss: 1.47234, train_accuracy: 45.31\n",
      "[12,    56] loss: 1.46278, train_accuracy: 47.27\n",
      "[12,    57] loss: 1.47360, train_accuracy: 48.44\n",
      "[12,    58] loss: 1.47037, train_accuracy: 46.88\n",
      "[12,    59] loss: 1.48273, train_accuracy: 49.02\n",
      "[12,    60] loss: 1.41263, train_accuracy: 50.39\n",
      "[12,    61] loss: 1.48092, train_accuracy: 47.85\n",
      "[12,    62] loss: 1.48079, train_accuracy: 45.51\n",
      "[12,    63] loss: 1.46740, train_accuracy: 45.12\n",
      "[12,    64] loss: 1.40789, train_accuracy: 50.39\n",
      "[12,    65] loss: 1.43916, train_accuracy: 47.46\n",
      "[12,    66] loss: 1.50206, train_accuracy: 47.66\n",
      "[12,    67] loss: 1.47372, train_accuracy: 48.44\n",
      "[12,    68] loss: 1.49618, train_accuracy: 44.53\n",
      "[12,    69] loss: 1.52873, train_accuracy: 49.41\n",
      "[12,    70] loss: 1.49184, train_accuracy: 46.48\n",
      "[12,    71] loss: 1.46758, train_accuracy: 49.02\n",
      "[12,    72] loss: 1.49060, train_accuracy: 45.51\n",
      "[12,    73] loss: 1.46688, train_accuracy: 47.46\n",
      "[12,    74] loss: 1.49259, train_accuracy: 43.95\n",
      "[12,    75] loss: 1.45096, train_accuracy: 51.56\n",
      "[12,    76] loss: 1.45387, train_accuracy: 47.66\n",
      "[12,    77] loss: 1.40430, train_accuracy: 47.66\n",
      "[12,    78] loss: 1.45281, train_accuracy: 47.46\n",
      "[12,    79] loss: 1.40721, train_accuracy: 50.78\n",
      "[12,    80] loss: 1.49790, train_accuracy: 46.88\n",
      "[12,    81] loss: 1.45252, train_accuracy: 45.70\n",
      "[12,    82] loss: 1.47269, train_accuracy: 45.51\n",
      "[12,    83] loss: 1.45677, train_accuracy: 47.07\n",
      "[12,    84] loss: 1.50386, train_accuracy: 43.75\n",
      "[12,    85] loss: 1.40785, train_accuracy: 49.61\n",
      "[12,    86] loss: 1.45019, train_accuracy: 49.80\n",
      "[12,    87] loss: 1.42817, train_accuracy: 49.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,    88] loss: 1.41276, train_accuracy: 47.27\n",
      "[12,    89] loss: 1.46816, train_accuracy: 46.68\n",
      "[12,    90] loss: 1.44488, train_accuracy: 50.00\n",
      "[12,    91] loss: 1.51187, train_accuracy: 43.36\n",
      "[12,    92] loss: 1.52992, train_accuracy: 44.73\n",
      "[12,    93] loss: 1.47650, train_accuracy: 47.66\n",
      "[12,    94] loss: 1.47650, train_accuracy: 46.68\n",
      "[12,    95] loss: 1.40658, train_accuracy: 50.20\n",
      "[12,    96] loss: 1.51699, train_accuracy: 46.88\n",
      "[12,    97] loss: 1.48515, train_accuracy: 46.09\n",
      "[12,    98] loss: 1.39417, train_accuracy: 49.40\n",
      "duration: 220 s - train loss: 1.46611 - train accuracy: 47.40 - validation loss: 1.17969 - validation accuracy: 58.91 \n",
      "[13,     1] loss: 1.49008, train_accuracy: 45.12\n",
      "[13,     2] loss: 1.46007, train_accuracy: 47.46\n",
      "[13,     3] loss: 1.44605, train_accuracy: 47.46\n",
      "[13,     4] loss: 1.57125, train_accuracy: 42.58\n",
      "[13,     5] loss: 1.43919, train_accuracy: 48.63\n",
      "[13,     6] loss: 1.34628, train_accuracy: 53.52\n",
      "[13,     7] loss: 1.47974, train_accuracy: 43.75\n",
      "[13,     8] loss: 1.39278, train_accuracy: 49.02\n",
      "[13,     9] loss: 1.48320, train_accuracy: 48.24\n",
      "[13,    10] loss: 1.49225, train_accuracy: 45.90\n",
      "[13,    11] loss: 1.38604, train_accuracy: 48.83\n",
      "[13,    12] loss: 1.40526, train_accuracy: 49.61\n",
      "[13,    13] loss: 1.34255, train_accuracy: 50.59\n",
      "[13,    14] loss: 1.43076, train_accuracy: 49.22\n",
      "[13,    15] loss: 1.46770, train_accuracy: 47.27\n",
      "[13,    16] loss: 1.41921, train_accuracy: 48.24\n",
      "[13,    17] loss: 1.43278, train_accuracy: 50.20\n",
      "[13,    18] loss: 1.40068, train_accuracy: 49.22\n",
      "[13,    19] loss: 1.43898, train_accuracy: 47.46\n",
      "[13,    20] loss: 1.49546, train_accuracy: 46.09\n",
      "[13,    21] loss: 1.52763, train_accuracy: 43.95\n",
      "[13,    22] loss: 1.48982, train_accuracy: 47.07\n",
      "[13,    23] loss: 1.51529, train_accuracy: 46.09\n",
      "[13,    24] loss: 1.50044, train_accuracy: 45.70\n",
      "[13,    25] loss: 1.42179, train_accuracy: 51.76\n",
      "[13,    26] loss: 1.55305, train_accuracy: 43.95\n",
      "[13,    27] loss: 1.36692, train_accuracy: 52.15\n",
      "[13,    28] loss: 1.46128, train_accuracy: 50.78\n",
      "[13,    29] loss: 1.36788, train_accuracy: 52.34\n",
      "[13,    30] loss: 1.47764, train_accuracy: 48.24\n",
      "[13,    31] loss: 1.48575, train_accuracy: 44.73\n",
      "[13,    32] loss: 1.42428, train_accuracy: 48.24\n",
      "[13,    33] loss: 1.46230, train_accuracy: 48.83\n",
      "[13,    34] loss: 1.47685, train_accuracy: 45.31\n",
      "[13,    35] loss: 1.56030, train_accuracy: 44.73\n",
      "[13,    36] loss: 1.45122, train_accuracy: 44.92\n",
      "[13,    37] loss: 1.43052, train_accuracy: 49.41\n",
      "[13,    38] loss: 1.52348, train_accuracy: 43.75\n",
      "[13,    39] loss: 1.42862, train_accuracy: 49.80\n",
      "[13,    40] loss: 1.45841, train_accuracy: 49.22\n",
      "[13,    41] loss: 1.46910, train_accuracy: 47.85\n",
      "[13,    42] loss: 1.47176, train_accuracy: 46.09\n",
      "[13,    43] loss: 1.46190, train_accuracy: 49.61\n",
      "[13,    44] loss: 1.48008, train_accuracy: 47.07\n",
      "[13,    45] loss: 1.38746, train_accuracy: 55.27\n",
      "[13,    46] loss: 1.44198, train_accuracy: 49.61\n",
      "[13,    47] loss: 1.49687, train_accuracy: 45.70\n",
      "[13,    48] loss: 1.44389, train_accuracy: 47.85\n",
      "[13,    49] loss: 1.39968, train_accuracy: 50.00\n",
      "[13,    50] loss: 1.47377, train_accuracy: 47.85\n",
      "[13,    51] loss: 1.37556, train_accuracy: 51.37\n",
      "[13,    52] loss: 1.42840, train_accuracy: 47.85\n",
      "[13,    53] loss: 1.46657, train_accuracy: 45.90\n",
      "[13,    54] loss: 1.50414, train_accuracy: 45.51\n",
      "[13,    55] loss: 1.51768, train_accuracy: 46.48\n",
      "[13,    56] loss: 1.46826, train_accuracy: 47.85\n",
      "[13,    57] loss: 1.47045, train_accuracy: 45.70\n",
      "[13,    58] loss: 1.46479, train_accuracy: 49.22\n",
      "[13,    59] loss: 1.40959, train_accuracy: 46.48\n",
      "[13,    60] loss: 1.41725, train_accuracy: 45.90\n",
      "[13,    61] loss: 1.42194, train_accuracy: 49.41\n",
      "[13,    62] loss: 1.43552, train_accuracy: 47.66\n",
      "[13,    63] loss: 1.53145, train_accuracy: 47.46\n",
      "[13,    64] loss: 1.40911, train_accuracy: 48.83\n",
      "[13,    65] loss: 1.50187, train_accuracy: 43.75\n",
      "[13,    66] loss: 1.48827, train_accuracy: 44.92\n",
      "[13,    67] loss: 1.46462, train_accuracy: 48.44\n",
      "[13,    68] loss: 1.52736, train_accuracy: 47.66\n",
      "[13,    69] loss: 1.47309, train_accuracy: 49.80\n",
      "[13,    70] loss: 1.50021, train_accuracy: 46.09\n",
      "[13,    71] loss: 1.46916, train_accuracy: 44.92\n",
      "[13,    72] loss: 1.48351, train_accuracy: 47.85\n",
      "[13,    73] loss: 1.48860, train_accuracy: 46.48\n",
      "[13,    74] loss: 1.47232, train_accuracy: 44.92\n",
      "[13,    75] loss: 1.45207, train_accuracy: 45.90\n",
      "[13,    76] loss: 1.47551, train_accuracy: 49.41\n",
      "[13,    77] loss: 1.43757, train_accuracy: 50.20\n",
      "[13,    78] loss: 1.46784, train_accuracy: 43.75\n",
      "[13,    79] loss: 1.42084, train_accuracy: 49.02\n",
      "[13,    80] loss: 1.48021, train_accuracy: 46.29\n",
      "[13,    81] loss: 1.47857, train_accuracy: 48.83\n",
      "[13,    82] loss: 1.47092, train_accuracy: 47.85\n",
      "[13,    83] loss: 1.50995, train_accuracy: 47.07\n",
      "[13,    84] loss: 1.46652, train_accuracy: 46.88\n",
      "[13,    85] loss: 1.44919, train_accuracy: 48.05\n",
      "[13,    86] loss: 1.50238, train_accuracy: 46.09\n",
      "[13,    87] loss: 1.49215, train_accuracy: 46.29\n",
      "[13,    88] loss: 1.45047, train_accuracy: 46.88\n",
      "[13,    89] loss: 1.38300, train_accuracy: 48.63\n",
      "[13,    90] loss: 1.44460, train_accuracy: 48.24\n",
      "[13,    91] loss: 1.46999, train_accuracy: 47.27\n",
      "[13,    92] loss: 1.52585, train_accuracy: 46.48\n",
      "[13,    93] loss: 1.50227, train_accuracy: 45.51\n",
      "[13,    94] loss: 1.42828, train_accuracy: 47.07\n",
      "[13,    95] loss: 1.44792, train_accuracy: 47.46\n",
      "[13,    96] loss: 1.51569, train_accuracy: 47.66\n",
      "[13,    97] loss: 1.37512, train_accuracy: 49.61\n",
      "[13,    98] loss: 1.49345, train_accuracy: 47.32\n",
      "duration: 211 s - train loss: 1.45980 - train accuracy: 47.60 - validation loss: 1.17711 - validation accuracy: 58.36 \n",
      "[14,     1] loss: 1.53239, train_accuracy: 45.90\n",
      "[14,     2] loss: 1.38641, train_accuracy: 50.78\n",
      "[14,     3] loss: 1.43826, train_accuracy: 49.22\n",
      "[14,     4] loss: 1.41592, train_accuracy: 51.76\n",
      "[14,     5] loss: 1.48544, train_accuracy: 47.27\n",
      "[14,     6] loss: 1.46150, train_accuracy: 46.29\n",
      "[14,     7] loss: 1.40069, train_accuracy: 49.80\n",
      "[14,     8] loss: 1.41046, train_accuracy: 49.02\n",
      "[14,     9] loss: 1.43622, train_accuracy: 46.88\n",
      "[14,    10] loss: 1.41011, train_accuracy: 49.80\n",
      "[14,    11] loss: 1.44734, train_accuracy: 45.31\n",
      "[14,    12] loss: 1.53717, train_accuracy: 45.51\n",
      "[14,    13] loss: 1.37055, train_accuracy: 52.54\n",
      "[14,    14] loss: 1.37369, train_accuracy: 51.95\n",
      "[14,    15] loss: 1.48358, train_accuracy: 45.90\n",
      "[14,    16] loss: 1.44961, train_accuracy: 49.41\n",
      "[14,    17] loss: 1.46245, train_accuracy: 47.85\n",
      "[14,    18] loss: 1.46387, train_accuracy: 46.29\n",
      "[14,    19] loss: 1.45937, train_accuracy: 49.41\n",
      "[14,    20] loss: 1.35218, train_accuracy: 51.56\n",
      "[14,    21] loss: 1.34032, train_accuracy: 50.59\n",
      "[14,    22] loss: 1.48107, train_accuracy: 47.07\n",
      "[14,    23] loss: 1.44366, train_accuracy: 46.09\n",
      "[14,    24] loss: 1.45212, train_accuracy: 47.66\n",
      "[14,    25] loss: 1.46915, train_accuracy: 46.09\n",
      "[14,    26] loss: 1.44833, train_accuracy: 49.02\n",
      "[14,    27] loss: 1.44040, train_accuracy: 49.41\n",
      "[14,    28] loss: 1.49527, train_accuracy: 46.09\n",
      "[14,    29] loss: 1.38200, train_accuracy: 50.98\n",
      "[14,    30] loss: 1.42246, train_accuracy: 51.37\n",
      "[14,    31] loss: 1.46207, train_accuracy: 47.66\n",
      "[14,    32] loss: 1.39280, train_accuracy: 50.20\n",
      "[14,    33] loss: 1.35245, train_accuracy: 52.15\n",
      "[14,    34] loss: 1.44733, train_accuracy: 46.29\n",
      "[14,    35] loss: 1.39883, train_accuracy: 51.37\n",
      "[14,    36] loss: 1.47379, train_accuracy: 48.44\n",
      "[14,    37] loss: 1.48876, train_accuracy: 49.41\n",
      "[14,    38] loss: 1.50825, train_accuracy: 47.46\n",
      "[14,    39] loss: 1.46922, train_accuracy: 45.70\n",
      "[14,    40] loss: 1.39629, train_accuracy: 50.20\n",
      "[14,    41] loss: 1.45641, train_accuracy: 47.66\n",
      "[14,    42] loss: 1.54939, train_accuracy: 44.53\n",
      "[14,    43] loss: 1.42211, train_accuracy: 47.46\n",
      "[14,    44] loss: 1.46015, train_accuracy: 46.68\n",
      "[14,    45] loss: 1.51698, train_accuracy: 46.09\n",
      "[14,    46] loss: 1.38434, train_accuracy: 49.41\n",
      "[14,    47] loss: 1.42722, train_accuracy: 50.78\n",
      "[14,    48] loss: 1.43603, train_accuracy: 50.78\n",
      "[14,    49] loss: 1.42419, train_accuracy: 49.22\n",
      "[14,    50] loss: 1.44820, train_accuracy: 48.05\n",
      "[14,    51] loss: 1.50861, train_accuracy: 45.90\n",
      "[14,    52] loss: 1.47642, train_accuracy: 42.77\n",
      "[14,    53] loss: 1.39515, train_accuracy: 50.00\n",
      "[14,    54] loss: 1.42344, train_accuracy: 50.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,    55] loss: 1.37196, train_accuracy: 48.24\n",
      "[14,    56] loss: 1.40112, train_accuracy: 49.41\n",
      "[14,    57] loss: 1.41886, train_accuracy: 50.59\n",
      "[14,    58] loss: 1.42205, train_accuracy: 50.59\n",
      "[14,    59] loss: 1.47696, train_accuracy: 50.39\n",
      "[14,    60] loss: 1.32737, train_accuracy: 52.93\n",
      "[14,    61] loss: 1.43409, train_accuracy: 47.85\n",
      "[14,    62] loss: 1.39120, train_accuracy: 50.39\n",
      "[14,    63] loss: 1.45461, train_accuracy: 46.88\n",
      "[14,    64] loss: 1.42387, train_accuracy: 49.80\n",
      "[14,    65] loss: 1.43996, train_accuracy: 48.05\n",
      "[14,    66] loss: 1.33173, train_accuracy: 53.91\n",
      "[14,    67] loss: 1.48375, train_accuracy: 43.16\n",
      "[14,    68] loss: 1.41654, train_accuracy: 45.90\n",
      "[14,    69] loss: 1.50818, train_accuracy: 46.88\n",
      "[14,    70] loss: 1.47642, train_accuracy: 47.66\n",
      "[14,    71] loss: 1.42162, train_accuracy: 48.05\n",
      "[14,    72] loss: 1.45431, train_accuracy: 43.75\n",
      "[14,    73] loss: 1.42585, train_accuracy: 51.37\n",
      "[14,    74] loss: 1.43663, train_accuracy: 50.39\n",
      "[14,    75] loss: 1.43740, train_accuracy: 51.56\n",
      "[14,    76] loss: 1.51861, train_accuracy: 42.19\n",
      "[14,    77] loss: 1.47803, train_accuracy: 45.31\n",
      "[14,    78] loss: 1.48488, train_accuracy: 44.14\n",
      "[14,    79] loss: 1.40962, train_accuracy: 50.00\n",
      "[14,    80] loss: 1.39546, train_accuracy: 50.00\n",
      "[14,    81] loss: 1.45384, train_accuracy: 48.44\n",
      "[14,    82] loss: 1.52197, train_accuracy: 44.73\n",
      "[14,    83] loss: 1.45456, train_accuracy: 48.24\n",
      "[14,    84] loss: 1.42843, train_accuracy: 48.24\n",
      "[14,    85] loss: 1.50423, train_accuracy: 43.75\n",
      "[14,    86] loss: 1.38126, train_accuracy: 51.76\n",
      "[14,    87] loss: 1.36218, train_accuracy: 50.59\n",
      "[14,    88] loss: 1.43581, train_accuracy: 46.48\n",
      "[14,    89] loss: 1.38595, train_accuracy: 51.56\n",
      "[14,    90] loss: 1.43112, train_accuracy: 49.22\n",
      "[14,    91] loss: 1.36923, train_accuracy: 50.39\n",
      "[14,    92] loss: 1.47247, train_accuracy: 50.00\n",
      "[14,    93] loss: 1.44382, train_accuracy: 46.29\n",
      "[14,    94] loss: 1.55127, train_accuracy: 43.36\n",
      "[14,    95] loss: 1.42689, train_accuracy: 48.24\n",
      "[14,    96] loss: 1.46580, train_accuracy: 49.41\n",
      "[14,    97] loss: 1.48202, train_accuracy: 50.00\n",
      "[14,    98] loss: 1.54186, train_accuracy: 46.73\n",
      "duration: 213 s - train loss: 1.44106 - train accuracy: 48.39 - validation loss: 1.18251 - validation accuracy: 58.47 \n",
      "[15,     1] loss: 1.47448, train_accuracy: 47.66\n",
      "[15,     2] loss: 1.47675, train_accuracy: 48.24\n",
      "[15,     3] loss: 1.39398, train_accuracy: 50.59\n",
      "[15,     4] loss: 1.38671, train_accuracy: 50.20\n",
      "[15,     5] loss: 1.45341, train_accuracy: 47.07\n",
      "[15,     6] loss: 1.42858, train_accuracy: 49.02\n",
      "[15,     7] loss: 1.50898, train_accuracy: 44.53\n",
      "[15,     8] loss: 1.44135, train_accuracy: 48.44\n",
      "[15,     9] loss: 1.48034, train_accuracy: 47.85\n",
      "[15,    10] loss: 1.42598, train_accuracy: 49.61\n",
      "[15,    11] loss: 1.44148, train_accuracy: 48.44\n",
      "[15,    12] loss: 1.44441, train_accuracy: 48.63\n",
      "[15,    13] loss: 1.40367, train_accuracy: 52.34\n",
      "[15,    14] loss: 1.40283, train_accuracy: 46.48\n",
      "[15,    15] loss: 1.47839, train_accuracy: 48.83\n",
      "[15,    16] loss: 1.50137, train_accuracy: 44.53\n",
      "[15,    17] loss: 1.37623, train_accuracy: 48.44\n",
      "[15,    18] loss: 1.49964, train_accuracy: 47.66\n",
      "[15,    19] loss: 1.40946, train_accuracy: 50.00\n",
      "[15,    20] loss: 1.45367, train_accuracy: 48.44\n",
      "[15,    21] loss: 1.42154, train_accuracy: 50.78\n",
      "[15,    22] loss: 1.39099, train_accuracy: 50.59\n",
      "[15,    23] loss: 1.41543, train_accuracy: 48.63\n",
      "[15,    24] loss: 1.40852, train_accuracy: 45.90\n",
      "[15,    25] loss: 1.44915, train_accuracy: 50.00\n",
      "[15,    26] loss: 1.41112, train_accuracy: 50.98\n",
      "[15,    27] loss: 1.46313, train_accuracy: 47.46\n",
      "[15,    28] loss: 1.50610, train_accuracy: 46.48\n",
      "[15,    29] loss: 1.36899, train_accuracy: 50.00\n",
      "[15,    30] loss: 1.42193, train_accuracy: 48.63\n",
      "[15,    31] loss: 1.41652, train_accuracy: 49.80\n",
      "[15,    32] loss: 1.43263, train_accuracy: 48.05\n",
      "[15,    33] loss: 1.39551, train_accuracy: 51.37\n",
      "[15,    34] loss: 1.43495, train_accuracy: 47.85\n",
      "[15,    35] loss: 1.45445, train_accuracy: 47.27\n",
      "[15,    36] loss: 1.34382, train_accuracy: 51.37\n",
      "[15,    37] loss: 1.46991, train_accuracy: 46.29\n",
      "[15,    38] loss: 1.45457, train_accuracy: 50.00\n",
      "[15,    39] loss: 1.45058, train_accuracy: 46.48\n",
      "[15,    40] loss: 1.35547, train_accuracy: 49.61\n",
      "[15,    41] loss: 1.47118, train_accuracy: 47.66\n",
      "[15,    42] loss: 1.39889, train_accuracy: 50.00\n",
      "[15,    43] loss: 1.43273, train_accuracy: 46.88\n",
      "[15,    44] loss: 1.39329, train_accuracy: 48.83\n",
      "[15,    45] loss: 1.40879, train_accuracy: 49.41\n",
      "[15,    46] loss: 1.44017, train_accuracy: 46.68\n",
      "[15,    47] loss: 1.45109, train_accuracy: 48.83\n",
      "[15,    48] loss: 1.53866, train_accuracy: 42.38\n",
      "[15,    49] loss: 1.48135, train_accuracy: 47.07\n",
      "[15,    50] loss: 1.41050, train_accuracy: 48.44\n",
      "[15,    51] loss: 1.36890, train_accuracy: 51.76\n",
      "[15,    52] loss: 1.50830, train_accuracy: 44.14\n",
      "[15,    53] loss: 1.50145, train_accuracy: 45.90\n",
      "[15,    54] loss: 1.32602, train_accuracy: 54.10\n",
      "[15,    55] loss: 1.38380, train_accuracy: 51.17\n",
      "[15,    56] loss: 1.45102, train_accuracy: 46.88\n",
      "[15,    57] loss: 1.42332, train_accuracy: 49.22\n",
      "[15,    58] loss: 1.45414, train_accuracy: 47.66\n",
      "[15,    59] loss: 1.44198, train_accuracy: 47.66\n",
      "[15,    60] loss: 1.33619, train_accuracy: 53.71\n",
      "[15,    61] loss: 1.42907, train_accuracy: 46.68\n",
      "[15,    62] loss: 1.53013, train_accuracy: 46.09\n",
      "[15,    63] loss: 1.43950, train_accuracy: 49.02\n",
      "[15,    64] loss: 1.40926, train_accuracy: 48.83\n",
      "[15,    65] loss: 1.38761, train_accuracy: 49.41\n",
      "[15,    66] loss: 1.47414, train_accuracy: 48.05\n",
      "[15,    67] loss: 1.35117, train_accuracy: 52.15\n",
      "[15,    68] loss: 1.41614, train_accuracy: 50.20\n",
      "[15,    69] loss: 1.46441, train_accuracy: 48.44\n",
      "[15,    70] loss: 1.45102, train_accuracy: 49.80\n",
      "[15,    71] loss: 1.37402, train_accuracy: 49.41\n",
      "[15,    72] loss: 1.45320, train_accuracy: 45.12\n",
      "[15,    73] loss: 1.37392, train_accuracy: 53.71\n",
      "[15,    74] loss: 1.40702, train_accuracy: 49.02\n",
      "[15,    75] loss: 1.44143, train_accuracy: 50.00\n",
      "[15,    76] loss: 1.46819, train_accuracy: 48.63\n",
      "[15,    77] loss: 1.44616, train_accuracy: 48.24\n",
      "[15,    78] loss: 1.47664, train_accuracy: 48.24\n",
      "[15,    79] loss: 1.37238, train_accuracy: 51.56\n",
      "[15,    80] loss: 1.40638, train_accuracy: 52.73\n",
      "[15,    81] loss: 1.42005, train_accuracy: 49.61\n",
      "[15,    82] loss: 1.38324, train_accuracy: 50.39\n",
      "[15,    83] loss: 1.47659, train_accuracy: 46.48\n",
      "[15,    84] loss: 1.41363, train_accuracy: 48.83\n",
      "[15,    85] loss: 1.41730, train_accuracy: 50.39\n",
      "[15,    86] loss: 1.42615, train_accuracy: 49.22\n",
      "[15,    87] loss: 1.42029, train_accuracy: 49.02\n",
      "[15,    88] loss: 1.30931, train_accuracy: 56.84\n",
      "[15,    89] loss: 1.46719, train_accuracy: 47.85\n",
      "[15,    90] loss: 1.41953, train_accuracy: 49.41\n",
      "[15,    91] loss: 1.50826, train_accuracy: 45.90\n",
      "[15,    92] loss: 1.42955, train_accuracy: 51.37\n",
      "[15,    93] loss: 1.45517, train_accuracy: 47.66\n",
      "[15,    94] loss: 1.49614, train_accuracy: 43.55\n",
      "[15,    95] loss: 1.40687, train_accuracy: 52.15\n",
      "[15,    96] loss: 1.41577, train_accuracy: 47.85\n",
      "[15,    97] loss: 1.49414, train_accuracy: 45.90\n",
      "[15,    98] loss: 1.51467, train_accuracy: 49.11\n",
      "duration: 278 s - train loss: 1.43280 - train accuracy: 48.77 - validation loss: 1.14282 - validation accuracy: 59.93 \n",
      "[16,     1] loss: 1.44709, train_accuracy: 46.68\n",
      "[16,     2] loss: 1.43352, train_accuracy: 50.20\n",
      "[16,     3] loss: 1.48091, train_accuracy: 48.44\n",
      "[16,     4] loss: 1.47214, train_accuracy: 45.51\n",
      "[16,     5] loss: 1.46440, train_accuracy: 44.53\n",
      "[16,     6] loss: 1.37312, train_accuracy: 52.34\n",
      "[16,     7] loss: 1.35457, train_accuracy: 51.17\n",
      "[16,     8] loss: 1.47211, train_accuracy: 47.07\n",
      "[16,     9] loss: 1.42365, train_accuracy: 50.20\n",
      "[16,    10] loss: 1.41076, train_accuracy: 46.68\n",
      "[16,    11] loss: 1.36559, train_accuracy: 49.02\n",
      "[16,    12] loss: 1.46532, train_accuracy: 49.02\n",
      "[16,    13] loss: 1.41671, train_accuracy: 48.63\n",
      "[16,    14] loss: 1.41701, train_accuracy: 51.17\n",
      "[16,    15] loss: 1.38076, train_accuracy: 51.17\n",
      "[16,    16] loss: 1.29874, train_accuracy: 53.71\n",
      "[16,    17] loss: 1.39438, train_accuracy: 50.78\n",
      "[16,    18] loss: 1.41150, train_accuracy: 50.00\n",
      "[16,    19] loss: 1.47203, train_accuracy: 47.46\n",
      "[16,    20] loss: 1.42429, train_accuracy: 47.46\n",
      "[16,    21] loss: 1.43934, train_accuracy: 49.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,    22] loss: 1.42223, train_accuracy: 50.39\n",
      "[16,    23] loss: 1.34812, train_accuracy: 51.37\n",
      "[16,    24] loss: 1.48425, train_accuracy: 46.68\n",
      "[16,    25] loss: 1.44628, train_accuracy: 50.00\n",
      "[16,    26] loss: 1.37801, train_accuracy: 50.59\n",
      "[16,    27] loss: 1.47073, train_accuracy: 47.85\n",
      "[16,    28] loss: 1.41481, train_accuracy: 48.44\n",
      "[16,    29] loss: 1.50524, train_accuracy: 43.95\n",
      "[16,    30] loss: 1.42064, train_accuracy: 50.59\n",
      "[16,    31] loss: 1.44001, train_accuracy: 49.80\n",
      "[16,    32] loss: 1.46592, train_accuracy: 48.44\n",
      "[16,    33] loss: 1.46732, train_accuracy: 45.70\n",
      "[16,    34] loss: 1.44285, train_accuracy: 51.76\n",
      "[16,    35] loss: 1.37192, train_accuracy: 48.63\n",
      "[16,    36] loss: 1.45139, train_accuracy: 48.83\n",
      "[16,    37] loss: 1.41038, train_accuracy: 50.98\n",
      "[16,    38] loss: 1.32279, train_accuracy: 51.17\n",
      "[16,    39] loss: 1.42855, train_accuracy: 48.44\n",
      "[16,    40] loss: 1.42207, train_accuracy: 49.80\n",
      "[16,    41] loss: 1.35796, train_accuracy: 49.80\n",
      "[16,    42] loss: 1.47946, train_accuracy: 50.78\n",
      "[16,    43] loss: 1.42327, train_accuracy: 48.44\n",
      "[16,    44] loss: 1.44602, train_accuracy: 50.20\n",
      "[16,    45] loss: 1.38891, train_accuracy: 50.00\n",
      "[16,    46] loss: 1.47645, train_accuracy: 46.09\n",
      "[16,    47] loss: 1.43210, train_accuracy: 47.46\n",
      "[16,    48] loss: 1.40699, train_accuracy: 49.80\n",
      "[16,    49] loss: 1.45942, train_accuracy: 47.27\n",
      "[16,    50] loss: 1.38278, train_accuracy: 51.17\n",
      "[16,    51] loss: 1.47050, train_accuracy: 49.22\n",
      "[16,    52] loss: 1.43613, train_accuracy: 49.80\n",
      "[16,    53] loss: 1.51321, train_accuracy: 46.29\n",
      "[16,    54] loss: 1.46258, train_accuracy: 47.66\n",
      "[16,    55] loss: 1.38176, train_accuracy: 50.78\n",
      "[16,    56] loss: 1.42230, train_accuracy: 49.61\n",
      "[16,    57] loss: 1.41308, train_accuracy: 49.02\n",
      "[16,    58] loss: 1.33979, train_accuracy: 53.32\n",
      "[16,    59] loss: 1.48668, train_accuracy: 44.34\n",
      "[16,    60] loss: 1.46258, train_accuracy: 48.24\n",
      "[16,    61] loss: 1.38327, train_accuracy: 50.00\n",
      "[16,    62] loss: 1.36418, train_accuracy: 49.80\n",
      "[16,    63] loss: 1.30799, train_accuracy: 52.15\n",
      "[16,    64] loss: 1.36608, train_accuracy: 51.56\n",
      "[16,    65] loss: 1.41406, train_accuracy: 48.05\n",
      "[16,    66] loss: 1.42021, train_accuracy: 46.29\n",
      "[16,    67] loss: 1.42902, train_accuracy: 51.17\n",
      "[16,    68] loss: 1.46966, train_accuracy: 45.90\n",
      "[16,    69] loss: 1.39270, train_accuracy: 50.78\n",
      "[16,    70] loss: 1.41747, train_accuracy: 50.59\n",
      "[16,    71] loss: 1.45013, train_accuracy: 46.48\n",
      "[16,    72] loss: 1.44445, train_accuracy: 47.66\n",
      "[16,    73] loss: 1.43542, train_accuracy: 47.85\n",
      "[16,    74] loss: 1.33794, train_accuracy: 54.30\n",
      "[16,    75] loss: 1.39939, train_accuracy: 50.00\n",
      "[16,    76] loss: 1.38849, train_accuracy: 46.48\n",
      "[16,    77] loss: 1.49837, train_accuracy: 45.51\n",
      "[16,    78] loss: 1.36401, train_accuracy: 50.78\n",
      "[16,    79] loss: 1.41517, train_accuracy: 48.83\n",
      "[16,    80] loss: 1.37747, train_accuracy: 51.95\n",
      "[16,    81] loss: 1.37676, train_accuracy: 49.80\n",
      "[16,    82] loss: 1.41406, train_accuracy: 49.22\n",
      "[16,    83] loss: 1.45641, train_accuracy: 49.02\n",
      "[16,    84] loss: 1.44092, train_accuracy: 50.59\n",
      "[16,    85] loss: 1.37270, train_accuracy: 50.39\n",
      "[16,    86] loss: 1.41948, train_accuracy: 49.22\n",
      "[16,    87] loss: 1.41193, train_accuracy: 50.20\n",
      "[16,    88] loss: 1.39655, train_accuracy: 49.02\n",
      "[16,    89] loss: 1.47282, train_accuracy: 44.14\n",
      "[16,    90] loss: 1.37328, train_accuracy: 48.83\n",
      "[16,    91] loss: 1.41018, train_accuracy: 48.63\n",
      "[16,    92] loss: 1.34614, train_accuracy: 52.34\n",
      "[16,    93] loss: 1.37856, train_accuracy: 51.76\n",
      "[16,    94] loss: 1.40885, train_accuracy: 47.07\n",
      "[16,    95] loss: 1.50287, train_accuracy: 44.14\n",
      "[16,    96] loss: 1.42217, train_accuracy: 51.76\n",
      "[16,    97] loss: 1.36518, train_accuracy: 49.02\n",
      "[16,    98] loss: 1.32863, train_accuracy: 49.40\n",
      "duration: 207 s - train loss: 1.41782 - train accuracy: 49.12 - validation loss: 1.12114 - validation accuracy: 60.76 \n",
      "[17,     1] loss: 1.43619, train_accuracy: 50.78\n",
      "[17,     2] loss: 1.40784, train_accuracy: 49.02\n",
      "[17,     3] loss: 1.37987, train_accuracy: 50.20\n",
      "[17,     4] loss: 1.37043, train_accuracy: 53.52\n",
      "[17,     5] loss: 1.43578, train_accuracy: 48.44\n",
      "[17,     6] loss: 1.43896, train_accuracy: 48.44\n",
      "[17,     7] loss: 1.36012, train_accuracy: 51.17\n",
      "[17,     8] loss: 1.47581, train_accuracy: 46.09\n",
      "[17,     9] loss: 1.38065, train_accuracy: 50.59\n",
      "[17,    10] loss: 1.46581, train_accuracy: 47.85\n",
      "[17,    11] loss: 1.40911, train_accuracy: 48.44\n",
      "[17,    12] loss: 1.45918, train_accuracy: 48.83\n",
      "[17,    13] loss: 1.46589, train_accuracy: 48.24\n",
      "[17,    14] loss: 1.34462, train_accuracy: 53.12\n",
      "[17,    15] loss: 1.49237, train_accuracy: 47.07\n",
      "[17,    16] loss: 1.41248, train_accuracy: 52.54\n",
      "[17,    17] loss: 1.46732, train_accuracy: 46.09\n",
      "[17,    18] loss: 1.40842, train_accuracy: 50.78\n",
      "[17,    19] loss: 1.36216, train_accuracy: 51.76\n",
      "[17,    20] loss: 1.48774, train_accuracy: 47.66\n",
      "[17,    21] loss: 1.37916, train_accuracy: 52.73\n",
      "[17,    22] loss: 1.39758, train_accuracy: 52.15\n",
      "[17,    23] loss: 1.44115, train_accuracy: 46.68\n",
      "[17,    24] loss: 1.41539, train_accuracy: 49.61\n",
      "[17,    25] loss: 1.45138, train_accuracy: 47.66\n",
      "[17,    26] loss: 1.34452, train_accuracy: 52.93\n",
      "[17,    27] loss: 1.42059, train_accuracy: 48.24\n",
      "[17,    28] loss: 1.44357, train_accuracy: 47.66\n",
      "[17,    29] loss: 1.40116, train_accuracy: 51.76\n",
      "[17,    30] loss: 1.42747, train_accuracy: 48.05\n",
      "[17,    31] loss: 1.43571, train_accuracy: 50.00\n",
      "[17,    32] loss: 1.37926, train_accuracy: 49.41\n",
      "[17,    33] loss: 1.37882, train_accuracy: 49.22\n",
      "[17,    34] loss: 1.42704, train_accuracy: 47.66\n",
      "[17,    35] loss: 1.42691, train_accuracy: 47.85\n",
      "[17,    36] loss: 1.44351, train_accuracy: 49.41\n",
      "[17,    37] loss: 1.40900, train_accuracy: 48.44\n",
      "[17,    38] loss: 1.43572, train_accuracy: 48.63\n",
      "[17,    39] loss: 1.42933, train_accuracy: 49.41\n",
      "[17,    40] loss: 1.43323, train_accuracy: 50.20\n",
      "[17,    41] loss: 1.33201, train_accuracy: 51.56\n",
      "[17,    42] loss: 1.41678, train_accuracy: 50.39\n",
      "[17,    43] loss: 1.39234, train_accuracy: 52.34\n",
      "[17,    44] loss: 1.34953, train_accuracy: 49.02\n",
      "[17,    45] loss: 1.40105, train_accuracy: 51.56\n",
      "[17,    46] loss: 1.41326, train_accuracy: 51.17\n",
      "[17,    47] loss: 1.48799, train_accuracy: 46.68\n",
      "[17,    48] loss: 1.42032, train_accuracy: 46.68\n",
      "[17,    49] loss: 1.42216, train_accuracy: 48.83\n",
      "[17,    50] loss: 1.43078, train_accuracy: 49.41\n",
      "[17,    51] loss: 1.40264, train_accuracy: 48.44\n",
      "[17,    52] loss: 1.40536, train_accuracy: 51.37\n",
      "[17,    53] loss: 1.46224, train_accuracy: 47.46\n",
      "[17,    54] loss: 1.42400, train_accuracy: 49.41\n",
      "[17,    55] loss: 1.39112, train_accuracy: 49.80\n",
      "[17,    56] loss: 1.38285, train_accuracy: 48.24\n",
      "[17,    57] loss: 1.38005, train_accuracy: 49.41\n",
      "[17,    58] loss: 1.38985, train_accuracy: 49.80\n",
      "[17,    59] loss: 1.35072, train_accuracy: 53.71\n",
      "[17,    60] loss: 1.45857, train_accuracy: 45.90\n",
      "[17,    61] loss: 1.41550, train_accuracy: 47.66\n",
      "[17,    62] loss: 1.41514, train_accuracy: 50.20\n",
      "[17,    63] loss: 1.39420, train_accuracy: 49.61\n",
      "[17,    64] loss: 1.39633, train_accuracy: 47.46\n",
      "[17,    65] loss: 1.38434, train_accuracy: 51.37\n",
      "[17,    66] loss: 1.43142, train_accuracy: 50.20\n",
      "[17,    67] loss: 1.44049, train_accuracy: 49.41\n",
      "[17,    68] loss: 1.39813, train_accuracy: 49.02\n",
      "[17,    69] loss: 1.40034, train_accuracy: 49.02\n",
      "[17,    70] loss: 1.46124, train_accuracy: 49.22\n",
      "[17,    71] loss: 1.43159, train_accuracy: 50.98\n",
      "[17,    72] loss: 1.35818, train_accuracy: 48.24\n",
      "[17,    73] loss: 1.44442, train_accuracy: 49.61\n",
      "[17,    74] loss: 1.33748, train_accuracy: 52.54\n",
      "[17,    75] loss: 1.45201, train_accuracy: 47.85\n",
      "[17,    76] loss: 1.41155, train_accuracy: 51.95\n",
      "[17,    77] loss: 1.46128, train_accuracy: 48.44\n",
      "[17,    78] loss: 1.40586, train_accuracy: 50.00\n",
      "[17,    79] loss: 1.40217, train_accuracy: 49.61\n",
      "[17,    80] loss: 1.47213, train_accuracy: 47.27\n",
      "[17,    81] loss: 1.40511, train_accuracy: 50.98\n",
      "[17,    82] loss: 1.46162, train_accuracy: 46.09\n",
      "[17,    83] loss: 1.44604, train_accuracy: 47.85\n",
      "[17,    84] loss: 1.45032, train_accuracy: 43.95\n",
      "[17,    85] loss: 1.45317, train_accuracy: 46.48\n",
      "[17,    86] loss: 1.42620, train_accuracy: 50.00\n",
      "[17,    87] loss: 1.47363, train_accuracy: 47.46\n",
      "[17,    88] loss: 1.39323, train_accuracy: 48.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17,    89] loss: 1.40331, train_accuracy: 48.24\n",
      "[17,    90] loss: 1.32057, train_accuracy: 53.12\n",
      "[17,    91] loss: 1.39010, train_accuracy: 52.15\n",
      "[17,    92] loss: 1.36745, train_accuracy: 49.61\n",
      "[17,    93] loss: 1.41566, train_accuracy: 53.32\n",
      "[17,    94] loss: 1.42137, train_accuracy: 47.46\n",
      "[17,    95] loss: 1.39317, train_accuracy: 49.22\n",
      "[17,    96] loss: 1.43371, train_accuracy: 50.78\n",
      "[17,    97] loss: 1.41755, train_accuracy: 49.41\n",
      "[17,    98] loss: 1.32652, train_accuracy: 53.87\n",
      "duration: 211 s - train loss: 1.41436 - train accuracy: 49.46 - validation loss: 1.11880 - validation accuracy: 60.92 \n",
      "[18,     1] loss: 1.39509, train_accuracy: 52.93\n",
      "[18,     2] loss: 1.47158, train_accuracy: 47.07\n",
      "[18,     3] loss: 1.35489, train_accuracy: 51.76\n",
      "[18,     4] loss: 1.38033, train_accuracy: 50.39\n",
      "[18,     5] loss: 1.43131, train_accuracy: 49.61\n",
      "[18,     6] loss: 1.34349, train_accuracy: 53.71\n",
      "[18,     7] loss: 1.33559, train_accuracy: 52.15\n",
      "[18,     8] loss: 1.48054, train_accuracy: 47.66\n",
      "[18,     9] loss: 1.42855, train_accuracy: 48.05\n",
      "[18,    10] loss: 1.40167, train_accuracy: 49.41\n",
      "[18,    11] loss: 1.41096, train_accuracy: 47.46\n",
      "[18,    12] loss: 1.46639, train_accuracy: 49.02\n",
      "[18,    13] loss: 1.37473, train_accuracy: 50.39\n",
      "[18,    14] loss: 1.38222, train_accuracy: 52.73\n",
      "[18,    15] loss: 1.39517, train_accuracy: 50.59\n",
      "[18,    16] loss: 1.40675, train_accuracy: 50.59\n",
      "[18,    17] loss: 1.47509, train_accuracy: 48.63\n",
      "[18,    18] loss: 1.37316, train_accuracy: 50.59\n",
      "[18,    19] loss: 1.43416, train_accuracy: 46.48\n",
      "[18,    20] loss: 1.42150, train_accuracy: 49.22\n",
      "[18,    21] loss: 1.39609, train_accuracy: 50.00\n",
      "[18,    22] loss: 1.42090, train_accuracy: 49.22\n",
      "[18,    23] loss: 1.36664, train_accuracy: 52.15\n",
      "[18,    24] loss: 1.38107, train_accuracy: 50.20\n",
      "[18,    25] loss: 1.37098, train_accuracy: 47.85\n",
      "[18,    26] loss: 1.40687, train_accuracy: 50.98\n",
      "[18,    27] loss: 1.46560, train_accuracy: 45.90\n",
      "[18,    28] loss: 1.48674, train_accuracy: 44.92\n",
      "[18,    29] loss: 1.46223, train_accuracy: 49.41\n",
      "[18,    30] loss: 1.33809, train_accuracy: 53.52\n",
      "[18,    31] loss: 1.36426, train_accuracy: 51.76\n",
      "[18,    32] loss: 1.38724, train_accuracy: 50.98\n",
      "[18,    33] loss: 1.41062, train_accuracy: 49.80\n",
      "[18,    34] loss: 1.46587, train_accuracy: 44.92\n",
      "[18,    35] loss: 1.46933, train_accuracy: 47.66\n",
      "[18,    36] loss: 1.43972, train_accuracy: 48.05\n",
      "[18,    37] loss: 1.33372, train_accuracy: 52.34\n",
      "[18,    38] loss: 1.39351, train_accuracy: 50.78\n",
      "[18,    39] loss: 1.39314, train_accuracy: 49.02\n",
      "[18,    40] loss: 1.39993, train_accuracy: 49.41\n",
      "[18,    41] loss: 1.35290, train_accuracy: 51.17\n",
      "[18,    42] loss: 1.41759, train_accuracy: 47.27\n",
      "[18,    43] loss: 1.38158, train_accuracy: 49.22\n",
      "[18,    44] loss: 1.34567, train_accuracy: 50.59\n",
      "[18,    45] loss: 1.34199, train_accuracy: 50.59\n",
      "[18,    46] loss: 1.36139, train_accuracy: 50.59\n",
      "[18,    47] loss: 1.38757, train_accuracy: 49.80\n",
      "[18,    48] loss: 1.42145, train_accuracy: 47.85\n",
      "[18,    49] loss: 1.37895, train_accuracy: 49.80\n",
      "[18,    50] loss: 1.41416, train_accuracy: 47.27\n",
      "[18,    51] loss: 1.46554, train_accuracy: 49.02\n",
      "[18,    52] loss: 1.45370, train_accuracy: 46.29\n",
      "[18,    53] loss: 1.34895, train_accuracy: 53.71\n",
      "[18,    54] loss: 1.43059, train_accuracy: 46.09\n",
      "[18,    55] loss: 1.41587, train_accuracy: 48.44\n",
      "[18,    56] loss: 1.51288, train_accuracy: 45.12\n",
      "[18,    57] loss: 1.37587, train_accuracy: 50.20\n",
      "[18,    58] loss: 1.40463, train_accuracy: 47.66\n",
      "[18,    59] loss: 1.39998, train_accuracy: 48.83\n",
      "[18,    60] loss: 1.40998, train_accuracy: 50.78\n",
      "[18,    61] loss: 1.32156, train_accuracy: 54.88\n",
      "[18,    62] loss: 1.49663, train_accuracy: 45.12\n",
      "[18,    63] loss: 1.38029, train_accuracy: 49.61\n",
      "[18,    64] loss: 1.35902, train_accuracy: 54.30\n",
      "[18,    65] loss: 1.28968, train_accuracy: 54.49\n",
      "[18,    66] loss: 1.29308, train_accuracy: 53.71\n",
      "[18,    67] loss: 1.33950, train_accuracy: 51.37\n",
      "[18,    68] loss: 1.45908, train_accuracy: 47.07\n",
      "[18,    69] loss: 1.42210, train_accuracy: 50.39\n",
      "[18,    70] loss: 1.40356, train_accuracy: 48.05\n",
      "[18,    71] loss: 1.36908, train_accuracy: 51.17\n",
      "[18,    72] loss: 1.33591, train_accuracy: 54.30\n",
      "[18,    73] loss: 1.44234, train_accuracy: 48.24\n",
      "[18,    74] loss: 1.45048, train_accuracy: 50.78\n",
      "[18,    75] loss: 1.48440, train_accuracy: 46.68\n",
      "[18,    76] loss: 1.40037, train_accuracy: 51.37\n",
      "[18,    77] loss: 1.28990, train_accuracy: 53.52\n",
      "[18,    78] loss: 1.42043, train_accuracy: 48.05\n",
      "[18,    79] loss: 1.49058, train_accuracy: 48.44\n",
      "[18,    80] loss: 1.43684, train_accuracy: 49.22\n",
      "[18,    81] loss: 1.38350, train_accuracy: 50.78\n",
      "[18,    82] loss: 1.35799, train_accuracy: 51.56\n",
      "[18,    83] loss: 1.36478, train_accuracy: 52.93\n",
      "[18,    84] loss: 1.44355, train_accuracy: 47.27\n",
      "[18,    85] loss: 1.40926, train_accuracy: 48.63\n",
      "[18,    86] loss: 1.33709, train_accuracy: 54.10\n",
      "[18,    87] loss: 1.41479, train_accuracy: 50.00\n",
      "[18,    88] loss: 1.38372, train_accuracy: 54.69\n",
      "[18,    89] loss: 1.40711, train_accuracy: 46.88\n",
      "[18,    90] loss: 1.39028, train_accuracy: 51.17\n",
      "[18,    91] loss: 1.44464, train_accuracy: 47.46\n",
      "[18,    92] loss: 1.37601, train_accuracy: 50.39\n",
      "[18,    93] loss: 1.45433, train_accuracy: 49.61\n",
      "[18,    94] loss: 1.37545, train_accuracy: 51.95\n",
      "[18,    95] loss: 1.43857, train_accuracy: 49.02\n",
      "[18,    96] loss: 1.44248, train_accuracy: 48.83\n",
      "[18,    97] loss: 1.42212, train_accuracy: 50.00\n",
      "[18,    98] loss: 1.45735, train_accuracy: 47.92\n",
      "duration: 194 s - train loss: 1.40331 - train accuracy: 49.81 - validation loss: 1.11046 - validation accuracy: 60.53 \n",
      "[19,     1] loss: 1.48453, train_accuracy: 45.31\n",
      "[19,     2] loss: 1.38622, train_accuracy: 50.20\n",
      "[19,     3] loss: 1.37754, train_accuracy: 51.37\n",
      "[19,     4] loss: 1.43756, train_accuracy: 47.66\n",
      "[19,     5] loss: 1.41880, train_accuracy: 49.22\n",
      "[19,     6] loss: 1.40919, train_accuracy: 50.98\n",
      "[19,     7] loss: 1.39189, train_accuracy: 51.95\n",
      "[19,     8] loss: 1.47960, train_accuracy: 49.22\n",
      "[19,     9] loss: 1.32144, train_accuracy: 53.71\n",
      "[19,    10] loss: 1.44000, train_accuracy: 48.05\n",
      "[19,    11] loss: 1.46774, train_accuracy: 47.46\n",
      "[19,    12] loss: 1.36322, train_accuracy: 52.34\n",
      "[19,    13] loss: 1.37774, train_accuracy: 51.56\n",
      "[19,    14] loss: 1.32813, train_accuracy: 53.52\n",
      "[19,    15] loss: 1.46379, train_accuracy: 46.29\n",
      "[19,    16] loss: 1.49513, train_accuracy: 50.39\n",
      "[19,    17] loss: 1.37553, train_accuracy: 52.15\n",
      "[19,    18] loss: 1.39372, train_accuracy: 51.56\n",
      "[19,    19] loss: 1.35202, train_accuracy: 52.93\n",
      "[19,    20] loss: 1.31608, train_accuracy: 52.15\n",
      "[19,    21] loss: 1.39445, train_accuracy: 51.56\n",
      "[19,    22] loss: 1.36270, train_accuracy: 54.88\n",
      "[19,    23] loss: 1.38214, train_accuracy: 51.76\n",
      "[19,    24] loss: 1.38294, train_accuracy: 50.98\n",
      "[19,    25] loss: 1.43021, train_accuracy: 47.07\n",
      "[19,    26] loss: 1.45178, train_accuracy: 46.68\n",
      "[19,    27] loss: 1.43554, train_accuracy: 46.48\n",
      "[19,    28] loss: 1.38594, train_accuracy: 51.95\n",
      "[19,    29] loss: 1.34865, train_accuracy: 54.10\n",
      "[19,    30] loss: 1.35248, train_accuracy: 51.17\n",
      "[19,    31] loss: 1.34649, train_accuracy: 51.37\n",
      "[19,    32] loss: 1.36704, train_accuracy: 52.73\n",
      "[19,    33] loss: 1.40587, train_accuracy: 50.59\n",
      "[19,    34] loss: 1.41646, train_accuracy: 49.41\n",
      "[19,    35] loss: 1.37581, train_accuracy: 49.61\n",
      "[19,    36] loss: 1.39932, train_accuracy: 50.98\n",
      "[19,    37] loss: 1.32448, train_accuracy: 51.76\n",
      "[19,    38] loss: 1.31613, train_accuracy: 53.32\n",
      "[19,    39] loss: 1.33475, train_accuracy: 52.73\n",
      "[19,    40] loss: 1.44899, train_accuracy: 46.09\n",
      "[19,    41] loss: 1.38380, train_accuracy: 51.37\n",
      "[19,    42] loss: 1.35778, train_accuracy: 50.20\n",
      "[19,    43] loss: 1.40839, train_accuracy: 51.95\n",
      "[19,    44] loss: 1.34898, train_accuracy: 50.59\n",
      "[19,    45] loss: 1.39927, train_accuracy: 48.44\n",
      "[19,    46] loss: 1.32901, train_accuracy: 54.10\n",
      "[19,    47] loss: 1.40574, train_accuracy: 50.20\n",
      "[19,    48] loss: 1.35002, train_accuracy: 49.41\n",
      "[19,    49] loss: 1.53426, train_accuracy: 46.09\n",
      "[19,    50] loss: 1.38008, train_accuracy: 49.22\n",
      "[19,    51] loss: 1.31896, train_accuracy: 52.34\n",
      "[19,    52] loss: 1.38928, train_accuracy: 52.73\n",
      "[19,    53] loss: 1.36907, train_accuracy: 51.17\n",
      "[19,    54] loss: 1.43229, train_accuracy: 49.41\n",
      "[19,    55] loss: 1.40046, train_accuracy: 46.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19,    56] loss: 1.34660, train_accuracy: 51.95\n",
      "[19,    57] loss: 1.40347, train_accuracy: 51.76\n",
      "[19,    58] loss: 1.32601, train_accuracy: 52.34\n",
      "[19,    59] loss: 1.37485, train_accuracy: 51.37\n",
      "[19,    60] loss: 1.44617, train_accuracy: 46.68\n",
      "[19,    61] loss: 1.40552, train_accuracy: 50.98\n",
      "[19,    62] loss: 1.44793, train_accuracy: 49.02\n",
      "[19,    63] loss: 1.31319, train_accuracy: 52.93\n",
      "[19,    64] loss: 1.38942, train_accuracy: 48.24\n",
      "[19,    65] loss: 1.36290, train_accuracy: 50.00\n",
      "[19,    66] loss: 1.39194, train_accuracy: 50.39\n",
      "[19,    67] loss: 1.44764, train_accuracy: 49.02\n",
      "[19,    68] loss: 1.41066, train_accuracy: 50.39\n",
      "[19,    69] loss: 1.40127, train_accuracy: 50.59\n",
      "[19,    70] loss: 1.37176, train_accuracy: 50.98\n",
      "[19,    71] loss: 1.43154, train_accuracy: 46.48\n",
      "[19,    72] loss: 1.34742, train_accuracy: 52.54\n",
      "[19,    73] loss: 1.38663, train_accuracy: 46.88\n",
      "[19,    74] loss: 1.44003, train_accuracy: 48.83\n",
      "[19,    75] loss: 1.38022, train_accuracy: 50.20\n",
      "[19,    76] loss: 1.38548, train_accuracy: 49.80\n",
      "[19,    77] loss: 1.42103, train_accuracy: 49.22\n",
      "[19,    78] loss: 1.37412, train_accuracy: 50.78\n",
      "[19,    79] loss: 1.42324, train_accuracy: 51.56\n",
      "[19,    80] loss: 1.38854, train_accuracy: 50.39\n",
      "[19,    81] loss: 1.45989, train_accuracy: 46.48\n",
      "[19,    82] loss: 1.39147, train_accuracy: 51.76\n",
      "[19,    83] loss: 1.35676, train_accuracy: 53.52\n",
      "[19,    84] loss: 1.27829, train_accuracy: 54.30\n",
      "[19,    85] loss: 1.36648, train_accuracy: 52.15\n",
      "[19,    86] loss: 1.40378, train_accuracy: 49.41\n",
      "[19,    87] loss: 1.37461, train_accuracy: 48.83\n",
      "[19,    88] loss: 1.40518, train_accuracy: 47.85\n",
      "[19,    89] loss: 1.35694, train_accuracy: 52.34\n",
      "[19,    90] loss: 1.41420, train_accuracy: 50.00\n",
      "[19,    91] loss: 1.37415, train_accuracy: 50.20\n",
      "[19,    92] loss: 1.48574, train_accuracy: 45.12\n",
      "[19,    93] loss: 1.40820, train_accuracy: 51.17\n",
      "[19,    94] loss: 1.40311, train_accuracy: 48.83\n",
      "[19,    95] loss: 1.42272, train_accuracy: 47.27\n",
      "[19,    96] loss: 1.37556, train_accuracy: 47.27\n",
      "[19,    97] loss: 1.46398, train_accuracy: 43.75\n",
      "[19,    98] loss: 1.36545, train_accuracy: 53.27\n",
      "duration: 216 s - train loss: 1.39259 - train accuracy: 50.25 - validation loss: 1.10556 - validation accuracy: 61.53 \n",
      "[20,     1] loss: 1.42353, train_accuracy: 45.31\n",
      "[20,     2] loss: 1.45080, train_accuracy: 46.29\n",
      "[20,     3] loss: 1.44728, train_accuracy: 49.22\n",
      "[20,     4] loss: 1.36545, train_accuracy: 51.37\n",
      "[20,     5] loss: 1.42075, train_accuracy: 47.27\n",
      "[20,     6] loss: 1.38389, train_accuracy: 51.76\n",
      "[20,     7] loss: 1.29144, train_accuracy: 54.10\n",
      "[20,     8] loss: 1.35288, train_accuracy: 48.63\n",
      "[20,     9] loss: 1.43175, train_accuracy: 49.80\n",
      "[20,    10] loss: 1.34979, train_accuracy: 48.63\n",
      "[20,    11] loss: 1.34765, train_accuracy: 51.17\n",
      "[20,    12] loss: 1.36334, train_accuracy: 50.20\n",
      "[20,    13] loss: 1.37286, train_accuracy: 51.76\n",
      "[20,    14] loss: 1.37792, train_accuracy: 50.59\n",
      "[20,    15] loss: 1.36467, train_accuracy: 50.59\n",
      "[20,    16] loss: 1.37590, train_accuracy: 52.93\n",
      "[20,    17] loss: 1.39805, train_accuracy: 48.24\n",
      "[20,    18] loss: 1.32246, train_accuracy: 50.59\n",
      "[20,    19] loss: 1.33240, train_accuracy: 53.32\n",
      "[20,    20] loss: 1.34617, train_accuracy: 50.39\n",
      "[20,    21] loss: 1.44932, train_accuracy: 45.90\n",
      "[20,    22] loss: 1.44031, train_accuracy: 49.02\n",
      "[20,    23] loss: 1.44385, train_accuracy: 47.66\n",
      "[20,    24] loss: 1.44162, train_accuracy: 49.22\n",
      "[20,    25] loss: 1.31510, train_accuracy: 53.32\n",
      "[20,    26] loss: 1.32245, train_accuracy: 52.73\n",
      "[20,    27] loss: 1.49528, train_accuracy: 45.51\n",
      "[20,    28] loss: 1.38312, train_accuracy: 50.59\n",
      "[20,    29] loss: 1.44439, train_accuracy: 49.22\n",
      "[20,    30] loss: 1.37078, train_accuracy: 51.76\n",
      "[20,    31] loss: 1.31599, train_accuracy: 53.12\n",
      "[20,    32] loss: 1.32653, train_accuracy: 50.59\n",
      "[20,    33] loss: 1.33816, train_accuracy: 51.76\n",
      "[20,    34] loss: 1.46948, train_accuracy: 47.07\n",
      "[20,    35] loss: 1.48507, train_accuracy: 49.02\n",
      "[20,    36] loss: 1.34474, train_accuracy: 53.52\n",
      "[20,    37] loss: 1.37291, train_accuracy: 49.61\n",
      "[20,    38] loss: 1.42092, train_accuracy: 49.61\n",
      "[20,    39] loss: 1.39983, train_accuracy: 50.20\n",
      "[20,    40] loss: 1.32030, train_accuracy: 50.00\n",
      "[20,    41] loss: 1.41999, train_accuracy: 49.80\n",
      "[20,    42] loss: 1.37310, train_accuracy: 53.32\n",
      "[20,    43] loss: 1.30965, train_accuracy: 53.32\n",
      "[20,    44] loss: 1.40769, train_accuracy: 49.41\n",
      "[20,    45] loss: 1.41729, train_accuracy: 47.46\n",
      "[20,    46] loss: 1.40935, train_accuracy: 47.07\n",
      "[20,    47] loss: 1.44445, train_accuracy: 47.46\n",
      "[20,    48] loss: 1.42958, train_accuracy: 49.02\n",
      "[20,    49] loss: 1.36981, train_accuracy: 52.54\n",
      "[20,    50] loss: 1.42800, train_accuracy: 49.61\n",
      "[20,    51] loss: 1.32834, train_accuracy: 52.73\n",
      "[20,    52] loss: 1.39678, train_accuracy: 49.02\n",
      "[20,    53] loss: 1.31868, train_accuracy: 54.49\n",
      "[20,    54] loss: 1.38918, train_accuracy: 51.56\n",
      "[20,    55] loss: 1.37180, train_accuracy: 49.80\n",
      "[20,    56] loss: 1.33540, train_accuracy: 52.34\n",
      "[20,    57] loss: 1.28887, train_accuracy: 53.91\n",
      "[20,    58] loss: 1.38382, train_accuracy: 49.80\n",
      "[20,    59] loss: 1.32655, train_accuracy: 51.37\n",
      "[20,    60] loss: 1.36491, train_accuracy: 50.98\n",
      "[20,    61] loss: 1.44259, train_accuracy: 48.63\n",
      "[20,    62] loss: 1.44371, train_accuracy: 47.85\n",
      "[20,    63] loss: 1.45040, train_accuracy: 47.27\n",
      "[20,    64] loss: 1.33210, train_accuracy: 53.12\n",
      "[20,    65] loss: 1.33838, train_accuracy: 53.71\n",
      "[20,    66] loss: 1.42350, train_accuracy: 51.17\n",
      "[20,    67] loss: 1.44346, train_accuracy: 49.02\n",
      "[20,    68] loss: 1.37753, train_accuracy: 51.95\n",
      "[20,    69] loss: 1.34749, train_accuracy: 52.34\n",
      "[20,    70] loss: 1.41798, train_accuracy: 49.02\n",
      "[20,    71] loss: 1.34581, train_accuracy: 52.15\n",
      "[20,    72] loss: 1.42792, train_accuracy: 47.46\n",
      "[20,    73] loss: 1.39699, train_accuracy: 50.00\n",
      "[20,    74] loss: 1.47483, train_accuracy: 44.53\n",
      "[20,    75] loss: 1.34041, train_accuracy: 52.15\n",
      "[20,    76] loss: 1.44156, train_accuracy: 48.05\n",
      "[20,    77] loss: 1.41483, train_accuracy: 50.00\n",
      "[20,    78] loss: 1.36897, train_accuracy: 48.83\n",
      "[20,    79] loss: 1.43881, train_accuracy: 51.17\n",
      "[20,    80] loss: 1.34772, train_accuracy: 51.37\n",
      "[20,    81] loss: 1.45533, train_accuracy: 49.41\n",
      "[20,    82] loss: 1.40768, train_accuracy: 49.80\n",
      "[20,    83] loss: 1.39377, train_accuracy: 52.54\n",
      "[20,    84] loss: 1.38782, train_accuracy: 50.59\n",
      "[20,    85] loss: 1.34321, train_accuracy: 51.56\n",
      "[20,    86] loss: 1.41726, train_accuracy: 49.61\n",
      "[20,    87] loss: 1.40369, train_accuracy: 49.61\n",
      "[20,    88] loss: 1.39996, train_accuracy: 50.00\n",
      "[20,    89] loss: 1.37294, train_accuracy: 52.15\n",
      "[20,    90] loss: 1.40861, train_accuracy: 50.39\n",
      "[20,    91] loss: 1.33956, train_accuracy: 53.52\n",
      "[20,    92] loss: 1.40194, train_accuracy: 53.71\n",
      "[20,    93] loss: 1.40128, train_accuracy: 52.15\n",
      "[20,    94] loss: 1.38526, train_accuracy: 52.93\n",
      "[20,    95] loss: 1.32420, train_accuracy: 53.52\n",
      "[20,    96] loss: 1.36916, train_accuracy: 52.54\n",
      "[20,    97] loss: 1.39499, train_accuracy: 48.63\n",
      "[20,    98] loss: 1.35669, train_accuracy: 51.19\n",
      "duration: 220 s - train loss: 1.38684 - train accuracy: 50.41 - validation loss: 1.09594 - validation accuracy: 61.53 \n",
      "[21,     1] loss: 1.39183, train_accuracy: 50.00\n",
      "[21,     2] loss: 1.48501, train_accuracy: 47.46\n",
      "[21,     3] loss: 1.29659, train_accuracy: 54.69\n",
      "[21,     4] loss: 1.34729, train_accuracy: 53.12\n",
      "[21,     5] loss: 1.33174, train_accuracy: 51.56\n",
      "[21,     6] loss: 1.41136, train_accuracy: 49.41\n",
      "[21,     7] loss: 1.30943, train_accuracy: 53.52\n",
      "[21,     8] loss: 1.33483, train_accuracy: 49.80\n",
      "[21,     9] loss: 1.43278, train_accuracy: 47.85\n",
      "[21,    10] loss: 1.25892, train_accuracy: 56.64\n",
      "[21,    11] loss: 1.42394, train_accuracy: 50.39\n",
      "[21,    12] loss: 1.39661, train_accuracy: 49.41\n",
      "[21,    13] loss: 1.37097, train_accuracy: 51.37\n",
      "[21,    14] loss: 1.38480, train_accuracy: 46.09\n",
      "[21,    15] loss: 1.41389, train_accuracy: 49.80\n",
      "[21,    16] loss: 1.45871, train_accuracy: 48.05\n",
      "[21,    17] loss: 1.38630, train_accuracy: 49.22\n",
      "[21,    18] loss: 1.45041, train_accuracy: 49.02\n",
      "[21,    19] loss: 1.31769, train_accuracy: 53.32\n",
      "[21,    20] loss: 1.43440, train_accuracy: 50.78\n",
      "[21,    21] loss: 1.38577, train_accuracy: 51.37\n",
      "[21,    22] loss: 1.37314, train_accuracy: 47.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21,    23] loss: 1.43796, train_accuracy: 48.83\n",
      "[21,    24] loss: 1.42799, train_accuracy: 50.00\n",
      "[21,    25] loss: 1.35709, train_accuracy: 50.78\n",
      "[21,    26] loss: 1.37438, train_accuracy: 51.56\n",
      "[21,    27] loss: 1.31944, train_accuracy: 55.47\n",
      "[21,    28] loss: 1.37542, train_accuracy: 52.54\n",
      "[21,    29] loss: 1.38820, train_accuracy: 49.22\n",
      "[21,    30] loss: 1.30404, train_accuracy: 54.10\n",
      "[21,    31] loss: 1.30364, train_accuracy: 55.47\n",
      "[21,    32] loss: 1.45445, train_accuracy: 49.22\n",
      "[21,    33] loss: 1.38508, train_accuracy: 47.46\n",
      "[21,    34] loss: 1.36044, train_accuracy: 52.34\n",
      "[21,    35] loss: 1.44392, train_accuracy: 47.27\n",
      "[21,    36] loss: 1.41624, train_accuracy: 48.05\n",
      "[21,    37] loss: 1.40537, train_accuracy: 49.80\n",
      "[21,    38] loss: 1.27171, train_accuracy: 54.10\n",
      "[21,    39] loss: 1.40040, train_accuracy: 50.78\n",
      "[21,    40] loss: 1.35041, train_accuracy: 49.80\n",
      "[21,    41] loss: 1.38968, train_accuracy: 52.15\n",
      "[21,    42] loss: 1.41117, train_accuracy: 46.88\n",
      "[21,    43] loss: 1.37167, train_accuracy: 51.37\n",
      "[21,    44] loss: 1.40928, train_accuracy: 49.02\n",
      "[21,    45] loss: 1.37728, train_accuracy: 49.41\n",
      "[21,    46] loss: 1.30638, train_accuracy: 55.27\n",
      "[21,    47] loss: 1.37272, train_accuracy: 54.10\n",
      "[21,    48] loss: 1.42343, train_accuracy: 50.00\n",
      "[21,    49] loss: 1.33812, train_accuracy: 53.12\n",
      "[21,    50] loss: 1.31216, train_accuracy: 52.15\n",
      "[21,    51] loss: 1.35568, train_accuracy: 53.32\n",
      "[21,    52] loss: 1.39639, train_accuracy: 50.59\n",
      "[21,    53] loss: 1.39876, train_accuracy: 51.95\n",
      "[21,    54] loss: 1.36125, train_accuracy: 53.52\n",
      "[21,    55] loss: 1.40620, train_accuracy: 49.41\n",
      "[21,    56] loss: 1.43050, train_accuracy: 49.02\n",
      "[21,    57] loss: 1.35340, train_accuracy: 53.12\n",
      "[21,    58] loss: 1.33637, train_accuracy: 51.76\n",
      "[21,    59] loss: 1.31474, train_accuracy: 52.54\n",
      "[21,    60] loss: 1.44523, train_accuracy: 49.22\n",
      "[21,    61] loss: 1.35959, train_accuracy: 50.98\n",
      "[21,    62] loss: 1.35189, train_accuracy: 52.54\n",
      "[21,    63] loss: 1.36054, train_accuracy: 52.34\n",
      "[21,    64] loss: 1.34368, train_accuracy: 54.49\n",
      "[21,    65] loss: 1.40747, train_accuracy: 50.00\n",
      "[21,    66] loss: 1.35915, train_accuracy: 51.37\n",
      "[21,    67] loss: 1.44143, train_accuracy: 47.07\n",
      "[21,    68] loss: 1.40279, train_accuracy: 49.80\n",
      "[21,    69] loss: 1.47169, train_accuracy: 46.09\n",
      "[21,    70] loss: 1.46221, train_accuracy: 47.85\n",
      "[21,    71] loss: 1.37828, train_accuracy: 47.85\n",
      "[21,    72] loss: 1.39511, train_accuracy: 49.80\n",
      "[21,    73] loss: 1.37931, train_accuracy: 51.56\n",
      "[21,    74] loss: 1.39669, train_accuracy: 52.15\n",
      "[21,    75] loss: 1.37009, train_accuracy: 50.00\n",
      "[21,    76] loss: 1.40791, train_accuracy: 50.98\n",
      "[21,    77] loss: 1.40867, train_accuracy: 49.61\n",
      "[21,    78] loss: 1.38535, train_accuracy: 49.41\n",
      "[21,    79] loss: 1.38483, train_accuracy: 47.85\n",
      "[21,    80] loss: 1.38892, train_accuracy: 50.98\n",
      "[21,    81] loss: 1.40565, train_accuracy: 51.56\n",
      "[21,    82] loss: 1.33190, train_accuracy: 53.12\n",
      "[21,    83] loss: 1.45169, train_accuracy: 50.39\n",
      "[21,    84] loss: 1.35555, train_accuracy: 50.59\n",
      "[21,    85] loss: 1.44505, train_accuracy: 47.27\n",
      "[21,    86] loss: 1.40118, train_accuracy: 47.46\n",
      "[21,    87] loss: 1.36670, train_accuracy: 50.00\n",
      "[21,    88] loss: 1.43742, train_accuracy: 47.27\n",
      "[21,    89] loss: 1.33806, train_accuracy: 52.93\n",
      "[21,    90] loss: 1.46448, train_accuracy: 48.44\n",
      "[21,    91] loss: 1.37545, train_accuracy: 50.59\n",
      "[21,    92] loss: 1.35602, train_accuracy: 50.98\n",
      "[21,    93] loss: 1.34373, train_accuracy: 50.78\n",
      "[21,    94] loss: 1.42973, train_accuracy: 50.78\n",
      "[21,    95] loss: 1.37695, train_accuracy: 49.22\n",
      "[21,    96] loss: 1.24974, train_accuracy: 55.66\n",
      "[21,    97] loss: 1.37035, train_accuracy: 51.76\n",
      "[21,    98] loss: 1.33899, train_accuracy: 51.49\n",
      "duration: 218 s - train loss: 1.38140 - train accuracy: 50.70 - validation loss: 1.08115 - validation accuracy: 62.15 \n",
      "[22,     1] loss: 1.28528, train_accuracy: 56.45\n",
      "[22,     2] loss: 1.44301, train_accuracy: 47.07\n",
      "[22,     3] loss: 1.43916, train_accuracy: 48.05\n",
      "[22,     4] loss: 1.36324, train_accuracy: 49.61\n",
      "[22,     5] loss: 1.39010, train_accuracy: 50.39\n",
      "[22,     6] loss: 1.36463, train_accuracy: 50.78\n",
      "[22,     7] loss: 1.40307, train_accuracy: 50.78\n",
      "[22,     8] loss: 1.37193, train_accuracy: 50.59\n",
      "[22,     9] loss: 1.40218, train_accuracy: 49.02\n",
      "[22,    10] loss: 1.33746, train_accuracy: 52.73\n",
      "[22,    11] loss: 1.36716, train_accuracy: 47.66\n",
      "[22,    12] loss: 1.43149, train_accuracy: 51.17\n",
      "[22,    13] loss: 1.31681, train_accuracy: 51.56\n",
      "[22,    14] loss: 1.45238, train_accuracy: 46.09\n",
      "[22,    15] loss: 1.34682, train_accuracy: 51.56\n",
      "[22,    16] loss: 1.41522, train_accuracy: 49.41\n",
      "[22,    17] loss: 1.41968, train_accuracy: 47.85\n",
      "[22,    18] loss: 1.35667, train_accuracy: 52.15\n",
      "[22,    19] loss: 1.41229, train_accuracy: 50.20\n",
      "[22,    20] loss: 1.42406, train_accuracy: 45.12\n",
      "[22,    21] loss: 1.39186, train_accuracy: 50.39\n",
      "[22,    22] loss: 1.38944, train_accuracy: 51.37\n",
      "[22,    23] loss: 1.36936, train_accuracy: 51.76\n",
      "[22,    24] loss: 1.40208, train_accuracy: 51.76\n",
      "[22,    25] loss: 1.33940, train_accuracy: 50.78\n",
      "[22,    26] loss: 1.29229, train_accuracy: 54.30\n",
      "[22,    27] loss: 1.34035, train_accuracy: 51.56\n",
      "[22,    28] loss: 1.34605, train_accuracy: 54.49\n",
      "[22,    29] loss: 1.25602, train_accuracy: 54.88\n",
      "[22,    30] loss: 1.42206, train_accuracy: 51.37\n",
      "[22,    31] loss: 1.39205, train_accuracy: 50.78\n",
      "[22,    32] loss: 1.37134, train_accuracy: 50.78\n",
      "[22,    33] loss: 1.36741, train_accuracy: 50.78\n",
      "[22,    34] loss: 1.32103, train_accuracy: 54.10\n",
      "[22,    35] loss: 1.31137, train_accuracy: 51.17\n",
      "[22,    36] loss: 1.36788, train_accuracy: 53.71\n",
      "[22,    37] loss: 1.32370, train_accuracy: 54.10\n",
      "[22,    38] loss: 1.42918, train_accuracy: 45.70\n",
      "[22,    39] loss: 1.39920, train_accuracy: 49.80\n"
     ]
    }
   ],
   "source": [
    "fit_fast_with_double_update(model, train_loader, test_loader, 30, device, number_of_replays=3, eps = 16/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_clean_accuracy(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_rob_accuracy(model, test_loader, device, epsilon=8/255, attack='PGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global global_noise_data\n",
    "global_noise_data = torch.zeros([512, 3, 32,32])\n",
    "def fit_free( model,train_loader, criterion, optimizer, epoch, eps=8/255):\n",
    "    global global_noise_data\n",
    "    mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "    mean = torch.tensor(mean).view(3,1,1).expand(3,32,32)\n",
    "    mean = torch.tensor(std).view(3,1,1).expand(3,32,32)\n",
    "    # Initialize the meters\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    for i, (inputs, target) in enumerate(train_loader):\n",
    "        running_loss, acc_epoch_loss, avg_epoch_loss, epoch_accuracy, acc_epoch_accuracy = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        inputs = inputs\n",
    "        target = target\n",
    "        for j in range(5):\n",
    "            # Ascend on the global noise\n",
    "            noise_batch = Variable(global_noise_data[0:inputs.size(0)], requires_grad=True)\n",
    "            in1 = inputs + noise_batch\n",
    "            in1.clamp_(0, 1.0)\n",
    "            in1.sub_(mean).div_(std)\n",
    "            output = model(in1)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # compute gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the noise for the next iteration\n",
    "            pert = fgsm(noise_batch.grad, .1)\n",
    "            global_noise_data[0:inputs.size(0)] += pert.data\n",
    "            global_noise_data.clamp_(eps, eps)\n",
    "\n",
    "            optimizer.step()\n",
    "            # measure elapsed time\n",
    "            accuracy = get_accuracy(target, output)\n",
    "            acc_epoch_loss += running_loss \n",
    "            avg_epoch_loss = acc_epoch_loss / (i+1)\n",
    "            acc_epoch_accuracy += accuracy\n",
    "            avg_epoch_accuracy = acc_epoch_accuracy / (i+1)\n",
    "            if i%2 == 0:\n",
    "                print('[%d, %5d] loss: %.5f, train_accuracy: %.2f' %(epoch + 1, i + 1, running_loss, accuracy))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "    \n",
    "    # Optimizer:\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "for epoch in range(10):\n",
    "    fit_free(model, train_loader,criterion, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
