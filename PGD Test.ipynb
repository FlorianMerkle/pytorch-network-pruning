{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import eagerpy as ep\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "from foolbox.attacks import PGD, FGSM\n",
    "\n",
    "\n",
    "from src.models  import CifarResNet, MNIST_CNN, CIFAR_CNN\n",
    "from src.helpers import evaluate_rob_accuracy, evaluate_clean_accuracy, load_model, safe_model,_evaluate_model\n",
    "from src.data_loader import load_torchvision_dataset, load_imagenette\n",
    "#from src.pruning import identify_layers, _evaluate_sparsity\n",
    "\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "identifying layers\n",
      "identifying layers\n"
     ]
    }
   ],
   "source": [
    "#rob_model = CifarResNet()\n",
    "#rob_model.to(device)\n",
    "train_loader, test_loader, attack_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True)\n",
    "#train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True)\n",
    "PATH='./saved-models/fast-double-vs-standard-experiment-standard-fast-training.pt'\n",
    "rob_model = CifarResNet().to(device)\n",
    "rob_model = load_model(rob_model, PATH)\n",
    "PATH='./saved-models/cifar-resnet-100e-data_aug'\n",
    "clean_model = CifarResNet().to(device)\n",
    "clean_model = load_model(clean_model, PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88.82, 0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_clean_accuracy(clean_model,test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87.93, 0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_clean_accuracy(rob_model,test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7321"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, rob = FGSM(clean_model, test_loader, torch.nn.CrossEntropyLoss(), 2/255, device)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5744"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, rob = FGSM(clean_model, test_loader, torch.nn.CrossEntropyLoss(), 4/255, device)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3444"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, rob = FGSM(clean_model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, rob = PGD(clean_model, test_loader, torch.nn.CrossEntropyLoss(), 7, .5/255, 2/255, device)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1185"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, rob = PGD(clean_model, test_loader, torch.nn.CrossEntropyLoss(), 7, 1/255, 4/255, device)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1181"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, rob = PGD(clean_model, test_loader, torch.nn.CrossEntropyLoss(), 7, 2/255, 8/255, device)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7212"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, rob = FGSM(rob_model, test_loader, torch.nn.CrossEntropyLoss(), 2/255, device)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5447"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, rob = FGSM(rob_model, test_loader, torch.nn.CrossEntropyLoss(), 4/255, device)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.299"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, rob = FGSM(rob_model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, rob = PGD(rob_model, test_loader, torch.nn.CrossEntropyLoss(), 7, .5/255, 2/255, device)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, rob = PGD(rob_model, test_loader, torch.nn.CrossEntropyLoss(), 7, 1/255, 4/255, device)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1006"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, rob = PGD(rob_model, test_loader, torch.nn.CrossEntropyLoss(), 7, 2/255, 8/255, device)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD(model, data_loader, criterion, steps, max_stepsize, eps, device):\n",
    "    model.eval()\n",
    "    advs = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(data_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels =inputs.to(device), labels.to(device)\n",
    "        adv_examples = inputs\n",
    "        #adv_inputs = inputs\n",
    "        #adv_inputs.requires_grad = True\n",
    "        #perturbation = torch.zeros_like(adv_inputs, requires_grad=True).to(device)\n",
    "        for step in range(steps):\n",
    "            adv_examples, pert = FGSM_step(model, inputs, labels, criterion, max_stepsize, device)\n",
    "            adv_examples.clamp_(-eps, eps)\n",
    "            #preds = model(adv_inputs)\n",
    "            #loss = criterion(preds, labels)\n",
    "            #loss.backward()\n",
    "            #perturbation = torch.sign(adv_inputs.grad).clamp_(-max_stepsize, max_stepsize)\n",
    "            #adv_inputs = inputs + perturbation\n",
    "        \n",
    "        advs.append(adv_examples)\n",
    "        preds = model(adv_examples)\n",
    "        #pred_labels = \n",
    "        _, predicted = torch.max(preds.data, 1)\n",
    "        total += len(predicted)\n",
    "        #correct += (pred_labels == labels).sum().item()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    return advs, correct/total\n",
    "        \n",
    "\n",
    "def FGSM_step(model, inputs, labels, criterion, eps, device):\n",
    "\n",
    "    inputs.requires_grad = True\n",
    "    perturbation = torch.zeros_like(inputs, requires_grad=True).to(device)\n",
    "    preds = model(inputs)\n",
    "    loss = criterion(preds, labels)\n",
    "    loss.backward()\n",
    "    perturbation = torch.sign(inputs.grad).clamp_(-eps, eps)\n",
    "    adv_examples = inputs + perturbation\n",
    "    return adv_examples, perturbation\n",
    "    \n",
    "\n",
    "def FGSM(model, data_loader, criterion, eps, device):\n",
    "    model.eval()\n",
    "    #mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "    #mean = torch.tensor(mean).view(3,1,1).expand(3,32,32).to(device)\n",
    "    #std = torch.tensor(std).view(3,1,1).expand(3,32,32).to(device)\n",
    "    advs = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in data_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels =inputs.to(device), labels.to(device)\n",
    "        adv_examples, perturbation = FGSM_step(model, inputs, labels, criterion, eps, device)\n",
    "        advs.append(adv_examples)\n",
    "        preds = model(adv_examples)\n",
    "        #pred_labels = \n",
    "        _, predicted = torch.max(preds.data, 1)\n",
    "        total += len(predicted)\n",
    "        #correct += (pred_labels == labels).sum().item()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    \n",
    "    return advs, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in attack_loader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    print(accuracy(fmodel, images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#model = models.resnet18(pretrained=True).eval()\n",
    "model = model.eval()\n",
    "preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "fmodel = PyTorchModel(model, bounds=(0, 1), preprocessing=preprocessing)\n",
    "#fmodel = PyTorchModel(model, bounds=(0, 1))\n",
    "\n",
    "    # get data and test the model\n",
    "    # wrapping the tensors with ep.astensors is optional, but it allows\n",
    "    # us to work with EagerPy tensors in the following\n",
    "#images, labels = next(iter(attack_loader))[0].to(device), next(iter(attack_loader))[1].to(device)\n",
    "clean_acc = accuracy(fmodel, images, labels)\n",
    "print(f\"clean accuracy:  {clean_acc * 100:.1f} %\")\n",
    "\n",
    "    # apply the attack\n",
    "attack = FGSM()\n",
    "epsilon = 0.06\n",
    "raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=epsilon)\n",
    "\n",
    "    # calculate and report the robust accuracy (the accuracy of the model when\n",
    "    # it is attacked)\n",
    "robust_accuracy = 1 - success.float32().mean(axis=-1)\n",
    "print(\"robust accuracy for perturbations with\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_accuracy = 1 - success.float32().mean(axis=-1)\n",
    "robust_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "for i, img in enumerate(clipped_advs):\n",
    "    diffs.append(img - images[i])\n",
    "len(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = (ep.astensor(images))\n",
    "raw_advs = ep.astensor(raw_advs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(images.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_torchvision_dataset(dataset, batchsize=512, data_augmentation=False):\n",
    "    if data_augmentation == True:\n",
    "        train_transforms = torchvision.transforms.Compose([\n",
    "            #torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.RandomRotation(20),\n",
    "            torchvision.transforms.Resize(40),\n",
    "            torchvision.transforms.RandomResizedCrop(32),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),        \n",
    "        ])\n",
    "    if data_augmentation == False:\n",
    "        train_transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),        \n",
    "        ])\n",
    "    val_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    if dataset == 'MNIST':\n",
    "        train = torchvision.datasets.MNIST('./data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "        test = torchvision.datasets.MNIST('./data', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "        attack = torchvision.datasets.MNIST('./data', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    if dataset == 'CIFAR10':\n",
    "        train = torchvision.datasets.CIFAR10('./data', train=True, transform=train_transforms, download=True)\n",
    "        test = torchvision.datasets.CIFAR10('./data', train=False, transform=val_transforms, download=True)\n",
    "        attack = torchvision.datasets.CIFAR10('./data', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train,\n",
    "        batch_size=batchsize,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test,\n",
    "        batch_size=batchsize,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    attack_loader = torch.utils.data.DataLoader(\n",
    "        attack,\n",
    "        batch_size=batchsize,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    return train_loader, test_loader, attack_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
