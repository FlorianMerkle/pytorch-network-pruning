{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.models import CifarResNet, MNIST_CNN, CIFAR_CNN\n",
    "from src.helpers import evaluate_rob_accuracy, evaluate_clean_accuracy, load_model, safe_model,_evaluate_model\n",
    "from src.data_loader import load_torchvision_dataset, load_imagenette\n",
    "import subprocess\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_memory_map():   \n",
    "    result = subprocess.check_output(\n",
    "        [\n",
    "            'nvidia-smi', '--query-gpu=memory.used',\n",
    "            '--format=csv,nounits,noheader'\n",
    "        ])\n",
    "    \n",
    "    return float(result)\n",
    "def safe_model(PATH, model, description='N/A', loss='N/A',epoch='N/A'):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        }, PATH)\n",
    "    return PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre Start GPU MEMORY: 3.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "identifying layers\n",
      "0 GPU MEMORY: 1050.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 6.12669, adv_train_accuracy: 0.00, clean_train_accuracy : 9.38\n",
      "[1,     6] loss: 24.18364, adv_train_accuracy: 7.81, clean_train_accuracy : 14.06\n",
      "[1,    11] loss: 12.61356, adv_train_accuracy: 10.16, clean_train_accuracy : 13.28\n",
      "[1,    16] loss: 5.76244, adv_train_accuracy: 15.62, clean_train_accuracy : 11.72\n",
      "[1,    21] loss: 6.37782, adv_train_accuracy: 6.25, clean_train_accuracy : 13.28\n",
      "[1,    26] loss: 4.62666, adv_train_accuracy: 10.94, clean_train_accuracy : 14.06\n",
      "[1,    31] loss: 3.04595, adv_train_accuracy: 8.59, clean_train_accuracy : 13.28\n",
      "[1,    36] loss: 4.25551, adv_train_accuracy: 11.72, clean_train_accuracy : 17.97\n",
      "[1,    41] loss: 3.45835, adv_train_accuracy: 12.50, clean_train_accuracy : 19.53\n",
      "[1,    46] loss: 2.89442, adv_train_accuracy: 10.94, clean_train_accuracy : 22.66\n",
      "[1,    51] loss: 2.48976, adv_train_accuracy: 13.28, clean_train_accuracy : 25.00\n",
      "[1,    56] loss: 2.93063, adv_train_accuracy: 13.28, clean_train_accuracy : 25.00\n",
      "[1,    61] loss: 2.62388, adv_train_accuracy: 9.38, clean_train_accuracy : 24.22\n",
      "[1,    66] loss: 2.30407, adv_train_accuracy: 12.50, clean_train_accuracy : 26.56\n",
      "[1,    71] loss: 2.30032, adv_train_accuracy: 25.00, clean_train_accuracy : 29.69\n",
      "[1,    76] loss: 2.32351, adv_train_accuracy: 9.38, clean_train_accuracy : 17.19\n",
      "[1,    81] loss: 2.23711, adv_train_accuracy: 14.84, clean_train_accuracy : 23.44\n",
      "[1,    86] loss: 2.35136, adv_train_accuracy: 14.84, clean_train_accuracy : 20.31\n",
      "[1,    91] loss: 2.51882, adv_train_accuracy: 14.06, clean_train_accuracy : 25.00\n",
      "[1,    96] loss: 2.44151, adv_train_accuracy: 18.75, clean_train_accuracy : 28.12\n",
      "[1,   101] loss: 2.33561, adv_train_accuracy: 10.94, clean_train_accuracy : 28.91\n",
      "[1,   106] loss: 2.43993, adv_train_accuracy: 20.31, clean_train_accuracy : 25.78\n",
      "[1,   111] loss: 2.24894, adv_train_accuracy: 21.09, clean_train_accuracy : 28.12\n",
      "[1,   116] loss: 2.27736, adv_train_accuracy: 11.72, clean_train_accuracy : 23.44\n",
      "[1,   121] loss: 2.40206, adv_train_accuracy: 14.06, clean_train_accuracy : 17.19\n",
      "[1,   126] loss: 2.19166, adv_train_accuracy: 21.88, clean_train_accuracy : 30.47\n",
      "[1,   131] loss: 2.24113, adv_train_accuracy: 19.53, clean_train_accuracy : 30.47\n",
      "[1,   136] loss: 2.20213, adv_train_accuracy: 17.97, clean_train_accuracy : 28.12\n",
      "[1,   141] loss: 2.08979, adv_train_accuracy: 25.00, clean_train_accuracy : 32.03\n",
      "[1,   146] loss: 2.13433, adv_train_accuracy: 21.09, clean_train_accuracy : 31.25\n",
      "[1,   151] loss: 2.24067, adv_train_accuracy: 17.19, clean_train_accuracy : 28.91\n",
      "[1,   156] loss: 2.10383, adv_train_accuracy: 22.66, clean_train_accuracy : 40.62\n",
      "[1,   161] loss: 2.04957, adv_train_accuracy: 17.19, clean_train_accuracy : 31.25\n",
      "[1,   166] loss: 2.08524, adv_train_accuracy: 20.31, clean_train_accuracy : 31.25\n",
      "[1,   171] loss: 2.14081, adv_train_accuracy: 25.00, clean_train_accuracy : 34.38\n",
      "[1,   176] loss: 2.27019, adv_train_accuracy: 16.41, clean_train_accuracy : 21.88\n",
      "[1,   181] loss: 2.25686, adv_train_accuracy: 17.97, clean_train_accuracy : 26.56\n",
      "[1,   186] loss: 2.01920, adv_train_accuracy: 29.69, clean_train_accuracy : 40.62\n",
      "[1,   191] loss: 2.08882, adv_train_accuracy: 23.44, clean_train_accuracy : 34.38\n",
      "[1,   196] loss: 2.20869, adv_train_accuracy: 20.31, clean_train_accuracy : 28.91\n",
      "[1,   201] loss: 1.98628, adv_train_accuracy: 24.22, clean_train_accuracy : 35.16\n",
      "[1,   206] loss: 2.07007, adv_train_accuracy: 14.84, clean_train_accuracy : 34.38\n",
      "[1,   211] loss: 2.11209, adv_train_accuracy: 24.22, clean_train_accuracy : 36.72\n",
      "[1,   216] loss: 2.12474, adv_train_accuracy: 17.97, clean_train_accuracy : 31.25\n",
      "[1,   221] loss: 2.08761, adv_train_accuracy: 31.25, clean_train_accuracy : 35.16\n",
      "[1,   226] loss: 2.01585, adv_train_accuracy: 25.78, clean_train_accuracy : 35.16\n",
      "[1,   231] loss: 2.02079, adv_train_accuracy: 27.34, clean_train_accuracy : 40.62\n",
      "[1,   236] loss: 2.17969, adv_train_accuracy: 19.53, clean_train_accuracy : 25.78\n",
      "[1,   241] loss: 2.00594, adv_train_accuracy: 27.34, clean_train_accuracy : 36.72\n",
      "[1,   246] loss: 2.04691, adv_train_accuracy: 22.66, clean_train_accuracy : 37.50\n",
      "[1,   251] loss: 2.12348, adv_train_accuracy: 21.88, clean_train_accuracy : 32.03\n",
      "[1,   256] loss: 2.03476, adv_train_accuracy: 28.91, clean_train_accuracy : 44.53\n",
      "[1,   261] loss: 2.14497, adv_train_accuracy: 25.00, clean_train_accuracy : 35.94\n",
      "[1,   266] loss: 2.05727, adv_train_accuracy: 22.66, clean_train_accuracy : 37.50\n",
      "[1,   271] loss: 2.19144, adv_train_accuracy: 20.31, clean_train_accuracy : 30.47\n",
      "[1,   276] loss: 2.09619, adv_train_accuracy: 17.19, clean_train_accuracy : 34.38\n",
      "[1,   281] loss: 2.00884, adv_train_accuracy: 21.88, clean_train_accuracy : 38.28\n",
      "[1,   286] loss: 2.02139, adv_train_accuracy: 22.66, clean_train_accuracy : 31.25\n",
      "[1,   291] loss: 1.90312, adv_train_accuracy: 23.44, clean_train_accuracy : 34.38\n",
      "[1,   296] loss: 2.17363, adv_train_accuracy: 24.22, clean_train_accuracy : 35.16\n",
      "[1,   301] loss: 2.05755, adv_train_accuracy: 21.88, clean_train_accuracy : 40.62\n",
      "[1,   306] loss: 2.19580, adv_train_accuracy: 21.88, clean_train_accuracy : 31.25\n",
      "[1,   311] loss: 1.94242, adv_train_accuracy: 23.44, clean_train_accuracy : 46.09\n",
      "[1,   316] loss: 2.00456, adv_train_accuracy: 21.09, clean_train_accuracy : 33.59\n",
      "[1,   321] loss: 2.24487, adv_train_accuracy: 21.09, clean_train_accuracy : 39.84\n",
      "[1,   326] loss: 1.97135, adv_train_accuracy: 26.56, clean_train_accuracy : 39.06\n",
      "[1,   331] loss: 2.07977, adv_train_accuracy: 27.34, clean_train_accuracy : 38.28\n",
      "[1,   336] loss: 2.09957, adv_train_accuracy: 21.88, clean_train_accuracy : 38.28\n",
      "[1,   341] loss: 2.11713, adv_train_accuracy: 25.00, clean_train_accuracy : 39.06\n",
      "[1,   346] loss: 1.92124, adv_train_accuracy: 25.78, clean_train_accuracy : 35.16\n",
      "[1,   351] loss: 2.10732, adv_train_accuracy: 21.09, clean_train_accuracy : 32.03\n",
      "[1,   356] loss: 1.99892, adv_train_accuracy: 27.34, clean_train_accuracy : 41.41\n",
      "[1,   361] loss: 2.12392, adv_train_accuracy: 29.69, clean_train_accuracy : 42.97\n",
      "[1,   366] loss: 2.02087, adv_train_accuracy: 24.22, clean_train_accuracy : 49.22\n",
      "[1,   371] loss: 1.93958, adv_train_accuracy: 27.34, clean_train_accuracy : 42.19\n",
      "[1,   376] loss: 2.06198, adv_train_accuracy: 25.78, clean_train_accuracy : 38.28\n",
      "[1,   381] loss: 2.09466, adv_train_accuracy: 21.09, clean_train_accuracy : 39.84\n",
      "[1,   386] loss: 2.04777, adv_train_accuracy: 25.78, clean_train_accuracy : 38.28\n",
      "[1,   391] loss: 2.14792, adv_train_accuracy: 22.50, clean_train_accuracy : 50.00\n",
      "fgsm robustness: 0.2353515625\n",
      "pgd robustness: 0.240234375\n",
      "duration: 159 s - train loss: 3.07113 - train accuracy: 19.83 - validation loss: 1.75441 - validation accuracy: 34.55 \n",
      "Finished Training\n",
      "1 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.99038, adv_train_accuracy: 25.78, clean_train_accuracy : 32.03\n",
      "[1,     6] loss: 2.18600, adv_train_accuracy: 19.53, clean_train_accuracy : 29.69\n",
      "[1,    11] loss: 2.00834, adv_train_accuracy: 28.91, clean_train_accuracy : 40.62\n",
      "[1,    16] loss: 1.89043, adv_train_accuracy: 29.69, clean_train_accuracy : 38.28\n",
      "[1,    21] loss: 2.05903, adv_train_accuracy: 23.44, clean_train_accuracy : 34.38\n",
      "[1,    26] loss: 1.98914, adv_train_accuracy: 25.78, clean_train_accuracy : 40.62\n",
      "[1,    31] loss: 1.91627, adv_train_accuracy: 28.91, clean_train_accuracy : 38.28\n",
      "[1,    36] loss: 1.99384, adv_train_accuracy: 27.34, clean_train_accuracy : 43.75\n",
      "[1,    41] loss: 1.93982, adv_train_accuracy: 19.53, clean_train_accuracy : 42.19\n",
      "[1,    46] loss: 2.00319, adv_train_accuracy: 23.44, clean_train_accuracy : 35.94\n",
      "[1,    51] loss: 2.21105, adv_train_accuracy: 16.41, clean_train_accuracy : 32.81\n",
      "[1,    56] loss: 1.95096, adv_train_accuracy: 28.12, clean_train_accuracy : 41.41\n",
      "[1,    61] loss: 2.01412, adv_train_accuracy: 21.09, clean_train_accuracy : 40.62\n",
      "[1,    66] loss: 1.96266, adv_train_accuracy: 30.47, clean_train_accuracy : 42.97\n",
      "[1,    71] loss: 1.99182, adv_train_accuracy: 25.00, clean_train_accuracy : 34.38\n",
      "[1,    76] loss: 2.00137, adv_train_accuracy: 26.56, clean_train_accuracy : 43.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    81] loss: 1.97759, adv_train_accuracy: 21.88, clean_train_accuracy : 48.44\n",
      "[1,    86] loss: 2.00056, adv_train_accuracy: 22.66, clean_train_accuracy : 38.28\n",
      "[1,    91] loss: 2.03890, adv_train_accuracy: 24.22, clean_train_accuracy : 34.38\n",
      "[1,    96] loss: 2.08880, adv_train_accuracy: 24.22, clean_train_accuracy : 40.62\n",
      "[1,   101] loss: 1.93549, adv_train_accuracy: 29.69, clean_train_accuracy : 40.62\n",
      "[1,   106] loss: 1.98643, adv_train_accuracy: 32.81, clean_train_accuracy : 44.53\n",
      "[1,   111] loss: 1.95832, adv_train_accuracy: 28.91, clean_train_accuracy : 37.50\n",
      "[1,   116] loss: 1.99452, adv_train_accuracy: 27.34, clean_train_accuracy : 36.72\n",
      "[1,   121] loss: 1.98348, adv_train_accuracy: 28.12, clean_train_accuracy : 39.84\n",
      "[1,   126] loss: 1.90714, adv_train_accuracy: 26.56, clean_train_accuracy : 42.19\n",
      "[1,   131] loss: 1.95784, adv_train_accuracy: 29.69, clean_train_accuracy : 42.19\n",
      "[1,   136] loss: 1.97752, adv_train_accuracy: 25.78, clean_train_accuracy : 43.75\n",
      "[1,   141] loss: 1.96291, adv_train_accuracy: 30.47, clean_train_accuracy : 41.41\n",
      "[1,   146] loss: 1.91718, adv_train_accuracy: 29.69, clean_train_accuracy : 41.41\n",
      "[1,   151] loss: 1.96553, adv_train_accuracy: 23.44, clean_train_accuracy : 33.59\n",
      "[1,   156] loss: 1.84425, adv_train_accuracy: 32.81, clean_train_accuracy : 48.44\n",
      "[1,   161] loss: 1.90704, adv_train_accuracy: 25.78, clean_train_accuracy : 42.97\n",
      "[1,   166] loss: 1.99975, adv_train_accuracy: 26.56, clean_train_accuracy : 37.50\n",
      "[1,   171] loss: 1.85241, adv_train_accuracy: 28.12, clean_train_accuracy : 44.53\n",
      "[1,   176] loss: 1.91986, adv_train_accuracy: 31.25, clean_train_accuracy : 40.62\n",
      "[1,   181] loss: 1.91089, adv_train_accuracy: 27.34, clean_train_accuracy : 40.62\n",
      "[1,   186] loss: 1.96705, adv_train_accuracy: 29.69, clean_train_accuracy : 43.75\n",
      "[1,   191] loss: 1.95347, adv_train_accuracy: 22.66, clean_train_accuracy : 32.03\n",
      "[1,   196] loss: 1.98357, adv_train_accuracy: 25.78, clean_train_accuracy : 37.50\n",
      "[1,   201] loss: 1.82180, adv_train_accuracy: 31.25, clean_train_accuracy : 46.88\n",
      "[1,   206] loss: 1.87548, adv_train_accuracy: 29.69, clean_train_accuracy : 42.19\n",
      "[1,   211] loss: 1.75338, adv_train_accuracy: 32.03, clean_train_accuracy : 50.78\n",
      "[1,   216] loss: 1.99221, adv_train_accuracy: 26.56, clean_train_accuracy : 39.84\n",
      "[1,   221] loss: 1.81079, adv_train_accuracy: 27.34, clean_train_accuracy : 49.22\n",
      "[1,   226] loss: 1.84107, adv_train_accuracy: 32.03, clean_train_accuracy : 53.12\n",
      "[1,   231] loss: 1.87756, adv_train_accuracy: 25.78, clean_train_accuracy : 42.19\n",
      "[1,   236] loss: 1.89166, adv_train_accuracy: 35.94, clean_train_accuracy : 49.22\n",
      "[1,   241] loss: 1.73249, adv_train_accuracy: 32.03, clean_train_accuracy : 53.12\n",
      "[1,   246] loss: 1.94323, adv_train_accuracy: 23.44, clean_train_accuracy : 42.97\n",
      "[1,   251] loss: 1.99849, adv_train_accuracy: 21.09, clean_train_accuracy : 42.97\n",
      "[1,   256] loss: 1.83817, adv_train_accuracy: 32.03, clean_train_accuracy : 46.09\n",
      "[1,   261] loss: 1.95371, adv_train_accuracy: 28.12, clean_train_accuracy : 46.88\n",
      "[1,   266] loss: 1.85535, adv_train_accuracy: 27.34, clean_train_accuracy : 40.62\n",
      "[1,   271] loss: 1.82302, adv_train_accuracy: 28.91, clean_train_accuracy : 42.97\n",
      "[1,   276] loss: 1.93734, adv_train_accuracy: 32.03, clean_train_accuracy : 51.56\n",
      "[1,   281] loss: 1.78250, adv_train_accuracy: 32.03, clean_train_accuracy : 45.31\n",
      "[1,   286] loss: 1.84672, adv_train_accuracy: 34.38, clean_train_accuracy : 42.19\n",
      "[1,   291] loss: 1.81041, adv_train_accuracy: 32.81, clean_train_accuracy : 50.00\n",
      "[1,   296] loss: 1.91403, adv_train_accuracy: 34.38, clean_train_accuracy : 50.78\n",
      "[1,   301] loss: 1.86683, adv_train_accuracy: 32.81, clean_train_accuracy : 43.75\n",
      "[1,   306] loss: 2.01822, adv_train_accuracy: 24.22, clean_train_accuracy : 40.62\n",
      "[1,   311] loss: 1.80819, adv_train_accuracy: 32.03, clean_train_accuracy : 44.53\n",
      "[1,   316] loss: 1.89895, adv_train_accuracy: 28.91, clean_train_accuracy : 38.28\n",
      "[1,   321] loss: 1.82856, adv_train_accuracy: 27.34, clean_train_accuracy : 52.34\n",
      "[1,   326] loss: 1.96792, adv_train_accuracy: 25.00, clean_train_accuracy : 43.75\n",
      "[1,   331] loss: 1.71756, adv_train_accuracy: 37.50, clean_train_accuracy : 48.44\n",
      "[1,   336] loss: 1.79447, adv_train_accuracy: 35.16, clean_train_accuracy : 47.66\n",
      "[1,   341] loss: 1.88818, adv_train_accuracy: 28.12, clean_train_accuracy : 37.50\n",
      "[1,   346] loss: 1.87446, adv_train_accuracy: 31.25, clean_train_accuracy : 46.88\n",
      "[1,   351] loss: 1.85986, adv_train_accuracy: 25.78, clean_train_accuracy : 42.97\n",
      "[1,   356] loss: 1.81022, adv_train_accuracy: 32.03, clean_train_accuracy : 46.09\n",
      "[1,   361] loss: 1.74864, adv_train_accuracy: 36.72, clean_train_accuracy : 49.22\n",
      "[1,   366] loss: 1.81292, adv_train_accuracy: 32.03, clean_train_accuracy : 46.88\n",
      "[1,   371] loss: 1.87940, adv_train_accuracy: 27.34, clean_train_accuracy : 45.31\n",
      "[1,   376] loss: 1.71093, adv_train_accuracy: 36.72, clean_train_accuracy : 54.69\n",
      "[1,   381] loss: 1.82363, adv_train_accuracy: 34.38, clean_train_accuracy : 53.12\n",
      "[1,   386] loss: 1.77217, adv_train_accuracy: 32.03, clean_train_accuracy : 53.12\n",
      "[1,   391] loss: 1.92588, adv_train_accuracy: 21.25, clean_train_accuracy : 43.75\n",
      "fgsm robustness: 0.2822265625\n",
      "pgd robustness: 0.25390625\n",
      "duration: 159 s - train loss: 1.92325 - train accuracy: 28.13 - validation loss: 1.51446 - validation accuracy: 45.35 \n",
      "Finished Training\n",
      "2 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.83547, adv_train_accuracy: 24.22, clean_train_accuracy : 44.53\n",
      "[1,     6] loss: 1.83268, adv_train_accuracy: 33.59, clean_train_accuracy : 48.44\n",
      "[1,    11] loss: 1.91789, adv_train_accuracy: 28.91, clean_train_accuracy : 46.09\n",
      "[1,    16] loss: 1.79080, adv_train_accuracy: 31.25, clean_train_accuracy : 46.09\n",
      "[1,    21] loss: 1.83992, adv_train_accuracy: 32.81, clean_train_accuracy : 50.78\n",
      "[1,    26] loss: 1.76927, adv_train_accuracy: 28.12, clean_train_accuracy : 49.22\n",
      "[1,    31] loss: 1.83199, adv_train_accuracy: 31.25, clean_train_accuracy : 57.81\n",
      "[1,    36] loss: 1.83702, adv_train_accuracy: 28.91, clean_train_accuracy : 45.31\n",
      "[1,    41] loss: 1.82787, adv_train_accuracy: 25.00, clean_train_accuracy : 47.66\n",
      "[1,    46] loss: 2.15070, adv_train_accuracy: 25.00, clean_train_accuracy : 45.31\n",
      "[1,    51] loss: 1.88796, adv_train_accuracy: 27.34, clean_train_accuracy : 46.88\n",
      "[1,    56] loss: 1.94829, adv_train_accuracy: 25.78, clean_train_accuracy : 46.09\n",
      "[1,    61] loss: 1.94717, adv_train_accuracy: 28.12, clean_train_accuracy : 42.97\n",
      "[1,    66] loss: 1.86457, adv_train_accuracy: 31.25, clean_train_accuracy : 48.44\n",
      "[1,    71] loss: 1.88891, adv_train_accuracy: 32.81, clean_train_accuracy : 48.44\n",
      "[1,    76] loss: 1.96833, adv_train_accuracy: 30.47, clean_train_accuracy : 40.62\n",
      "[1,    81] loss: 1.87275, adv_train_accuracy: 27.34, clean_train_accuracy : 43.75\n",
      "[1,    86] loss: 2.09733, adv_train_accuracy: 25.78, clean_train_accuracy : 40.62\n",
      "[1,    91] loss: 1.74624, adv_train_accuracy: 31.25, clean_train_accuracy : 46.09\n",
      "[1,    96] loss: 1.79272, adv_train_accuracy: 30.47, clean_train_accuracy : 48.44\n",
      "[1,   101] loss: 1.78168, adv_train_accuracy: 30.47, clean_train_accuracy : 47.66\n",
      "[1,   106] loss: 1.83590, adv_train_accuracy: 26.56, clean_train_accuracy : 47.66\n",
      "[1,   111] loss: 1.78123, adv_train_accuracy: 30.47, clean_train_accuracy : 46.88\n",
      "[1,   116] loss: 1.69866, adv_train_accuracy: 40.62, clean_train_accuracy : 59.38\n",
      "[1,   121] loss: 1.88602, adv_train_accuracy: 28.91, clean_train_accuracy : 49.22\n",
      "[1,   126] loss: 1.86077, adv_train_accuracy: 30.47, clean_train_accuracy : 51.56\n",
      "[1,   131] loss: 1.71705, adv_train_accuracy: 39.84, clean_train_accuracy : 53.91\n",
      "[1,   136] loss: 1.74916, adv_train_accuracy: 33.59, clean_train_accuracy : 50.78\n",
      "[1,   141] loss: 1.78156, adv_train_accuracy: 35.94, clean_train_accuracy : 56.25\n",
      "[1,   146] loss: 1.83982, adv_train_accuracy: 28.91, clean_train_accuracy : 46.09\n",
      "[1,   151] loss: 1.76526, adv_train_accuracy: 32.81, clean_train_accuracy : 46.88\n",
      "[1,   156] loss: 1.75381, adv_train_accuracy: 30.47, clean_train_accuracy : 51.56\n",
      "[1,   161] loss: 1.79634, adv_train_accuracy: 33.59, clean_train_accuracy : 46.09\n",
      "[1,   166] loss: 1.85765, adv_train_accuracy: 27.34, clean_train_accuracy : 46.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   171] loss: 1.90488, adv_train_accuracy: 21.09, clean_train_accuracy : 43.75\n",
      "[1,   176] loss: 1.90629, adv_train_accuracy: 27.34, clean_train_accuracy : 46.88\n",
      "[1,   181] loss: 1.86717, adv_train_accuracy: 28.91, clean_train_accuracy : 42.97\n",
      "[1,   186] loss: 1.76452, adv_train_accuracy: 30.47, clean_train_accuracy : 51.56\n",
      "[1,   191] loss: 1.89558, adv_train_accuracy: 29.69, clean_train_accuracy : 42.97\n",
      "[1,   196] loss: 1.88108, adv_train_accuracy: 35.16, clean_train_accuracy : 44.53\n",
      "[1,   201] loss: 1.86033, adv_train_accuracy: 36.72, clean_train_accuracy : 53.91\n",
      "[1,   206] loss: 2.00661, adv_train_accuracy: 25.00, clean_train_accuracy : 40.62\n",
      "[1,   211] loss: 1.85713, adv_train_accuracy: 35.94, clean_train_accuracy : 53.12\n",
      "[1,   216] loss: 1.89250, adv_train_accuracy: 37.50, clean_train_accuracy : 50.78\n",
      "[1,   221] loss: 1.77835, adv_train_accuracy: 29.69, clean_train_accuracy : 48.44\n",
      "[1,   226] loss: 1.68458, adv_train_accuracy: 34.38, clean_train_accuracy : 53.12\n",
      "[1,   231] loss: 1.80786, adv_train_accuracy: 34.38, clean_train_accuracy : 60.16\n",
      "[1,   236] loss: 1.75039, adv_train_accuracy: 32.81, clean_train_accuracy : 54.69\n",
      "[1,   241] loss: 1.84306, adv_train_accuracy: 32.81, clean_train_accuracy : 52.34\n",
      "[1,   246] loss: 1.81589, adv_train_accuracy: 26.56, clean_train_accuracy : 46.88\n",
      "[1,   251] loss: 1.76546, adv_train_accuracy: 35.16, clean_train_accuracy : 50.78\n",
      "[1,   256] loss: 1.71398, adv_train_accuracy: 42.19, clean_train_accuracy : 55.47\n",
      "[1,   261] loss: 1.81399, adv_train_accuracy: 32.03, clean_train_accuracy : 51.56\n",
      "[1,   266] loss: 1.74695, adv_train_accuracy: 36.72, clean_train_accuracy : 58.59\n",
      "[1,   271] loss: 1.70871, adv_train_accuracy: 35.16, clean_train_accuracy : 58.59\n",
      "[1,   276] loss: 1.76241, adv_train_accuracy: 30.47, clean_train_accuracy : 46.88\n",
      "[1,   281] loss: 1.84670, adv_train_accuracy: 27.34, clean_train_accuracy : 53.91\n",
      "[1,   286] loss: 1.69123, adv_train_accuracy: 39.84, clean_train_accuracy : 57.03\n",
      "[1,   291] loss: 1.75003, adv_train_accuracy: 30.47, clean_train_accuracy : 50.78\n",
      "[1,   296] loss: 1.71028, adv_train_accuracy: 28.91, clean_train_accuracy : 50.00\n",
      "[1,   301] loss: 1.66007, adv_train_accuracy: 33.59, clean_train_accuracy : 52.34\n",
      "[1,   306] loss: 1.80813, adv_train_accuracy: 26.56, clean_train_accuracy : 44.53\n",
      "[1,   311] loss: 1.75212, adv_train_accuracy: 35.94, clean_train_accuracy : 55.47\n",
      "[1,   316] loss: 1.88628, adv_train_accuracy: 34.38, clean_train_accuracy : 50.78\n",
      "[1,   321] loss: 1.74877, adv_train_accuracy: 35.16, clean_train_accuracy : 53.91\n",
      "[1,   326] loss: 1.90137, adv_train_accuracy: 32.81, clean_train_accuracy : 47.66\n",
      "[1,   331] loss: 1.75317, adv_train_accuracy: 32.81, clean_train_accuracy : 60.94\n",
      "[1,   336] loss: 1.70289, adv_train_accuracy: 34.38, clean_train_accuracy : 53.12\n",
      "[1,   341] loss: 1.77097, adv_train_accuracy: 31.25, clean_train_accuracy : 53.91\n",
      "[1,   346] loss: 1.76095, adv_train_accuracy: 31.25, clean_train_accuracy : 44.53\n",
      "[1,   351] loss: 1.75075, adv_train_accuracy: 35.16, clean_train_accuracy : 51.56\n",
      "[1,   356] loss: 1.79792, adv_train_accuracy: 33.59, clean_train_accuracy : 50.78\n",
      "[1,   361] loss: 1.79431, adv_train_accuracy: 33.59, clean_train_accuracy : 52.34\n",
      "[1,   366] loss: 1.78427, adv_train_accuracy: 34.38, clean_train_accuracy : 49.22\n",
      "[1,   371] loss: 1.84570, adv_train_accuracy: 32.03, clean_train_accuracy : 50.78\n",
      "[1,   376] loss: 1.76168, adv_train_accuracy: 38.28, clean_train_accuracy : 57.81\n",
      "[1,   381] loss: 1.57967, adv_train_accuracy: 42.97, clean_train_accuracy : 59.38\n",
      "[1,   386] loss: 1.74234, adv_train_accuracy: 28.91, clean_train_accuracy : 54.69\n",
      "[1,   391] loss: 1.72513, adv_train_accuracy: 37.50, clean_train_accuracy : 56.25\n",
      "fgsm robustness: 0.2880859375\n",
      "pgd robustness: 0.27734375\n",
      "duration: 159 s - train loss: 1.82170 - train accuracy: 31.52 - validation loss: 1.41977 - validation accuracy: 51.18 \n",
      "Finished Training\n",
      "3 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.70138, adv_train_accuracy: 36.72, clean_train_accuracy : 50.78\n",
      "[1,     6] loss: 1.74905, adv_train_accuracy: 29.69, clean_train_accuracy : 60.94\n",
      "[1,    11] loss: 1.87211, adv_train_accuracy: 33.59, clean_train_accuracy : 51.56\n",
      "[1,    16] loss: 1.84563, adv_train_accuracy: 30.47, clean_train_accuracy : 42.19\n",
      "[1,    21] loss: 1.97400, adv_train_accuracy: 30.47, clean_train_accuracy : 53.12\n",
      "[1,    26] loss: 1.74562, adv_train_accuracy: 34.38, clean_train_accuracy : 49.22\n",
      "[1,    31] loss: 1.87099, adv_train_accuracy: 34.38, clean_train_accuracy : 49.22\n",
      "[1,    36] loss: 1.69799, adv_train_accuracy: 32.03, clean_train_accuracy : 50.00\n",
      "[1,    41] loss: 1.97069, adv_train_accuracy: 23.44, clean_train_accuracy : 46.09\n",
      "[1,    46] loss: 1.83481, adv_train_accuracy: 32.03, clean_train_accuracy : 53.91\n",
      "[1,    51] loss: 1.84767, adv_train_accuracy: 25.00, clean_train_accuracy : 47.66\n",
      "[1,    56] loss: 1.65750, adv_train_accuracy: 34.38, clean_train_accuracy : 57.03\n",
      "[1,    61] loss: 1.76728, adv_train_accuracy: 30.47, clean_train_accuracy : 55.47\n",
      "[1,    66] loss: 1.78667, adv_train_accuracy: 34.38, clean_train_accuracy : 53.12\n",
      "[1,    71] loss: 1.89540, adv_train_accuracy: 28.91, clean_train_accuracy : 45.31\n",
      "[1,    76] loss: 1.85593, adv_train_accuracy: 33.59, clean_train_accuracy : 50.78\n",
      "[1,    81] loss: 1.82054, adv_train_accuracy: 25.78, clean_train_accuracy : 44.53\n",
      "[1,    86] loss: 1.64905, adv_train_accuracy: 37.50, clean_train_accuracy : 58.59\n",
      "[1,    91] loss: 1.81387, adv_train_accuracy: 28.91, clean_train_accuracy : 50.78\n",
      "[1,    96] loss: 1.99471, adv_train_accuracy: 29.69, clean_train_accuracy : 50.78\n",
      "[1,   101] loss: 1.86368, adv_train_accuracy: 33.59, clean_train_accuracy : 50.78\n",
      "[1,   106] loss: 1.71098, adv_train_accuracy: 35.16, clean_train_accuracy : 50.78\n",
      "[1,   111] loss: 1.85565, adv_train_accuracy: 28.12, clean_train_accuracy : 46.09\n",
      "[1,   116] loss: 1.72263, adv_train_accuracy: 35.94, clean_train_accuracy : 60.94\n",
      "[1,   121] loss: 1.62097, adv_train_accuracy: 37.50, clean_train_accuracy : 57.03\n",
      "[1,   126] loss: 1.74491, adv_train_accuracy: 33.59, clean_train_accuracy : 54.69\n",
      "[1,   131] loss: 1.80021, adv_train_accuracy: 32.81, clean_train_accuracy : 51.56\n",
      "[1,   136] loss: 1.90883, adv_train_accuracy: 28.12, clean_train_accuracy : 56.25\n",
      "[1,   141] loss: 1.83388, adv_train_accuracy: 26.56, clean_train_accuracy : 50.78\n",
      "[1,   146] loss: 1.66486, adv_train_accuracy: 39.84, clean_train_accuracy : 57.81\n",
      "[1,   151] loss: 1.67416, adv_train_accuracy: 36.72, clean_train_accuracy : 53.91\n",
      "[1,   156] loss: 1.67043, adv_train_accuracy: 37.50, clean_train_accuracy : 60.16\n",
      "[1,   161] loss: 1.76864, adv_train_accuracy: 32.81, clean_train_accuracy : 52.34\n",
      "[1,   166] loss: 1.61609, adv_train_accuracy: 40.62, clean_train_accuracy : 59.38\n",
      "[1,   171] loss: 1.69146, adv_train_accuracy: 39.06, clean_train_accuracy : 60.16\n",
      "[1,   176] loss: 1.69247, adv_train_accuracy: 39.06, clean_train_accuracy : 53.91\n",
      "[1,   181] loss: 1.70031, adv_train_accuracy: 32.81, clean_train_accuracy : 56.25\n",
      "[1,   186] loss: 1.65737, adv_train_accuracy: 33.59, clean_train_accuracy : 50.00\n",
      "[1,   191] loss: 1.72144, adv_train_accuracy: 33.59, clean_train_accuracy : 53.91\n",
      "[1,   196] loss: 1.67995, adv_train_accuracy: 35.16, clean_train_accuracy : 54.69\n",
      "[1,   201] loss: 1.70596, adv_train_accuracy: 29.69, clean_train_accuracy : 53.12\n",
      "[1,   206] loss: 1.72105, adv_train_accuracy: 35.16, clean_train_accuracy : 56.25\n",
      "[1,   211] loss: 1.72927, adv_train_accuracy: 42.97, clean_train_accuracy : 56.25\n",
      "[1,   216] loss: 1.79175, adv_train_accuracy: 38.28, clean_train_accuracy : 56.25\n",
      "[1,   221] loss: 1.52990, adv_train_accuracy: 47.66, clean_train_accuracy : 60.94\n",
      "[1,   226] loss: 1.80718, adv_train_accuracy: 28.91, clean_train_accuracy : 54.69\n",
      "[1,   231] loss: 1.69456, adv_train_accuracy: 32.03, clean_train_accuracy : 60.16\n",
      "[1,   236] loss: 1.80298, adv_train_accuracy: 35.94, clean_train_accuracy : 54.69\n",
      "[1,   241] loss: 1.58713, adv_train_accuracy: 41.41, clean_train_accuracy : 63.28\n",
      "[1,   246] loss: 1.58826, adv_train_accuracy: 43.75, clean_train_accuracy : 60.16\n",
      "[1,   251] loss: 1.67345, adv_train_accuracy: 35.94, clean_train_accuracy : 57.03\n",
      "[1,   256] loss: 1.79519, adv_train_accuracy: 31.25, clean_train_accuracy : 56.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   261] loss: 1.66937, adv_train_accuracy: 39.06, clean_train_accuracy : 60.94\n",
      "[1,   266] loss: 1.57501, adv_train_accuracy: 40.62, clean_train_accuracy : 57.03\n",
      "[1,   271] loss: 1.74900, adv_train_accuracy: 38.28, clean_train_accuracy : 58.59\n",
      "[1,   276] loss: 1.69420, adv_train_accuracy: 39.06, clean_train_accuracy : 60.94\n",
      "[1,   281] loss: 1.87796, adv_train_accuracy: 29.69, clean_train_accuracy : 46.88\n",
      "[1,   286] loss: 1.69613, adv_train_accuracy: 35.94, clean_train_accuracy : 56.25\n",
      "[1,   291] loss: 1.62784, adv_train_accuracy: 39.06, clean_train_accuracy : 64.06\n",
      "[1,   296] loss: 1.45974, adv_train_accuracy: 46.88, clean_train_accuracy : 61.72\n",
      "[1,   301] loss: 1.89982, adv_train_accuracy: 24.22, clean_train_accuracy : 46.09\n",
      "[1,   306] loss: 1.74976, adv_train_accuracy: 33.59, clean_train_accuracy : 50.78\n",
      "[1,   311] loss: 1.76495, adv_train_accuracy: 29.69, clean_train_accuracy : 49.22\n",
      "[1,   316] loss: 1.68481, adv_train_accuracy: 35.94, clean_train_accuracy : 59.38\n",
      "[1,   321] loss: 1.70757, adv_train_accuracy: 31.25, clean_train_accuracy : 56.25\n",
      "[1,   326] loss: 1.59973, adv_train_accuracy: 39.06, clean_train_accuracy : 64.06\n",
      "[1,   331] loss: 1.68561, adv_train_accuracy: 35.94, clean_train_accuracy : 53.91\n",
      "[1,   336] loss: 1.73490, adv_train_accuracy: 38.28, clean_train_accuracy : 61.72\n",
      "[1,   341] loss: 1.66666, adv_train_accuracy: 41.41, clean_train_accuracy : 55.47\n",
      "[1,   346] loss: 1.79198, adv_train_accuracy: 34.38, clean_train_accuracy : 56.25\n",
      "[1,   351] loss: 1.57123, adv_train_accuracy: 41.41, clean_train_accuracy : 60.94\n",
      "[1,   356] loss: 1.63122, adv_train_accuracy: 37.50, clean_train_accuracy : 53.91\n",
      "[1,   361] loss: 1.72462, adv_train_accuracy: 29.69, clean_train_accuracy : 46.88\n",
      "[1,   366] loss: 1.58079, adv_train_accuracy: 39.84, clean_train_accuracy : 64.06\n",
      "[1,   371] loss: 1.71488, adv_train_accuracy: 39.06, clean_train_accuracy : 53.91\n",
      "[1,   376] loss: 1.59109, adv_train_accuracy: 40.62, clean_train_accuracy : 61.72\n",
      "[1,   381] loss: 1.72047, adv_train_accuracy: 31.25, clean_train_accuracy : 53.91\n",
      "[1,   386] loss: 1.69287, adv_train_accuracy: 37.50, clean_train_accuracy : 53.91\n",
      "[1,   391] loss: 1.74781, adv_train_accuracy: 41.25, clean_train_accuracy : 60.00\n",
      "fgsm robustness: 0.3115234375\n",
      "pgd robustness: 0.2607421875\n",
      "duration: 159 s - train loss: 1.74973 - train accuracy: 34.15 - validation loss: 1.34977 - validation accuracy: 54.62 \n",
      "Finished Training\n",
      "4 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.75053, adv_train_accuracy: 31.25, clean_train_accuracy : 50.00\n",
      "[1,     6] loss: 1.68107, adv_train_accuracy: 34.38, clean_train_accuracy : 57.81\n",
      "[1,    11] loss: 1.60164, adv_train_accuracy: 39.06, clean_train_accuracy : 65.62\n",
      "[1,    16] loss: 1.54208, adv_train_accuracy: 39.06, clean_train_accuracy : 65.62\n",
      "[1,    21] loss: 1.70260, adv_train_accuracy: 35.16, clean_train_accuracy : 55.47\n",
      "[1,    26] loss: 1.81723, adv_train_accuracy: 32.03, clean_train_accuracy : 53.12\n",
      "[1,    31] loss: 1.84871, adv_train_accuracy: 24.22, clean_train_accuracy : 50.00\n",
      "[1,    36] loss: 1.64999, adv_train_accuracy: 37.50, clean_train_accuracy : 55.47\n",
      "[1,    41] loss: 1.86219, adv_train_accuracy: 28.12, clean_train_accuracy : 55.47\n",
      "[1,    46] loss: 1.74672, adv_train_accuracy: 32.81, clean_train_accuracy : 53.12\n",
      "[1,    51] loss: 1.75285, adv_train_accuracy: 32.03, clean_train_accuracy : 56.25\n",
      "[1,    56] loss: 1.57305, adv_train_accuracy: 35.94, clean_train_accuracy : 57.03\n",
      "[1,    61] loss: 1.52911, adv_train_accuracy: 38.28, clean_train_accuracy : 62.50\n",
      "[1,    66] loss: 1.77382, adv_train_accuracy: 32.03, clean_train_accuracy : 47.66\n",
      "[1,    71] loss: 1.70439, adv_train_accuracy: 37.50, clean_train_accuracy : 56.25\n",
      "[1,    76] loss: 1.51684, adv_train_accuracy: 46.88, clean_train_accuracy : 64.06\n",
      "[1,    81] loss: 1.53156, adv_train_accuracy: 49.22, clean_train_accuracy : 65.62\n",
      "[1,    86] loss: 1.68280, adv_train_accuracy: 35.16, clean_train_accuracy : 60.16\n",
      "[1,    91] loss: 1.59791, adv_train_accuracy: 40.62, clean_train_accuracy : 60.16\n",
      "[1,    96] loss: 1.76314, adv_train_accuracy: 28.12, clean_train_accuracy : 55.47\n",
      "[1,   101] loss: 1.64959, adv_train_accuracy: 42.19, clean_train_accuracy : 66.41\n",
      "[1,   106] loss: 1.55217, adv_train_accuracy: 37.50, clean_train_accuracy : 62.50\n",
      "[1,   111] loss: 1.61338, adv_train_accuracy: 32.81, clean_train_accuracy : 59.38\n",
      "[1,   116] loss: 1.86029, adv_train_accuracy: 30.47, clean_train_accuracy : 56.25\n",
      "[1,   121] loss: 1.60522, adv_train_accuracy: 39.06, clean_train_accuracy : 60.16\n",
      "[1,   126] loss: 1.59923, adv_train_accuracy: 46.09, clean_train_accuracy : 59.38\n",
      "[1,   131] loss: 1.63275, adv_train_accuracy: 39.06, clean_train_accuracy : 53.91\n",
      "[1,   136] loss: 1.64542, adv_train_accuracy: 39.84, clean_train_accuracy : 53.91\n",
      "[1,   141] loss: 1.68855, adv_train_accuracy: 39.06, clean_train_accuracy : 60.16\n",
      "[1,   146] loss: 1.73080, adv_train_accuracy: 36.72, clean_train_accuracy : 61.72\n",
      "[1,   151] loss: 1.72160, adv_train_accuracy: 30.47, clean_train_accuracy : 51.56\n",
      "[1,   156] loss: 1.66325, adv_train_accuracy: 34.38, clean_train_accuracy : 55.47\n",
      "[1,   161] loss: 1.70914, adv_train_accuracy: 35.16, clean_train_accuracy : 53.12\n",
      "[1,   166] loss: 1.62745, adv_train_accuracy: 41.41, clean_train_accuracy : 64.84\n",
      "[1,   171] loss: 1.66350, adv_train_accuracy: 39.84, clean_train_accuracy : 63.28\n",
      "[1,   176] loss: 1.79994, adv_train_accuracy: 33.59, clean_train_accuracy : 59.38\n",
      "[1,   181] loss: 1.69251, adv_train_accuracy: 35.94, clean_train_accuracy : 53.91\n",
      "[1,   186] loss: 1.51195, adv_train_accuracy: 46.09, clean_train_accuracy : 66.41\n",
      "[1,   191] loss: 1.65129, adv_train_accuracy: 33.59, clean_train_accuracy : 57.03\n",
      "[1,   196] loss: 1.72160, adv_train_accuracy: 32.81, clean_train_accuracy : 55.47\n",
      "[1,   201] loss: 1.77479, adv_train_accuracy: 34.38, clean_train_accuracy : 53.12\n",
      "[1,   206] loss: 1.76730, adv_train_accuracy: 33.59, clean_train_accuracy : 49.22\n",
      "[1,   211] loss: 1.81023, adv_train_accuracy: 30.47, clean_train_accuracy : 59.38\n",
      "[1,   216] loss: 1.81422, adv_train_accuracy: 27.34, clean_train_accuracy : 54.69\n",
      "[1,   221] loss: 1.68686, adv_train_accuracy: 34.38, clean_train_accuracy : 57.03\n",
      "[1,   226] loss: 1.65880, adv_train_accuracy: 32.81, clean_train_accuracy : 57.81\n",
      "[1,   231] loss: 1.70905, adv_train_accuracy: 34.38, clean_train_accuracy : 56.25\n",
      "[1,   236] loss: 1.63837, adv_train_accuracy: 39.84, clean_train_accuracy : 58.59\n",
      "[1,   241] loss: 1.81896, adv_train_accuracy: 27.34, clean_train_accuracy : 53.12\n",
      "[1,   246] loss: 1.72818, adv_train_accuracy: 33.59, clean_train_accuracy : 57.81\n",
      "[1,   251] loss: 1.53403, adv_train_accuracy: 39.84, clean_train_accuracy : 66.41\n",
      "[1,   256] loss: 1.62613, adv_train_accuracy: 39.84, clean_train_accuracy : 59.38\n",
      "[1,   261] loss: 1.66348, adv_train_accuracy: 41.41, clean_train_accuracy : 64.06\n",
      "[1,   266] loss: 1.82468, adv_train_accuracy: 36.72, clean_train_accuracy : 54.69\n",
      "[1,   271] loss: 1.59915, adv_train_accuracy: 40.62, clean_train_accuracy : 63.28\n",
      "[1,   276] loss: 1.69726, adv_train_accuracy: 35.94, clean_train_accuracy : 58.59\n",
      "[1,   281] loss: 1.63247, adv_train_accuracy: 35.94, clean_train_accuracy : 57.81\n",
      "[1,   286] loss: 1.69077, adv_train_accuracy: 33.59, clean_train_accuracy : 59.38\n",
      "[1,   291] loss: 1.70927, adv_train_accuracy: 40.62, clean_train_accuracy : 60.16\n",
      "[1,   296] loss: 1.79557, adv_train_accuracy: 39.06, clean_train_accuracy : 56.25\n",
      "[1,   301] loss: 1.57731, adv_train_accuracy: 47.66, clean_train_accuracy : 61.72\n",
      "[1,   306] loss: 1.58354, adv_train_accuracy: 38.28, clean_train_accuracy : 63.28\n",
      "[1,   311] loss: 1.64746, adv_train_accuracy: 40.62, clean_train_accuracy : 68.75\n",
      "[1,   316] loss: 1.73759, adv_train_accuracy: 30.47, clean_train_accuracy : 59.38\n",
      "[1,   321] loss: 1.45613, adv_train_accuracy: 43.75, clean_train_accuracy : 63.28\n",
      "[1,   326] loss: 1.53123, adv_train_accuracy: 37.50, clean_train_accuracy : 66.41\n",
      "[1,   331] loss: 1.76791, adv_train_accuracy: 34.38, clean_train_accuracy : 61.72\n",
      "[1,   336] loss: 1.59185, adv_train_accuracy: 43.75, clean_train_accuracy : 66.41\n",
      "[1,   341] loss: 1.53421, adv_train_accuracy: 41.41, clean_train_accuracy : 64.06\n",
      "[1,   346] loss: 1.58576, adv_train_accuracy: 35.94, clean_train_accuracy : 67.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   351] loss: 1.69765, adv_train_accuracy: 39.06, clean_train_accuracy : 61.72\n",
      "[1,   356] loss: 1.51802, adv_train_accuracy: 44.53, clean_train_accuracy : 63.28\n",
      "[1,   361] loss: 1.78171, adv_train_accuracy: 32.81, clean_train_accuracy : 57.03\n",
      "[1,   366] loss: 1.65207, adv_train_accuracy: 35.94, clean_train_accuracy : 60.16\n",
      "[1,   371] loss: 1.60154, adv_train_accuracy: 43.75, clean_train_accuracy : 55.47\n",
      "[1,   376] loss: 1.49323, adv_train_accuracy: 40.62, clean_train_accuracy : 61.72\n",
      "[1,   381] loss: 1.75799, adv_train_accuracy: 32.81, clean_train_accuracy : 50.78\n",
      "[1,   386] loss: 1.85035, adv_train_accuracy: 26.56, clean_train_accuracy : 48.44\n",
      "[1,   391] loss: 1.87279, adv_train_accuracy: 27.50, clean_train_accuracy : 51.25\n",
      "fgsm robustness: 0.232421875\n",
      "pgd robustness: 0.2255859375\n",
      "duration: 159 s - train loss: 1.66968 - train accuracy: 36.79 - validation loss: 1.61903 - validation accuracy: 45.76 \n",
      "Finished Training\n",
      "5 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.90449, adv_train_accuracy: 29.69, clean_train_accuracy : 51.56\n",
      "[1,     6] loss: 1.82295, adv_train_accuracy: 28.12, clean_train_accuracy : 52.34\n",
      "[1,    11] loss: 1.77166, adv_train_accuracy: 28.12, clean_train_accuracy : 52.34\n",
      "[1,    16] loss: 1.75071, adv_train_accuracy: 36.72, clean_train_accuracy : 57.81\n",
      "[1,    21] loss: 1.80329, adv_train_accuracy: 32.81, clean_train_accuracy : 57.03\n",
      "[1,    26] loss: 1.80502, adv_train_accuracy: 32.81, clean_train_accuracy : 51.56\n",
      "[1,    31] loss: 1.48409, adv_train_accuracy: 41.41, clean_train_accuracy : 67.97\n",
      "[1,    36] loss: 1.75482, adv_train_accuracy: 32.03, clean_train_accuracy : 59.38\n",
      "[1,    41] loss: 1.73257, adv_train_accuracy: 35.16, clean_train_accuracy : 53.12\n",
      "[1,    46] loss: 1.71386, adv_train_accuracy: 29.69, clean_train_accuracy : 50.00\n",
      "[1,    51] loss: 1.59305, adv_train_accuracy: 40.62, clean_train_accuracy : 60.94\n",
      "[1,    56] loss: 1.55358, adv_train_accuracy: 37.50, clean_train_accuracy : 64.84\n",
      "[1,    61] loss: 1.80467, adv_train_accuracy: 33.59, clean_train_accuracy : 56.25\n",
      "[1,    66] loss: 1.82410, adv_train_accuracy: 31.25, clean_train_accuracy : 57.03\n",
      "[1,    71] loss: 1.68056, adv_train_accuracy: 42.19, clean_train_accuracy : 60.16\n",
      "[1,    76] loss: 1.63996, adv_train_accuracy: 35.94, clean_train_accuracy : 60.94\n",
      "[1,    81] loss: 1.73004, adv_train_accuracy: 32.03, clean_train_accuracy : 55.47\n",
      "[1,    86] loss: 1.62404, adv_train_accuracy: 36.72, clean_train_accuracy : 55.47\n",
      "[1,    91] loss: 1.67046, adv_train_accuracy: 31.25, clean_train_accuracy : 57.03\n",
      "[1,    96] loss: 1.72347, adv_train_accuracy: 33.59, clean_train_accuracy : 57.81\n",
      "[1,   101] loss: 1.68062, adv_train_accuracy: 35.16, clean_train_accuracy : 58.59\n",
      "[1,   106] loss: 1.69389, adv_train_accuracy: 36.72, clean_train_accuracy : 67.19\n",
      "[1,   111] loss: 1.55708, adv_train_accuracy: 42.97, clean_train_accuracy : 60.16\n",
      "[1,   116] loss: 1.67887, adv_train_accuracy: 37.50, clean_train_accuracy : 62.50\n",
      "[1,   121] loss: 1.55569, adv_train_accuracy: 39.84, clean_train_accuracy : 63.28\n",
      "[1,   126] loss: 1.58731, adv_train_accuracy: 40.62, clean_train_accuracy : 56.25\n",
      "[1,   131] loss: 1.55333, adv_train_accuracy: 39.84, clean_train_accuracy : 68.75\n",
      "[1,   136] loss: 1.83421, adv_train_accuracy: 34.38, clean_train_accuracy : 57.81\n",
      "[1,   141] loss: 1.66364, adv_train_accuracy: 34.38, clean_train_accuracy : 58.59\n",
      "[1,   146] loss: 1.69425, adv_train_accuracy: 31.25, clean_train_accuracy : 52.34\n",
      "[1,   151] loss: 1.60747, adv_train_accuracy: 39.84, clean_train_accuracy : 61.72\n",
      "[1,   156] loss: 1.56150, adv_train_accuracy: 37.50, clean_train_accuracy : 61.72\n",
      "[1,   161] loss: 1.64026, adv_train_accuracy: 42.97, clean_train_accuracy : 60.16\n",
      "[1,   166] loss: 1.68106, adv_train_accuracy: 38.28, clean_train_accuracy : 57.81\n",
      "[1,   171] loss: 1.60208, adv_train_accuracy: 39.84, clean_train_accuracy : 63.28\n",
      "[1,   176] loss: 1.62316, adv_train_accuracy: 38.28, clean_train_accuracy : 55.47\n",
      "[1,   181] loss: 1.63119, adv_train_accuracy: 35.16, clean_train_accuracy : 57.03\n",
      "[1,   186] loss: 1.64745, adv_train_accuracy: 35.94, clean_train_accuracy : 61.72\n",
      "[1,   191] loss: 1.59155, adv_train_accuracy: 39.84, clean_train_accuracy : 64.06\n",
      "[1,   196] loss: 1.69266, adv_train_accuracy: 37.50, clean_train_accuracy : 61.72\n",
      "[1,   201] loss: 1.76998, adv_train_accuracy: 33.59, clean_train_accuracy : 50.78\n",
      "[1,   206] loss: 1.68978, adv_train_accuracy: 37.50, clean_train_accuracy : 54.69\n",
      "[1,   211] loss: 1.50295, adv_train_accuracy: 43.75, clean_train_accuracy : 69.53\n",
      "[1,   216] loss: 1.80003, adv_train_accuracy: 34.38, clean_train_accuracy : 59.38\n",
      "[1,   221] loss: 1.83936, adv_train_accuracy: 31.25, clean_train_accuracy : 60.16\n",
      "[1,   226] loss: 1.52133, adv_train_accuracy: 50.00, clean_train_accuracy : 64.06\n",
      "[1,   231] loss: 1.67816, adv_train_accuracy: 35.94, clean_train_accuracy : 54.69\n",
      "[1,   236] loss: 1.61398, adv_train_accuracy: 39.06, clean_train_accuracy : 60.16\n",
      "[1,   241] loss: 1.61455, adv_train_accuracy: 35.94, clean_train_accuracy : 64.84\n",
      "[1,   246] loss: 1.45817, adv_train_accuracy: 47.66, clean_train_accuracy : 71.09\n",
      "[1,   251] loss: 1.67606, adv_train_accuracy: 38.28, clean_train_accuracy : 58.59\n",
      "[1,   256] loss: 1.47217, adv_train_accuracy: 47.66, clean_train_accuracy : 62.50\n",
      "[1,   261] loss: 1.74006, adv_train_accuracy: 41.41, clean_train_accuracy : 60.94\n",
      "[1,   266] loss: 1.61507, adv_train_accuracy: 42.97, clean_train_accuracy : 62.50\n",
      "[1,   271] loss: 1.63533, adv_train_accuracy: 35.94, clean_train_accuracy : 61.72\n",
      "[1,   276] loss: 1.65478, adv_train_accuracy: 39.84, clean_train_accuracy : 64.06\n",
      "[1,   281] loss: 1.44237, adv_train_accuracy: 42.19, clean_train_accuracy : 63.28\n",
      "[1,   286] loss: 1.55882, adv_train_accuracy: 36.72, clean_train_accuracy : 64.84\n",
      "[1,   291] loss: 1.54908, adv_train_accuracy: 42.19, clean_train_accuracy : 68.75\n",
      "[1,   296] loss: 1.60724, adv_train_accuracy: 39.06, clean_train_accuracy : 65.62\n",
      "[1,   301] loss: 1.66197, adv_train_accuracy: 31.25, clean_train_accuracy : 64.84\n",
      "[1,   306] loss: 1.45766, adv_train_accuracy: 46.88, clean_train_accuracy : 65.62\n",
      "[1,   311] loss: 1.47657, adv_train_accuracy: 43.75, clean_train_accuracy : 67.19\n",
      "[1,   316] loss: 1.64340, adv_train_accuracy: 35.94, clean_train_accuracy : 63.28\n",
      "[1,   321] loss: 1.73823, adv_train_accuracy: 41.41, clean_train_accuracy : 62.50\n",
      "[1,   326] loss: 1.67272, adv_train_accuracy: 36.72, clean_train_accuracy : 62.50\n",
      "[1,   331] loss: 1.50579, adv_train_accuracy: 36.72, clean_train_accuracy : 67.19\n",
      "[1,   336] loss: 1.54822, adv_train_accuracy: 41.41, clean_train_accuracy : 59.38\n",
      "[1,   341] loss: 1.56362, adv_train_accuracy: 50.00, clean_train_accuracy : 65.62\n",
      "[1,   346] loss: 1.52073, adv_train_accuracy: 41.41, clean_train_accuracy : 66.41\n",
      "[1,   351] loss: 1.50915, adv_train_accuracy: 37.50, clean_train_accuracy : 60.94\n",
      "[1,   356] loss: 1.51918, adv_train_accuracy: 45.31, clean_train_accuracy : 64.84\n",
      "[1,   361] loss: 1.63910, adv_train_accuracy: 39.84, clean_train_accuracy : 66.41\n",
      "[1,   366] loss: 1.58853, adv_train_accuracy: 41.41, clean_train_accuracy : 63.28\n",
      "[1,   371] loss: 1.63424, adv_train_accuracy: 32.81, clean_train_accuracy : 62.50\n",
      "[1,   376] loss: 1.70961, adv_train_accuracy: 32.81, clean_train_accuracy : 62.50\n",
      "[1,   381] loss: 1.67091, adv_train_accuracy: 42.97, clean_train_accuracy : 64.84\n",
      "[1,   386] loss: 1.44449, adv_train_accuracy: 41.41, clean_train_accuracy : 64.84\n",
      "[1,   391] loss: 1.72232, adv_train_accuracy: 31.25, clean_train_accuracy : 60.00\n",
      "fgsm robustness: 0.34765625\n",
      "pgd robustness: 0.314453125\n",
      "duration: 158 s - train loss: 1.64034 - train accuracy: 37.99 - validation loss: 1.11142 - validation accuracy: 62.11 \n",
      "Finished Training\n",
      "6 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.50791, adv_train_accuracy: 35.94, clean_train_accuracy : 64.84\n",
      "[1,     6] loss: 1.53504, adv_train_accuracy: 42.97, clean_train_accuracy : 63.28\n",
      "[1,    11] loss: 1.65311, adv_train_accuracy: 41.41, clean_train_accuracy : 61.72\n",
      "[1,    16] loss: 1.51521, adv_train_accuracy: 44.53, clean_train_accuracy : 69.53\n",
      "[1,    21] loss: 1.59670, adv_train_accuracy: 41.41, clean_train_accuracy : 58.59\n",
      "[1,    26] loss: 1.52252, adv_train_accuracy: 42.97, clean_train_accuracy : 65.62\n",
      "[1,    31] loss: 1.65090, adv_train_accuracy: 37.50, clean_train_accuracy : 57.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    36] loss: 1.48284, adv_train_accuracy: 43.75, clean_train_accuracy : 64.84\n",
      "[1,    41] loss: 1.55957, adv_train_accuracy: 35.94, clean_train_accuracy : 64.84\n",
      "[1,    46] loss: 1.42295, adv_train_accuracy: 40.62, clean_train_accuracy : 65.62\n",
      "[1,    51] loss: 1.57212, adv_train_accuracy: 38.28, clean_train_accuracy : 62.50\n",
      "[1,    56] loss: 1.53053, adv_train_accuracy: 44.53, clean_train_accuracy : 63.28\n",
      "[1,    61] loss: 1.53911, adv_train_accuracy: 44.53, clean_train_accuracy : 59.38\n",
      "[1,    66] loss: 1.55756, adv_train_accuracy: 42.19, clean_train_accuracy : 65.62\n",
      "[1,    71] loss: 1.59961, adv_train_accuracy: 37.50, clean_train_accuracy : 60.16\n",
      "[1,    76] loss: 1.51264, adv_train_accuracy: 42.19, clean_train_accuracy : 63.28\n",
      "[1,    81] loss: 1.62115, adv_train_accuracy: 35.94, clean_train_accuracy : 67.19\n",
      "[1,    86] loss: 1.55961, adv_train_accuracy: 44.53, clean_train_accuracy : 67.19\n",
      "[1,    91] loss: 1.65379, adv_train_accuracy: 35.16, clean_train_accuracy : 53.91\n",
      "[1,    96] loss: 1.70798, adv_train_accuracy: 30.47, clean_train_accuracy : 62.50\n",
      "[1,   101] loss: 1.71199, adv_train_accuracy: 32.81, clean_train_accuracy : 60.94\n",
      "[1,   106] loss: 1.50948, adv_train_accuracy: 42.97, clean_train_accuracy : 65.62\n",
      "[1,   111] loss: 1.46889, adv_train_accuracy: 42.97, clean_train_accuracy : 60.94\n",
      "[1,   116] loss: 1.54449, adv_train_accuracy: 41.41, clean_train_accuracy : 67.97\n",
      "[1,   121] loss: 1.48965, adv_train_accuracy: 49.22, clean_train_accuracy : 65.62\n",
      "[1,   126] loss: 1.54151, adv_train_accuracy: 43.75, clean_train_accuracy : 70.31\n",
      "[1,   131] loss: 1.74595, adv_train_accuracy: 29.69, clean_train_accuracy : 59.38\n",
      "[1,   136] loss: 1.54722, adv_train_accuracy: 42.19, clean_train_accuracy : 64.06\n",
      "[1,   141] loss: 1.57779, adv_train_accuracy: 39.84, clean_train_accuracy : 62.50\n",
      "[1,   146] loss: 1.51549, adv_train_accuracy: 41.41, clean_train_accuracy : 70.31\n",
      "[1,   151] loss: 1.61894, adv_train_accuracy: 41.41, clean_train_accuracy : 59.38\n",
      "[1,   156] loss: 1.58983, adv_train_accuracy: 39.84, clean_train_accuracy : 63.28\n",
      "[1,   161] loss: 1.39382, adv_train_accuracy: 42.97, clean_train_accuracy : 73.44\n",
      "[1,   166] loss: 1.57997, adv_train_accuracy: 39.84, clean_train_accuracy : 64.06\n",
      "[1,   171] loss: 1.48709, adv_train_accuracy: 48.44, clean_train_accuracy : 66.41\n",
      "[1,   176] loss: 1.46485, adv_train_accuracy: 42.97, clean_train_accuracy : 62.50\n",
      "[1,   181] loss: 1.51948, adv_train_accuracy: 40.62, clean_train_accuracy : 67.97\n",
      "[1,   186] loss: 1.42284, adv_train_accuracy: 42.19, clean_train_accuracy : 67.19\n",
      "[1,   191] loss: 1.49661, adv_train_accuracy: 42.19, clean_train_accuracy : 70.31\n",
      "[1,   196] loss: 1.59541, adv_train_accuracy: 40.62, clean_train_accuracy : 63.28\n",
      "[1,   201] loss: 1.54149, adv_train_accuracy: 40.62, clean_train_accuracy : 70.31\n",
      "[1,   206] loss: 1.57975, adv_train_accuracy: 39.06, clean_train_accuracy : 63.28\n",
      "[1,   211] loss: 1.55263, adv_train_accuracy: 39.84, clean_train_accuracy : 64.84\n",
      "[1,   216] loss: 1.52643, adv_train_accuracy: 41.41, clean_train_accuracy : 65.62\n",
      "[1,   221] loss: 1.31969, adv_train_accuracy: 50.00, clean_train_accuracy : 75.00\n",
      "[1,   226] loss: 1.60172, adv_train_accuracy: 41.41, clean_train_accuracy : 67.19\n",
      "[1,   231] loss: 1.57505, adv_train_accuracy: 42.19, clean_train_accuracy : 65.62\n",
      "[1,   236] loss: 1.40903, adv_train_accuracy: 49.22, clean_train_accuracy : 65.62\n",
      "[1,   241] loss: 1.50422, adv_train_accuracy: 44.53, clean_train_accuracy : 71.88\n",
      "[1,   246] loss: 1.47989, adv_train_accuracy: 42.19, clean_train_accuracy : 65.62\n",
      "[1,   251] loss: 1.45106, adv_train_accuracy: 46.09, clean_train_accuracy : 66.41\n",
      "[1,   256] loss: 1.38867, adv_train_accuracy: 46.88, clean_train_accuracy : 70.31\n",
      "[1,   261] loss: 1.52914, adv_train_accuracy: 44.53, clean_train_accuracy : 68.75\n",
      "[1,   266] loss: 1.43083, adv_train_accuracy: 48.44, clean_train_accuracy : 71.88\n",
      "[1,   271] loss: 1.53612, adv_train_accuracy: 43.75, clean_train_accuracy : 65.62\n",
      "[1,   276] loss: 1.46960, adv_train_accuracy: 39.84, clean_train_accuracy : 68.75\n",
      "[1,   281] loss: 1.57976, adv_train_accuracy: 40.62, clean_train_accuracy : 67.19\n",
      "[1,   286] loss: 1.43605, adv_train_accuracy: 42.19, clean_train_accuracy : 64.06\n",
      "[1,   291] loss: 1.51334, adv_train_accuracy: 38.28, clean_train_accuracy : 64.84\n",
      "[1,   296] loss: 1.47163, adv_train_accuracy: 41.41, clean_train_accuracy : 72.66\n",
      "[1,   301] loss: 1.60278, adv_train_accuracy: 43.75, clean_train_accuracy : 65.62\n",
      "[1,   306] loss: 1.50917, adv_train_accuracy: 47.66, clean_train_accuracy : 72.66\n",
      "[1,   311] loss: 1.55494, adv_train_accuracy: 44.53, clean_train_accuracy : 68.75\n",
      "[1,   316] loss: 1.54367, adv_train_accuracy: 43.75, clean_train_accuracy : 67.97\n",
      "[1,   321] loss: 1.59400, adv_train_accuracy: 38.28, clean_train_accuracy : 63.28\n",
      "[1,   326] loss: 1.56642, adv_train_accuracy: 40.62, clean_train_accuracy : 70.31\n",
      "[1,   331] loss: 1.52451, adv_train_accuracy: 45.31, clean_train_accuracy : 70.31\n",
      "[1,   336] loss: 1.49605, adv_train_accuracy: 41.41, clean_train_accuracy : 63.28\n",
      "[1,   341] loss: 1.58196, adv_train_accuracy: 38.28, clean_train_accuracy : 62.50\n",
      "[1,   346] loss: 1.48417, adv_train_accuracy: 42.19, clean_train_accuracy : 65.62\n",
      "[1,   351] loss: 1.47250, adv_train_accuracy: 41.41, clean_train_accuracy : 64.06\n",
      "[1,   356] loss: 1.50344, adv_train_accuracy: 44.53, clean_train_accuracy : 69.53\n",
      "[1,   361] loss: 1.66023, adv_train_accuracy: 42.19, clean_train_accuracy : 62.50\n",
      "[1,   366] loss: 1.45937, adv_train_accuracy: 43.75, clean_train_accuracy : 69.53\n",
      "[1,   371] loss: 1.48173, adv_train_accuracy: 46.09, clean_train_accuracy : 68.75\n",
      "[1,   376] loss: 1.52959, adv_train_accuracy: 42.97, clean_train_accuracy : 66.41\n",
      "[1,   381] loss: 1.45104, adv_train_accuracy: 42.19, clean_train_accuracy : 72.66\n",
      "[1,   386] loss: 1.53435, adv_train_accuracy: 41.41, clean_train_accuracy : 65.62\n",
      "[1,   391] loss: 1.55549, adv_train_accuracy: 37.50, clean_train_accuracy : 72.50\n",
      "fgsm robustness: 0.36328125\n",
      "pgd robustness: 0.369140625\n",
      "duration: 159 s - train loss: 1.53937 - train accuracy: 41.36 - validation loss: 1.09858 - validation accuracy: 62.49 \n",
      "Finished Training\n",
      "7 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.58314, adv_train_accuracy: 38.28, clean_train_accuracy : 67.97\n",
      "[1,     6] loss: 1.36188, adv_train_accuracy: 46.09, clean_train_accuracy : 72.66\n",
      "[1,    11] loss: 1.55934, adv_train_accuracy: 42.19, clean_train_accuracy : 68.75\n",
      "[1,    16] loss: 1.36126, adv_train_accuracy: 50.78, clean_train_accuracy : 71.09\n",
      "[1,    21] loss: 1.33680, adv_train_accuracy: 52.34, clean_train_accuracy : 72.66\n",
      "[1,    26] loss: 1.24391, adv_train_accuracy: 53.91, clean_train_accuracy : 77.34\n",
      "[1,    31] loss: 1.49828, adv_train_accuracy: 45.31, clean_train_accuracy : 69.53\n",
      "[1,    36] loss: 1.38559, adv_train_accuracy: 47.66, clean_train_accuracy : 71.88\n",
      "[1,    41] loss: 1.51209, adv_train_accuracy: 36.72, clean_train_accuracy : 69.53\n",
      "[1,    46] loss: 1.53177, adv_train_accuracy: 40.62, clean_train_accuracy : 67.97\n",
      "[1,    51] loss: 1.65076, adv_train_accuracy: 37.50, clean_train_accuracy : 63.28\n",
      "[1,    56] loss: 1.46140, adv_train_accuracy: 42.97, clean_train_accuracy : 71.88\n",
      "[1,    61] loss: 1.50241, adv_train_accuracy: 42.19, clean_train_accuracy : 71.88\n",
      "[1,    66] loss: 1.48198, adv_train_accuracy: 47.66, clean_train_accuracy : 67.97\n",
      "[1,    71] loss: 1.47623, adv_train_accuracy: 40.62, clean_train_accuracy : 71.09\n",
      "[1,    76] loss: 1.33395, adv_train_accuracy: 48.44, clean_train_accuracy : 75.78\n",
      "[1,    81] loss: 1.47599, adv_train_accuracy: 46.09, clean_train_accuracy : 65.62\n",
      "[1,    86] loss: 1.43508, adv_train_accuracy: 46.09, clean_train_accuracy : 67.19\n",
      "[1,    91] loss: 1.38920, adv_train_accuracy: 46.88, clean_train_accuracy : 71.09\n",
      "[1,    96] loss: 1.46480, adv_train_accuracy: 42.19, clean_train_accuracy : 70.31\n",
      "[1,   101] loss: 1.51745, adv_train_accuracy: 36.72, clean_train_accuracy : 67.19\n",
      "[1,   106] loss: 1.42642, adv_train_accuracy: 39.84, clean_train_accuracy : 66.41\n",
      "[1,   111] loss: 1.41348, adv_train_accuracy: 50.78, clean_train_accuracy : 70.31\n",
      "[1,   116] loss: 1.44257, adv_train_accuracy: 44.53, clean_train_accuracy : 70.31\n",
      "[1,   121] loss: 1.53329, adv_train_accuracy: 37.50, clean_train_accuracy : 65.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   126] loss: 1.44227, adv_train_accuracy: 42.19, clean_train_accuracy : 71.09\n",
      "[1,   131] loss: 1.39676, adv_train_accuracy: 44.53, clean_train_accuracy : 73.44\n",
      "[1,   136] loss: 1.40068, adv_train_accuracy: 46.88, clean_train_accuracy : 75.00\n",
      "[1,   141] loss: 1.46656, adv_train_accuracy: 44.53, clean_train_accuracy : 71.09\n",
      "[1,   146] loss: 1.63832, adv_train_accuracy: 35.94, clean_train_accuracy : 68.75\n",
      "[1,   151] loss: 1.49782, adv_train_accuracy: 42.19, clean_train_accuracy : 66.41\n",
      "[1,   156] loss: 1.46677, adv_train_accuracy: 39.84, clean_train_accuracy : 73.44\n",
      "[1,   161] loss: 1.61991, adv_train_accuracy: 34.38, clean_train_accuracy : 65.62\n",
      "[1,   166] loss: 1.59191, adv_train_accuracy: 38.28, clean_train_accuracy : 66.41\n",
      "[1,   171] loss: 1.39803, adv_train_accuracy: 46.88, clean_train_accuracy : 67.19\n",
      "[1,   176] loss: 1.55773, adv_train_accuracy: 37.50, clean_train_accuracy : 67.19\n",
      "[1,   181] loss: 1.62955, adv_train_accuracy: 39.84, clean_train_accuracy : 73.44\n",
      "[1,   186] loss: 1.50763, adv_train_accuracy: 40.62, clean_train_accuracy : 66.41\n",
      "[1,   191] loss: 1.40457, adv_train_accuracy: 48.44, clean_train_accuracy : 70.31\n",
      "[1,   196] loss: 1.37130, adv_train_accuracy: 51.56, clean_train_accuracy : 72.66\n",
      "[1,   201] loss: 1.22375, adv_train_accuracy: 53.91, clean_train_accuracy : 75.78\n",
      "[1,   206] loss: 1.44098, adv_train_accuracy: 42.97, clean_train_accuracy : 73.44\n",
      "[1,   211] loss: 1.55337, adv_train_accuracy: 38.28, clean_train_accuracy : 62.50\n",
      "[1,   216] loss: 1.40679, adv_train_accuracy: 46.09, clean_train_accuracy : 66.41\n",
      "[1,   221] loss: 1.63643, adv_train_accuracy: 32.81, clean_train_accuracy : 70.31\n",
      "[1,   226] loss: 1.39148, adv_train_accuracy: 48.44, clean_train_accuracy : 71.88\n",
      "[1,   231] loss: 1.57825, adv_train_accuracy: 43.75, clean_train_accuracy : 65.62\n",
      "[1,   236] loss: 1.48211, adv_train_accuracy: 43.75, clean_train_accuracy : 69.53\n",
      "[1,   241] loss: 1.46056, adv_train_accuracy: 43.75, clean_train_accuracy : 66.41\n",
      "[1,   246] loss: 1.40091, adv_train_accuracy: 45.31, clean_train_accuracy : 69.53\n",
      "[1,   251] loss: 1.40716, adv_train_accuracy: 45.31, clean_train_accuracy : 71.88\n",
      "[1,   256] loss: 1.45294, adv_train_accuracy: 45.31, clean_train_accuracy : 65.62\n",
      "[1,   261] loss: 1.61195, adv_train_accuracy: 35.94, clean_train_accuracy : 59.38\n",
      "[1,   266] loss: 1.39808, adv_train_accuracy: 44.53, clean_train_accuracy : 71.88\n",
      "[1,   271] loss: 1.57725, adv_train_accuracy: 38.28, clean_train_accuracy : 66.41\n",
      "[1,   276] loss: 1.37059, adv_train_accuracy: 46.09, clean_train_accuracy : 73.44\n",
      "[1,   281] loss: 1.27957, adv_train_accuracy: 50.00, clean_train_accuracy : 79.69\n",
      "[1,   286] loss: 1.42791, adv_train_accuracy: 50.78, clean_train_accuracy : 75.78\n",
      "[1,   291] loss: 1.34055, adv_train_accuracy: 51.56, clean_train_accuracy : 78.91\n",
      "[1,   296] loss: 1.50062, adv_train_accuracy: 41.41, clean_train_accuracy : 71.88\n",
      "[1,   301] loss: 1.34789, adv_train_accuracy: 53.12, clean_train_accuracy : 75.00\n",
      "[1,   306] loss: 1.56131, adv_train_accuracy: 37.50, clean_train_accuracy : 64.06\n",
      "[1,   311] loss: 1.49641, adv_train_accuracy: 38.28, clean_train_accuracy : 64.84\n",
      "[1,   316] loss: 1.47846, adv_train_accuracy: 39.84, clean_train_accuracy : 69.53\n",
      "[1,   321] loss: 1.39656, adv_train_accuracy: 42.97, clean_train_accuracy : 75.00\n",
      "[1,   326] loss: 1.46497, adv_train_accuracy: 46.09, clean_train_accuracy : 64.84\n",
      "[1,   331] loss: 1.34919, adv_train_accuracy: 44.53, clean_train_accuracy : 77.34\n",
      "[1,   336] loss: 1.37874, adv_train_accuracy: 46.88, clean_train_accuracy : 70.31\n",
      "[1,   341] loss: 1.50554, adv_train_accuracy: 42.97, clean_train_accuracy : 68.75\n",
      "[1,   346] loss: 1.43610, adv_train_accuracy: 46.88, clean_train_accuracy : 67.97\n",
      "[1,   351] loss: 1.38507, adv_train_accuracy: 46.09, clean_train_accuracy : 75.00\n",
      "[1,   356] loss: 1.51648, adv_train_accuracy: 38.28, clean_train_accuracy : 64.84\n",
      "[1,   361] loss: 1.42685, adv_train_accuracy: 50.78, clean_train_accuracy : 71.88\n",
      "[1,   366] loss: 1.31774, adv_train_accuracy: 51.56, clean_train_accuracy : 76.56\n",
      "[1,   371] loss: 1.42458, adv_train_accuracy: 41.41, clean_train_accuracy : 72.66\n",
      "[1,   376] loss: 1.40394, adv_train_accuracy: 47.66, clean_train_accuracy : 70.31\n",
      "[1,   381] loss: 1.42226, adv_train_accuracy: 44.53, clean_train_accuracy : 73.44\n",
      "[1,   386] loss: 1.48976, adv_train_accuracy: 42.97, clean_train_accuracy : 71.09\n",
      "[1,   391] loss: 1.36080, adv_train_accuracy: 58.75, clean_train_accuracy : 77.50\n",
      "fgsm robustness: 0.404296875\n",
      "pgd robustness: 0.3662109375\n",
      "duration: 159 s - train loss: 1.46229 - train accuracy: 43.92 - validation loss: 1.01777 - validation accuracy: 65.75 \n",
      "Finished Training\n",
      "8 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.42774, adv_train_accuracy: 41.41, clean_train_accuracy : 71.88\n",
      "[1,     6] loss: 1.30856, adv_train_accuracy: 48.44, clean_train_accuracy : 74.22\n",
      "[1,    11] loss: 1.40021, adv_train_accuracy: 48.44, clean_train_accuracy : 74.22\n",
      "[1,    16] loss: 1.33783, adv_train_accuracy: 46.09, clean_train_accuracy : 77.34\n",
      "[1,    21] loss: 1.39988, adv_train_accuracy: 46.09, clean_train_accuracy : 77.34\n",
      "[1,    26] loss: 1.31559, adv_train_accuracy: 47.66, clean_train_accuracy : 76.56\n",
      "[1,    31] loss: 1.29310, adv_train_accuracy: 48.44, clean_train_accuracy : 74.22\n",
      "[1,    36] loss: 1.55448, adv_train_accuracy: 37.50, clean_train_accuracy : 80.47\n",
      "[1,    41] loss: 1.38872, adv_train_accuracy: 38.28, clean_train_accuracy : 74.22\n",
      "[1,    46] loss: 1.39034, adv_train_accuracy: 42.97, clean_train_accuracy : 67.19\n",
      "[1,    51] loss: 1.42233, adv_train_accuracy: 44.53, clean_train_accuracy : 74.22\n",
      "[1,    56] loss: 1.50282, adv_train_accuracy: 41.41, clean_train_accuracy : 70.31\n",
      "[1,    61] loss: 1.48702, adv_train_accuracy: 43.75, clean_train_accuracy : 68.75\n",
      "[1,    66] loss: 1.29881, adv_train_accuracy: 53.12, clean_train_accuracy : 78.12\n",
      "[1,    71] loss: 1.27869, adv_train_accuracy: 52.34, clean_train_accuracy : 77.34\n",
      "[1,    76] loss: 1.34639, adv_train_accuracy: 53.12, clean_train_accuracy : 71.09\n",
      "[1,    81] loss: 1.39655, adv_train_accuracy: 42.97, clean_train_accuracy : 74.22\n",
      "[1,    86] loss: 1.48537, adv_train_accuracy: 38.28, clean_train_accuracy : 66.41\n",
      "[1,    91] loss: 1.37610, adv_train_accuracy: 42.19, clean_train_accuracy : 77.34\n",
      "[1,    96] loss: 1.29826, adv_train_accuracy: 53.12, clean_train_accuracy : 82.81\n",
      "[1,   101] loss: 1.53306, adv_train_accuracy: 38.28, clean_train_accuracy : 70.31\n",
      "[1,   106] loss: 1.33571, adv_train_accuracy: 42.97, clean_train_accuracy : 77.34\n",
      "[1,   111] loss: 1.30233, adv_train_accuracy: 46.09, clean_train_accuracy : 76.56\n",
      "[1,   116] loss: 1.36094, adv_train_accuracy: 45.31, clean_train_accuracy : 74.22\n",
      "[1,   121] loss: 1.53798, adv_train_accuracy: 39.06, clean_train_accuracy : 73.44\n",
      "[1,   126] loss: 1.38716, adv_train_accuracy: 50.78, clean_train_accuracy : 73.44\n",
      "[1,   131] loss: 1.20946, adv_train_accuracy: 55.47, clean_train_accuracy : 79.69\n",
      "[1,   136] loss: 1.42367, adv_train_accuracy: 40.62, clean_train_accuracy : 75.00\n",
      "[1,   141] loss: 1.36070, adv_train_accuracy: 46.09, clean_train_accuracy : 72.66\n",
      "[1,   146] loss: 1.31238, adv_train_accuracy: 50.00, clean_train_accuracy : 78.91\n",
      "[1,   151] loss: 1.39292, adv_train_accuracy: 45.31, clean_train_accuracy : 78.91\n",
      "[1,   156] loss: 1.48767, adv_train_accuracy: 50.78, clean_train_accuracy : 69.53\n",
      "[1,   161] loss: 1.38233, adv_train_accuracy: 47.66, clean_train_accuracy : 70.31\n",
      "[1,   166] loss: 1.38269, adv_train_accuracy: 48.44, clean_train_accuracy : 75.00\n",
      "[1,   171] loss: 1.26526, adv_train_accuracy: 54.69, clean_train_accuracy : 78.91\n",
      "[1,   176] loss: 1.59222, adv_train_accuracy: 42.19, clean_train_accuracy : 65.62\n",
      "[1,   181] loss: 1.72509, adv_train_accuracy: 35.94, clean_train_accuracy : 65.62\n",
      "[1,   186] loss: 1.37051, adv_train_accuracy: 47.66, clean_train_accuracy : 71.88\n",
      "[1,   191] loss: 1.46771, adv_train_accuracy: 42.19, clean_train_accuracy : 65.62\n",
      "[1,   196] loss: 1.49794, adv_train_accuracy: 40.62, clean_train_accuracy : 78.91\n",
      "[1,   201] loss: 1.54598, adv_train_accuracy: 39.84, clean_train_accuracy : 62.50\n",
      "[1,   206] loss: 1.26366, adv_train_accuracy: 52.34, clean_train_accuracy : 83.59\n",
      "[1,   211] loss: 1.27464, adv_train_accuracy: 50.00, clean_train_accuracy : 75.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   216] loss: 1.51082, adv_train_accuracy: 44.53, clean_train_accuracy : 69.53\n",
      "[1,   221] loss: 1.48987, adv_train_accuracy: 44.53, clean_train_accuracy : 73.44\n",
      "[1,   226] loss: 1.56540, adv_train_accuracy: 42.19, clean_train_accuracy : 69.53\n",
      "[1,   231] loss: 1.52622, adv_train_accuracy: 43.75, clean_train_accuracy : 67.97\n",
      "[1,   236] loss: 1.47241, adv_train_accuracy: 40.62, clean_train_accuracy : 67.97\n",
      "[1,   241] loss: 1.33108, adv_train_accuracy: 49.22, clean_train_accuracy : 75.78\n",
      "[1,   246] loss: 1.38754, adv_train_accuracy: 48.44, clean_train_accuracy : 75.00\n",
      "[1,   251] loss: 1.23170, adv_train_accuracy: 53.91, clean_train_accuracy : 79.69\n",
      "[1,   256] loss: 1.44155, adv_train_accuracy: 46.88, clean_train_accuracy : 68.75\n",
      "[1,   261] loss: 1.62150, adv_train_accuracy: 36.72, clean_train_accuracy : 62.50\n",
      "[1,   266] loss: 1.89981, adv_train_accuracy: 29.69, clean_train_accuracy : 49.22\n",
      "[1,   271] loss: 1.77564, adv_train_accuracy: 27.34, clean_train_accuracy : 63.28\n",
      "[1,   276] loss: 1.76871, adv_train_accuracy: 35.94, clean_train_accuracy : 57.03\n",
      "[1,   281] loss: 1.86492, adv_train_accuracy: 32.81, clean_train_accuracy : 50.78\n",
      "[1,   286] loss: 1.72710, adv_train_accuracy: 32.81, clean_train_accuracy : 64.06\n",
      "[1,   291] loss: 1.98894, adv_train_accuracy: 39.06, clean_train_accuracy : 66.41\n",
      "[1,   296] loss: 1.92116, adv_train_accuracy: 34.38, clean_train_accuracy : 58.59\n",
      "[1,   301] loss: 1.77525, adv_train_accuracy: 45.31, clean_train_accuracy : 65.62\n",
      "[1,   306] loss: 1.46136, adv_train_accuracy: 43.75, clean_train_accuracy : 69.53\n",
      "[1,   311] loss: 1.57163, adv_train_accuracy: 38.28, clean_train_accuracy : 63.28\n",
      "[1,   316] loss: 1.74653, adv_train_accuracy: 37.50, clean_train_accuracy : 64.06\n",
      "[1,   321] loss: 1.76575, adv_train_accuracy: 39.06, clean_train_accuracy : 65.62\n",
      "[1,   326] loss: 1.53632, adv_train_accuracy: 43.75, clean_train_accuracy : 68.75\n",
      "[1,   331] loss: 1.42160, adv_train_accuracy: 42.97, clean_train_accuracy : 72.66\n",
      "[1,   336] loss: 1.63131, adv_train_accuracy: 42.19, clean_train_accuracy : 68.75\n",
      "[1,   341] loss: 1.57141, adv_train_accuracy: 42.97, clean_train_accuracy : 61.72\n",
      "[1,   346] loss: 1.52909, adv_train_accuracy: 39.84, clean_train_accuracy : 71.88\n",
      "[1,   351] loss: 1.60932, adv_train_accuracy: 42.19, clean_train_accuracy : 64.06\n",
      "[1,   356] loss: 1.51585, adv_train_accuracy: 43.75, clean_train_accuracy : 68.75\n",
      "[1,   361] loss: 1.41404, adv_train_accuracy: 41.41, clean_train_accuracy : 70.31\n",
      "[1,   366] loss: 1.35225, adv_train_accuracy: 50.00, clean_train_accuracy : 78.12\n",
      "[1,   371] loss: 1.41869, adv_train_accuracy: 47.66, clean_train_accuracy : 72.66\n",
      "[1,   376] loss: 1.49245, adv_train_accuracy: 41.41, clean_train_accuracy : 73.44\n",
      "[1,   381] loss: 1.48916, adv_train_accuracy: 45.31, clean_train_accuracy : 71.09\n",
      "[1,   386] loss: 1.52553, adv_train_accuracy: 45.31, clean_train_accuracy : 71.09\n",
      "[1,   391] loss: 1.18400, adv_train_accuracy: 57.50, clean_train_accuracy : 77.50\n",
      "fgsm robustness: 0.3681640625\n",
      "pgd robustness: 0.349609375\n",
      "duration: 159 s - train loss: 1.48302 - train accuracy: 43.93 - validation loss: 1.07091 - validation accuracy: 62.14 \n",
      "Finished Training\n",
      "9 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.41850, adv_train_accuracy: 39.84, clean_train_accuracy : 71.09\n",
      "[1,     6] loss: 1.31298, adv_train_accuracy: 47.66, clean_train_accuracy : 80.47\n",
      "[1,    11] loss: 1.67084, adv_train_accuracy: 37.50, clean_train_accuracy : 63.28\n",
      "[1,    16] loss: 1.46488, adv_train_accuracy: 46.09, clean_train_accuracy : 71.09\n",
      "[1,    21] loss: 1.51070, adv_train_accuracy: 38.28, clean_train_accuracy : 70.31\n",
      "[1,    26] loss: 1.49489, adv_train_accuracy: 48.44, clean_train_accuracy : 75.78\n",
      "[1,    31] loss: 1.32693, adv_train_accuracy: 50.00, clean_train_accuracy : 70.31\n",
      "[1,    36] loss: 1.37022, adv_train_accuracy: 46.88, clean_train_accuracy : 72.66\n",
      "[1,    41] loss: 1.42421, adv_train_accuracy: 46.88, clean_train_accuracy : 66.41\n",
      "[1,    46] loss: 1.22059, adv_train_accuracy: 52.34, clean_train_accuracy : 77.34\n",
      "[1,    51] loss: 1.39875, adv_train_accuracy: 46.88, clean_train_accuracy : 75.78\n",
      "[1,    56] loss: 1.47226, adv_train_accuracy: 46.88, clean_train_accuracy : 75.00\n",
      "[1,    61] loss: 1.48731, adv_train_accuracy: 45.31, clean_train_accuracy : 71.88\n",
      "[1,    66] loss: 1.25020, adv_train_accuracy: 50.78, clean_train_accuracy : 78.91\n",
      "[1,    71] loss: 1.45790, adv_train_accuracy: 46.09, clean_train_accuracy : 66.41\n",
      "[1,    76] loss: 1.31964, adv_train_accuracy: 46.09, clean_train_accuracy : 67.97\n",
      "[1,    81] loss: 1.32266, adv_train_accuracy: 49.22, clean_train_accuracy : 72.66\n",
      "[1,    86] loss: 1.38343, adv_train_accuracy: 49.22, clean_train_accuracy : 67.19\n",
      "[1,    91] loss: 1.22863, adv_train_accuracy: 55.47, clean_train_accuracy : 79.69\n",
      "[1,    96] loss: 1.50109, adv_train_accuracy: 45.31, clean_train_accuracy : 77.34\n",
      "[1,   101] loss: 1.34528, adv_train_accuracy: 47.66, clean_train_accuracy : 75.78\n",
      "[1,   106] loss: 1.44084, adv_train_accuracy: 42.19, clean_train_accuracy : 77.34\n",
      "[1,   111] loss: 1.32855, adv_train_accuracy: 46.88, clean_train_accuracy : 77.34\n",
      "[1,   116] loss: 1.41590, adv_train_accuracy: 44.53, clean_train_accuracy : 77.34\n",
      "[1,   121] loss: 1.44515, adv_train_accuracy: 43.75, clean_train_accuracy : 73.44\n",
      "[1,   126] loss: 1.38032, adv_train_accuracy: 43.75, clean_train_accuracy : 78.12\n",
      "[1,   131] loss: 1.51133, adv_train_accuracy: 43.75, clean_train_accuracy : 63.28\n",
      "[1,   136] loss: 1.48140, adv_train_accuracy: 43.75, clean_train_accuracy : 73.44\n",
      "[1,   141] loss: 1.40346, adv_train_accuracy: 46.09, clean_train_accuracy : 68.75\n",
      "[1,   146] loss: 1.28450, adv_train_accuracy: 50.00, clean_train_accuracy : 80.47\n",
      "[1,   151] loss: 1.39255, adv_train_accuracy: 43.75, clean_train_accuracy : 77.34\n",
      "[1,   156] loss: 1.41040, adv_train_accuracy: 42.19, clean_train_accuracy : 70.31\n",
      "[1,   161] loss: 1.40747, adv_train_accuracy: 48.44, clean_train_accuracy : 75.00\n",
      "[1,   166] loss: 1.47114, adv_train_accuracy: 42.97, clean_train_accuracy : 73.44\n",
      "[1,   171] loss: 1.24484, adv_train_accuracy: 46.09, clean_train_accuracy : 76.56\n",
      "[1,   176] loss: 1.25617, adv_train_accuracy: 50.00, clean_train_accuracy : 82.81\n",
      "[1,   181] loss: 1.47246, adv_train_accuracy: 46.88, clean_train_accuracy : 78.12\n",
      "[1,   186] loss: 1.24917, adv_train_accuracy: 53.91, clean_train_accuracy : 80.47\n",
      "[1,   191] loss: 1.34177, adv_train_accuracy: 45.31, clean_train_accuracy : 69.53\n",
      "[1,   196] loss: 1.31937, adv_train_accuracy: 44.53, clean_train_accuracy : 71.09\n",
      "[1,   201] loss: 1.27097, adv_train_accuracy: 46.88, clean_train_accuracy : 77.34\n",
      "[1,   206] loss: 1.26852, adv_train_accuracy: 48.44, clean_train_accuracy : 75.00\n",
      "[1,   211] loss: 1.40748, adv_train_accuracy: 43.75, clean_train_accuracy : 70.31\n",
      "[1,   216] loss: 1.39974, adv_train_accuracy: 48.44, clean_train_accuracy : 70.31\n",
      "[1,   221] loss: 1.22899, adv_train_accuracy: 53.12, clean_train_accuracy : 78.91\n",
      "[1,   226] loss: 1.35736, adv_train_accuracy: 42.97, clean_train_accuracy : 73.44\n",
      "[1,   231] loss: 1.44216, adv_train_accuracy: 42.19, clean_train_accuracy : 71.88\n",
      "[1,   236] loss: 1.44311, adv_train_accuracy: 47.66, clean_train_accuracy : 73.44\n",
      "[1,   241] loss: 1.34650, adv_train_accuracy: 49.22, clean_train_accuracy : 79.69\n",
      "[1,   246] loss: 1.31240, adv_train_accuracy: 46.88, clean_train_accuracy : 73.44\n",
      "[1,   251] loss: 1.19614, adv_train_accuracy: 52.34, clean_train_accuracy : 79.69\n",
      "[1,   256] loss: 1.38711, adv_train_accuracy: 48.44, clean_train_accuracy : 71.88\n",
      "[1,   261] loss: 1.25476, adv_train_accuracy: 53.91, clean_train_accuracy : 76.56\n",
      "[1,   266] loss: 1.27926, adv_train_accuracy: 54.69, clean_train_accuracy : 78.12\n",
      "[1,   271] loss: 1.33059, adv_train_accuracy: 47.66, clean_train_accuracy : 74.22\n",
      "[1,   276] loss: 1.26828, adv_train_accuracy: 49.22, clean_train_accuracy : 79.69\n",
      "[1,   281] loss: 1.33626, adv_train_accuracy: 48.44, clean_train_accuracy : 76.56\n",
      "[1,   286] loss: 1.51038, adv_train_accuracy: 36.72, clean_train_accuracy : 75.00\n",
      "[1,   291] loss: 1.39982, adv_train_accuracy: 48.44, clean_train_accuracy : 75.78\n",
      "[1,   296] loss: 1.33853, adv_train_accuracy: 46.09, clean_train_accuracy : 71.88\n",
      "[1,   301] loss: 1.32355, adv_train_accuracy: 50.78, clean_train_accuracy : 78.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   306] loss: 1.30981, adv_train_accuracy: 46.88, clean_train_accuracy : 72.66\n",
      "[1,   311] loss: 1.50992, adv_train_accuracy: 45.31, clean_train_accuracy : 71.09\n",
      "[1,   316] loss: 1.37857, adv_train_accuracy: 45.31, clean_train_accuracy : 73.44\n",
      "[1,   321] loss: 1.28635, adv_train_accuracy: 50.78, clean_train_accuracy : 71.88\n",
      "[1,   326] loss: 1.29235, adv_train_accuracy: 49.22, clean_train_accuracy : 76.56\n",
      "[1,   331] loss: 1.43956, adv_train_accuracy: 44.53, clean_train_accuracy : 76.56\n",
      "[1,   336] loss: 1.43087, adv_train_accuracy: 48.44, clean_train_accuracy : 76.56\n",
      "[1,   341] loss: 1.37316, adv_train_accuracy: 39.84, clean_train_accuracy : 74.22\n",
      "[1,   346] loss: 1.20082, adv_train_accuracy: 54.69, clean_train_accuracy : 78.91\n",
      "[1,   351] loss: 1.33358, adv_train_accuracy: 48.44, clean_train_accuracy : 72.66\n",
      "[1,   356] loss: 1.39285, adv_train_accuracy: 43.75, clean_train_accuracy : 73.44\n",
      "[1,   361] loss: 1.50079, adv_train_accuracy: 45.31, clean_train_accuracy : 71.88\n",
      "[1,   366] loss: 1.43477, adv_train_accuracy: 41.41, clean_train_accuracy : 74.22\n",
      "[1,   371] loss: 1.46221, adv_train_accuracy: 41.41, clean_train_accuracy : 67.97\n",
      "[1,   376] loss: 1.31863, adv_train_accuracy: 50.00, clean_train_accuracy : 77.34\n",
      "[1,   381] loss: 1.28792, adv_train_accuracy: 50.00, clean_train_accuracy : 77.34\n",
      "[1,   386] loss: 1.35902, adv_train_accuracy: 45.31, clean_train_accuracy : 79.69\n",
      "[1,   391] loss: 1.55185, adv_train_accuracy: 45.00, clean_train_accuracy : 77.50\n",
      "fgsm robustness: 0.3837890625\n",
      "pgd robustness: 0.3671875\n",
      "duration: 159 s - train loss: 1.38110 - train accuracy: 46.91 - validation loss: 0.95007 - validation accuracy: 67.03 \n",
      "Finished Training\n",
      "10 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.24825, adv_train_accuracy: 51.56, clean_train_accuracy : 80.47\n",
      "[1,     6] loss: 1.34247, adv_train_accuracy: 46.09, clean_train_accuracy : 76.56\n",
      "[1,    11] loss: 1.14185, adv_train_accuracy: 60.16, clean_train_accuracy : 81.25\n",
      "[1,    16] loss: 1.45699, adv_train_accuracy: 42.97, clean_train_accuracy : 71.09\n",
      "[1,    21] loss: 1.23907, adv_train_accuracy: 58.59, clean_train_accuracy : 81.25\n",
      "[1,    26] loss: 1.20298, adv_train_accuracy: 49.22, clean_train_accuracy : 83.59\n",
      "[1,    31] loss: 1.17737, adv_train_accuracy: 50.00, clean_train_accuracy : 81.25\n",
      "[1,    36] loss: 1.27928, adv_train_accuracy: 55.47, clean_train_accuracy : 79.69\n",
      "[1,    41] loss: 1.25044, adv_train_accuracy: 48.44, clean_train_accuracy : 78.12\n",
      "[1,    46] loss: 1.29684, adv_train_accuracy: 50.78, clean_train_accuracy : 84.38\n",
      "[1,    51] loss: 1.38915, adv_train_accuracy: 46.88, clean_train_accuracy : 74.22\n",
      "[1,    56] loss: 1.51174, adv_train_accuracy: 40.62, clean_train_accuracy : 71.09\n",
      "[1,    61] loss: 1.42424, adv_train_accuracy: 41.41, clean_train_accuracy : 75.78\n",
      "[1,    66] loss: 1.24002, adv_train_accuracy: 49.22, clean_train_accuracy : 78.91\n",
      "[1,    71] loss: 1.18177, adv_train_accuracy: 59.38, clean_train_accuracy : 78.91\n",
      "[1,    76] loss: 1.29122, adv_train_accuracy: 47.66, clean_train_accuracy : 80.47\n",
      "[1,    81] loss: 1.44932, adv_train_accuracy: 39.84, clean_train_accuracy : 78.91\n",
      "[1,    86] loss: 1.45200, adv_train_accuracy: 48.44, clean_train_accuracy : 71.88\n",
      "[1,    91] loss: 1.38576, adv_train_accuracy: 51.56, clean_train_accuracy : 75.00\n",
      "[1,    96] loss: 1.34033, adv_train_accuracy: 46.88, clean_train_accuracy : 82.81\n",
      "[1,   101] loss: 1.36683, adv_train_accuracy: 53.91, clean_train_accuracy : 80.47\n",
      "[1,   106] loss: 1.28299, adv_train_accuracy: 54.69, clean_train_accuracy : 75.00\n",
      "[1,   111] loss: 1.35703, adv_train_accuracy: 48.44, clean_train_accuracy : 72.66\n",
      "[1,   116] loss: 1.35977, adv_train_accuracy: 48.44, clean_train_accuracy : 77.34\n",
      "[1,   121] loss: 1.30533, adv_train_accuracy: 51.56, clean_train_accuracy : 79.69\n",
      "[1,   126] loss: 1.22516, adv_train_accuracy: 56.25, clean_train_accuracy : 78.12\n",
      "[1,   131] loss: 1.49456, adv_train_accuracy: 38.28, clean_train_accuracy : 73.44\n",
      "[1,   136] loss: 1.43655, adv_train_accuracy: 43.75, clean_train_accuracy : 76.56\n",
      "[1,   141] loss: 1.36458, adv_train_accuracy: 45.31, clean_train_accuracy : 76.56\n",
      "[1,   146] loss: 1.24314, adv_train_accuracy: 50.78, clean_train_accuracy : 80.47\n",
      "[1,   151] loss: 1.38107, adv_train_accuracy: 43.75, clean_train_accuracy : 76.56\n",
      "[1,   156] loss: 1.15031, adv_train_accuracy: 57.03, clean_train_accuracy : 84.38\n",
      "[1,   161] loss: 1.32787, adv_train_accuracy: 45.31, clean_train_accuracy : 77.34\n",
      "[1,   166] loss: 1.30457, adv_train_accuracy: 50.00, clean_train_accuracy : 80.47\n",
      "[1,   171] loss: 1.47604, adv_train_accuracy: 42.19, clean_train_accuracy : 77.34\n",
      "[1,   176] loss: 1.33391, adv_train_accuracy: 47.66, clean_train_accuracy : 80.47\n",
      "[1,   181] loss: 1.55539, adv_train_accuracy: 47.66, clean_train_accuracy : 74.22\n",
      "[1,   186] loss: 1.30489, adv_train_accuracy: 53.91, clean_train_accuracy : 79.69\n",
      "[1,   191] loss: 1.34244, adv_train_accuracy: 48.44, clean_train_accuracy : 78.91\n",
      "[1,   196] loss: 1.42201, adv_train_accuracy: 41.41, clean_train_accuracy : 75.78\n",
      "[1,   201] loss: 1.33900, adv_train_accuracy: 50.00, clean_train_accuracy : 72.66\n",
      "[1,   206] loss: 1.28558, adv_train_accuracy: 46.09, clean_train_accuracy : 79.69\n",
      "[1,   211] loss: 1.26493, adv_train_accuracy: 50.00, clean_train_accuracy : 77.34\n",
      "[1,   216] loss: 1.36022, adv_train_accuracy: 45.31, clean_train_accuracy : 76.56\n",
      "[1,   221] loss: 1.14383, adv_train_accuracy: 59.38, clean_train_accuracy : 78.91\n",
      "[1,   226] loss: 1.26730, adv_train_accuracy: 50.78, clean_train_accuracy : 78.91\n",
      "[1,   231] loss: 1.27190, adv_train_accuracy: 53.12, clean_train_accuracy : 75.78\n",
      "[1,   236] loss: 1.32394, adv_train_accuracy: 46.09, clean_train_accuracy : 78.12\n",
      "[1,   241] loss: 1.36706, adv_train_accuracy: 43.75, clean_train_accuracy : 74.22\n",
      "[1,   246] loss: 1.48412, adv_train_accuracy: 47.66, clean_train_accuracy : 77.34\n",
      "[1,   251] loss: 1.26948, adv_train_accuracy: 48.44, clean_train_accuracy : 73.44\n",
      "[1,   256] loss: 1.28687, adv_train_accuracy: 46.09, clean_train_accuracy : 76.56\n",
      "[1,   261] loss: 1.44402, adv_train_accuracy: 45.31, clean_train_accuracy : 77.34\n",
      "[1,   266] loss: 1.18740, adv_train_accuracy: 57.03, clean_train_accuracy : 80.47\n",
      "[1,   271] loss: 1.22759, adv_train_accuracy: 53.12, clean_train_accuracy : 82.03\n",
      "[1,   276] loss: 1.40647, adv_train_accuracy: 50.00, clean_train_accuracy : 72.66\n",
      "[1,   281] loss: 1.17887, adv_train_accuracy: 57.03, clean_train_accuracy : 82.03\n",
      "[1,   286] loss: 1.37357, adv_train_accuracy: 47.66, clean_train_accuracy : 73.44\n",
      "[1,   291] loss: 1.26513, adv_train_accuracy: 50.78, clean_train_accuracy : 82.03\n",
      "[1,   296] loss: 1.44136, adv_train_accuracy: 46.09, clean_train_accuracy : 71.88\n",
      "[1,   301] loss: 1.38044, adv_train_accuracy: 44.53, clean_train_accuracy : 72.66\n",
      "[1,   306] loss: 1.32376, adv_train_accuracy: 52.34, clean_train_accuracy : 75.00\n",
      "[1,   311] loss: 1.41819, adv_train_accuracy: 44.53, clean_train_accuracy : 78.12\n",
      "[1,   316] loss: 1.18577, adv_train_accuracy: 55.47, clean_train_accuracy : 78.12\n",
      "[1,   321] loss: 1.22898, adv_train_accuracy: 50.78, clean_train_accuracy : 80.47\n",
      "[1,   326] loss: 1.44116, adv_train_accuracy: 43.75, clean_train_accuracy : 71.09\n",
      "[1,   331] loss: 1.31325, adv_train_accuracy: 46.09, clean_train_accuracy : 78.91\n",
      "[1,   336] loss: 1.42194, adv_train_accuracy: 43.75, clean_train_accuracy : 71.88\n",
      "[1,   341] loss: 1.55783, adv_train_accuracy: 39.84, clean_train_accuracy : 69.53\n",
      "[1,   346] loss: 1.46845, adv_train_accuracy: 47.66, clean_train_accuracy : 77.34\n",
      "[1,   351] loss: 1.34554, adv_train_accuracy: 46.88, clean_train_accuracy : 73.44\n",
      "[1,   356] loss: 1.22350, adv_train_accuracy: 53.91, clean_train_accuracy : 74.22\n",
      "[1,   361] loss: 1.28547, adv_train_accuracy: 49.22, clean_train_accuracy : 77.34\n",
      "[1,   366] loss: 1.24549, adv_train_accuracy: 47.66, clean_train_accuracy : 79.69\n",
      "[1,   371] loss: 1.23360, adv_train_accuracy: 47.66, clean_train_accuracy : 79.69\n",
      "[1,   376] loss: 1.56107, adv_train_accuracy: 45.31, clean_train_accuracy : 64.84\n",
      "[1,   381] loss: 1.39909, adv_train_accuracy: 45.31, clean_train_accuracy : 75.00\n",
      "[1,   386] loss: 1.16783, adv_train_accuracy: 50.78, clean_train_accuracy : 82.81\n",
      "[1,   391] loss: 1.54279, adv_train_accuracy: 43.75, clean_train_accuracy : 66.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgsm robustness: 0.404296875\n",
      "pgd robustness: 0.3876953125\n",
      "duration: 159 s - train loss: 1.31288 - train accuracy: 49.39 - validation loss: 0.90070 - validation accuracy: 68.85 \n",
      "Finished Training\n",
      "11 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.25682, adv_train_accuracy: 50.78, clean_train_accuracy : 76.56\n",
      "[1,     6] loss: 1.28147, adv_train_accuracy: 50.78, clean_train_accuracy : 82.03\n",
      "[1,    11] loss: 1.04422, adv_train_accuracy: 58.59, clean_train_accuracy : 83.59\n",
      "[1,    16] loss: 1.20133, adv_train_accuracy: 56.25, clean_train_accuracy : 81.25\n",
      "[1,    21] loss: 1.25615, adv_train_accuracy: 55.47, clean_train_accuracy : 81.25\n",
      "[1,    26] loss: 1.25013, adv_train_accuracy: 53.12, clean_train_accuracy : 75.78\n",
      "[1,    31] loss: 1.26853, adv_train_accuracy: 48.44, clean_train_accuracy : 82.81\n",
      "[1,    36] loss: 1.43387, adv_train_accuracy: 50.78, clean_train_accuracy : 76.56\n",
      "[1,    41] loss: 1.20624, adv_train_accuracy: 49.22, clean_train_accuracy : 75.00\n",
      "[1,    46] loss: 1.15889, adv_train_accuracy: 56.25, clean_train_accuracy : 79.69\n",
      "[1,    51] loss: 1.10083, adv_train_accuracy: 54.69, clean_train_accuracy : 82.81\n",
      "[1,    56] loss: 1.13028, adv_train_accuracy: 55.47, clean_train_accuracy : 82.81\n",
      "[1,    61] loss: 1.16073, adv_train_accuracy: 53.91, clean_train_accuracy : 80.47\n",
      "[1,    66] loss: 1.35143, adv_train_accuracy: 49.22, clean_train_accuracy : 76.56\n",
      "[1,    71] loss: 1.30105, adv_train_accuracy: 48.44, clean_train_accuracy : 77.34\n",
      "[1,    76] loss: 1.18001, adv_train_accuracy: 53.91, clean_train_accuracy : 79.69\n",
      "[1,    81] loss: 1.20861, adv_train_accuracy: 48.44, clean_train_accuracy : 78.91\n",
      "[1,    86] loss: 1.24663, adv_train_accuracy: 49.22, clean_train_accuracy : 76.56\n",
      "[1,    91] loss: 1.13624, adv_train_accuracy: 53.91, clean_train_accuracy : 81.25\n",
      "[1,    96] loss: 1.12447, adv_train_accuracy: 59.38, clean_train_accuracy : 82.03\n",
      "[1,   101] loss: 1.10284, adv_train_accuracy: 60.16, clean_train_accuracy : 81.25\n",
      "[1,   106] loss: 1.20636, adv_train_accuracy: 55.47, clean_train_accuracy : 85.94\n",
      "[1,   111] loss: 1.24385, adv_train_accuracy: 53.91, clean_train_accuracy : 84.38\n",
      "[1,   116] loss: 1.23810, adv_train_accuracy: 57.03, clean_train_accuracy : 79.69\n",
      "[1,   121] loss: 1.22676, adv_train_accuracy: 52.34, clean_train_accuracy : 82.81\n",
      "[1,   126] loss: 1.35981, adv_train_accuracy: 44.53, clean_train_accuracy : 82.03\n",
      "[1,   131] loss: 1.26330, adv_train_accuracy: 45.31, clean_train_accuracy : 83.59\n",
      "[1,   136] loss: 1.29389, adv_train_accuracy: 55.47, clean_train_accuracy : 78.91\n",
      "[1,   141] loss: 1.22162, adv_train_accuracy: 57.81, clean_train_accuracy : 80.47\n",
      "[1,   146] loss: 1.27961, adv_train_accuracy: 52.34, clean_train_accuracy : 82.03\n",
      "[1,   151] loss: 1.28641, adv_train_accuracy: 44.53, clean_train_accuracy : 77.34\n",
      "[1,   156] loss: 1.25510, adv_train_accuracy: 53.91, clean_train_accuracy : 79.69\n",
      "[1,   161] loss: 1.15475, adv_train_accuracy: 57.03, clean_train_accuracy : 77.34\n",
      "[1,   166] loss: 1.32706, adv_train_accuracy: 44.53, clean_train_accuracy : 74.22\n",
      "[1,   171] loss: 1.35290, adv_train_accuracy: 45.31, clean_train_accuracy : 78.12\n",
      "[1,   176] loss: 1.13024, adv_train_accuracy: 57.03, clean_train_accuracy : 83.59\n",
      "[1,   181] loss: 1.12510, adv_train_accuracy: 61.72, clean_train_accuracy : 78.91\n",
      "[1,   186] loss: 1.28181, adv_train_accuracy: 51.56, clean_train_accuracy : 79.69\n",
      "[1,   191] loss: 1.21733, adv_train_accuracy: 47.66, clean_train_accuracy : 85.16\n",
      "[1,   196] loss: 1.10360, adv_train_accuracy: 58.59, clean_train_accuracy : 80.47\n",
      "[1,   201] loss: 1.20171, adv_train_accuracy: 54.69, clean_train_accuracy : 81.25\n",
      "[1,   206] loss: 1.17963, adv_train_accuracy: 54.69, clean_train_accuracy : 83.59\n",
      "[1,   211] loss: 1.21685, adv_train_accuracy: 53.91, clean_train_accuracy : 78.12\n",
      "[1,   216] loss: 1.46935, adv_train_accuracy: 44.53, clean_train_accuracy : 80.47\n",
      "[1,   221] loss: 1.25834, adv_train_accuracy: 50.78, clean_train_accuracy : 77.34\n",
      "[1,   226] loss: 1.13011, adv_train_accuracy: 51.56, clean_train_accuracy : 86.72\n",
      "[1,   231] loss: 1.20635, adv_train_accuracy: 46.88, clean_train_accuracy : 84.38\n",
      "[1,   236] loss: 1.22015, adv_train_accuracy: 51.56, clean_train_accuracy : 85.94\n",
      "[1,   241] loss: 1.45007, adv_train_accuracy: 42.19, clean_train_accuracy : 75.00\n",
      "[1,   246] loss: 1.28738, adv_train_accuracy: 53.12, clean_train_accuracy : 72.66\n",
      "[1,   251] loss: 1.18783, adv_train_accuracy: 53.91, clean_train_accuracy : 79.69\n",
      "[1,   256] loss: 1.25182, adv_train_accuracy: 47.66, clean_train_accuracy : 78.12\n",
      "[1,   261] loss: 1.33615, adv_train_accuracy: 53.12, clean_train_accuracy : 75.00\n",
      "[1,   266] loss: 1.28794, adv_train_accuracy: 46.09, clean_train_accuracy : 77.34\n",
      "[1,   271] loss: 1.10204, adv_train_accuracy: 52.34, clean_train_accuracy : 87.50\n",
      "[1,   276] loss: 1.36942, adv_train_accuracy: 49.22, clean_train_accuracy : 76.56\n",
      "[1,   281] loss: 1.15338, adv_train_accuracy: 56.25, clean_train_accuracy : 80.47\n",
      "[1,   286] loss: 1.27484, adv_train_accuracy: 53.12, clean_train_accuracy : 77.34\n",
      "[1,   291] loss: 1.36047, adv_train_accuracy: 46.88, clean_train_accuracy : 77.34\n",
      "[1,   296] loss: 1.05840, adv_train_accuracy: 59.38, clean_train_accuracy : 82.81\n",
      "[1,   301] loss: 1.11902, adv_train_accuracy: 57.03, clean_train_accuracy : 82.81\n",
      "[1,   306] loss: 1.08114, adv_train_accuracy: 57.03, clean_train_accuracy : 82.81\n",
      "[1,   311] loss: 1.31261, adv_train_accuracy: 48.44, clean_train_accuracy : 76.56\n",
      "[1,   316] loss: 1.21570, adv_train_accuracy: 53.12, clean_train_accuracy : 84.38\n",
      "[1,   321] loss: 1.29514, adv_train_accuracy: 53.12, clean_train_accuracy : 78.12\n",
      "[1,   326] loss: 1.20949, adv_train_accuracy: 50.78, clean_train_accuracy : 80.47\n",
      "[1,   331] loss: 1.25440, adv_train_accuracy: 46.88, clean_train_accuracy : 82.81\n",
      "[1,   336] loss: 1.19706, adv_train_accuracy: 56.25, clean_train_accuracy : 83.59\n",
      "[1,   341] loss: 1.24949, adv_train_accuracy: 53.12, clean_train_accuracy : 82.81\n",
      "[1,   346] loss: 1.24428, adv_train_accuracy: 50.78, clean_train_accuracy : 85.16\n",
      "[1,   351] loss: 1.26095, adv_train_accuracy: 47.66, clean_train_accuracy : 77.34\n",
      "[1,   356] loss: 1.34822, adv_train_accuracy: 43.75, clean_train_accuracy : 72.66\n",
      "[1,   361] loss: 1.13388, adv_train_accuracy: 57.03, clean_train_accuracy : 82.81\n",
      "[1,   366] loss: 1.29970, adv_train_accuracy: 52.34, clean_train_accuracy : 77.34\n",
      "[1,   371] loss: 1.20041, adv_train_accuracy: 48.44, clean_train_accuracy : 78.12\n",
      "[1,   376] loss: 1.18987, adv_train_accuracy: 53.12, clean_train_accuracy : 82.03\n",
      "[1,   381] loss: 1.24081, adv_train_accuracy: 48.44, clean_train_accuracy : 78.12\n",
      "[1,   386] loss: 1.20861, adv_train_accuracy: 47.66, clean_train_accuracy : 79.69\n",
      "[1,   391] loss: 0.96764, adv_train_accuracy: 62.50, clean_train_accuracy : 87.50\n",
      "fgsm robustness: 0.412109375\n",
      "pgd robustness: 0.373046875\n",
      "duration: 159 s - train loss: 1.23134 - train accuracy: 52.29 - validation loss: 0.88144 - validation accuracy: 69.84 \n",
      "Finished Training\n",
      "12 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.32235, adv_train_accuracy: 47.66, clean_train_accuracy : 73.44\n",
      "[1,     6] loss: 1.28377, adv_train_accuracy: 51.56, clean_train_accuracy : 79.69\n",
      "[1,    11] loss: 1.14682, adv_train_accuracy: 47.66, clean_train_accuracy : 80.47\n",
      "[1,    16] loss: 1.08035, adv_train_accuracy: 60.16, clean_train_accuracy : 85.94\n",
      "[1,    21] loss: 1.08959, adv_train_accuracy: 57.03, clean_train_accuracy : 82.03\n",
      "[1,    26] loss: 1.06078, adv_train_accuracy: 60.16, clean_train_accuracy : 89.84\n",
      "[1,    31] loss: 1.15309, adv_train_accuracy: 55.47, clean_train_accuracy : 88.28\n",
      "[1,    36] loss: 1.21398, adv_train_accuracy: 50.78, clean_train_accuracy : 78.91\n",
      "[1,    41] loss: 1.12428, adv_train_accuracy: 52.34, clean_train_accuracy : 85.16\n",
      "[1,    46] loss: 1.04845, adv_train_accuracy: 58.59, clean_train_accuracy : 86.72\n",
      "[1,    51] loss: 1.12586, adv_train_accuracy: 54.69, clean_train_accuracy : 85.94\n",
      "[1,    56] loss: 1.14044, adv_train_accuracy: 58.59, clean_train_accuracy : 85.16\n",
      "[1,    61] loss: 1.05778, adv_train_accuracy: 60.16, clean_train_accuracy : 86.72\n",
      "[1,    66] loss: 1.17593, adv_train_accuracy: 56.25, clean_train_accuracy : 82.03\n",
      "[1,    71] loss: 1.03856, adv_train_accuracy: 59.38, clean_train_accuracy : 83.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    76] loss: 1.13522, adv_train_accuracy: 58.59, clean_train_accuracy : 82.03\n",
      "[1,    81] loss: 1.08984, adv_train_accuracy: 58.59, clean_train_accuracy : 81.25\n",
      "[1,    86] loss: 1.14522, adv_train_accuracy: 58.59, clean_train_accuracy : 83.59\n",
      "[1,    91] loss: 1.07520, adv_train_accuracy: 57.03, clean_train_accuracy : 83.59\n",
      "[1,    96] loss: 1.16688, adv_train_accuracy: 56.25, clean_train_accuracy : 86.72\n",
      "[1,   101] loss: 1.17746, adv_train_accuracy: 53.91, clean_train_accuracy : 80.47\n",
      "[1,   106] loss: 2.12149, adv_train_accuracy: 36.72, clean_train_accuracy : 79.69\n",
      "[1,   111] loss: 1.42767, adv_train_accuracy: 44.53, clean_train_accuracy : 75.78\n",
      "[1,   116] loss: 1.61273, adv_train_accuracy: 47.66, clean_train_accuracy : 74.22\n",
      "[1,   121] loss: 1.58061, adv_train_accuracy: 46.88, clean_train_accuracy : 73.44\n",
      "[1,   126] loss: 1.38323, adv_train_accuracy: 50.00, clean_train_accuracy : 75.78\n",
      "[1,   131] loss: 1.39183, adv_train_accuracy: 46.88, clean_train_accuracy : 78.12\n",
      "[1,   136] loss: 1.33778, adv_train_accuracy: 50.00, clean_train_accuracy : 78.91\n",
      "[1,   141] loss: 1.45288, adv_train_accuracy: 39.84, clean_train_accuracy : 71.88\n",
      "[1,   146] loss: 1.37830, adv_train_accuracy: 47.66, clean_train_accuracy : 75.00\n",
      "[1,   151] loss: 1.51337, adv_train_accuracy: 49.22, clean_train_accuracy : 78.12\n",
      "[1,   156] loss: 1.27889, adv_train_accuracy: 51.56, clean_train_accuracy : 85.94\n",
      "[1,   161] loss: 1.38596, adv_train_accuracy: 46.09, clean_train_accuracy : 80.47\n",
      "[1,   166] loss: 1.28369, adv_train_accuracy: 47.66, clean_train_accuracy : 79.69\n",
      "[1,   171] loss: 1.23139, adv_train_accuracy: 50.78, clean_train_accuracy : 78.12\n",
      "[1,   176] loss: 1.31939, adv_train_accuracy: 43.75, clean_train_accuracy : 82.81\n",
      "[1,   181] loss: 1.22769, adv_train_accuracy: 58.59, clean_train_accuracy : 82.03\n",
      "[1,   186] loss: 1.18063, adv_train_accuracy: 50.78, clean_train_accuracy : 82.03\n",
      "[1,   191] loss: 1.32205, adv_train_accuracy: 46.09, clean_train_accuracy : 80.47\n",
      "[1,   196] loss: 1.34629, adv_train_accuracy: 46.88, clean_train_accuracy : 75.00\n",
      "[1,   201] loss: 1.28571, adv_train_accuracy: 46.88, clean_train_accuracy : 78.12\n",
      "[1,   206] loss: 1.15994, adv_train_accuracy: 53.12, clean_train_accuracy : 80.47\n",
      "[1,   211] loss: 1.23117, adv_train_accuracy: 46.09, clean_train_accuracy : 86.72\n",
      "[1,   216] loss: 1.31223, adv_train_accuracy: 46.88, clean_train_accuracy : 82.03\n",
      "[1,   221] loss: 1.27914, adv_train_accuracy: 52.34, clean_train_accuracy : 78.91\n",
      "[1,   226] loss: 1.18705, adv_train_accuracy: 55.47, clean_train_accuracy : 82.03\n",
      "[1,   231] loss: 1.32109, adv_train_accuracy: 50.00, clean_train_accuracy : 81.25\n",
      "[1,   236] loss: 1.22840, adv_train_accuracy: 53.91, clean_train_accuracy : 79.69\n",
      "[1,   241] loss: 1.11942, adv_train_accuracy: 58.59, clean_train_accuracy : 80.47\n",
      "[1,   246] loss: 1.27645, adv_train_accuracy: 47.66, clean_train_accuracy : 78.91\n",
      "[1,   251] loss: 1.52370, adv_train_accuracy: 42.97, clean_train_accuracy : 71.88\n",
      "[1,   256] loss: 1.27899, adv_train_accuracy: 49.22, clean_train_accuracy : 81.25\n",
      "[1,   261] loss: 1.01699, adv_train_accuracy: 64.84, clean_train_accuracy : 87.50\n",
      "[1,   266] loss: 1.14813, adv_train_accuracy: 56.25, clean_train_accuracy : 83.59\n",
      "[1,   271] loss: 1.21089, adv_train_accuracy: 53.12, clean_train_accuracy : 80.47\n",
      "[1,   276] loss: 1.05149, adv_train_accuracy: 58.59, clean_train_accuracy : 89.06\n",
      "[1,   281] loss: 1.06201, adv_train_accuracy: 60.16, clean_train_accuracy : 85.16\n",
      "[1,   286] loss: 1.09220, adv_train_accuracy: 54.69, clean_train_accuracy : 81.25\n",
      "[1,   291] loss: 1.28210, adv_train_accuracy: 42.97, clean_train_accuracy : 88.28\n",
      "[1,   296] loss: 1.29855, adv_train_accuracy: 51.56, clean_train_accuracy : 84.38\n",
      "[1,   301] loss: 1.24835, adv_train_accuracy: 46.88, clean_train_accuracy : 82.81\n",
      "[1,   306] loss: 1.03873, adv_train_accuracy: 58.59, clean_train_accuracy : 84.38\n",
      "[1,   311] loss: 1.14980, adv_train_accuracy: 47.66, clean_train_accuracy : 86.72\n",
      "[1,   316] loss: 1.15527, adv_train_accuracy: 53.91, clean_train_accuracy : 85.16\n",
      "[1,   321] loss: 1.24290, adv_train_accuracy: 49.22, clean_train_accuracy : 80.47\n",
      "[1,   326] loss: 1.25630, adv_train_accuracy: 50.78, clean_train_accuracy : 78.12\n",
      "[1,   331] loss: 1.13390, adv_train_accuracy: 57.03, clean_train_accuracy : 85.16\n",
      "[1,   336] loss: 1.20625, adv_train_accuracy: 56.25, clean_train_accuracy : 79.69\n",
      "[1,   341] loss: 1.10685, adv_train_accuracy: 53.91, clean_train_accuracy : 85.94\n",
      "[1,   346] loss: 1.28584, adv_train_accuracy: 48.44, clean_train_accuracy : 85.16\n",
      "[1,   351] loss: 1.15731, adv_train_accuracy: 53.91, clean_train_accuracy : 85.94\n",
      "[1,   356] loss: 1.14895, adv_train_accuracy: 50.78, clean_train_accuracy : 90.62\n",
      "[1,   361] loss: 1.13718, adv_train_accuracy: 53.12, clean_train_accuracy : 84.38\n",
      "[1,   366] loss: 1.39629, adv_train_accuracy: 48.44, clean_train_accuracy : 83.59\n",
      "[1,   371] loss: 1.25399, adv_train_accuracy: 42.97, clean_train_accuracy : 80.47\n",
      "[1,   376] loss: 1.19690, adv_train_accuracy: 56.25, clean_train_accuracy : 82.03\n",
      "[1,   381] loss: 1.29409, adv_train_accuracy: 52.34, clean_train_accuracy : 77.34\n",
      "[1,   386] loss: 1.29342, adv_train_accuracy: 49.22, clean_train_accuracy : 80.47\n",
      "[1,   391] loss: 1.10688, adv_train_accuracy: 51.25, clean_train_accuracy : 90.00\n",
      "fgsm robustness: 0.3779296875\n",
      "pgd robustness: 0.3466796875\n",
      "duration: 159 s - train loss: 1.20239 - train accuracy: 53.15 - validation loss: 0.83423 - validation accuracy: 71.11 \n",
      "Finished Training\n",
      "13 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 1.04615, adv_train_accuracy: 59.38, clean_train_accuracy : 82.03\n",
      "[1,     6] loss: 1.06491, adv_train_accuracy: 60.16, clean_train_accuracy : 86.72\n",
      "[1,    11] loss: 1.08534, adv_train_accuracy: 64.84, clean_train_accuracy : 87.50\n",
      "[1,    16] loss: 0.98514, adv_train_accuracy: 59.38, clean_train_accuracy : 85.94\n",
      "[1,    21] loss: 1.07396, adv_train_accuracy: 60.16, clean_train_accuracy : 85.16\n",
      "[1,    26] loss: 1.23596, adv_train_accuracy: 47.66, clean_train_accuracy : 82.81\n",
      "[1,    31] loss: 1.11472, adv_train_accuracy: 57.81, clean_train_accuracy : 82.03\n",
      "[1,    36] loss: 1.20203, adv_train_accuracy: 52.34, clean_train_accuracy : 79.69\n",
      "[1,    41] loss: 1.18489, adv_train_accuracy: 55.47, clean_train_accuracy : 81.25\n",
      "[1,    46] loss: 1.04559, adv_train_accuracy: 60.94, clean_train_accuracy : 85.94\n",
      "[1,    51] loss: 0.97730, adv_train_accuracy: 60.94, clean_train_accuracy : 84.38\n",
      "[1,    56] loss: 0.92697, adv_train_accuracy: 61.72, clean_train_accuracy : 92.97\n",
      "[1,    61] loss: 0.99256, adv_train_accuracy: 59.38, clean_train_accuracy : 87.50\n",
      "[1,    66] loss: 0.97132, adv_train_accuracy: 59.38, clean_train_accuracy : 89.06\n",
      "[1,    71] loss: 1.00476, adv_train_accuracy: 57.81, clean_train_accuracy : 86.72\n",
      "[1,    76] loss: 1.10781, adv_train_accuracy: 57.81, clean_train_accuracy : 88.28\n",
      "[1,    81] loss: 1.05587, adv_train_accuracy: 58.59, clean_train_accuracy : 85.94\n",
      "[1,    86] loss: 1.24783, adv_train_accuracy: 46.88, clean_train_accuracy : 82.03\n",
      "[1,    91] loss: 1.13113, adv_train_accuracy: 54.69, clean_train_accuracy : 82.81\n",
      "[1,    96] loss: 1.14486, adv_train_accuracy: 52.34, clean_train_accuracy : 86.72\n",
      "[1,   101] loss: 1.14484, adv_train_accuracy: 56.25, clean_train_accuracy : 84.38\n",
      "[1,   106] loss: 0.99341, adv_train_accuracy: 64.84, clean_train_accuracy : 85.16\n",
      "[1,   111] loss: 1.13418, adv_train_accuracy: 50.78, clean_train_accuracy : 80.47\n",
      "[1,   116] loss: 1.11342, adv_train_accuracy: 54.69, clean_train_accuracy : 87.50\n",
      "[1,   121] loss: 1.12934, adv_train_accuracy: 57.03, clean_train_accuracy : 87.50\n",
      "[1,   126] loss: 1.09956, adv_train_accuracy: 55.47, clean_train_accuracy : 87.50\n",
      "[1,   131] loss: 1.04194, adv_train_accuracy: 58.59, clean_train_accuracy : 82.03\n",
      "[1,   136] loss: 0.98619, adv_train_accuracy: 60.94, clean_train_accuracy : 87.50\n",
      "[1,   141] loss: 1.11982, adv_train_accuracy: 59.38, clean_train_accuracy : 83.59\n",
      "[1,   146] loss: 1.15384, adv_train_accuracy: 55.47, clean_train_accuracy : 81.25\n",
      "[1,   151] loss: 0.96181, adv_train_accuracy: 59.38, clean_train_accuracy : 85.94\n",
      "[1,   156] loss: 0.94069, adv_train_accuracy: 65.62, clean_train_accuracy : 86.72\n",
      "[1,   161] loss: 1.05397, adv_train_accuracy: 64.84, clean_train_accuracy : 85.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   166] loss: 1.12447, adv_train_accuracy: 59.38, clean_train_accuracy : 86.72\n",
      "[1,   171] loss: 1.15878, adv_train_accuracy: 53.12, clean_train_accuracy : 84.38\n",
      "[1,   176] loss: 1.11202, adv_train_accuracy: 55.47, clean_train_accuracy : 87.50\n",
      "[1,   181] loss: 1.19100, adv_train_accuracy: 57.03, clean_train_accuracy : 81.25\n",
      "[1,   186] loss: 1.07098, adv_train_accuracy: 57.81, clean_train_accuracy : 85.94\n",
      "[1,   191] loss: 1.15197, adv_train_accuracy: 48.44, clean_train_accuracy : 82.03\n",
      "[1,   196] loss: 1.03590, adv_train_accuracy: 60.94, clean_train_accuracy : 87.50\n",
      "[1,   201] loss: 1.16968, adv_train_accuracy: 56.25, clean_train_accuracy : 87.50\n",
      "[1,   206] loss: 1.08750, adv_train_accuracy: 56.25, clean_train_accuracy : 86.72\n",
      "[1,   211] loss: 1.06891, adv_train_accuracy: 52.34, clean_train_accuracy : 89.84\n",
      "[1,   216] loss: 1.19153, adv_train_accuracy: 53.12, clean_train_accuracy : 83.59\n",
      "[1,   221] loss: 1.21244, adv_train_accuracy: 53.91, clean_train_accuracy : 82.03\n",
      "[1,   226] loss: 0.89604, adv_train_accuracy: 58.59, clean_train_accuracy : 91.41\n",
      "[1,   231] loss: 1.18656, adv_train_accuracy: 50.78, clean_train_accuracy : 82.81\n",
      "[1,   236] loss: 1.16398, adv_train_accuracy: 56.25, clean_train_accuracy : 82.81\n",
      "[1,   241] loss: 1.05756, adv_train_accuracy: 60.16, clean_train_accuracy : 85.94\n",
      "[1,   246] loss: 1.10029, adv_train_accuracy: 54.69, clean_train_accuracy : 90.62\n",
      "[1,   251] loss: 0.88383, adv_train_accuracy: 63.28, clean_train_accuracy : 88.28\n",
      "[1,   256] loss: 1.11456, adv_train_accuracy: 58.59, clean_train_accuracy : 84.38\n",
      "[1,   261] loss: 0.98384, adv_train_accuracy: 60.94, clean_train_accuracy : 90.62\n",
      "[1,   266] loss: 1.04589, adv_train_accuracy: 60.16, clean_train_accuracy : 85.94\n",
      "[1,   271] loss: 1.19879, adv_train_accuracy: 50.78, clean_train_accuracy : 78.12\n",
      "[1,   276] loss: 1.00146, adv_train_accuracy: 60.16, clean_train_accuracy : 87.50\n",
      "[1,   281] loss: 1.26993, adv_train_accuracy: 50.78, clean_train_accuracy : 80.47\n",
      "[1,   286] loss: 1.08455, adv_train_accuracy: 54.69, clean_train_accuracy : 85.94\n",
      "[1,   291] loss: 1.02443, adv_train_accuracy: 57.81, clean_train_accuracy : 90.62\n",
      "[1,   296] loss: 1.20638, adv_train_accuracy: 46.09, clean_train_accuracy : 85.94\n",
      "[1,   301] loss: 1.00393, adv_train_accuracy: 64.84, clean_train_accuracy : 87.50\n",
      "[1,   306] loss: 1.24830, adv_train_accuracy: 53.91, clean_train_accuracy : 85.16\n",
      "[1,   311] loss: 0.96064, adv_train_accuracy: 58.59, clean_train_accuracy : 92.97\n",
      "[1,   316] loss: 1.15683, adv_train_accuracy: 53.12, clean_train_accuracy : 85.16\n",
      "[1,   321] loss: 1.12441, adv_train_accuracy: 54.69, clean_train_accuracy : 83.59\n",
      "[1,   326] loss: 1.00841, adv_train_accuracy: 64.06, clean_train_accuracy : 89.84\n",
      "[1,   331] loss: 1.14553, adv_train_accuracy: 53.12, clean_train_accuracy : 88.28\n",
      "[1,   336] loss: 1.14016, adv_train_accuracy: 48.44, clean_train_accuracy : 86.72\n",
      "[1,   341] loss: 1.23556, adv_train_accuracy: 50.78, clean_train_accuracy : 83.59\n",
      "[1,   346] loss: 1.22450, adv_train_accuracy: 52.34, clean_train_accuracy : 82.81\n",
      "[1,   351] loss: 1.13705, adv_train_accuracy: 50.78, clean_train_accuracy : 85.94\n",
      "[1,   356] loss: 1.32557, adv_train_accuracy: 50.00, clean_train_accuracy : 77.34\n",
      "[1,   361] loss: 0.97532, adv_train_accuracy: 63.28, clean_train_accuracy : 89.06\n",
      "[1,   366] loss: 1.23627, adv_train_accuracy: 50.00, clean_train_accuracy : 85.16\n",
      "[1,   371] loss: 1.15234, adv_train_accuracy: 52.34, clean_train_accuracy : 84.38\n",
      "[1,   376] loss: 1.11207, adv_train_accuracy: 59.38, clean_train_accuracy : 86.72\n",
      "[1,   381] loss: 1.23732, adv_train_accuracy: 49.22, clean_train_accuracy : 82.03\n",
      "[1,   386] loss: 1.19248, adv_train_accuracy: 52.34, clean_train_accuracy : 81.25\n",
      "[1,   391] loss: 1.06722, adv_train_accuracy: 62.50, clean_train_accuracy : 82.50\n",
      "fgsm robustness: 0.404296875\n",
      "pgd robustness: 0.373046875\n",
      "duration: 159 s - train loss: 1.08842 - train accuracy: 57.22 - validation loss: 0.84704 - validation accuracy: 70.24 \n",
      "Finished Training\n",
      "14 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.93652, adv_train_accuracy: 64.84, clean_train_accuracy : 92.19\n",
      "[1,     6] loss: 0.92726, adv_train_accuracy: 57.81, clean_train_accuracy : 91.41\n",
      "[1,    11] loss: 0.83674, adv_train_accuracy: 69.53, clean_train_accuracy : 91.41\n",
      "[1,    16] loss: 0.75747, adv_train_accuracy: 70.31, clean_train_accuracy : 87.50\n",
      "[1,    21] loss: 0.98887, adv_train_accuracy: 62.50, clean_train_accuracy : 87.50\n",
      "[1,    26] loss: 0.86392, adv_train_accuracy: 68.75, clean_train_accuracy : 92.97\n",
      "[1,    31] loss: 1.22558, adv_train_accuracy: 49.22, clean_train_accuracy : 85.94\n",
      "[1,    36] loss: 0.86620, adv_train_accuracy: 64.06, clean_train_accuracy : 92.97\n",
      "[1,    41] loss: 0.97297, adv_train_accuracy: 61.72, clean_train_accuracy : 89.06\n",
      "[1,    46] loss: 1.03751, adv_train_accuracy: 62.50, clean_train_accuracy : 84.38\n",
      "[1,    51] loss: 0.93397, adv_train_accuracy: 67.19, clean_train_accuracy : 86.72\n",
      "[1,    56] loss: 0.98195, adv_train_accuracy: 60.94, clean_train_accuracy : 90.62\n",
      "[1,    61] loss: 0.86137, adv_train_accuracy: 62.50, clean_train_accuracy : 87.50\n",
      "[1,    66] loss: 0.86304, adv_train_accuracy: 65.62, clean_train_accuracy : 90.62\n",
      "[1,    71] loss: 1.13960, adv_train_accuracy: 57.81, clean_train_accuracy : 85.94\n",
      "[1,    76] loss: 0.94239, adv_train_accuracy: 63.28, clean_train_accuracy : 88.28\n",
      "[1,    81] loss: 0.91258, adv_train_accuracy: 64.84, clean_train_accuracy : 89.84\n",
      "[1,    86] loss: 0.87107, adv_train_accuracy: 64.06, clean_train_accuracy : 90.62\n",
      "[1,    91] loss: 1.11246, adv_train_accuracy: 50.78, clean_train_accuracy : 85.16\n",
      "[1,    96] loss: 1.04892, adv_train_accuracy: 56.25, clean_train_accuracy : 91.41\n",
      "[1,   101] loss: 0.81629, adv_train_accuracy: 70.31, clean_train_accuracy : 92.19\n",
      "[1,   106] loss: 1.01239, adv_train_accuracy: 60.94, clean_train_accuracy : 87.50\n",
      "[1,   111] loss: 1.02556, adv_train_accuracy: 60.16, clean_train_accuracy : 85.16\n",
      "[1,   116] loss: 1.03282, adv_train_accuracy: 60.16, clean_train_accuracy : 83.59\n",
      "[1,   121] loss: 0.94527, adv_train_accuracy: 69.53, clean_train_accuracy : 89.84\n",
      "[1,   126] loss: 0.93688, adv_train_accuracy: 65.62, clean_train_accuracy : 87.50\n",
      "[1,   131] loss: 1.06348, adv_train_accuracy: 60.16, clean_train_accuracy : 89.84\n",
      "[1,   136] loss: 0.90513, adv_train_accuracy: 62.50, clean_train_accuracy : 86.72\n",
      "[1,   141] loss: 1.09792, adv_train_accuracy: 52.34, clean_train_accuracy : 84.38\n",
      "[1,   146] loss: 0.94034, adv_train_accuracy: 63.28, clean_train_accuracy : 94.53\n",
      "[1,   151] loss: 1.05986, adv_train_accuracy: 55.47, clean_train_accuracy : 88.28\n",
      "[1,   156] loss: 0.93822, adv_train_accuracy: 63.28, clean_train_accuracy : 90.62\n",
      "[1,   161] loss: 1.07381, adv_train_accuracy: 57.81, clean_train_accuracy : 89.84\n",
      "[1,   166] loss: 1.07348, adv_train_accuracy: 52.34, clean_train_accuracy : 92.19\n",
      "[1,   171] loss: 1.07310, adv_train_accuracy: 58.59, clean_train_accuracy : 85.16\n",
      "[1,   176] loss: 0.96014, adv_train_accuracy: 61.72, clean_train_accuracy : 89.84\n",
      "[1,   181] loss: 1.29886, adv_train_accuracy: 49.22, clean_train_accuracy : 89.06\n",
      "[1,   186] loss: 1.19554, adv_train_accuracy: 52.34, clean_train_accuracy : 87.50\n",
      "[1,   191] loss: 1.20362, adv_train_accuracy: 53.12, clean_train_accuracy : 83.59\n",
      "[1,   196] loss: 1.17600, adv_train_accuracy: 50.78, clean_train_accuracy : 87.50\n",
      "[1,   201] loss: 1.12524, adv_train_accuracy: 55.47, clean_train_accuracy : 85.94\n",
      "[1,   206] loss: 1.20642, adv_train_accuracy: 46.09, clean_train_accuracy : 82.03\n",
      "[1,   211] loss: 1.19219, adv_train_accuracy: 51.56, clean_train_accuracy : 85.16\n",
      "[1,   216] loss: 1.19652, adv_train_accuracy: 54.69, clean_train_accuracy : 85.94\n",
      "[1,   221] loss: 1.15657, adv_train_accuracy: 53.91, clean_train_accuracy : 86.72\n",
      "[1,   226] loss: 0.99692, adv_train_accuracy: 58.59, clean_train_accuracy : 83.59\n",
      "[1,   231] loss: 1.12002, adv_train_accuracy: 57.81, clean_train_accuracy : 82.81\n",
      "[1,   236] loss: 1.10170, adv_train_accuracy: 58.59, clean_train_accuracy : 85.94\n",
      "[1,   241] loss: 1.25700, adv_train_accuracy: 46.88, clean_train_accuracy : 85.16\n",
      "[1,   246] loss: 1.11351, adv_train_accuracy: 60.94, clean_train_accuracy : 85.94\n",
      "[1,   251] loss: 0.99627, adv_train_accuracy: 56.25, clean_train_accuracy : 91.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   256] loss: 1.11009, adv_train_accuracy: 59.38, clean_train_accuracy : 82.03\n",
      "[1,   261] loss: 0.97419, adv_train_accuracy: 59.38, clean_train_accuracy : 87.50\n",
      "[1,   266] loss: 1.07126, adv_train_accuracy: 60.16, clean_train_accuracy : 86.72\n",
      "[1,   271] loss: 1.13988, adv_train_accuracy: 57.81, clean_train_accuracy : 80.47\n",
      "[1,   276] loss: 1.04499, adv_train_accuracy: 55.47, clean_train_accuracy : 87.50\n",
      "[1,   281] loss: 1.05933, adv_train_accuracy: 60.94, clean_train_accuracy : 85.16\n",
      "[1,   286] loss: 1.08172, adv_train_accuracy: 53.91, clean_train_accuracy : 79.69\n",
      "[1,   291] loss: 1.01645, adv_train_accuracy: 58.59, clean_train_accuracy : 89.84\n",
      "[1,   296] loss: 1.17728, adv_train_accuracy: 45.31, clean_train_accuracy : 92.19\n",
      "[1,   301] loss: 0.90709, adv_train_accuracy: 64.84, clean_train_accuracy : 90.62\n",
      "[1,   306] loss: 1.09655, adv_train_accuracy: 53.91, clean_train_accuracy : 86.72\n",
      "[1,   311] loss: 1.16486, adv_train_accuracy: 52.34, clean_train_accuracy : 84.38\n",
      "[1,   316] loss: 0.98861, adv_train_accuracy: 64.06, clean_train_accuracy : 91.41\n",
      "[1,   321] loss: 1.07872, adv_train_accuracy: 57.03, clean_train_accuracy : 82.03\n",
      "[1,   326] loss: 1.13462, adv_train_accuracy: 57.03, clean_train_accuracy : 84.38\n",
      "[1,   331] loss: 1.15249, adv_train_accuracy: 48.44, clean_train_accuracy : 87.50\n",
      "[1,   336] loss: 0.95539, adv_train_accuracy: 64.84, clean_train_accuracy : 89.06\n",
      "[1,   341] loss: 1.04162, adv_train_accuracy: 55.47, clean_train_accuracy : 92.97\n",
      "[1,   346] loss: 1.01366, adv_train_accuracy: 58.59, clean_train_accuracy : 87.50\n",
      "[1,   351] loss: 1.02760, adv_train_accuracy: 60.16, clean_train_accuracy : 85.94\n",
      "[1,   356] loss: 0.96517, adv_train_accuracy: 61.72, clean_train_accuracy : 90.62\n",
      "[1,   361] loss: 0.88040, adv_train_accuracy: 61.72, clean_train_accuracy : 91.41\n",
      "[1,   366] loss: 1.00081, adv_train_accuracy: 60.16, clean_train_accuracy : 89.84\n",
      "[1,   371] loss: 1.03350, adv_train_accuracy: 58.59, clean_train_accuracy : 87.50\n",
      "[1,   376] loss: 1.19732, adv_train_accuracy: 53.91, clean_train_accuracy : 86.72\n",
      "[1,   381] loss: 1.07236, adv_train_accuracy: 56.25, clean_train_accuracy : 86.72\n",
      "[1,   386] loss: 0.99910, adv_train_accuracy: 57.81, clean_train_accuracy : 89.06\n",
      "[1,   391] loss: 1.18355, adv_train_accuracy: 48.75, clean_train_accuracy : 87.50\n",
      "fgsm robustness: 0.3857421875\n",
      "pgd robustness: 0.3193359375\n",
      "duration: 158 s - train loss: 1.02164 - train accuracy: 59.14 - validation loss: 0.80890 - validation accuracy: 72.54 \n",
      "Finished Training\n",
      "15 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.90167, adv_train_accuracy: 63.28, clean_train_accuracy : 93.75\n",
      "[1,     6] loss: 1.07695, adv_train_accuracy: 54.69, clean_train_accuracy : 89.06\n",
      "[1,    11] loss: 0.82731, adv_train_accuracy: 68.75, clean_train_accuracy : 89.84\n",
      "[1,    16] loss: 0.95233, adv_train_accuracy: 62.50, clean_train_accuracy : 89.84\n",
      "[1,    21] loss: 0.99615, adv_train_accuracy: 60.16, clean_train_accuracy : 90.62\n",
      "[1,    26] loss: 0.89910, adv_train_accuracy: 63.28, clean_train_accuracy : 90.62\n",
      "[1,    31] loss: 0.69059, adv_train_accuracy: 78.12, clean_train_accuracy : 94.53\n",
      "[1,    36] loss: 0.80299, adv_train_accuracy: 67.97, clean_train_accuracy : 93.75\n",
      "[1,    41] loss: 0.96995, adv_train_accuracy: 60.16, clean_train_accuracy : 90.62\n",
      "[1,    46] loss: 0.97825, adv_train_accuracy: 59.38, clean_train_accuracy : 87.50\n",
      "[1,    51] loss: 0.93732, adv_train_accuracy: 58.59, clean_train_accuracy : 91.41\n",
      "[1,    56] loss: 1.00359, adv_train_accuracy: 57.03, clean_train_accuracy : 93.75\n",
      "[1,    61] loss: 0.87702, adv_train_accuracy: 64.84, clean_train_accuracy : 88.28\n",
      "[1,    66] loss: 0.82232, adv_train_accuracy: 61.72, clean_train_accuracy : 89.06\n",
      "[1,    71] loss: 0.83492, adv_train_accuracy: 67.97, clean_train_accuracy : 95.31\n",
      "[1,    76] loss: 0.80344, adv_train_accuracy: 66.41, clean_train_accuracy : 90.62\n",
      "[1,    81] loss: 0.88488, adv_train_accuracy: 67.97, clean_train_accuracy : 91.41\n",
      "[1,    86] loss: 0.84417, adv_train_accuracy: 64.06, clean_train_accuracy : 92.97\n",
      "[1,    91] loss: 1.06348, adv_train_accuracy: 60.16, clean_train_accuracy : 88.28\n",
      "[1,    96] loss: 0.92136, adv_train_accuracy: 58.59, clean_train_accuracy : 89.84\n",
      "[1,   101] loss: 0.84301, adv_train_accuracy: 64.84, clean_train_accuracy : 89.84\n",
      "[1,   106] loss: 0.88153, adv_train_accuracy: 65.62, clean_train_accuracy : 92.19\n",
      "[1,   111] loss: 0.79551, adv_train_accuracy: 64.06, clean_train_accuracy : 92.19\n",
      "[1,   116] loss: 0.88838, adv_train_accuracy: 65.62, clean_train_accuracy : 89.06\n",
      "[1,   121] loss: 0.97160, adv_train_accuracy: 63.28, clean_train_accuracy : 85.16\n",
      "[1,   126] loss: 0.92578, adv_train_accuracy: 64.84, clean_train_accuracy : 92.97\n",
      "[1,   131] loss: 0.85365, adv_train_accuracy: 71.09, clean_train_accuracy : 93.75\n",
      "[1,   136] loss: 0.90955, adv_train_accuracy: 62.50, clean_train_accuracy : 92.97\n",
      "[1,   141] loss: 0.94809, adv_train_accuracy: 60.16, clean_train_accuracy : 90.62\n",
      "[1,   146] loss: 0.95116, adv_train_accuracy: 61.72, clean_train_accuracy : 88.28\n",
      "[1,   151] loss: 0.83007, adv_train_accuracy: 70.31, clean_train_accuracy : 93.75\n",
      "[1,   156] loss: 0.88311, adv_train_accuracy: 63.28, clean_train_accuracy : 89.84\n",
      "[1,   161] loss: 0.97978, adv_train_accuracy: 61.72, clean_train_accuracy : 89.84\n",
      "[1,   166] loss: 0.89799, adv_train_accuracy: 61.72, clean_train_accuracy : 89.06\n",
      "[1,   171] loss: 1.09702, adv_train_accuracy: 55.47, clean_train_accuracy : 85.94\n",
      "[1,   176] loss: 0.78518, adv_train_accuracy: 61.72, clean_train_accuracy : 91.41\n",
      "[1,   181] loss: 0.81604, adv_train_accuracy: 67.19, clean_train_accuracy : 91.41\n",
      "[1,   186] loss: 0.76071, adv_train_accuracy: 69.53, clean_train_accuracy : 90.62\n",
      "[1,   191] loss: 0.90061, adv_train_accuracy: 60.94, clean_train_accuracy : 92.97\n",
      "[1,   196] loss: 0.81030, adv_train_accuracy: 65.62, clean_train_accuracy : 92.19\n",
      "[1,   201] loss: 0.90554, adv_train_accuracy: 67.19, clean_train_accuracy : 91.41\n",
      "[1,   206] loss: 0.95009, adv_train_accuracy: 62.50, clean_train_accuracy : 92.19\n",
      "[1,   211] loss: 0.97632, adv_train_accuracy: 59.38, clean_train_accuracy : 83.59\n",
      "[1,   216] loss: 1.05742, adv_train_accuracy: 57.03, clean_train_accuracy : 89.84\n",
      "[1,   221] loss: 0.87487, adv_train_accuracy: 67.97, clean_train_accuracy : 87.50\n",
      "[1,   226] loss: 0.87154, adv_train_accuracy: 68.75, clean_train_accuracy : 92.19\n",
      "[1,   231] loss: 0.87409, adv_train_accuracy: 67.97, clean_train_accuracy : 91.41\n",
      "[1,   236] loss: 0.94791, adv_train_accuracy: 58.59, clean_train_accuracy : 92.19\n",
      "[1,   241] loss: 1.06411, adv_train_accuracy: 54.69, clean_train_accuracy : 88.28\n",
      "[1,   246] loss: 0.98077, adv_train_accuracy: 55.47, clean_train_accuracy : 88.28\n",
      "[1,   251] loss: 0.92953, adv_train_accuracy: 61.72, clean_train_accuracy : 93.75\n",
      "[1,   256] loss: 0.93484, adv_train_accuracy: 66.41, clean_train_accuracy : 87.50\n",
      "[1,   261] loss: 0.93412, adv_train_accuracy: 62.50, clean_train_accuracy : 87.50\n",
      "[1,   266] loss: 0.82398, adv_train_accuracy: 71.09, clean_train_accuracy : 93.75\n",
      "[1,   271] loss: 1.02937, adv_train_accuracy: 55.47, clean_train_accuracy : 90.62\n",
      "[1,   276] loss: 0.92995, adv_train_accuracy: 60.94, clean_train_accuracy : 96.88\n",
      "[1,   281] loss: 0.99785, adv_train_accuracy: 56.25, clean_train_accuracy : 87.50\n",
      "[1,   286] loss: 0.95432, adv_train_accuracy: 65.62, clean_train_accuracy : 89.06\n",
      "[1,   291] loss: 0.91523, adv_train_accuracy: 57.81, clean_train_accuracy : 94.53\n",
      "[1,   296] loss: 0.96033, adv_train_accuracy: 57.03, clean_train_accuracy : 93.75\n",
      "[1,   301] loss: 1.02049, adv_train_accuracy: 58.59, clean_train_accuracy : 86.72\n",
      "[1,   306] loss: 0.88656, adv_train_accuracy: 65.62, clean_train_accuracy : 90.62\n",
      "[1,   311] loss: 0.91774, adv_train_accuracy: 67.97, clean_train_accuracy : 88.28\n",
      "[1,   316] loss: 1.01763, adv_train_accuracy: 60.16, clean_train_accuracy : 92.97\n",
      "[1,   321] loss: 0.92858, adv_train_accuracy: 65.62, clean_train_accuracy : 85.94\n",
      "[1,   326] loss: 0.98422, adv_train_accuracy: 60.16, clean_train_accuracy : 85.16\n",
      "[1,   331] loss: 1.12373, adv_train_accuracy: 55.47, clean_train_accuracy : 83.59\n",
      "[1,   336] loss: 1.13466, adv_train_accuracy: 53.12, clean_train_accuracy : 86.72\n",
      "[1,   341] loss: 0.87290, adv_train_accuracy: 67.97, clean_train_accuracy : 89.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   346] loss: 0.96822, adv_train_accuracy: 56.25, clean_train_accuracy : 90.62\n",
      "[1,   351] loss: 0.99581, adv_train_accuracy: 59.38, clean_train_accuracy : 89.06\n",
      "[1,   356] loss: 0.81128, adv_train_accuracy: 70.31, clean_train_accuracy : 91.41\n",
      "[1,   361] loss: 0.73469, adv_train_accuracy: 69.53, clean_train_accuracy : 92.97\n",
      "[1,   366] loss: 0.98235, adv_train_accuracy: 59.38, clean_train_accuracy : 89.06\n",
      "[1,   371] loss: 0.90278, adv_train_accuracy: 64.84, clean_train_accuracy : 92.97\n",
      "[1,   376] loss: 0.85724, adv_train_accuracy: 66.41, clean_train_accuracy : 89.06\n",
      "[1,   381] loss: 0.96894, adv_train_accuracy: 60.16, clean_train_accuracy : 86.72\n",
      "[1,   386] loss: 0.93571, adv_train_accuracy: 62.50, clean_train_accuracy : 91.41\n",
      "[1,   391] loss: 0.95284, adv_train_accuracy: 63.75, clean_train_accuracy : 93.75\n",
      "fgsm robustness: 0.3798828125\n",
      "pgd robustness: 0.3095703125\n",
      "duration: 158 s - train loss: 0.91975 - train accuracy: 62.70 - validation loss: 0.83367 - validation accuracy: 71.38 \n",
      "Finished Training\n",
      "16 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.84335, adv_train_accuracy: 71.09, clean_train_accuracy : 92.19\n",
      "[1,     6] loss: 0.63193, adv_train_accuracy: 74.22, clean_train_accuracy : 92.97\n",
      "[1,    11] loss: 0.71811, adv_train_accuracy: 71.88, clean_train_accuracy : 92.97\n",
      "[1,    16] loss: 0.62911, adv_train_accuracy: 73.44, clean_train_accuracy : 96.88\n",
      "[1,    21] loss: 0.85238, adv_train_accuracy: 67.19, clean_train_accuracy : 96.88\n",
      "[1,    26] loss: 0.79819, adv_train_accuracy: 67.97, clean_train_accuracy : 95.31\n",
      "[1,    31] loss: 0.67229, adv_train_accuracy: 69.53, clean_train_accuracy : 93.75\n",
      "[1,    36] loss: 0.84217, adv_train_accuracy: 64.06, clean_train_accuracy : 92.19\n",
      "[1,    41] loss: 0.80008, adv_train_accuracy: 64.06, clean_train_accuracy : 90.62\n",
      "[1,    46] loss: 0.74882, adv_train_accuracy: 70.31, clean_train_accuracy : 93.75\n",
      "[1,    51] loss: 0.74978, adv_train_accuracy: 71.09, clean_train_accuracy : 92.19\n",
      "[1,    56] loss: 0.80009, adv_train_accuracy: 65.62, clean_train_accuracy : 90.62\n",
      "[1,    61] loss: 0.67341, adv_train_accuracy: 68.75, clean_train_accuracy : 93.75\n",
      "[1,    66] loss: 0.67746, adv_train_accuracy: 72.66, clean_train_accuracy : 94.53\n",
      "[1,    71] loss: 0.82873, adv_train_accuracy: 65.62, clean_train_accuracy : 89.06\n",
      "[1,    76] loss: 0.64845, adv_train_accuracy: 71.09, clean_train_accuracy : 95.31\n",
      "[1,    81] loss: 0.73858, adv_train_accuracy: 68.75, clean_train_accuracy : 95.31\n",
      "[1,    86] loss: 0.77474, adv_train_accuracy: 67.97, clean_train_accuracy : 93.75\n",
      "[1,    91] loss: 0.74189, adv_train_accuracy: 70.31, clean_train_accuracy : 87.50\n",
      "[1,    96] loss: 0.69051, adv_train_accuracy: 75.00, clean_train_accuracy : 93.75\n",
      "[1,   101] loss: 0.84107, adv_train_accuracy: 64.06, clean_train_accuracy : 94.53\n",
      "[1,   106] loss: 0.69014, adv_train_accuracy: 71.88, clean_train_accuracy : 96.09\n",
      "[1,   111] loss: 0.89000, adv_train_accuracy: 64.06, clean_train_accuracy : 87.50\n",
      "[1,   116] loss: 0.80240, adv_train_accuracy: 67.97, clean_train_accuracy : 93.75\n",
      "[1,   121] loss: 0.97412, adv_train_accuracy: 64.84, clean_train_accuracy : 92.97\n",
      "[1,   126] loss: 0.99322, adv_train_accuracy: 57.03, clean_train_accuracy : 92.19\n",
      "[1,   131] loss: 0.73153, adv_train_accuracy: 72.66, clean_train_accuracy : 96.09\n",
      "[1,   136] loss: 0.63460, adv_train_accuracy: 72.66, clean_train_accuracy : 95.31\n",
      "[1,   141] loss: 0.81022, adv_train_accuracy: 67.19, clean_train_accuracy : 96.88\n",
      "[1,   146] loss: 0.76841, adv_train_accuracy: 67.19, clean_train_accuracy : 96.09\n",
      "[1,   151] loss: 0.79695, adv_train_accuracy: 66.41, clean_train_accuracy : 93.75\n",
      "[1,   156] loss: 0.69138, adv_train_accuracy: 73.44, clean_train_accuracy : 92.97\n",
      "[1,   161] loss: 0.77635, adv_train_accuracy: 69.53, clean_train_accuracy : 92.97\n",
      "[1,   166] loss: 0.71694, adv_train_accuracy: 67.97, clean_train_accuracy : 95.31\n",
      "[1,   171] loss: 0.80535, adv_train_accuracy: 71.88, clean_train_accuracy : 92.19\n",
      "[1,   176] loss: 0.78816, adv_train_accuracy: 69.53, clean_train_accuracy : 92.19\n",
      "[1,   181] loss: 0.77674, adv_train_accuracy: 72.66, clean_train_accuracy : 92.97\n",
      "[1,   186] loss: 0.80176, adv_train_accuracy: 73.44, clean_train_accuracy : 94.53\n",
      "[1,   191] loss: 0.84955, adv_train_accuracy: 64.06, clean_train_accuracy : 94.53\n",
      "[1,   196] loss: 0.85061, adv_train_accuracy: 64.06, clean_train_accuracy : 95.31\n",
      "[1,   201] loss: 0.74812, adv_train_accuracy: 76.56, clean_train_accuracy : 91.41\n",
      "[1,   206] loss: 0.90290, adv_train_accuracy: 68.75, clean_train_accuracy : 92.19\n",
      "[1,   211] loss: 0.98020, adv_train_accuracy: 64.06, clean_train_accuracy : 95.31\n",
      "[1,   216] loss: 0.70976, adv_train_accuracy: 74.22, clean_train_accuracy : 94.53\n",
      "[1,   221] loss: 0.89423, adv_train_accuracy: 64.84, clean_train_accuracy : 93.75\n",
      "[1,   226] loss: 0.73159, adv_train_accuracy: 70.31, clean_train_accuracy : 92.97\n",
      "[1,   231] loss: 0.83188, adv_train_accuracy: 70.31, clean_train_accuracy : 87.50\n",
      "[1,   236] loss: 0.80008, adv_train_accuracy: 69.53, clean_train_accuracy : 91.41\n",
      "[1,   241] loss: 0.87609, adv_train_accuracy: 63.28, clean_train_accuracy : 87.50\n",
      "[1,   246] loss: 0.76643, adv_train_accuracy: 68.75, clean_train_accuracy : 92.97\n",
      "[1,   251] loss: 0.65853, adv_train_accuracy: 71.09, clean_train_accuracy : 93.75\n",
      "[1,   256] loss: 0.74062, adv_train_accuracy: 70.31, clean_train_accuracy : 94.53\n",
      "[1,   261] loss: 0.75518, adv_train_accuracy: 68.75, clean_train_accuracy : 93.75\n",
      "[1,   266] loss: 0.87559, adv_train_accuracy: 62.50, clean_train_accuracy : 92.19\n",
      "[1,   271] loss: 0.92083, adv_train_accuracy: 64.84, clean_train_accuracy : 89.84\n",
      "[1,   276] loss: 0.92461, adv_train_accuracy: 63.28, clean_train_accuracy : 90.62\n",
      "[1,   281] loss: 0.80744, adv_train_accuracy: 66.41, clean_train_accuracy : 92.97\n",
      "[1,   286] loss: 0.71573, adv_train_accuracy: 71.88, clean_train_accuracy : 99.22\n",
      "[1,   291] loss: 1.03139, adv_train_accuracy: 56.25, clean_train_accuracy : 92.97\n",
      "[1,   296] loss: 0.92577, adv_train_accuracy: 63.28, clean_train_accuracy : 94.53\n",
      "[1,   301] loss: 0.88910, adv_train_accuracy: 62.50, clean_train_accuracy : 96.88\n",
      "[1,   306] loss: 0.89234, adv_train_accuracy: 63.28, clean_train_accuracy : 88.28\n",
      "[1,   311] loss: 0.87411, adv_train_accuracy: 62.50, clean_train_accuracy : 94.53\n",
      "[1,   316] loss: 0.78555, adv_train_accuracy: 68.75, clean_train_accuracy : 93.75\n",
      "[1,   321] loss: 0.75321, adv_train_accuracy: 65.62, clean_train_accuracy : 92.19\n",
      "[1,   326] loss: 0.72252, adv_train_accuracy: 75.00, clean_train_accuracy : 96.09\n",
      "[1,   331] loss: 0.83073, adv_train_accuracy: 65.62, clean_train_accuracy : 92.19\n",
      "[1,   336] loss: 0.84766, adv_train_accuracy: 65.62, clean_train_accuracy : 92.97\n",
      "[1,   341] loss: 0.89217, adv_train_accuracy: 61.72, clean_train_accuracy : 92.19\n",
      "[1,   346] loss: 0.83487, adv_train_accuracy: 62.50, clean_train_accuracy : 89.84\n",
      "[1,   351] loss: 0.72083, adv_train_accuracy: 68.75, clean_train_accuracy : 93.75\n",
      "[1,   356] loss: 0.86005, adv_train_accuracy: 69.53, clean_train_accuracy : 94.53\n",
      "[1,   361] loss: 0.82440, adv_train_accuracy: 65.62, clean_train_accuracy : 92.97\n",
      "[1,   366] loss: 0.80126, adv_train_accuracy: 67.19, clean_train_accuracy : 92.97\n",
      "[1,   371] loss: 0.92518, adv_train_accuracy: 61.72, clean_train_accuracy : 91.41\n",
      "[1,   376] loss: 0.85524, adv_train_accuracy: 62.50, clean_train_accuracy : 92.97\n",
      "[1,   381] loss: 0.91666, adv_train_accuracy: 61.72, clean_train_accuracy : 95.31\n",
      "[1,   386] loss: 0.86093, adv_train_accuracy: 60.94, clean_train_accuracy : 91.41\n",
      "[1,   391] loss: 0.86089, adv_train_accuracy: 65.00, clean_train_accuracy : 91.25\n",
      "fgsm robustness: 0.37109375\n",
      "pgd robustness: 0.279296875\n",
      "duration: 159 s - train loss: 0.80725 - train accuracy: 67.14 - validation loss: 0.78794 - validation accuracy: 73.12 \n",
      "Finished Training\n",
      "17 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.96931, adv_train_accuracy: 58.59, clean_train_accuracy : 89.06\n",
      "[1,     6] loss: 0.62891, adv_train_accuracy: 77.34, clean_train_accuracy : 97.66\n",
      "[1,    11] loss: 0.62759, adv_train_accuracy: 74.22, clean_train_accuracy : 94.53\n",
      "[1,    16] loss: 0.73206, adv_train_accuracy: 71.09, clean_train_accuracy : 95.31\n",
      "[1,    21] loss: 0.68641, adv_train_accuracy: 71.88, clean_train_accuracy : 96.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    26] loss: 0.57857, adv_train_accuracy: 76.56, clean_train_accuracy : 94.53\n",
      "[1,    31] loss: 0.51644, adv_train_accuracy: 78.91, clean_train_accuracy : 96.88\n",
      "[1,    36] loss: 0.68275, adv_train_accuracy: 68.75, clean_train_accuracy : 94.53\n",
      "[1,    41] loss: 0.69414, adv_train_accuracy: 70.31, clean_train_accuracy : 96.88\n",
      "[1,    46] loss: 0.55836, adv_train_accuracy: 77.34, clean_train_accuracy : 96.88\n",
      "[1,    51] loss: 0.58864, adv_train_accuracy: 70.31, clean_train_accuracy : 94.53\n",
      "[1,    56] loss: 0.72691, adv_train_accuracy: 67.97, clean_train_accuracy : 94.53\n",
      "[1,    61] loss: 0.53877, adv_train_accuracy: 81.25, clean_train_accuracy : 96.88\n",
      "[1,    66] loss: 0.68665, adv_train_accuracy: 67.19, clean_train_accuracy : 95.31\n",
      "[1,    71] loss: 0.72613, adv_train_accuracy: 67.97, clean_train_accuracy : 90.62\n",
      "[1,    76] loss: 0.86547, adv_train_accuracy: 64.06, clean_train_accuracy : 93.75\n",
      "[1,    81] loss: 0.66293, adv_train_accuracy: 75.00, clean_train_accuracy : 95.31\n",
      "[1,    86] loss: 0.59822, adv_train_accuracy: 72.66, clean_train_accuracy : 96.88\n",
      "[1,    91] loss: 0.69837, adv_train_accuracy: 67.97, clean_train_accuracy : 93.75\n",
      "[1,    96] loss: 0.73904, adv_train_accuracy: 70.31, clean_train_accuracy : 95.31\n",
      "[1,   101] loss: 0.55529, adv_train_accuracy: 78.12, clean_train_accuracy : 97.66\n",
      "[1,   106] loss: 0.67459, adv_train_accuracy: 71.88, clean_train_accuracy : 95.31\n",
      "[1,   111] loss: 0.60897, adv_train_accuracy: 75.78, clean_train_accuracy : 94.53\n",
      "[1,   116] loss: 0.55692, adv_train_accuracy: 75.78, clean_train_accuracy : 97.66\n",
      "[1,   121] loss: 0.71236, adv_train_accuracy: 70.31, clean_train_accuracy : 96.88\n",
      "[1,   126] loss: 0.52887, adv_train_accuracy: 80.47, clean_train_accuracy : 96.88\n",
      "[1,   131] loss: 0.72579, adv_train_accuracy: 74.22, clean_train_accuracy : 92.97\n",
      "[1,   136] loss: 0.71348, adv_train_accuracy: 71.09, clean_train_accuracy : 92.97\n",
      "[1,   141] loss: 0.66978, adv_train_accuracy: 73.44, clean_train_accuracy : 95.31\n",
      "[1,   146] loss: 0.81459, adv_train_accuracy: 71.88, clean_train_accuracy : 92.19\n",
      "[1,   151] loss: 0.84139, adv_train_accuracy: 67.19, clean_train_accuracy : 92.19\n",
      "[1,   156] loss: 0.68814, adv_train_accuracy: 66.41, clean_train_accuracy : 96.09\n",
      "[1,   161] loss: 0.78566, adv_train_accuracy: 65.62, clean_train_accuracy : 94.53\n",
      "[1,   166] loss: 0.82956, adv_train_accuracy: 65.62, clean_train_accuracy : 93.75\n",
      "[1,   171] loss: 0.78830, adv_train_accuracy: 69.53, clean_train_accuracy : 90.62\n",
      "[1,   176] loss: 0.71853, adv_train_accuracy: 68.75, clean_train_accuracy : 96.88\n",
      "[1,   181] loss: 0.70137, adv_train_accuracy: 72.66, clean_train_accuracy : 96.88\n",
      "[1,   186] loss: 0.68110, adv_train_accuracy: 71.09, clean_train_accuracy : 93.75\n",
      "[1,   191] loss: 0.77672, adv_train_accuracy: 70.31, clean_train_accuracy : 94.53\n",
      "[1,   196] loss: 0.73966, adv_train_accuracy: 67.19, clean_train_accuracy : 93.75\n",
      "[1,   201] loss: 0.70065, adv_train_accuracy: 74.22, clean_train_accuracy : 94.53\n",
      "[1,   206] loss: 0.90429, adv_train_accuracy: 64.06, clean_train_accuracy : 92.19\n",
      "[1,   211] loss: 0.67742, adv_train_accuracy: 75.78, clean_train_accuracy : 93.75\n",
      "[1,   216] loss: 0.68070, adv_train_accuracy: 72.66, clean_train_accuracy : 94.53\n",
      "[1,   221] loss: 0.74677, adv_train_accuracy: 67.19, clean_train_accuracy : 94.53\n",
      "[1,   226] loss: 0.65923, adv_train_accuracy: 75.78, clean_train_accuracy : 97.66\n",
      "[1,   231] loss: 0.67350, adv_train_accuracy: 69.53, clean_train_accuracy : 96.09\n",
      "[1,   236] loss: 0.78061, adv_train_accuracy: 68.75, clean_train_accuracy : 94.53\n",
      "[1,   241] loss: 0.70769, adv_train_accuracy: 67.97, clean_train_accuracy : 96.09\n",
      "[1,   246] loss: 0.73168, adv_train_accuracy: 71.88, clean_train_accuracy : 94.53\n",
      "[1,   251] loss: 0.71768, adv_train_accuracy: 72.66, clean_train_accuracy : 96.09\n",
      "[1,   256] loss: 0.68134, adv_train_accuracy: 70.31, clean_train_accuracy : 96.09\n",
      "[1,   261] loss: 0.66587, adv_train_accuracy: 75.00, clean_train_accuracy : 95.31\n",
      "[1,   266] loss: 0.63417, adv_train_accuracy: 73.44, clean_train_accuracy : 97.66\n",
      "[1,   271] loss: 0.68344, adv_train_accuracy: 74.22, clean_train_accuracy : 92.97\n",
      "[1,   276] loss: 0.78935, adv_train_accuracy: 70.31, clean_train_accuracy : 92.97\n",
      "[1,   281] loss: 0.67807, adv_train_accuracy: 75.00, clean_train_accuracy : 97.66\n",
      "[1,   286] loss: 0.76817, adv_train_accuracy: 69.53, clean_train_accuracy : 94.53\n",
      "[1,   291] loss: 0.69009, adv_train_accuracy: 67.97, clean_train_accuracy : 94.53\n",
      "[1,   296] loss: 0.79260, adv_train_accuracy: 69.53, clean_train_accuracy : 94.53\n",
      "[1,   301] loss: 0.70280, adv_train_accuracy: 75.78, clean_train_accuracy : 95.31\n",
      "[1,   306] loss: 0.84749, adv_train_accuracy: 65.62, clean_train_accuracy : 95.31\n",
      "[1,   311] loss: 0.75501, adv_train_accuracy: 67.19, clean_train_accuracy : 94.53\n",
      "[1,   316] loss: 0.79224, adv_train_accuracy: 68.75, clean_train_accuracy : 94.53\n",
      "[1,   321] loss: 0.83394, adv_train_accuracy: 58.59, clean_train_accuracy : 95.31\n",
      "[1,   326] loss: 0.79366, adv_train_accuracy: 70.31, clean_train_accuracy : 94.53\n",
      "[1,   331] loss: 0.95833, adv_train_accuracy: 57.81, clean_train_accuracy : 91.41\n",
      "[1,   336] loss: 0.75867, adv_train_accuracy: 66.41, clean_train_accuracy : 94.53\n",
      "[1,   341] loss: 0.70306, adv_train_accuracy: 76.56, clean_train_accuracy : 96.09\n",
      "[1,   346] loss: 0.74760, adv_train_accuracy: 71.09, clean_train_accuracy : 94.53\n",
      "[1,   351] loss: 0.73246, adv_train_accuracy: 71.09, clean_train_accuracy : 95.31\n",
      "[1,   356] loss: 0.71426, adv_train_accuracy: 68.75, clean_train_accuracy : 93.75\n",
      "[1,   361] loss: 0.86782, adv_train_accuracy: 64.06, clean_train_accuracy : 92.97\n",
      "[1,   366] loss: 0.82771, adv_train_accuracy: 65.62, clean_train_accuracy : 90.62\n",
      "[1,   371] loss: 0.82588, adv_train_accuracy: 63.28, clean_train_accuracy : 88.28\n",
      "[1,   376] loss: 0.81194, adv_train_accuracy: 69.53, clean_train_accuracy : 92.97\n",
      "[1,   381] loss: 0.82443, adv_train_accuracy: 67.19, clean_train_accuracy : 94.53\n",
      "[1,   386] loss: 0.81204, adv_train_accuracy: 66.41, clean_train_accuracy : 94.53\n",
      "[1,   391] loss: 0.91391, adv_train_accuracy: 63.75, clean_train_accuracy : 96.25\n",
      "fgsm robustness: 0.3798828125\n",
      "pgd robustness: 0.310546875\n",
      "duration: 158 s - train loss: 0.73235 - train accuracy: 69.96 - validation loss: 0.78808 - validation accuracy: 73.24 \n",
      "Finished Training\n",
      "18 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.74782, adv_train_accuracy: 67.97, clean_train_accuracy : 92.97\n",
      "[1,     6] loss: 0.52227, adv_train_accuracy: 82.03, clean_train_accuracy : 97.66\n",
      "[1,    11] loss: 0.59530, adv_train_accuracy: 76.56, clean_train_accuracy : 96.88\n",
      "[1,    16] loss: 0.55796, adv_train_accuracy: 75.78, clean_train_accuracy : 97.66\n",
      "[1,    21] loss: 0.72053, adv_train_accuracy: 67.97, clean_train_accuracy : 92.19\n",
      "[1,    26] loss: 0.61031, adv_train_accuracy: 77.34, clean_train_accuracy : 99.22\n",
      "[1,    31] loss: 0.57797, adv_train_accuracy: 76.56, clean_train_accuracy : 97.66\n",
      "[1,    36] loss: 0.64737, adv_train_accuracy: 72.66, clean_train_accuracy : 97.66\n",
      "[1,    41] loss: 0.61193, adv_train_accuracy: 76.56, clean_train_accuracy : 97.66\n",
      "[1,    46] loss: 0.65039, adv_train_accuracy: 73.44, clean_train_accuracy : 95.31\n",
      "[1,    51] loss: 0.51066, adv_train_accuracy: 78.12, clean_train_accuracy : 98.44\n",
      "[1,    56] loss: 0.50748, adv_train_accuracy: 80.47, clean_train_accuracy : 96.09\n",
      "[1,    61] loss: 0.55175, adv_train_accuracy: 77.34, clean_train_accuracy : 98.44\n",
      "[1,    66] loss: 0.64236, adv_train_accuracy: 71.88, clean_train_accuracy : 95.31\n",
      "[1,    71] loss: 0.66029, adv_train_accuracy: 76.56, clean_train_accuracy : 96.09\n",
      "[1,    76] loss: 0.68091, adv_train_accuracy: 70.31, clean_train_accuracy : 93.75\n",
      "[1,    81] loss: 0.62790, adv_train_accuracy: 71.09, clean_train_accuracy : 96.88\n",
      "[1,    86] loss: 0.65317, adv_train_accuracy: 72.66, clean_train_accuracy : 94.53\n",
      "[1,    91] loss: 0.59655, adv_train_accuracy: 73.44, clean_train_accuracy : 96.88\n",
      "[1,    96] loss: 0.63376, adv_train_accuracy: 74.22, clean_train_accuracy : 96.88\n",
      "[1,   101] loss: 0.54975, adv_train_accuracy: 75.78, clean_train_accuracy : 98.44\n",
      "[1,   106] loss: 0.55995, adv_train_accuracy: 75.78, clean_train_accuracy : 95.31\n",
      "[1,   111] loss: 0.60661, adv_train_accuracy: 76.56, clean_train_accuracy : 92.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   116] loss: 0.59445, adv_train_accuracy: 76.56, clean_train_accuracy : 96.09\n",
      "[1,   121] loss: 0.59951, adv_train_accuracy: 77.34, clean_train_accuracy : 96.09\n",
      "[1,   126] loss: 0.66910, adv_train_accuracy: 75.78, clean_train_accuracy : 92.97\n",
      "[1,   131] loss: 0.63510, adv_train_accuracy: 77.34, clean_train_accuracy : 94.53\n",
      "[1,   136] loss: 0.62846, adv_train_accuracy: 75.78, clean_train_accuracy : 95.31\n",
      "[1,   141] loss: 0.66985, adv_train_accuracy: 71.09, clean_train_accuracy : 95.31\n",
      "[1,   146] loss: 0.56680, adv_train_accuracy: 76.56, clean_train_accuracy : 96.88\n",
      "[1,   151] loss: 0.64499, adv_train_accuracy: 70.31, clean_train_accuracy : 93.75\n",
      "[1,   156] loss: 0.44027, adv_train_accuracy: 83.59, clean_train_accuracy : 96.88\n",
      "[1,   161] loss: 0.49456, adv_train_accuracy: 83.59, clean_train_accuracy : 97.66\n",
      "[1,   166] loss: 0.63923, adv_train_accuracy: 70.31, clean_train_accuracy : 96.88\n",
      "[1,   171] loss: 0.64644, adv_train_accuracy: 71.88, clean_train_accuracy : 93.75\n",
      "[1,   176] loss: 0.68793, adv_train_accuracy: 71.09, clean_train_accuracy : 97.66\n",
      "[1,   181] loss: 0.73434, adv_train_accuracy: 67.97, clean_train_accuracy : 93.75\n",
      "[1,   186] loss: 0.63637, adv_train_accuracy: 72.66, clean_train_accuracy : 95.31\n",
      "[1,   191] loss: 0.67869, adv_train_accuracy: 73.44, clean_train_accuracy : 93.75\n",
      "[1,   196] loss: 0.73134, adv_train_accuracy: 68.75, clean_train_accuracy : 96.88\n",
      "[1,   201] loss: 0.65856, adv_train_accuracy: 74.22, clean_train_accuracy : 92.97\n",
      "[1,   206] loss: 0.66619, adv_train_accuracy: 70.31, clean_train_accuracy : 95.31\n",
      "[1,   211] loss: 0.60680, adv_train_accuracy: 72.66, clean_train_accuracy : 98.44\n",
      "[1,   216] loss: 0.65935, adv_train_accuracy: 76.56, clean_train_accuracy : 95.31\n",
      "[1,   221] loss: 0.58512, adv_train_accuracy: 75.00, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.67307, adv_train_accuracy: 71.09, clean_train_accuracy : 96.09\n",
      "[1,   231] loss: 0.59870, adv_train_accuracy: 75.78, clean_train_accuracy : 94.53\n",
      "[1,   236] loss: 0.63589, adv_train_accuracy: 73.44, clean_train_accuracy : 96.09\n",
      "[1,   241] loss: 0.62070, adv_train_accuracy: 73.44, clean_train_accuracy : 96.88\n",
      "[1,   246] loss: 0.55452, adv_train_accuracy: 77.34, clean_train_accuracy : 97.66\n",
      "[1,   251] loss: 0.66209, adv_train_accuracy: 74.22, clean_train_accuracy : 97.66\n",
      "[1,   256] loss: 0.53425, adv_train_accuracy: 80.47, clean_train_accuracy : 98.44\n",
      "[1,   261] loss: 0.68048, adv_train_accuracy: 72.66, clean_train_accuracy : 96.09\n",
      "[1,   266] loss: 0.66146, adv_train_accuracy: 71.88, clean_train_accuracy : 95.31\n",
      "[1,   271] loss: 0.61924, adv_train_accuracy: 72.66, clean_train_accuracy : 94.53\n",
      "[1,   276] loss: 0.54004, adv_train_accuracy: 76.56, clean_train_accuracy : 98.44\n",
      "[1,   281] loss: 0.62192, adv_train_accuracy: 73.44, clean_train_accuracy : 98.44\n",
      "[1,   286] loss: 0.47962, adv_train_accuracy: 83.59, clean_train_accuracy : 98.44\n",
      "[1,   291] loss: 0.57689, adv_train_accuracy: 75.00, clean_train_accuracy : 98.44\n",
      "[1,   296] loss: 0.61837, adv_train_accuracy: 74.22, clean_train_accuracy : 96.09\n",
      "[1,   301] loss: 0.52911, adv_train_accuracy: 78.91, clean_train_accuracy : 96.88\n",
      "[1,   306] loss: 0.68787, adv_train_accuracy: 70.31, clean_train_accuracy : 96.09\n",
      "[1,   311] loss: 0.60917, adv_train_accuracy: 78.12, clean_train_accuracy : 97.66\n",
      "[1,   316] loss: 0.75638, adv_train_accuracy: 66.41, clean_train_accuracy : 96.09\n",
      "[1,   321] loss: 0.80504, adv_train_accuracy: 62.50, clean_train_accuracy : 94.53\n",
      "[1,   326] loss: 0.68719, adv_train_accuracy: 71.88, clean_train_accuracy : 98.44\n",
      "[1,   331] loss: 0.73649, adv_train_accuracy: 74.22, clean_train_accuracy : 94.53\n",
      "[1,   336] loss: 0.70514, adv_train_accuracy: 68.75, clean_train_accuracy : 94.53\n",
      "[1,   341] loss: 0.78081, adv_train_accuracy: 69.53, clean_train_accuracy : 96.09\n",
      "[1,   346] loss: 0.74737, adv_train_accuracy: 71.88, clean_train_accuracy : 92.19\n",
      "[1,   351] loss: 0.77265, adv_train_accuracy: 66.41, clean_train_accuracy : 95.31\n",
      "[1,   356] loss: 0.70793, adv_train_accuracy: 67.97, clean_train_accuracy : 95.31\n",
      "[1,   361] loss: 0.79978, adv_train_accuracy: 64.84, clean_train_accuracy : 92.19\n",
      "[1,   366] loss: 0.68976, adv_train_accuracy: 72.66, clean_train_accuracy : 97.66\n",
      "[1,   371] loss: 0.76101, adv_train_accuracy: 65.62, clean_train_accuracy : 93.75\n",
      "[1,   376] loss: 0.64138, adv_train_accuracy: 72.66, clean_train_accuracy : 96.09\n",
      "[1,   381] loss: 0.63814, adv_train_accuracy: 71.88, clean_train_accuracy : 99.22\n",
      "[1,   386] loss: 0.67055, adv_train_accuracy: 70.31, clean_train_accuracy : 93.75\n",
      "[1,   391] loss: 0.72748, adv_train_accuracy: 66.25, clean_train_accuracy : 97.50\n",
      "fgsm robustness: 0.361328125\n",
      "pgd robustness: 0.2822265625\n",
      "duration: 159 s - train loss: 0.63735 - train accuracy: 73.51 - validation loss: 0.80957 - validation accuracy: 72.83 \n",
      "Finished Training\n",
      "19 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.55763, adv_train_accuracy: 76.56, clean_train_accuracy : 99.22\n",
      "[1,     6] loss: 0.44503, adv_train_accuracy: 82.81, clean_train_accuracy : 98.44\n",
      "[1,    11] loss: 0.60827, adv_train_accuracy: 74.22, clean_train_accuracy : 97.66\n",
      "[1,    16] loss: 0.52693, adv_train_accuracy: 78.91, clean_train_accuracy : 96.88\n",
      "[1,    21] loss: 0.42918, adv_train_accuracy: 80.47, clean_train_accuracy : 97.66\n",
      "[1,    26] loss: 0.49774, adv_train_accuracy: 78.91, clean_train_accuracy : 97.66\n",
      "[1,    31] loss: 0.65383, adv_train_accuracy: 77.34, clean_train_accuracy : 96.88\n",
      "[1,    36] loss: 0.53083, adv_train_accuracy: 82.03, clean_train_accuracy : 95.31\n",
      "[1,    41] loss: 0.56913, adv_train_accuracy: 73.44, clean_train_accuracy : 97.66\n",
      "[1,    46] loss: 0.51384, adv_train_accuracy: 81.25, clean_train_accuracy : 97.66\n",
      "[1,    51] loss: 0.48689, adv_train_accuracy: 79.69, clean_train_accuracy : 98.44\n",
      "[1,    56] loss: 0.37739, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[1,    61] loss: 0.58566, adv_train_accuracy: 73.44, clean_train_accuracy : 97.66\n",
      "[1,    66] loss: 0.48173, adv_train_accuracy: 77.34, clean_train_accuracy : 97.66\n",
      "[1,    71] loss: 0.51000, adv_train_accuracy: 77.34, clean_train_accuracy : 98.44\n",
      "[1,    76] loss: 0.49739, adv_train_accuracy: 75.78, clean_train_accuracy : 97.66\n",
      "[1,    81] loss: 0.40722, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,    86] loss: 0.48379, adv_train_accuracy: 77.34, clean_train_accuracy : 99.22\n",
      "[1,    91] loss: 0.44710, adv_train_accuracy: 81.25, clean_train_accuracy : 97.66\n",
      "[1,    96] loss: 0.44679, adv_train_accuracy: 81.25, clean_train_accuracy : 99.22\n",
      "[1,   101] loss: 0.47645, adv_train_accuracy: 82.81, clean_train_accuracy : 96.09\n",
      "[1,   106] loss: 0.50785, adv_train_accuracy: 81.25, clean_train_accuracy : 96.09\n",
      "[1,   111] loss: 0.43962, adv_train_accuracy: 82.81, clean_train_accuracy : 97.66\n",
      "[1,   116] loss: 0.55129, adv_train_accuracy: 77.34, clean_train_accuracy : 95.31\n",
      "[1,   121] loss: 0.50512, adv_train_accuracy: 76.56, clean_train_accuracy : 96.88\n",
      "[1,   126] loss: 0.65118, adv_train_accuracy: 71.88, clean_train_accuracy : 93.75\n",
      "[1,   131] loss: 0.42991, adv_train_accuracy: 85.16, clean_train_accuracy : 98.44\n",
      "[1,   136] loss: 0.50981, adv_train_accuracy: 78.91, clean_train_accuracy : 97.66\n",
      "[1,   141] loss: 0.60777, adv_train_accuracy: 72.66, clean_train_accuracy : 95.31\n",
      "[1,   146] loss: 0.48846, adv_train_accuracy: 82.03, clean_train_accuracy : 97.66\n",
      "[1,   151] loss: 0.49108, adv_train_accuracy: 82.03, clean_train_accuracy : 96.09\n",
      "[1,   156] loss: 0.50786, adv_train_accuracy: 82.81, clean_train_accuracy : 96.09\n",
      "[1,   161] loss: 0.54275, adv_train_accuracy: 78.91, clean_train_accuracy : 97.66\n",
      "[1,   166] loss: 0.66222, adv_train_accuracy: 70.31, clean_train_accuracy : 99.22\n",
      "[1,   171] loss: 0.60698, adv_train_accuracy: 72.66, clean_train_accuracy : 96.88\n",
      "[1,   176] loss: 0.58053, adv_train_accuracy: 72.66, clean_train_accuracy : 96.09\n",
      "[1,   181] loss: 0.47392, adv_train_accuracy: 76.56, clean_train_accuracy : 97.66\n",
      "[1,   186] loss: 0.66564, adv_train_accuracy: 71.88, clean_train_accuracy : 97.66\n",
      "[1,   191] loss: 0.66804, adv_train_accuracy: 74.22, clean_train_accuracy : 96.09\n",
      "[1,   196] loss: 0.69061, adv_train_accuracy: 75.00, clean_train_accuracy : 98.44\n",
      "[1,   201] loss: 0.47529, adv_train_accuracy: 76.56, clean_train_accuracy : 98.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   206] loss: 0.58813, adv_train_accuracy: 71.88, clean_train_accuracy : 96.88\n",
      "[1,   211] loss: 0.61424, adv_train_accuracy: 75.78, clean_train_accuracy : 96.88\n",
      "[1,   216] loss: 0.59046, adv_train_accuracy: 75.78, clean_train_accuracy : 96.88\n",
      "[1,   221] loss: 0.52095, adv_train_accuracy: 78.91, clean_train_accuracy : 97.66\n",
      "[1,   226] loss: 0.59866, adv_train_accuracy: 75.78, clean_train_accuracy : 97.66\n",
      "[1,   231] loss: 0.67780, adv_train_accuracy: 73.44, clean_train_accuracy : 94.53\n",
      "[1,   236] loss: 0.58928, adv_train_accuracy: 74.22, clean_train_accuracy : 97.66\n",
      "[1,   241] loss: 0.56088, adv_train_accuracy: 75.00, clean_train_accuracy : 95.31\n",
      "[1,   246] loss: 0.52168, adv_train_accuracy: 78.12, clean_train_accuracy : 99.22\n",
      "[1,   251] loss: 0.53937, adv_train_accuracy: 79.69, clean_train_accuracy : 95.31\n",
      "[1,   256] loss: 0.57569, adv_train_accuracy: 75.78, clean_train_accuracy : 94.53\n",
      "[1,   261] loss: 0.53002, adv_train_accuracy: 77.34, clean_train_accuracy : 96.88\n",
      "[1,   266] loss: 0.53356, adv_train_accuracy: 81.25, clean_train_accuracy : 97.66\n",
      "[1,   271] loss: 0.62587, adv_train_accuracy: 71.88, clean_train_accuracy : 97.66\n",
      "[1,   276] loss: 0.68189, adv_train_accuracy: 70.31, clean_train_accuracy : 95.31\n",
      "[1,   281] loss: 0.67788, adv_train_accuracy: 75.00, clean_train_accuracy : 94.53\n",
      "[1,   286] loss: 0.60324, adv_train_accuracy: 74.22, clean_train_accuracy : 96.88\n",
      "[1,   291] loss: 0.56528, adv_train_accuracy: 75.00, clean_train_accuracy : 96.88\n",
      "[1,   296] loss: 0.68193, adv_train_accuracy: 70.31, clean_train_accuracy : 94.53\n",
      "[1,   301] loss: 0.79857, adv_train_accuracy: 69.53, clean_train_accuracy : 93.75\n",
      "[1,   306] loss: 0.66830, adv_train_accuracy: 68.75, clean_train_accuracy : 93.75\n",
      "[1,   311] loss: 0.59076, adv_train_accuracy: 78.12, clean_train_accuracy : 96.88\n",
      "[1,   316] loss: 0.56796, adv_train_accuracy: 75.78, clean_train_accuracy : 97.66\n",
      "[1,   321] loss: 0.72194, adv_train_accuracy: 70.31, clean_train_accuracy : 95.31\n",
      "[1,   326] loss: 0.76741, adv_train_accuracy: 67.97, clean_train_accuracy : 95.31\n",
      "[1,   331] loss: 0.53242, adv_train_accuracy: 78.91, clean_train_accuracy : 95.31\n",
      "[1,   336] loss: 0.63795, adv_train_accuracy: 71.88, clean_train_accuracy : 98.44\n",
      "[1,   341] loss: 0.50941, adv_train_accuracy: 78.12, clean_train_accuracy : 97.66\n",
      "[1,   346] loss: 0.53797, adv_train_accuracy: 77.34, clean_train_accuracy : 97.66\n",
      "[1,   351] loss: 0.54514, adv_train_accuracy: 76.56, clean_train_accuracy : 97.66\n",
      "[1,   356] loss: 0.58767, adv_train_accuracy: 75.00, clean_train_accuracy : 99.22\n",
      "[1,   361] loss: 0.56548, adv_train_accuracy: 79.69, clean_train_accuracy : 96.88\n",
      "[1,   366] loss: 0.64836, adv_train_accuracy: 75.00, clean_train_accuracy : 95.31\n",
      "[1,   371] loss: 0.64698, adv_train_accuracy: 75.00, clean_train_accuracy : 96.09\n",
      "[1,   376] loss: 0.58645, adv_train_accuracy: 78.12, clean_train_accuracy : 96.88\n",
      "[1,   381] loss: 0.59228, adv_train_accuracy: 75.00, clean_train_accuracy : 97.66\n",
      "[1,   386] loss: 0.67407, adv_train_accuracy: 70.31, clean_train_accuracy : 93.75\n",
      "[1,   391] loss: 0.56487, adv_train_accuracy: 78.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3818359375\n",
      "pgd robustness: 0.3017578125\n",
      "duration: 159 s - train loss: 0.57122 - train accuracy: 76.38 - validation loss: 0.83107 - validation accuracy: 73.88 \n",
      "Finished Training\n",
      "20 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.55545, adv_train_accuracy: 78.91, clean_train_accuracy : 95.31\n",
      "[1,     6] loss: 0.52380, adv_train_accuracy: 75.78, clean_train_accuracy : 99.22\n",
      "[1,    11] loss: 0.43697, adv_train_accuracy: 78.91, clean_train_accuracy : 98.44\n",
      "[1,    16] loss: 0.47990, adv_train_accuracy: 82.03, clean_train_accuracy : 97.66\n",
      "[1,    21] loss: 0.59060, adv_train_accuracy: 78.12, clean_train_accuracy : 92.97\n",
      "[1,    26] loss: 0.56838, adv_train_accuracy: 75.00, clean_train_accuracy : 94.53\n",
      "[1,    31] loss: 0.52717, adv_train_accuracy: 80.47, clean_train_accuracy : 98.44\n",
      "[1,    36] loss: 0.51403, adv_train_accuracy: 79.69, clean_train_accuracy : 96.88\n",
      "[1,    41] loss: 0.34090, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.37593, adv_train_accuracy: 84.38, clean_train_accuracy : 96.88\n",
      "[1,    51] loss: 0.37840, adv_train_accuracy: 83.59, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.40790, adv_train_accuracy: 81.25, clean_train_accuracy : 96.88\n",
      "[1,    61] loss: 0.48596, adv_train_accuracy: 80.47, clean_train_accuracy : 97.66\n",
      "[1,    66] loss: 0.50735, adv_train_accuracy: 76.56, clean_train_accuracy : 96.88\n",
      "[1,    71] loss: 0.48444, adv_train_accuracy: 83.59, clean_train_accuracy : 97.66\n",
      "[1,    76] loss: 0.47482, adv_train_accuracy: 78.12, clean_train_accuracy : 99.22\n",
      "[1,    81] loss: 0.54057, adv_train_accuracy: 80.47, clean_train_accuracy : 98.44\n",
      "[1,    86] loss: 0.40957, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,    91] loss: 0.57633, adv_train_accuracy: 73.44, clean_train_accuracy : 99.22\n",
      "[1,    96] loss: 0.51289, adv_train_accuracy: 78.91, clean_train_accuracy : 97.66\n",
      "[1,   101] loss: 0.50400, adv_train_accuracy: 80.47, clean_train_accuracy : 98.44\n",
      "[1,   106] loss: 0.54327, adv_train_accuracy: 76.56, clean_train_accuracy : 96.09\n",
      "[1,   111] loss: 0.57645, adv_train_accuracy: 75.78, clean_train_accuracy : 95.31\n",
      "[1,   116] loss: 0.34980, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   121] loss: 0.36834, adv_train_accuracy: 81.25, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.41597, adv_train_accuracy: 81.25, clean_train_accuracy : 97.66\n",
      "[1,   131] loss: 0.49165, adv_train_accuracy: 78.91, clean_train_accuracy : 96.88\n",
      "[1,   136] loss: 0.52208, adv_train_accuracy: 79.69, clean_train_accuracy : 98.44\n",
      "[1,   141] loss: 0.44027, adv_train_accuracy: 82.81, clean_train_accuracy : 97.66\n",
      "[1,   146] loss: 0.40785, adv_train_accuracy: 82.03, clean_train_accuracy : 99.22\n",
      "[1,   151] loss: 0.43013, adv_train_accuracy: 85.16, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.54726, adv_train_accuracy: 78.12, clean_train_accuracy : 97.66\n",
      "[1,   161] loss: 0.52965, adv_train_accuracy: 77.34, clean_train_accuracy : 98.44\n",
      "[1,   166] loss: 0.37370, adv_train_accuracy: 82.03, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.52339, adv_train_accuracy: 74.22, clean_train_accuracy : 96.88\n",
      "[1,   176] loss: 0.57396, adv_train_accuracy: 75.78, clean_train_accuracy : 96.09\n",
      "[1,   181] loss: 0.43070, adv_train_accuracy: 80.47, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.46830, adv_train_accuracy: 82.03, clean_train_accuracy : 96.88\n",
      "[1,   191] loss: 0.47903, adv_train_accuracy: 79.69, clean_train_accuracy : 98.44\n",
      "[1,   196] loss: 0.48383, adv_train_accuracy: 83.59, clean_train_accuracy : 96.09\n",
      "[1,   201] loss: 0.47381, adv_train_accuracy: 78.91, clean_train_accuracy : 96.88\n",
      "[1,   206] loss: 0.42514, adv_train_accuracy: 82.81, clean_train_accuracy : 97.66\n",
      "[1,   211] loss: 0.41221, adv_train_accuracy: 81.25, clean_train_accuracy : 98.44\n",
      "[1,   216] loss: 0.68906, adv_train_accuracy: 71.88, clean_train_accuracy : 97.66\n",
      "[1,   221] loss: 0.56066, adv_train_accuracy: 75.00, clean_train_accuracy : 98.44\n",
      "[1,   226] loss: 0.42805, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.42062, adv_train_accuracy: 85.16, clean_train_accuracy : 97.66\n",
      "[1,   236] loss: 0.42351, adv_train_accuracy: 83.59, clean_train_accuracy : 98.44\n",
      "[1,   241] loss: 0.48333, adv_train_accuracy: 78.91, clean_train_accuracy : 96.88\n",
      "[1,   246] loss: 0.64670, adv_train_accuracy: 74.22, clean_train_accuracy : 95.31\n",
      "[1,   251] loss: 0.54921, adv_train_accuracy: 73.44, clean_train_accuracy : 97.66\n",
      "[1,   256] loss: 0.57209, adv_train_accuracy: 75.78, clean_train_accuracy : 96.88\n",
      "[1,   261] loss: 0.70844, adv_train_accuracy: 73.44, clean_train_accuracy : 96.88\n",
      "[1,   266] loss: 0.54852, adv_train_accuracy: 77.34, clean_train_accuracy : 99.22\n",
      "[1,   271] loss: 0.57318, adv_train_accuracy: 78.12, clean_train_accuracy : 96.09\n",
      "[1,   276] loss: 0.57870, adv_train_accuracy: 76.56, clean_train_accuracy : 96.88\n",
      "[1,   281] loss: 0.49358, adv_train_accuracy: 78.12, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.55097, adv_train_accuracy: 77.34, clean_train_accuracy : 96.09\n",
      "[1,   291] loss: 0.47840, adv_train_accuracy: 78.91, clean_train_accuracy : 99.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   296] loss: 0.56542, adv_train_accuracy: 78.12, clean_train_accuracy : 96.88\n",
      "[1,   301] loss: 0.49868, adv_train_accuracy: 80.47, clean_train_accuracy : 96.88\n",
      "[1,   306] loss: 0.60237, adv_train_accuracy: 76.56, clean_train_accuracy : 96.09\n",
      "[1,   311] loss: 0.50856, adv_train_accuracy: 79.69, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.51013, adv_train_accuracy: 78.91, clean_train_accuracy : 98.44\n",
      "[1,   321] loss: 0.57551, adv_train_accuracy: 78.91, clean_train_accuracy : 96.88\n",
      "[1,   326] loss: 0.52788, adv_train_accuracy: 75.00, clean_train_accuracy : 98.44\n",
      "[1,   331] loss: 0.47252, adv_train_accuracy: 82.03, clean_train_accuracy : 96.88\n",
      "[1,   336] loss: 0.57237, adv_train_accuracy: 75.00, clean_train_accuracy : 99.22\n",
      "[1,   341] loss: 0.55133, adv_train_accuracy: 77.34, clean_train_accuracy : 96.88\n",
      "[1,   346] loss: 0.45965, adv_train_accuracy: 83.59, clean_train_accuracy : 96.09\n",
      "[1,   351] loss: 0.63129, adv_train_accuracy: 73.44, clean_train_accuracy : 96.88\n",
      "[1,   356] loss: 0.56762, adv_train_accuracy: 76.56, clean_train_accuracy : 96.09\n",
      "[1,   361] loss: 0.46908, adv_train_accuracy: 80.47, clean_train_accuracy : 97.66\n",
      "[1,   366] loss: 0.49173, adv_train_accuracy: 80.47, clean_train_accuracy : 98.44\n",
      "[1,   371] loss: 0.49832, adv_train_accuracy: 78.12, clean_train_accuracy : 99.22\n",
      "[1,   376] loss: 0.43513, adv_train_accuracy: 80.47, clean_train_accuracy : 98.44\n",
      "[1,   381] loss: 0.51043, adv_train_accuracy: 81.25, clean_train_accuracy : 96.09\n",
      "[1,   386] loss: 0.44530, adv_train_accuracy: 80.47, clean_train_accuracy : 98.44\n",
      "[1,   391] loss: 0.56787, adv_train_accuracy: 76.25, clean_train_accuracy : 98.75\n",
      "fgsm robustness: 0.353515625\n",
      "pgd robustness: 0.3056640625\n",
      "duration: 159 s - train loss: 0.50401 - train accuracy: 79.27 - validation loss: 0.82356 - validation accuracy: 74.02 \n",
      "Finished Training\n",
      "21 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.49823, adv_train_accuracy: 78.91, clean_train_accuracy : 98.44\n",
      "[1,     6] loss: 0.32697, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,    11] loss: 0.40358, adv_train_accuracy: 83.59, clean_train_accuracy : 98.44\n",
      "[1,    16] loss: 0.37175, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,    21] loss: 0.44089, adv_train_accuracy: 81.25, clean_train_accuracy : 98.44\n",
      "[1,    26] loss: 0.42627, adv_train_accuracy: 79.69, clean_train_accuracy : 99.22\n",
      "[1,    31] loss: 0.47299, adv_train_accuracy: 82.81, clean_train_accuracy : 96.88\n",
      "[1,    36] loss: 0.36499, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,    41] loss: 0.38162, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,    46] loss: 0.51500, adv_train_accuracy: 78.91, clean_train_accuracy : 96.09\n",
      "[1,    51] loss: 0.41889, adv_train_accuracy: 81.25, clean_train_accuracy : 97.66\n",
      "[1,    56] loss: 0.29191, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,    61] loss: 0.41231, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,    66] loss: 0.37498, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,    71] loss: 0.46353, adv_train_accuracy: 80.47, clean_train_accuracy : 99.22\n",
      "[1,    76] loss: 0.38866, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "[1,    81] loss: 0.36662, adv_train_accuracy: 83.59, clean_train_accuracy : 96.88\n",
      "[1,    86] loss: 0.28541, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n",
      "[1,    91] loss: 0.57144, adv_train_accuracy: 80.47, clean_train_accuracy : 96.09\n",
      "[1,    96] loss: 0.43920, adv_train_accuracy: 83.59, clean_train_accuracy : 97.66\n",
      "[1,   101] loss: 0.38607, adv_train_accuracy: 86.72, clean_train_accuracy : 97.66\n",
      "[1,   106] loss: 0.42333, adv_train_accuracy: 81.25, clean_train_accuracy : 99.22\n",
      "[1,   111] loss: 0.48362, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,   116] loss: 0.45982, adv_train_accuracy: 80.47, clean_train_accuracy : 96.88\n",
      "[1,   121] loss: 0.35664, adv_train_accuracy: 85.16, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.42481, adv_train_accuracy: 80.47, clean_train_accuracy : 97.66\n",
      "[1,   131] loss: 0.36065, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.40276, adv_train_accuracy: 83.59, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.40254, adv_train_accuracy: 82.81, clean_train_accuracy : 98.44\n",
      "[1,   146] loss: 0.43670, adv_train_accuracy: 82.03, clean_train_accuracy : 98.44\n",
      "[1,   151] loss: 0.45437, adv_train_accuracy: 80.47, clean_train_accuracy : 98.44\n",
      "[1,   156] loss: 0.47812, adv_train_accuracy: 82.03, clean_train_accuracy : 98.44\n",
      "[1,   161] loss: 0.42055, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "[1,   166] loss: 0.43231, adv_train_accuracy: 80.47, clean_train_accuracy : 96.88\n",
      "[1,   171] loss: 0.44330, adv_train_accuracy: 84.38, clean_train_accuracy : 96.88\n",
      "[1,   176] loss: 0.44907, adv_train_accuracy: 79.69, clean_train_accuracy : 99.22\n",
      "[1,   181] loss: 0.39443, adv_train_accuracy: 83.59, clean_train_accuracy : 99.22\n",
      "[1,   186] loss: 0.65327, adv_train_accuracy: 71.09, clean_train_accuracy : 95.31\n",
      "[1,   191] loss: 0.51199, adv_train_accuracy: 79.69, clean_train_accuracy : 99.22\n",
      "[1,   196] loss: 0.43314, adv_train_accuracy: 86.72, clean_train_accuracy : 97.66\n",
      "[1,   201] loss: 0.41633, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,   206] loss: 0.46234, adv_train_accuracy: 79.69, clean_train_accuracy : 99.22\n",
      "[1,   211] loss: 0.53412, adv_train_accuracy: 75.78, clean_train_accuracy : 97.66\n",
      "[1,   216] loss: 0.30811, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "[1,   221] loss: 0.45955, adv_train_accuracy: 80.47, clean_train_accuracy : 97.66\n",
      "[1,   226] loss: 0.37370, adv_train_accuracy: 82.03, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.49079, adv_train_accuracy: 79.69, clean_train_accuracy : 97.66\n",
      "[1,   236] loss: 0.46528, adv_train_accuracy: 81.25, clean_train_accuracy : 98.44\n",
      "[1,   241] loss: 0.44400, adv_train_accuracy: 82.81, clean_train_accuracy : 96.88\n",
      "[1,   246] loss: 0.73364, adv_train_accuracy: 72.66, clean_train_accuracy : 96.09\n",
      "[1,   251] loss: 0.50189, adv_train_accuracy: 79.69, clean_train_accuracy : 98.44\n",
      "[1,   256] loss: 0.38570, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.59911, adv_train_accuracy: 73.44, clean_train_accuracy : 99.22\n",
      "[1,   266] loss: 0.49007, adv_train_accuracy: 82.03, clean_train_accuracy : 98.44\n",
      "[1,   271] loss: 0.50927, adv_train_accuracy: 78.91, clean_train_accuracy : 98.44\n",
      "[1,   276] loss: 0.42776, adv_train_accuracy: 83.59, clean_train_accuracy : 98.44\n",
      "[1,   281] loss: 0.43091, adv_train_accuracy: 81.25, clean_train_accuracy : 98.44\n",
      "[1,   286] loss: 0.49136, adv_train_accuracy: 76.56, clean_train_accuracy : 96.88\n",
      "[1,   291] loss: 0.49841, adv_train_accuracy: 77.34, clean_train_accuracy : 98.44\n",
      "[1,   296] loss: 0.49855, adv_train_accuracy: 78.91, clean_train_accuracy : 97.66\n",
      "[1,   301] loss: 0.46285, adv_train_accuracy: 82.03, clean_train_accuracy : 98.44\n",
      "[1,   306] loss: 0.51503, adv_train_accuracy: 77.34, clean_train_accuracy : 97.66\n",
      "[1,   311] loss: 0.61280, adv_train_accuracy: 72.66, clean_train_accuracy : 97.66\n",
      "[1,   316] loss: 0.52284, adv_train_accuracy: 77.34, clean_train_accuracy : 97.66\n",
      "[1,   321] loss: 0.50032, adv_train_accuracy: 82.81, clean_train_accuracy : 96.09\n",
      "[1,   326] loss: 0.49069, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,   331] loss: 0.46570, adv_train_accuracy: 82.03, clean_train_accuracy : 97.66\n",
      "[1,   336] loss: 0.60415, adv_train_accuracy: 75.78, clean_train_accuracy : 96.09\n",
      "[1,   341] loss: 0.53216, adv_train_accuracy: 76.56, clean_train_accuracy : 97.66\n",
      "[1,   346] loss: 0.49998, adv_train_accuracy: 78.12, clean_train_accuracy : 96.09\n",
      "[1,   351] loss: 0.65987, adv_train_accuracy: 70.31, clean_train_accuracy : 96.88\n",
      "[1,   356] loss: 0.34530, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   361] loss: 0.49284, adv_train_accuracy: 78.91, clean_train_accuracy : 99.22\n",
      "[1,   366] loss: 0.43961, adv_train_accuracy: 83.59, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.54099, adv_train_accuracy: 80.47, clean_train_accuracy : 98.44\n",
      "[1,   376] loss: 0.62091, adv_train_accuracy: 74.22, clean_train_accuracy : 98.44\n",
      "[1,   381] loss: 0.44024, adv_train_accuracy: 77.34, clean_train_accuracy : 97.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   386] loss: 0.50922, adv_train_accuracy: 75.78, clean_train_accuracy : 96.88\n",
      "[1,   391] loss: 0.49231, adv_train_accuracy: 78.75, clean_train_accuracy : 98.75\n",
      "fgsm robustness: 0.328125\n",
      "pgd robustness: 0.296875\n",
      "duration: 158 s - train loss: 0.45631 - train accuracy: 81.20 - validation loss: 0.85723 - validation accuracy: 74.03 \n",
      "Finished Training\n",
      "22 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.38946, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.41314, adv_train_accuracy: 86.72, clean_train_accuracy : 96.88\n",
      "[1,    11] loss: 0.37189, adv_train_accuracy: 81.25, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.41740, adv_train_accuracy: 81.25, clean_train_accuracy : 98.44\n",
      "[1,    21] loss: 0.42622, adv_train_accuracy: 80.47, clean_train_accuracy : 97.66\n",
      "[1,    26] loss: 0.41404, adv_train_accuracy: 83.59, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.29820, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.40322, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "[1,    41] loss: 0.59159, adv_train_accuracy: 74.22, clean_train_accuracy : 99.22\n",
      "[1,    46] loss: 0.42185, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "[1,    51] loss: 0.34341, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "[1,    56] loss: 0.48534, adv_train_accuracy: 81.25, clean_train_accuracy : 97.66\n",
      "[1,    61] loss: 0.33779, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[1,    66] loss: 0.33901, adv_train_accuracy: 84.38, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.51158, adv_train_accuracy: 78.91, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.36223, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.29717, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,    86] loss: 0.38757, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,    91] loss: 0.30619, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,    96] loss: 0.35219, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,   101] loss: 0.37197, adv_train_accuracy: 82.81, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.37392, adv_train_accuracy: 83.59, clean_train_accuracy : 98.44\n",
      "[1,   111] loss: 0.42908, adv_train_accuracy: 86.72, clean_train_accuracy : 96.09\n",
      "[1,   116] loss: 0.39140, adv_train_accuracy: 83.59, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.38684, adv_train_accuracy: 85.94, clean_train_accuracy : 97.66\n",
      "[1,   126] loss: 0.53769, adv_train_accuracy: 79.69, clean_train_accuracy : 95.31\n",
      "[1,   131] loss: 0.44238, adv_train_accuracy: 81.25, clean_train_accuracy : 97.66\n",
      "[1,   136] loss: 0.42568, adv_train_accuracy: 81.25, clean_train_accuracy : 98.44\n",
      "[1,   141] loss: 0.41435, adv_train_accuracy: 82.03, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.35232, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,   151] loss: 0.31812, adv_train_accuracy: 89.06, clean_train_accuracy : 98.44\n",
      "[1,   156] loss: 0.30060, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.38301, adv_train_accuracy: 83.59, clean_train_accuracy : 97.66\n",
      "[1,   166] loss: 0.32815, adv_train_accuracy: 83.59, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.50546, adv_train_accuracy: 80.47, clean_train_accuracy : 99.22\n",
      "[1,   176] loss: 0.40489, adv_train_accuracy: 84.38, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.41048, adv_train_accuracy: 81.25, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.43156, adv_train_accuracy: 85.16, clean_train_accuracy : 98.44\n",
      "[1,   191] loss: 0.46997, adv_train_accuracy: 85.16, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.31347, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "[1,   201] loss: 0.48979, adv_train_accuracy: 80.47, clean_train_accuracy : 97.66\n",
      "[1,   206] loss: 0.56860, adv_train_accuracy: 79.69, clean_train_accuracy : 96.88\n",
      "[1,   211] loss: 0.44164, adv_train_accuracy: 79.69, clean_train_accuracy : 99.22\n",
      "[1,   216] loss: 0.43297, adv_train_accuracy: 79.69, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.56511, adv_train_accuracy: 78.12, clean_train_accuracy : 96.88\n",
      "[1,   226] loss: 0.45122, adv_train_accuracy: 83.59, clean_train_accuracy : 96.88\n",
      "[1,   231] loss: 0.35648, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   236] loss: 0.41568, adv_train_accuracy: 82.03, clean_train_accuracy : 98.44\n",
      "[1,   241] loss: 0.39613, adv_train_accuracy: 82.03, clean_train_accuracy : 99.22\n",
      "[1,   246] loss: 0.37068, adv_train_accuracy: 80.47, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.31194, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   256] loss: 0.42841, adv_train_accuracy: 80.47, clean_train_accuracy : 98.44\n",
      "[1,   261] loss: 0.33520, adv_train_accuracy: 87.50, clean_train_accuracy : 98.44\n",
      "[1,   266] loss: 0.43240, adv_train_accuracy: 79.69, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.40806, adv_train_accuracy: 85.16, clean_train_accuracy : 96.88\n",
      "[1,   276] loss: 0.35039, adv_train_accuracy: 89.84, clean_train_accuracy : 96.88\n",
      "[1,   281] loss: 0.30585, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.41335, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,   291] loss: 0.33720, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.42829, adv_train_accuracy: 83.59, clean_train_accuracy : 97.66\n",
      "[1,   301] loss: 0.46992, adv_train_accuracy: 78.91, clean_train_accuracy : 96.09\n",
      "[1,   306] loss: 0.43421, adv_train_accuracy: 81.25, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.40956, adv_train_accuracy: 79.69, clean_train_accuracy : 99.22\n",
      "[1,   316] loss: 0.58620, adv_train_accuracy: 76.56, clean_train_accuracy : 98.44\n",
      "[1,   321] loss: 0.42942, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   326] loss: 0.41130, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,   331] loss: 0.49377, adv_train_accuracy: 82.03, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.41430, adv_train_accuracy: 81.25, clean_train_accuracy : 94.53\n",
      "[1,   341] loss: 0.38498, adv_train_accuracy: 83.59, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.43322, adv_train_accuracy: 82.81, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.59697, adv_train_accuracy: 75.00, clean_train_accuracy : 97.66\n",
      "[1,   356] loss: 0.35291, adv_train_accuracy: 84.38, clean_train_accuracy : 97.66\n",
      "[1,   361] loss: 0.37798, adv_train_accuracy: 85.16, clean_train_accuracy : 98.44\n",
      "[1,   366] loss: 0.43552, adv_train_accuracy: 85.16, clean_train_accuracy : 96.88\n",
      "[1,   371] loss: 0.47985, adv_train_accuracy: 78.12, clean_train_accuracy : 97.66\n",
      "[1,   376] loss: 0.46480, adv_train_accuracy: 77.34, clean_train_accuracy : 98.44\n",
      "[1,   381] loss: 0.41434, adv_train_accuracy: 83.59, clean_train_accuracy : 99.22\n",
      "[1,   386] loss: 0.44460, adv_train_accuracy: 83.59, clean_train_accuracy : 99.22\n",
      "[1,   391] loss: 0.33110, adv_train_accuracy: 80.00, clean_train_accuracy : 97.50\n",
      "fgsm robustness: 0.333984375\n",
      "pgd robustness: 0.265625\n",
      "duration: 158 s - train loss: 0.40867 - train accuracy: 83.25 - validation loss: 0.83809 - validation accuracy: 73.87 \n",
      "Finished Training\n",
      "23 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.22346, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.38298, adv_train_accuracy: 85.16, clean_train_accuracy : 96.88\n",
      "[1,    11] loss: 0.29824, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,    16] loss: 0.30567, adv_train_accuracy: 88.28, clean_train_accuracy : 98.44\n",
      "[1,    21] loss: 0.28011, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    26] loss: 0.22963, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.34024, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.44564, adv_train_accuracy: 82.81, clean_train_accuracy : 96.88\n",
      "[1,    41] loss: 0.38022, adv_train_accuracy: 82.03, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.33946, adv_train_accuracy: 87.50, clean_train_accuracy : 98.44\n",
      "[1,    51] loss: 0.30708, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n",
      "[1,    56] loss: 0.29750, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,    61] loss: 0.29020, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    66] loss: 0.24280, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,    71] loss: 0.33634, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,    76] loss: 0.26542, adv_train_accuracy: 88.28, clean_train_accuracy : 96.88\n",
      "[1,    81] loss: 0.33782, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.44173, adv_train_accuracy: 82.81, clean_train_accuracy : 95.31\n",
      "[1,    91] loss: 0.38138, adv_train_accuracy: 83.59, clean_train_accuracy : 95.31\n",
      "[1,    96] loss: 0.37186, adv_train_accuracy: 82.03, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.34308, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.38721, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,   111] loss: 0.36697, adv_train_accuracy: 83.59, clean_train_accuracy : 98.44\n",
      "[1,   116] loss: 0.36403, adv_train_accuracy: 86.72, clean_train_accuracy : 97.66\n",
      "[1,   121] loss: 0.38683, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,   126] loss: 0.23255, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.37903, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[1,   136] loss: 0.35507, adv_train_accuracy: 85.16, clean_train_accuracy : 98.44\n",
      "[1,   141] loss: 0.24974, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   146] loss: 0.24809, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.28000, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,   156] loss: 0.21680, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.42965, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,   166] loss: 0.49244, adv_train_accuracy: 79.69, clean_train_accuracy : 96.88\n",
      "[1,   171] loss: 0.34826, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,   176] loss: 0.33487, adv_train_accuracy: 83.59, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.33318, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   186] loss: 0.41343, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "[1,   191] loss: 0.31455, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   196] loss: 0.34822, adv_train_accuracy: 88.28, clean_train_accuracy : 98.44\n",
      "[1,   201] loss: 0.35397, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   206] loss: 0.40292, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.40173, adv_train_accuracy: 82.03, clean_train_accuracy : 97.66\n",
      "[1,   216] loss: 0.30066, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.41944, adv_train_accuracy: 82.81, clean_train_accuracy : 98.44\n",
      "[1,   226] loss: 0.27987, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.29251, adv_train_accuracy: 84.38, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.41028, adv_train_accuracy: 85.16, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.44821, adv_train_accuracy: 82.03, clean_train_accuracy : 99.22\n",
      "[1,   246] loss: 0.43560, adv_train_accuracy: 85.94, clean_train_accuracy : 97.66\n",
      "[1,   251] loss: 0.36000, adv_train_accuracy: 85.16, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.38544, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   261] loss: 0.33787, adv_train_accuracy: 85.16, clean_train_accuracy : 98.44\n",
      "[1,   266] loss: 0.28553, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,   271] loss: 0.49424, adv_train_accuracy: 78.91, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.34453, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   281] loss: 0.42894, adv_train_accuracy: 81.25, clean_train_accuracy : 99.22\n",
      "[1,   286] loss: 0.32883, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   291] loss: 0.36668, adv_train_accuracy: 85.16, clean_train_accuracy : 98.44\n",
      "[1,   296] loss: 0.36963, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.38155, adv_train_accuracy: 85.16, clean_train_accuracy : 96.88\n",
      "[1,   306] loss: 0.38954, adv_train_accuracy: 83.59, clean_train_accuracy : 98.44\n",
      "[1,   311] loss: 0.51602, adv_train_accuracy: 78.12, clean_train_accuracy : 97.66\n",
      "[1,   316] loss: 0.29041, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   321] loss: 0.36737, adv_train_accuracy: 83.59, clean_train_accuracy : 99.22\n",
      "[1,   326] loss: 0.44947, adv_train_accuracy: 82.81, clean_train_accuracy : 98.44\n",
      "[1,   331] loss: 0.40003, adv_train_accuracy: 82.03, clean_train_accuracy : 98.44\n",
      "[1,   336] loss: 0.34332, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   341] loss: 0.28795, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.35625, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,   351] loss: 0.43902, adv_train_accuracy: 80.47, clean_train_accuracy : 98.44\n",
      "[1,   356] loss: 0.35411, adv_train_accuracy: 84.38, clean_train_accuracy : 97.66\n",
      "[1,   361] loss: 0.42061, adv_train_accuracy: 81.25, clean_train_accuracy : 98.44\n",
      "[1,   366] loss: 0.38742, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "[1,   371] loss: 0.49403, adv_train_accuracy: 79.69, clean_train_accuracy : 96.09\n",
      "[1,   376] loss: 0.31326, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,   381] loss: 0.42217, adv_train_accuracy: 82.03, clean_train_accuracy : 96.09\n",
      "[1,   386] loss: 0.33932, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,   391] loss: 0.45873, adv_train_accuracy: 80.00, clean_train_accuracy : 97.50\n",
      "fgsm robustness: 0.3408203125\n",
      "pgd robustness: 0.2744140625\n",
      "duration: 158 s - train loss: 0.35649 - train accuracy: 85.53 - validation loss: 0.91188 - validation accuracy: 72.94 \n",
      "Finished Training\n",
      "24 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.30476, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[1,     6] loss: 0.24172, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,    11] loss: 0.21541, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.32229, adv_train_accuracy: 86.72, clean_train_accuracy : 97.66\n",
      "[1,    21] loss: 0.26987, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,    26] loss: 0.31201, adv_train_accuracy: 89.06, clean_train_accuracy : 98.44\n",
      "[1,    31] loss: 0.22089, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.33890, adv_train_accuracy: 82.81, clean_train_accuracy : 98.44\n",
      "[1,    41] loss: 0.36155, adv_train_accuracy: 87.50, clean_train_accuracy : 98.44\n",
      "[1,    46] loss: 0.29375, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.33721, adv_train_accuracy: 85.16, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.28872, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[1,    61] loss: 0.29377, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,    66] loss: 0.29082, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,    71] loss: 0.34482, adv_train_accuracy: 83.59, clean_train_accuracy : 98.44\n",
      "[1,    76] loss: 0.29302, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n",
      "[1,    81] loss: 0.37135, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,    86] loss: 0.33481, adv_train_accuracy: 88.28, clean_train_accuracy : 97.66\n",
      "[1,    91] loss: 0.31894, adv_train_accuracy: 84.38, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.32710, adv_train_accuracy: 84.38, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.23745, adv_train_accuracy: 87.50, clean_train_accuracy : 98.44\n",
      "[1,   106] loss: 0.35065, adv_train_accuracy: 83.59, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 1.32516, adv_train_accuracy: 82.03, clean_train_accuracy : 98.44\n",
      "[1,   116] loss: 0.71816, adv_train_accuracy: 72.66, clean_train_accuracy : 97.66\n",
      "[1,   121] loss: 0.87093, adv_train_accuracy: 67.97, clean_train_accuracy : 96.09\n",
      "[1,   126] loss: 0.99727, adv_train_accuracy: 60.94, clean_train_accuracy : 96.88\n",
      "[1,   131] loss: 1.11529, adv_train_accuracy: 57.03, clean_train_accuracy : 95.31\n",
      "[1,   136] loss: 0.86904, adv_train_accuracy: 67.97, clean_train_accuracy : 93.75\n",
      "[1,   141] loss: 1.26355, adv_train_accuracy: 53.12, clean_train_accuracy : 94.53\n",
      "[1,   146] loss: 0.89078, adv_train_accuracy: 69.53, clean_train_accuracy : 94.53\n",
      "[1,   151] loss: 0.80502, adv_train_accuracy: 71.09, clean_train_accuracy : 94.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   156] loss: 0.81786, adv_train_accuracy: 69.53, clean_train_accuracy : 97.66\n",
      "[1,   161] loss: 0.77025, adv_train_accuracy: 72.66, clean_train_accuracy : 94.53\n",
      "[1,   166] loss: 0.59585, adv_train_accuracy: 75.78, clean_train_accuracy : 96.88\n",
      "[1,   171] loss: 0.77441, adv_train_accuracy: 72.66, clean_train_accuracy : 93.75\n",
      "[1,   176] loss: 0.62678, adv_train_accuracy: 74.22, clean_train_accuracy : 96.88\n",
      "[1,   181] loss: 0.55937, adv_train_accuracy: 78.12, clean_train_accuracy : 96.88\n",
      "[1,   186] loss: 0.80303, adv_train_accuracy: 68.75, clean_train_accuracy : 97.66\n",
      "[1,   191] loss: 0.46676, adv_train_accuracy: 78.91, clean_train_accuracy : 96.88\n",
      "[1,   196] loss: 0.56090, adv_train_accuracy: 74.22, clean_train_accuracy : 98.44\n",
      "[1,   201] loss: 0.54999, adv_train_accuracy: 73.44, clean_train_accuracy : 99.22\n",
      "[1,   206] loss: 0.51608, adv_train_accuracy: 78.12, clean_train_accuracy : 98.44\n",
      "[1,   211] loss: 0.58384, adv_train_accuracy: 73.44, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.50981, adv_train_accuracy: 81.25, clean_train_accuracy : 97.66\n",
      "[1,   221] loss: 0.44096, adv_train_accuracy: 79.69, clean_train_accuracy : 98.44\n",
      "[1,   226] loss: 0.42705, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.55114, adv_train_accuracy: 76.56, clean_train_accuracy : 98.44\n",
      "[1,   236] loss: 0.58548, adv_train_accuracy: 74.22, clean_train_accuracy : 98.44\n",
      "[1,   241] loss: 0.48610, adv_train_accuracy: 81.25, clean_train_accuracy : 97.66\n",
      "[1,   246] loss: 0.58021, adv_train_accuracy: 75.00, clean_train_accuracy : 96.88\n",
      "[1,   251] loss: 0.49363, adv_train_accuracy: 81.25, clean_train_accuracy : 98.44\n",
      "[1,   256] loss: 0.43519, adv_train_accuracy: 85.94, clean_train_accuracy : 98.44\n",
      "[1,   261] loss: 0.44689, adv_train_accuracy: 78.91, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.47321, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,   271] loss: 0.42142, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   276] loss: 0.35900, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[1,   281] loss: 0.39851, adv_train_accuracy: 82.03, clean_train_accuracy : 98.44\n",
      "[1,   286] loss: 0.39510, adv_train_accuracy: 78.91, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.28737, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.40737, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "[1,   301] loss: 0.40623, adv_train_accuracy: 79.69, clean_train_accuracy : 97.66\n",
      "[1,   306] loss: 0.33310, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   311] loss: 0.37125, adv_train_accuracy: 84.38, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.44798, adv_train_accuracy: 80.47, clean_train_accuracy : 97.66\n",
      "[1,   321] loss: 0.40026, adv_train_accuracy: 82.81, clean_train_accuracy : 95.31\n",
      "[1,   326] loss: 0.41613, adv_train_accuracy: 83.59, clean_train_accuracy : 99.22\n",
      "[1,   331] loss: 0.35325, adv_train_accuracy: 82.81, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.32116, adv_train_accuracy: 83.59, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.28730, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.32962, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n",
      "[1,   351] loss: 0.27535, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.33764, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "[1,   361] loss: 0.42719, adv_train_accuracy: 83.59, clean_train_accuracy : 98.44\n",
      "[1,   366] loss: 0.40709, adv_train_accuracy: 80.47, clean_train_accuracy : 99.22\n",
      "[1,   371] loss: 0.37252, adv_train_accuracy: 87.50, clean_train_accuracy : 96.09\n",
      "[1,   376] loss: 0.47033, adv_train_accuracy: 78.12, clean_train_accuracy : 97.66\n",
      "[1,   381] loss: 0.36196, adv_train_accuracy: 84.38, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.29320, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   391] loss: 0.32887, adv_train_accuracy: 87.50, clean_train_accuracy : 98.75\n",
      "fgsm robustness: 0.298828125\n",
      "pgd robustness: 0.2802734375\n",
      "duration: 158 s - train loss: 0.47698 - train accuracy: 81.29 - validation loss: 0.84655 - validation accuracy: 73.73 \n",
      "Finished Training\n",
      "25 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.27035, adv_train_accuracy: 87.50, clean_train_accuracy : 98.44\n",
      "[1,     6] loss: 0.31400, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.25407, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    16] loss: 0.26419, adv_train_accuracy: 89.84, clean_train_accuracy : 98.44\n",
      "[1,    21] loss: 0.21364, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    26] loss: 0.31838, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,    31] loss: 0.40403, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "[1,    36] loss: 0.32508, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,    41] loss: 0.38966, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,    46] loss: 0.35974, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,    51] loss: 0.23872, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.26441, adv_train_accuracy: 89.84, clean_train_accuracy : 98.44\n",
      "[1,    61] loss: 0.32907, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.33315, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[1,    71] loss: 0.28977, adv_train_accuracy: 89.06, clean_train_accuracy : 97.66\n",
      "[1,    76] loss: 0.31545, adv_train_accuracy: 88.28, clean_train_accuracy : 97.66\n",
      "[1,    81] loss: 0.24374, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,    86] loss: 0.32929, adv_train_accuracy: 85.94, clean_train_accuracy : 97.66\n",
      "[1,    91] loss: 0.29761, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,    96] loss: 0.33191, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n",
      "[1,   101] loss: 0.22719, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   106] loss: 0.17950, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   111] loss: 0.22996, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   116] loss: 0.26699, adv_train_accuracy: 91.41, clean_train_accuracy : 98.44\n",
      "[1,   121] loss: 0.22392, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   126] loss: 0.20977, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   131] loss: 0.27385, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   136] loss: 0.33421, adv_train_accuracy: 88.28, clean_train_accuracy : 98.44\n",
      "[1,   141] loss: 0.33535, adv_train_accuracy: 88.28, clean_train_accuracy : 98.44\n",
      "[1,   146] loss: 0.31121, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.21737, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   156] loss: 0.24116, adv_train_accuracy: 92.19, clean_train_accuracy : 98.44\n",
      "[1,   161] loss: 0.30181, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.27498, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   171] loss: 0.20795, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.27788, adv_train_accuracy: 89.84, clean_train_accuracy : 98.44\n",
      "[1,   181] loss: 0.22428, adv_train_accuracy: 88.28, clean_train_accuracy : 98.44\n",
      "[1,   186] loss: 0.22782, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   191] loss: 0.28842, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   196] loss: 0.30758, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.21690, adv_train_accuracy: 92.19, clean_train_accuracy : 98.44\n",
      "[1,   206] loss: 0.31608, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,   211] loss: 0.24477, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   216] loss: 0.27719, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   221] loss: 0.30745, adv_train_accuracy: 83.59, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.30720, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.24847, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   236] loss: 0.23203, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   241] loss: 0.20349, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   246] loss: 0.18497, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.31048, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   256] loss: 0.24949, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.36798, adv_train_accuracy: 88.28, clean_train_accuracy : 97.66\n",
      "[1,   266] loss: 0.33355, adv_train_accuracy: 88.28, clean_train_accuracy : 98.44\n",
      "[1,   271] loss: 0.28434, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,   276] loss: 0.29985, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.35668, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,   286] loss: 0.30156, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   291] loss: 0.28782, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,   296] loss: 0.34422, adv_train_accuracy: 89.06, clean_train_accuracy : 97.66\n",
      "[1,   301] loss: 0.30911, adv_train_accuracy: 85.16, clean_train_accuracy : 98.44\n",
      "[1,   306] loss: 0.26247, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n",
      "[1,   311] loss: 0.26130, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   316] loss: 0.25008, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.34839, adv_train_accuracy: 82.81, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.24437, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.33710, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "[1,   336] loss: 0.28141, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.32666, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.28572, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   351] loss: 0.28233, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.22658, adv_train_accuracy: 92.19, clean_train_accuracy : 97.66\n",
      "[1,   361] loss: 0.37353, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   366] loss: 0.33739, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.42349, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,   376] loss: 0.29617, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,   381] loss: 0.25295, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   386] loss: 0.26371, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.22455, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.33984375\n",
      "pgd robustness: 0.2646484375\n",
      "duration: 158 s - train loss: 0.27810 - train accuracy: 88.85 - validation loss: 0.90658 - validation accuracy: 73.78 \n",
      "Finished Training\n",
      "26 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.17314, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.22240, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,    11] loss: 0.24108, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,    16] loss: 0.30908, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,    21] loss: 0.21307, adv_train_accuracy: 92.19, clean_train_accuracy : 98.44\n",
      "[1,    26] loss: 0.26503, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,    31] loss: 0.22277, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,    36] loss: 0.23481, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,    41] loss: 0.15662, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.18977, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.26963, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.25581, adv_train_accuracy: 91.41, clean_train_accuracy : 98.44\n",
      "[1,    61] loss: 0.28967, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.31195, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n",
      "[1,    71] loss: 0.21889, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.26229, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,    81] loss: 0.21723, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    86] loss: 0.26650, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.43432, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "[1,    96] loss: 0.39007, adv_train_accuracy: 85.16, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.37618, adv_train_accuracy: 82.81, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.27755, adv_train_accuracy: 87.50, clean_train_accuracy : 98.44\n",
      "[1,   111] loss: 0.20050, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.22780, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   121] loss: 0.24879, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.18543, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   131] loss: 0.20810, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.30040, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   141] loss: 0.23871, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   146] loss: 0.26552, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n",
      "[1,   151] loss: 0.18446, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.27878, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,   161] loss: 0.22465, adv_train_accuracy: 89.84, clean_train_accuracy : 98.44\n",
      "[1,   166] loss: 0.24151, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   171] loss: 0.23162, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.21300, adv_train_accuracy: 89.84, clean_train_accuracy : 98.44\n",
      "[1,   181] loss: 0.21614, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.22009, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.20944, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   196] loss: 0.21347, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.25026, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.39334, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.26684, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   216] loss: 0.29520, adv_train_accuracy: 89.84, clean_train_accuracy : 98.44\n",
      "[1,   221] loss: 0.25808, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.30734, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.24318, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.31138, adv_train_accuracy: 88.28, clean_train_accuracy : 98.44\n",
      "[1,   241] loss: 0.36625, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "[1,   246] loss: 0.31916, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.24821, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   256] loss: 0.25701, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.39963, adv_train_accuracy: 82.81, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.35025, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[1,   271] loss: 0.28294, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.38577, adv_train_accuracy: 89.84, clean_train_accuracy : 98.44\n",
      "[1,   281] loss: 0.26147, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.30441, adv_train_accuracy: 89.06, clean_train_accuracy : 98.44\n",
      "[1,   291] loss: 0.32605, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,   296] loss: 0.31835, adv_train_accuracy: 87.50, clean_train_accuracy : 97.66\n",
      "[1,   301] loss: 0.26811, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   306] loss: 0.30833, adv_train_accuracy: 89.06, clean_train_accuracy : 98.44\n",
      "[1,   311] loss: 0.42477, adv_train_accuracy: 84.38, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.27037, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.31667, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.30190, adv_train_accuracy: 87.50, clean_train_accuracy : 97.66\n",
      "[1,   331] loss: 0.39299, adv_train_accuracy: 82.81, clean_train_accuracy : 98.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   336] loss: 0.35493, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,   341] loss: 0.29643, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.25683, adv_train_accuracy: 85.16, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.33513, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.32496, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.37846, adv_train_accuracy: 82.81, clean_train_accuracy : 99.22\n",
      "[1,   366] loss: 0.21948, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.28722, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "[1,   376] loss: 0.20960, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   381] loss: 0.31500, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   386] loss: 0.34778, adv_train_accuracy: 82.03, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.34661, adv_train_accuracy: 91.25, clean_train_accuracy : 98.75\n",
      "fgsm robustness: 0.36328125\n",
      "pgd robustness: 0.2900390625\n",
      "duration: 158 s - train loss: 0.27038 - train accuracy: 89.24 - validation loss: 0.90082 - validation accuracy: 73.79 \n",
      "Finished Training\n",
      "27 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.23023, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.35592, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    11] loss: 0.20319, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.13894, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.22630, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.24277, adv_train_accuracy: 89.84, clean_train_accuracy : 98.44\n",
      "[1,    31] loss: 0.30940, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    36] loss: 0.19997, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.20569, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.15069, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,    51] loss: 0.20894, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n",
      "[1,    56] loss: 0.19313, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.23294, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,    66] loss: 0.22435, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,    71] loss: 0.24732, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.20218, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.26986, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    86] loss: 0.21151, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.26935, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,    96] loss: 0.31045, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,   101] loss: 0.26671, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.24667, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.19572, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   116] loss: 0.29816, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.25838, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.29048, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   131] loss: 0.30707, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   136] loss: 0.25355, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.27705, adv_train_accuracy: 84.38, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.18204, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.26836, adv_train_accuracy: 90.62, clean_train_accuracy : 97.66\n",
      "[1,   156] loss: 0.21537, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   161] loss: 0.19453, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   166] loss: 0.17317, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.23400, adv_train_accuracy: 89.84, clean_train_accuracy : 98.44\n",
      "[1,   176] loss: 0.24392, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   181] loss: 0.31081, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.26123, adv_train_accuracy: 89.84, clean_train_accuracy : 97.66\n",
      "[1,   191] loss: 0.21197, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.15581, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.22604, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   206] loss: 0.25940, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.27155, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   216] loss: 0.27478, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "[1,   221] loss: 0.30593, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.31596, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.31167, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.36063, adv_train_accuracy: 85.94, clean_train_accuracy : 98.44\n",
      "[1,   241] loss: 0.30059, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   246] loss: 0.32050, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.30030, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.26713, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   261] loss: 0.26459, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.25954, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   271] loss: 0.32965, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.29694, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.35492, adv_train_accuracy: 87.50, clean_train_accuracy : 98.44\n",
      "[1,   286] loss: 0.34403, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   291] loss: 0.28604, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.30470, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.32655, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   306] loss: 0.19872, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.39535, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,   316] loss: 0.30985, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   321] loss: 0.42937, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,   326] loss: 0.35458, adv_train_accuracy: 83.59, clean_train_accuracy : 99.22\n",
      "[1,   331] loss: 0.25764, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   336] loss: 0.22769, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   341] loss: 0.25698, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.22034, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   351] loss: 0.32256, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,   356] loss: 0.35996, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,   361] loss: 0.34294, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.39959, adv_train_accuracy: 80.47, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.30347, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.30908, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   381] loss: 0.29526, adv_train_accuracy: 92.19, clean_train_accuracy : 98.44\n",
      "[1,   386] loss: 0.21680, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.24029, adv_train_accuracy: 88.75, clean_train_accuracy : 97.50\n",
      "fgsm robustness: 0.3271484375\n",
      "pgd robustness: 0.2529296875\n",
      "duration: 158 s - train loss: 0.27510 - train accuracy: 89.05 - validation loss: 0.86217 - validation accuracy: 74.01 \n",
      "Finished Training\n",
      "28 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.16959, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.30187, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.27346, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    16] loss: 0.32130, adv_train_accuracy: 89.06, clean_train_accuracy : 98.44\n",
      "[1,    21] loss: 0.38678, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,    26] loss: 0.24694, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.29910, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.17083, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.24078, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.32309, adv_train_accuracy: 88.28, clean_train_accuracy : 98.44\n",
      "[1,    51] loss: 0.18558, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.18462, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.15375, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.22888, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.22196, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    76] loss: 0.13041, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.17205, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    86] loss: 0.16218, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.14956, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,    96] loss: 0.19828, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.21697, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   106] loss: 0.21845, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.14140, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   116] loss: 0.23317, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.20050, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.21783, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.28662, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.20626, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   141] loss: 0.24665, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.18115, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.24510, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n",
      "[1,   156] loss: 0.29680, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.34690, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.17185, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   171] loss: 0.18894, adv_train_accuracy: 92.97, clean_train_accuracy : 97.66\n",
      "[1,   176] loss: 0.21122, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.22875, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   186] loss: 0.22249, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.28735, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[1,   196] loss: 0.24868, adv_train_accuracy: 89.06, clean_train_accuracy : 98.44\n",
      "[1,   201] loss: 0.21941, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.23716, adv_train_accuracy: 89.06, clean_train_accuracy : 98.44\n",
      "[1,   211] loss: 0.30192, adv_train_accuracy: 90.62, clean_train_accuracy : 97.66\n",
      "[1,   216] loss: 0.23090, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   221] loss: 0.18501, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.17185, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.26686, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.45924, adv_train_accuracy: 89.06, clean_train_accuracy : 98.44\n",
      "[1,   241] loss: 0.25426, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   246] loss: 0.32179, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.27149, adv_train_accuracy: 88.28, clean_train_accuracy : 98.44\n",
      "[1,   256] loss: 0.26080, adv_train_accuracy: 89.06, clean_train_accuracy : 98.44\n",
      "[1,   261] loss: 0.24108, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   266] loss: 0.15836, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.21627, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.32015, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.17095, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.31441, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "[1,   291] loss: 0.22670, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n",
      "[1,   296] loss: 0.20566, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.23890, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.19969, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   311] loss: 0.17323, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.29140, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   321] loss: 0.39959, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "[1,   326] loss: 0.25194, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.20840, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.30698, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   341] loss: 0.22278, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.27802, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.24643, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   356] loss: 0.23757, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.30596, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   366] loss: 0.27407, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   371] loss: 0.25364, adv_train_accuracy: 89.84, clean_train_accuracy : 97.66\n",
      "[1,   376] loss: 0.21808, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.17742, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.22471, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.23002, adv_train_accuracy: 88.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3193359375\n",
      "pgd robustness: 0.24609375\n",
      "duration: 158 s - train loss: 0.23411 - train accuracy: 90.81 - validation loss: 1.00047 - validation accuracy: 73.89 \n",
      "Finished Training\n",
      "29 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.17520, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,     6] loss: 0.19525, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.17787, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.29037, adv_train_accuracy: 87.50, clean_train_accuracy : 98.44\n",
      "[1,    21] loss: 0.20391, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    26] loss: 0.27124, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,    31] loss: 0.18574, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    36] loss: 0.15399, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.19908, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.15114, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,    51] loss: 0.11520, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    56] loss: 0.24160, adv_train_accuracy: 89.06, clean_train_accuracy : 98.44\n",
      "[1,    61] loss: 0.17450, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.16589, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,    71] loss: 0.20633, adv_train_accuracy: 91.41, clean_train_accuracy : 98.44\n",
      "[1,    76] loss: 0.23997, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.29047, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "[1,    86] loss: 0.21254, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.25656, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    96] loss: 0.28002, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.17576, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   106] loss: 0.19618, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.16154, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   116] loss: 0.31205, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.16983, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   126] loss: 0.23285, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.27244, adv_train_accuracy: 91.41, clean_train_accuracy : 98.44\n",
      "[1,   136] loss: 0.30630, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.27304, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   146] loss: 0.13747, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.24114, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.18209, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.28308, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.19935, adv_train_accuracy: 94.53, clean_train_accuracy : 98.44\n",
      "[1,   171] loss: 0.21309, adv_train_accuracy: 91.41, clean_train_accuracy : 98.44\n",
      "[1,   176] loss: 0.26166, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.28464, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.20834, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   191] loss: 0.22388, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.23263, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.27309, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.15623, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.25047, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.19434, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.20813, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.19132, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.21103, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.19734, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.32799, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   246] loss: 0.30045, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   251] loss: 0.21574, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.17122, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   261] loss: 0.18827, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.25297, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.22872, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.26388, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   281] loss: 0.32100, adv_train_accuracy: 86.72, clean_train_accuracy : 96.88\n",
      "[1,   286] loss: 0.20005, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.21146, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.28338, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.38426, adv_train_accuracy: 83.59, clean_train_accuracy : 98.44\n",
      "[1,   306] loss: 0.27799, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.34188, adv_train_accuracy: 85.16, clean_train_accuracy : 98.44\n",
      "[1,   316] loss: 0.24537, adv_train_accuracy: 88.28, clean_train_accuracy : 97.66\n",
      "[1,   321] loss: 0.15402, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.35439, adv_train_accuracy: 82.81, clean_train_accuracy : 98.44\n",
      "[1,   331] loss: 0.39153, adv_train_accuracy: 82.03, clean_train_accuracy : 99.22\n",
      "[1,   336] loss: 0.21325, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.25544, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.28904, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[1,   351] loss: 0.34451, adv_train_accuracy: 89.06, clean_train_accuracy : 98.44\n",
      "[1,   356] loss: 0.24309, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.28565, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.29745, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.32959, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.21728, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.38038, adv_train_accuracy: 85.16, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.37148, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[1,   391] loss: 0.33693, adv_train_accuracy: 86.25, clean_train_accuracy : 98.75\n",
      "fgsm robustness: 0.3046875\n",
      "pgd robustness: 0.244140625\n",
      "duration: 158 s - train loss: 0.24169 - train accuracy: 90.57 - validation loss: 0.85959 - validation accuracy: 73.64 \n",
      "Finished Training\n",
      "30 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.22547, adv_train_accuracy: 92.97, clean_train_accuracy : 98.44\n",
      "[1,     6] loss: 0.26571, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,    11] loss: 0.17721, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,    16] loss: 0.16441, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.19212, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,    26] loss: 0.19430, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.26787, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.21005, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.17558, adv_train_accuracy: 95.31, clean_train_accuracy : 97.66\n",
      "[1,    46] loss: 0.15692, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.16886, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.17180, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.24887, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.18199, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.23796, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.20107, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.30368, adv_train_accuracy: 87.50, clean_train_accuracy : 98.44\n",
      "[1,    86] loss: 0.12810, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.25716, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,    96] loss: 0.28805, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,   101] loss: 0.28370, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.23465, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   111] loss: 0.24652, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.17482, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.22040, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.20014, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.19836, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   136] loss: 0.24655, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.38614, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[1,   146] loss: 0.23103, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.21098, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.25043, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   161] loss: 0.16061, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   166] loss: 0.28976, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.15769, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   176] loss: 0.20873, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.14948, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.28664, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.20271, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   196] loss: 0.18400, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.23883, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.29814, adv_train_accuracy: 91.41, clean_train_accuracy : 97.66\n",
      "[1,   211] loss: 0.18489, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.21640, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   221] loss: 0.19610, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   226] loss: 0.23015, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.18672, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.16150, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.16675, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.22041, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.17856, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.18611, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.19129, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   266] loss: 0.18052, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.27027, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.18933, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.27349, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.18422, adv_train_accuracy: 92.97, clean_train_accuracy : 98.44\n",
      "[1,   291] loss: 0.23956, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.18089, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.15299, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   306] loss: 0.23789, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.28632, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.21860, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.20765, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.26661, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.12414, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.23984, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   341] loss: 0.21103, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.29885, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[1,   351] loss: 0.30427, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.26718, adv_train_accuracy: 91.41, clean_train_accuracy : 98.44\n",
      "[1,   361] loss: 0.24038, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.21692, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.19974, adv_train_accuracy: 91.41, clean_train_accuracy : 98.44\n",
      "[1,   376] loss: 0.32368, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.29383, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   386] loss: 0.21078, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   391] loss: 0.25936, adv_train_accuracy: 92.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.326171875\n",
      "pgd robustness: 0.265625\n",
      "duration: 158 s - train loss: 0.22058 - train accuracy: 91.27 - validation loss: 0.94536 - validation accuracy: 73.33 \n",
      "Finished Training\n",
      "31 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.21564, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.28571, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[1,    11] loss: 0.22464, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.15759, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.18196, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    26] loss: 0.11063, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.23661, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.18584, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.13816, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.15262, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.13010, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.15094, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,    61] loss: 0.16433, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.21966, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.15168, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,    76] loss: 0.17307, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.36654, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    86] loss: 0.16504, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.12690, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.11556, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.18315, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.15040, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.12194, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.09692, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.12674, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   126] loss: 0.17974, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.29956, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.26553, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.22571, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.18631, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.15966, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   156] loss: 0.13893, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.24971, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.32577, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.26463, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.20033, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   181] loss: 0.15940, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   186] loss: 0.24475, adv_train_accuracy: 89.84, clean_train_accuracy : 98.44\n",
      "[1,   191] loss: 0.25805, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.17264, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.19940, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.18307, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.23758, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.19583, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   221] loss: 0.24024, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   226] loss: 0.20678, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.21338, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.27293, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.26470, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.38267, adv_train_accuracy: 80.47, clean_train_accuracy : 99.22\n",
      "[1,   251] loss: 0.28362, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   256] loss: 0.24495, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.19972, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   266] loss: 0.37189, adv_train_accuracy: 82.03, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.29338, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   276] loss: 0.24694, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.22496, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   286] loss: 0.20751, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   291] loss: 0.16118, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   296] loss: 0.22781, adv_train_accuracy: 89.84, clean_train_accuracy : 98.44\n",
      "[1,   301] loss: 0.21680, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   306] loss: 0.16599, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.18163, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.14428, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.15342, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.18382, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.20691, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.22425, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   341] loss: 0.15409, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.15037, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   351] loss: 0.26370, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.32178, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.14658, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.12573, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.17410, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.22686, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.22391, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   386] loss: 0.19110, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.30748, adv_train_accuracy: 90.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3310546875\n",
      "pgd robustness: 0.25390625\n",
      "duration: 158 s - train loss: 0.20430 - train accuracy: 91.98 - validation loss: 0.91254 - validation accuracy: 73.30 \n",
      "Finished Training\n",
      "32 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.19304, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.25558, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,    11] loss: 0.11185, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.08466, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.33498, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.29872, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    31] loss: 0.23380, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    36] loss: 0.19651, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.12268, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    46] loss: 0.14767, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,    51] loss: 0.21657, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,    56] loss: 0.13183, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.23834, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.16979, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.22733, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.18613, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.17653, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.26552, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.24208, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,    96] loss: 0.12274, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   101] loss: 0.16594, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.14815, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.11191, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.15814, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   121] loss: 0.11813, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   126] loss: 0.08245, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.10284, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.23381, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.16878, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.16208, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.15998, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.18825, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   161] loss: 0.24617, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.19262, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.14538, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.18807, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   181] loss: 0.11830, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.23547, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.15993, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.16092, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.19826, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.19732, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.16523, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.26250, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.13422, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   226] loss: 0.22539, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.23469, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.12533, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.14443, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   246] loss: 0.13656, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.16844, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.18185, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.26130, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   266] loss: 0.18291, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.16600, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   276] loss: 0.17135, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.12971, adv_train_accuracy: 95.31, clean_train_accuracy : 98.44\n",
      "[1,   286] loss: 0.26837, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.16955, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.22345, adv_train_accuracy: 92.19, clean_train_accuracy : 97.66\n",
      "[1,   301] loss: 0.19008, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.19746, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.30950, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.27357, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.15733, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.20869, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.31327, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.13623, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.19357, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.22194, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   351] loss: 0.28145, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.23857, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.28162, adv_train_accuracy: 90.62, clean_train_accuracy : 98.44\n",
      "[1,   366] loss: 0.19312, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.19543, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   376] loss: 0.18649, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.25107, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.21897, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   391] loss: 0.14057, adv_train_accuracy: 93.75, clean_train_accuracy : 98.75\n",
      "fgsm robustness: 0.3212890625\n",
      "pgd robustness: 0.267578125\n",
      "duration: 158 s - train loss: 0.19321 - train accuracy: 92.47 - validation loss: 0.95624 - validation accuracy: 73.87 \n",
      "Finished Training\n",
      "33 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.16204, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.12798, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.11457, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.10682, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.15371, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.15838, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.22867, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,    36] loss: 0.10269, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.13263, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.17490, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.18236, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.15328, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.12553, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.13581, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,    71] loss: 0.38134, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,    76] loss: 0.20536, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.17255, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.21954, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.11637, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.16257, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   101] loss: 0.26155, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   106] loss: 0.15519, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.14333, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.18312, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.17998, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.16077, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   131] loss: 0.14151, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.16528, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.25089, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.29415, adv_train_accuracy: 89.84, clean_train_accuracy : 97.66\n",
      "[1,   151] loss: 0.16536, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.21258, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.16534, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.23499, adv_train_accuracy: 92.19, clean_train_accuracy : 98.44\n",
      "[1,   171] loss: 0.18181, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   176] loss: 0.32751, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.11620, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.18290, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.24687, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.24591, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.39993, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.23328, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.29135, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.36632, adv_train_accuracy: 84.38, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.18053, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.19662, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.25404, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.27714, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.21666, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.16658, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.23180, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   256] loss: 0.23288, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.17633, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.21809, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.20592, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.21029, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   281] loss: 0.28467, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   286] loss: 0.25187, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.16886, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.13378, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.23005, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   306] loss: 0.17888, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.20228, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.11646, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.21917, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   326] loss: 0.19160, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.21682, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   336] loss: 0.20014, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.18803, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.25108, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.18436, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.22874, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   361] loss: 0.29625, adv_train_accuracy: 90.62, clean_train_accuracy : 97.66\n",
      "[1,   366] loss: 0.23254, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   371] loss: 0.21741, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.19280, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.21061, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.19553, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   391] loss: 0.11009, adv_train_accuracy: 95.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.333984375\n",
      "pgd robustness: 0.2529296875\n",
      "duration: 158 s - train loss: 0.19360 - train accuracy: 92.51 - validation loss: 1.07597 - validation accuracy: 73.27 \n",
      "Finished Training\n",
      "34 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.18531, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.16670, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.24451, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.19281, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.11662, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,    26] loss: 0.15603, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.25410, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.05750, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,    41] loss: 0.16378, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.19234, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.19072, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    56] loss: 0.17590, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.09288, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,    66] loss: 0.23790, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.08737, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.18378, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.11713, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.22256, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    91] loss: 0.08416, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.20020, adv_train_accuracy: 94.53, clean_train_accuracy : 97.66\n",
      "[1,   101] loss: 0.13187, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.20105, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.11455, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   116] loss: 0.13132, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   121] loss: 0.18046, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.17935, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.20078, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.16980, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.27773, adv_train_accuracy: 91.41, clean_train_accuracy : 98.44\n",
      "[1,   146] loss: 0.21261, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   151] loss: 0.17366, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.16014, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.13892, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.12537, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   171] loss: 0.14713, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   176] loss: 0.18982, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.26414, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.14847, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.10062, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.15137, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.12165, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   206] loss: 0.20419, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   211] loss: 0.12409, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.24242, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   221] loss: 0.18353, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.15908, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.16020, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.15467, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.18866, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.13495, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   251] loss: 0.32725, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[1,   256] loss: 0.13387, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.16296, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.22256, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.18927, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   276] loss: 0.22623, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.10015, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   286] loss: 0.14545, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.25535, adv_train_accuracy: 91.41, clean_train_accuracy : 98.44\n",
      "[1,   296] loss: 0.20015, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.26913, adv_train_accuracy: 89.06, clean_train_accuracy : 98.44\n",
      "[1,   306] loss: 0.16883, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.17613, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.15150, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.16753, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.25785, adv_train_accuracy: 92.19, clean_train_accuracy : 97.66\n",
      "[1,   331] loss: 0.18658, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.11423, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.14711, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.20183, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.32760, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.19591, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   361] loss: 0.15020, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.23420, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.23873, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   376] loss: 0.19405, adv_train_accuracy: 92.19, clean_train_accuracy : 98.44\n",
      "[1,   381] loss: 0.13329, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.28001, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   391] loss: 0.25514, adv_train_accuracy: 90.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.2998046875\n",
      "pgd robustness: 0.228515625\n",
      "duration: 158 s - train loss: 0.17923 - train accuracy: 93.09 - validation loss: 0.93299 - validation accuracy: 73.76 \n",
      "Finished Training\n",
      "35 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.11144, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.16116, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.16079, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.21419, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    21] loss: 0.27120, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,    26] loss: 0.25741, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.14628, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,    36] loss: 0.15980, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,    41] loss: 0.17880, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.17245, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.29463, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.19491, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.19799, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.12041, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.15324, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.16704, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.15006, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.16855, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,    91] loss: 0.14316, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.16026, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.10244, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.13380, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.11868, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   116] loss: 0.13050, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.26310, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "[1,   126] loss: 0.12063, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.14134, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   136] loss: 0.09286, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.03119, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   146] loss: 0.14364, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.14820, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.15516, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   161] loss: 0.12542, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.17489, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.12688, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.07814, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   181] loss: 0.21504, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.11214, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.12994, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.17641, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.18200, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   206] loss: 0.22033, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   211] loss: 0.12523, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.12298, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.13052, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.11036, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.12060, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   236] loss: 0.13778, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.11015, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.17124, adv_train_accuracy: 95.31, clean_train_accuracy : 98.44\n",
      "[1,   251] loss: 0.28039, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.18110, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.23130, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.17178, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   271] loss: 0.11224, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   276] loss: 0.19501, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.17474, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   286] loss: 0.15717, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   291] loss: 0.20173, adv_train_accuracy: 92.97, clean_train_accuracy : 98.44\n",
      "[1,   296] loss: 0.30618, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.12837, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.12682, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.12945, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.31761, adv_train_accuracy: 85.16, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.21519, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.24879, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.16975, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.16895, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   341] loss: 0.18338, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.20306, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   351] loss: 0.14148, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.17501, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.23075, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.16231, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.21671, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   376] loss: 0.16208, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.15228, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.28704, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "[1,   391] loss: 0.24606, adv_train_accuracy: 92.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.32421875\n",
      "pgd robustness: 0.2734375\n",
      "duration: 157 s - train loss: 0.16620 - train accuracy: 93.58 - validation loss: 1.00115 - validation accuracy: 72.18 \n",
      "Finished Training\n",
      "36 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.20580, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.15534, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.29593, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.11280, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,    21] loss: 0.16658, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,    26] loss: 0.19815, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.08536, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.11608, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.13770, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.07573, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.13461, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    56] loss: 0.15390, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    61] loss: 0.14864, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.13155, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.13625, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.17191, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,    81] loss: 0.15500, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    86] loss: 0.14015, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,    91] loss: 0.16887, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.19218, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.15456, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.16287, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.13543, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.12530, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.12401, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.11423, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.08895, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.15436, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.13482, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.13343, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.14527, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.20505, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.09700, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.12261, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.16066, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.23360, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   181] loss: 0.14870, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   186] loss: 0.18170, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   191] loss: 0.26161, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   196] loss: 0.15316, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.10244, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.16955, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   211] loss: 0.21641, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.20025, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.19391, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.23671, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.20824, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   236] loss: 0.23806, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.14294, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.15263, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.11751, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.21295, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   261] loss: 0.24197, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   266] loss: 0.22768, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.15974, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.21318, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.25472, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.18763, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.19725, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   296] loss: 0.22505, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.22922, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.16101, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.18905, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.22836, adv_train_accuracy: 92.97, clean_train_accuracy : 98.44\n",
      "[1,   321] loss: 0.25809, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.09313, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.14698, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.20893, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.14519, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.13226, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.19312, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   356] loss: 0.18178, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.07924, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.14015, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.15350, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.13381, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.09495, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   386] loss: 0.16034, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   391] loss: 0.15045, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.337890625\n",
      "pgd robustness: 0.255859375\n",
      "duration: 157 s - train loss: 0.16450 - train accuracy: 93.72 - validation loss: 1.08102 - validation accuracy: 73.39 \n",
      "Finished Training\n",
      "37 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.11162, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.15640, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.15659, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.12463, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.14384, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.18497, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.15659, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.17799, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    41] loss: 0.26452, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.13686, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.15315, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.12987, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.15403, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.08477, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.07051, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.08295, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,    81] loss: 0.11836, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.15210, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.06551, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.11072, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   101] loss: 0.19823, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   106] loss: 0.15895, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.17320, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.13349, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.19478, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   126] loss: 0.11780, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.19460, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.22135, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.16502, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   146] loss: 0.16874, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.15064, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.13824, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   161] loss: 0.11765, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.17562, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.10032, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.12952, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.11158, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.15503, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.15050, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.11915, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.09114, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.07742, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.11544, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.12337, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.18094, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   226] loss: 0.10482, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.13745, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.15155, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.19111, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.14509, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.13721, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.12146, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.08813, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.08832, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.23014, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.24325, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   281] loss: 0.10282, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.13986, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.18682, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.13390, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.17729, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.09429, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   311] loss: 0.11920, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.10074, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   321] loss: 0.09872, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.08640, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.12187, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.18409, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.20982, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.16568, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.22534, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.14054, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.20894, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.14433, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.23864, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.16655, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.15682, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   386] loss: 0.15711, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.19207, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3330078125\n",
      "pgd robustness: 0.2763671875\n",
      "duration: 157 s - train loss: 0.14242 - train accuracy: 94.55 - validation loss: 1.05905 - validation accuracy: 73.77 \n",
      "Finished Training\n",
      "38 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.11682, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.20366, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.15690, adv_train_accuracy: 94.53, clean_train_accuracy : 98.44\n",
      "[1,    16] loss: 0.20408, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.11496, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.08976, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.11371, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,    36] loss: 0.11626, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.15947, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.11892, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.12785, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.19769, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.20048, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.11127, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.18192, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.15891, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.15163, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.12659, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.17136, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.19809, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.20639, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.29419, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   111] loss: 0.11215, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   116] loss: 0.15616, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.15093, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.11397, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.08194, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.20801, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.21067, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   146] loss: 0.21340, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.17803, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   156] loss: 0.17911, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.15188, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.10916, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.17612, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.22759, adv_train_accuracy: 91.41, clean_train_accuracy : 98.44\n",
      "[1,   181] loss: 0.19172, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   186] loss: 0.21225, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.14590, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.11489, adv_train_accuracy: 97.66, clean_train_accuracy : 98.44\n",
      "[1,   201] loss: 0.15252, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.11992, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.10288, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.12319, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.10913, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   226] loss: 0.13449, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.18491, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.07752, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.13295, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.16905, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.12629, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.19631, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.13388, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.12011, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.08870, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.18274, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.18385, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   286] loss: 0.18540, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.20086, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.21773, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.17382, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.20513, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   311] loss: 0.24376, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.12009, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.17859, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.18620, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.10114, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   336] loss: 0.31145, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.23932, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.08804, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.20983, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.21535, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.27301, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.17105, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.22780, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.25457, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.26325, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.20320, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.10753, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3076171875\n",
      "pgd robustness: 0.24609375\n",
      "duration: 157 s - train loss: 0.16823 - train accuracy: 93.65 - validation loss: 1.16666 - validation accuracy: 72.58 \n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.16125, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.13493, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.22630, adv_train_accuracy: 92.97, clean_train_accuracy : 98.44\n",
      "[1,    16] loss: 0.13807, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.19649, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.12099, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.10945, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.12907, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.11178, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.15776, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.11839, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.10926, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.15180, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,    66] loss: 0.17564, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.11272, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.11121, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.10759, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.12109, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.16772, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.12144, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   101] loss: 0.08746, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.10058, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.11964, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.17454, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   121] loss: 0.11019, adv_train_accuracy: 97.66, clean_train_accuracy : 98.44\n",
      "[1,   126] loss: 0.17846, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.10328, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.10682, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   141] loss: 0.09655, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.12783, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.08889, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   156] loss: 0.09150, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.13166, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.12204, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.16157, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.15517, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   181] loss: 0.11561, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.11207, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.15158, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   196] loss: 0.15502, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.12545, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   206] loss: 0.19848, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.13123, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.06748, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.14807, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.11396, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.13457, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.07866, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.20236, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.13897, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.12910, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.09898, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   261] loss: 0.17319, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.10997, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.21612, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.14623, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.11273, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.08973, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.24704, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.25407, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.14789, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   306] loss: 0.07816, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.15928, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.08503, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.21860, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.16965, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.16014, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.14136, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.17345, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.15117, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   351] loss: 0.11671, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.13264, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.16518, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   366] loss: 0.17881, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.15525, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   376] loss: 0.08208, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.08792, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.11316, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.12660, adv_train_accuracy: 95.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3359375\n",
      "pgd robustness: 0.2890625\n",
      "duration: 158 s - train loss: 0.13619 - train accuracy: 94.89 - validation loss: 1.16179 - validation accuracy: 73.08 \n",
      "Finished Training\n",
      "40 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.13907, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.08982, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,    11] loss: 0.10954, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.14472, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.16218, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.14850, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.06929, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.12956, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.18658, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.13118, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.13525, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.08842, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,    61] loss: 0.14101, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.07585, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.05960, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,    76] loss: 0.17418, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.14219, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    86] loss: 0.14165, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.18873, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.19769, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.08335, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.13659, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.13967, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.09717, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   121] loss: 0.09619, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.10603, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.15006, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   136] loss: 0.10625, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.13761, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   146] loss: 0.10473, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.20280, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.15485, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.09589, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.17080, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.16613, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.11274, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   181] loss: 0.09205, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.12780, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.18971, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.12209, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.12238, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.12461, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.14742, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.18873, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.22305, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.22897, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.15761, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.10491, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.22544, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.16948, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.29934, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.17920, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.14715, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.19878, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.23009, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   276] loss: 0.16042, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.17981, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.24032, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.11794, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.08466, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.11092, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.21300, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.21921, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.13972, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.13487, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.09811, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.12213, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.20377, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.27900, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.26983, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.10344, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.14515, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.11923, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.17844, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.17523, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.10270, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.11546, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.12755, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.10654, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3203125\n",
      "pgd robustness: 0.2578125\n",
      "duration: 158 s - train loss: 0.14480 - train accuracy: 94.51 - validation loss: 1.05402 - validation accuracy: 73.29 \n",
      "Finished Training\n",
      "41 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.09358, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,     6] loss: 0.14394, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.10662, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.08230, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.11307, adv_train_accuracy: 96.09, clean_train_accuracy : 98.44\n",
      "[1,    26] loss: 0.11020, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.10477, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.21106, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.06555, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.07818, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.13010, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,    56] loss: 0.07917, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.09967, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.09904, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.08441, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.16496, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.12433, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,    86] loss: 0.12916, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.13464, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.28764, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.12576, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.11505, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.05728, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.07891, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   121] loss: 0.09717, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.09764, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.14163, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.12174, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.17367, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.09426, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.13502, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.11050, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.21847, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.15547, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   171] loss: 0.22782, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.16969, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.16274, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.86539, adv_train_accuracy: 82.81, clean_train_accuracy : 98.44\n",
      "[1,   191] loss: 0.97184, adv_train_accuracy: 75.00, clean_train_accuracy : 96.09\n",
      "[1,   196] loss: 0.97419, adv_train_accuracy: 63.28, clean_train_accuracy : 96.88\n",
      "[1,   201] loss: 0.79472, adv_train_accuracy: 73.44, clean_train_accuracy : 97.66\n",
      "[1,   206] loss: 0.89742, adv_train_accuracy: 70.31, clean_train_accuracy : 96.09\n",
      "[1,   211] loss: 0.69540, adv_train_accuracy: 72.66, clean_train_accuracy : 98.44\n",
      "[1,   216] loss: 0.62283, adv_train_accuracy: 76.56, clean_train_accuracy : 98.44\n",
      "[1,   221] loss: 0.72602, adv_train_accuracy: 78.12, clean_train_accuracy : 99.22\n",
      "[1,   226] loss: 0.62433, adv_train_accuracy: 74.22, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.58106, adv_train_accuracy: 73.44, clean_train_accuracy : 99.22\n",
      "[1,   236] loss: 0.59500, adv_train_accuracy: 81.25, clean_train_accuracy : 99.22\n",
      "[1,   241] loss: 0.50707, adv_train_accuracy: 79.69, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.47075, adv_train_accuracy: 82.81, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.57823, adv_train_accuracy: 75.00, clean_train_accuracy : 99.22\n",
      "[1,   256] loss: 0.40372, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.45471, adv_train_accuracy: 83.59, clean_train_accuracy : 99.22\n",
      "[1,   266] loss: 0.43658, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.31924, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.25531, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.32772, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.40613, adv_train_accuracy: 85.16, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.23367, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.19647, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.25081, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   306] loss: 0.21077, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.24017, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.22363, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[1,   321] loss: 0.21132, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.33078, adv_train_accuracy: 82.81, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.26065, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[1,   336] loss: 0.26592, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.12977, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.15678, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.26540, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[1,   356] loss: 0.15342, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.22615, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   366] loss: 0.15459, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.23857, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.10706, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.26946, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.24766, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.18385, adv_train_accuracy: 95.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3154296875\n",
      "pgd robustness: 0.25\n",
      "duration: 157 s - train loss: 0.28536 - train accuracy: 90.16 - validation loss: 0.97519 - validation accuracy: 73.66 \n",
      "Finished Training\n",
      "42 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.17737, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.13450, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.14860, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.10790, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.10509, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.13904, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.14884, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.13052, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.12600, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.15428, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.11434, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.07937, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.08935, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.10421, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.08940, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.12546, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.09499, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.08165, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.06822, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.22458, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.14987, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   106] loss: 0.13759, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.08312, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.10087, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.09801, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   126] loss: 0.09932, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.13752, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.11599, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.11962, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.14597, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.12000, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.10070, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.07850, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.08430, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   171] loss: 0.08323, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.07210, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.15250, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.12272, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.07489, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.08150, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.13778, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.09170, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.08575, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.15161, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.11514, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.14478, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.13769, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.10074, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.09372, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.14565, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.12487, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   256] loss: 0.07228, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   261] loss: 0.11249, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.21111, adv_train_accuracy: 92.97, clean_train_accuracy : 97.66\n",
      "[1,   271] loss: 0.09650, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.12015, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.20226, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.08431, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.13666, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.07429, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   301] loss: 0.06890, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.08080, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.09100, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.12712, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.09360, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.15563, adv_train_accuracy: 92.97, clean_train_accuracy : 98.44\n",
      "[1,   331] loss: 0.11515, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.13463, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.14757, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.16531, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.14674, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.08890, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.13964, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.09350, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.15048, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.07347, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   381] loss: 0.12110, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.09089, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.04792, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.34375\n",
      "pgd robustness: 0.271484375\n",
      "duration: 157 s - train loss: 0.11765 - train accuracy: 95.56 - validation loss: 1.13831 - validation accuracy: 73.49 \n",
      "Finished Training\n",
      "43 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.06329, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.11050, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.06291, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.09730, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.10103, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.07729, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.05962, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.07021, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.03154, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.07258, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.12683, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.07271, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,    61] loss: 0.05939, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,    66] loss: 0.03712, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.08736, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.09501, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.11548, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,    86] loss: 0.05909, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.07066, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.04533, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.04896, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.03318, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.05374, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.05471, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.13824, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.08799, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.14493, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.09450, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.07487, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.03608, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.05286, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.05205, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.06522, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.05679, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.08228, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.10558, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.05927, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.12291, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.11663, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.06892, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.10668, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.07934, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.14284, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.13186, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.13407, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.06144, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.16502, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.12126, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.10890, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.09504, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   251] loss: 0.14824, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.05893, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.06755, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.07167, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   271] loss: 0.09353, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.09548, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.12563, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.08393, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   291] loss: 0.10901, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.06984, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.21069, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.05934, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.07707, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.12529, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.10721, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.06111, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.10580, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.12633, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.09797, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   346] loss: 0.13278, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.17924, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.12442, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.06625, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.06884, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.04235, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.06535, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.07974, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.12932, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.20155, adv_train_accuracy: 91.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3310546875\n",
      "pgd robustness: 0.2607421875\n",
      "duration: 157 s - train loss: 0.08949 - train accuracy: 96.66 - validation loss: 1.16027 - validation accuracy: 73.67 \n",
      "Finished Training\n",
      "44 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.17176, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.12293, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.14760, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    16] loss: 0.12297, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.03670, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.04184, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.11429, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.07665, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.08474, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.12866, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.05944, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.08819, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.22520, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.16275, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.08253, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.08985, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.13959, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.08794, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.08833, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.08825, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   101] loss: 0.05311, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.16375, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.10671, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.12604, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   121] loss: 0.09946, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.14706, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.14421, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.16166, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.18458, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.24569, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.11538, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.13682, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.16111, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.08165, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.16957, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.30171, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.09738, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.09339, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.15360, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.07885, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.14237, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.10369, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.08029, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.16761, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.10109, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.10873, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.20481, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.12336, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.11241, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   246] loss: 0.16105, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.12741, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.13119, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.13422, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.11611, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.15160, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.08844, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.28578, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[1,   286] loss: 0.10644, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   291] loss: 0.13681, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.15915, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.25268, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.21254, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.06997, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.13318, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.16699, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.10686, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.11058, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.15026, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.09678, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.21302, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.19941, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.11564, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.09570, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.15819, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.09835, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.07920, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.09373, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   386] loss: 0.09031, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.05659, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3291015625\n",
      "pgd robustness: 0.259765625\n",
      "duration: 157 s - train loss: 0.13008 - train accuracy: 95.10 - validation loss: 1.11818 - validation accuracy: 74.01 \n",
      "Finished Training\n",
      "45 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.06744, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.05625, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.09797, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.06148, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    21] loss: 0.07549, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,    26] loss: 0.09252, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.03659, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.08269, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.05888, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.10984, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.11201, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.12257, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.10171, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.07231, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.05645, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.04498, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.07193, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.08737, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.10609, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.08676, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.13742, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.06657, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.16415, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.08090, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.06037, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.10925, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.09911, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   136] loss: 0.03201, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.09937, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.09285, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   151] loss: 0.04568, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.04152, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.11654, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.07340, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.09170, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.09029, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.05686, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.10006, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.07045, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   196] loss: 0.11565, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.09561, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.04788, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.12337, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.08003, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.11564, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.07018, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.09255, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.13169, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   241] loss: 0.07549, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.13215, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   251] loss: 0.10985, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.08762, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.14541, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.06389, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.11127, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.15549, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.14224, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.12831, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   291] loss: 0.08821, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.11662, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.14550, adv_train_accuracy: 95.31, clean_train_accuracy : 98.44\n",
      "[1,   306] loss: 0.13788, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.12872, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.12376, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.13991, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   326] loss: 0.16214, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.10203, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.14863, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.08433, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.11610, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.11142, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.16385, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.13662, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.07991, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.04870, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.12940, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.16860, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.16839, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.26105, adv_train_accuracy: 90.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.31640625\n",
      "pgd robustness: 0.2509765625\n",
      "duration: 157 s - train loss: 0.10286 - train accuracy: 96.07 - validation loss: 1.06073 - validation accuracy: 73.23 \n",
      "Finished Training\n",
      "46 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.17308, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.09744, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.07387, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,    16] loss: 0.12008, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.07626, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.14310, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.13188, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.12297, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.12378, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.16938, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.08243, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.14934, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.08770, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.15972, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.08324, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.09981, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.07080, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.10127, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.09206, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.10850, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.13182, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   106] loss: 0.04498, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.09253, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.06233, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.07966, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.06364, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.12080, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.07632, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.14256, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.13702, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.13613, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.12539, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.07430, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.12893, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.19822, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.17930, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.19790, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.15977, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.06796, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.13116, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.08957, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.10172, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   211] loss: 0.13655, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.07540, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   221] loss: 0.13115, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.08052, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.04786, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.15990, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.11111, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.15227, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.07268, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.16868, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[1,   261] loss: 0.28293, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.06955, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.11274, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.04648, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.12474, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.12116, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.12270, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.10707, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.09167, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.18572, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.14164, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.18075, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.15199, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   326] loss: 0.14282, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.13297, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.03942, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.25031, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.15050, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   351] loss: 0.13406, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.10950, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.13621, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.14058, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.10482, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.19126, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.14421, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.06098, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.07341, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3291015625\n",
      "pgd robustness: 0.259765625\n",
      "duration: 157 s - train loss: 0.12320 - train accuracy: 95.34 - validation loss: 1.18394 - validation accuracy: 73.86 \n",
      "Finished Training\n",
      "47 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.10044, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.08582, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,    11] loss: 0.12295, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.09042, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.10298, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.09078, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.09682, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.10783, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.10257, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.08421, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.05945, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.15149, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.07320, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.10908, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.11360, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.11080, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.05760, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.12305, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.07150, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.12521, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.13487, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.07126, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   111] loss: 0.13180, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.16897, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.07907, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.09257, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.17408, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.17853, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.10992, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.22591, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.08743, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.19331, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.10707, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.11685, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.12716, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.08813, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.10075, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   186] loss: 0.10340, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   191] loss: 0.11997, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   196] loss: 0.08816, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.09553, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.13220, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.08868, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.08224, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.08808, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.11797, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.14369, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.13960, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.15622, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.06181, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.11248, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.12880, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.13596, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.15977, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.14150, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.08327, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.08121, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.13897, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.07341, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.15714, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.14546, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.07186, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.11254, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.08979, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.12926, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.07214, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.09467, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.11617, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.08696, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.14313, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.15254, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.06448, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   361] loss: 0.07894, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.13815, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.21659, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.11044, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.11719, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.14835, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.22795, adv_train_accuracy: 90.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.2890625\n",
      "pgd robustness: 0.24609375\n",
      "duration: 158 s - train loss: 0.11630 - train accuracy: 95.65 - validation loss: 1.20608 - validation accuracy: 72.28 \n",
      "Finished Training\n",
      "48 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.12767, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,     6] loss: 0.24225, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.23001, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.17023, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.21458, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.11276, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.06434, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.11356, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.11323, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.07025, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.07220, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.09397, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.13325, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.11362, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.10013, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.21693, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.15672, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.05718, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.06161, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.12496, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.18371, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.10460, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.07039, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.06502, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.08561, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.15256, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.13122, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   136] loss: 0.16105, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.08513, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.15550, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.07524, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.10137, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.08189, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.12317, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.10678, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.09283, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.12235, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.13411, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.09179, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.13871, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.08118, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.12450, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.06766, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.06319, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.07973, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.08375, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.14407, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.12375, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.10663, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.07251, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   251] loss: 0.15443, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.20435, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   261] loss: 0.17201, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.11329, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.07304, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   276] loss: 0.12766, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.03293, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.06142, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   291] loss: 0.19977, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.09333, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.13771, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   306] loss: 0.16276, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.12411, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.05501, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.09947, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.07713, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.13866, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.18384, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.13118, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.08987, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.09337, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.10783, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.10173, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.11325, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.21270, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.12900, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.16746, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.18557, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.12149, adv_train_accuracy: 95.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.2998046875\n",
      "pgd robustness: 0.2548828125\n",
      "duration: 157 s - train loss: 0.11893 - train accuracy: 95.54 - validation loss: 1.08275 - validation accuracy: 74.44 \n",
      "Finished Training\n",
      "49 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.08232, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.06153, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.10042, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.08755, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.08941, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.10294, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.12733, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.10381, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.04449, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.18123, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.09194, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.14845, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.14711, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.18807, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.09814, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,    76] loss: 0.16425, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.11066, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.15060, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.05467, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.10441, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.10603, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   106] loss: 0.07603, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.05948, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.11951, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.15710, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.06482, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.11426, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.12274, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.07389, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.10460, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.12993, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.10819, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.09536, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.08266, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.10373, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.21283, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.08088, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.11055, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.14585, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.12698, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.09225, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.06857, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.10243, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.18842, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.14051, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.09993, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.09121, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.07574, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.17747, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.10606, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.08070, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.14257, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.12493, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.18552, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.15412, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.10566, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.09349, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.08720, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.13038, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.12306, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.09854, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.12489, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.12135, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.09058, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.12689, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.09756, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.13660, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.15806, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.04954, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.11393, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.22870, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.08230, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   361] loss: 0.06780, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.13017, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.13222, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.11133, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.07759, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.12407, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.21501, adv_train_accuracy: 88.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.2978515625\n",
      "pgd robustness: 0.24609375\n",
      "duration: 157 s - train loss: 0.11285 - train accuracy: 95.77 - validation loss: 1.12968 - validation accuracy: 73.62 \n",
      "Finished Training\n",
      "50 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.12673, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.11150, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.15083, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.10774, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.13386, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.08356, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.06037, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.05059, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.10614, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,    46] loss: 0.05921, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.14485, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.15146, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.10566, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.15509, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.09015, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.06782, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.09230, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.06213, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.09016, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.04897, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.07906, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.08284, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.09941, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.12842, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.10092, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.05823, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.08549, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.16126, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.14444, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.15287, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.22043, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.09838, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.06721, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   166] loss: 0.05978, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.10202, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.08672, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.14808, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.13351, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.10145, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.12564, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.07654, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.10406, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.11321, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.15072, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.11436, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.09463, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.15051, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.06669, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.07722, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.09955, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.09882, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.14065, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.08383, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.13351, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.09058, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.17288, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.17492, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.08562, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.11426, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.05419, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.14805, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.16744, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.14975, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.11170, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.12772, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.13879, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.16100, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.11226, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.21711, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.15919, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.13369, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.14435, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.07094, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.16104, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.12100, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.07047, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.18751, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.16541, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.34847, adv_train_accuracy: 87.50, clean_train_accuracy : 98.75\n",
      "fgsm robustness: 0.3056640625\n",
      "pgd robustness: 0.267578125\n",
      "duration: 157 s - train loss: 0.11440 - train accuracy: 95.64 - validation loss: 1.10712 - validation accuracy: 72.60 \n",
      "Finished Training\n",
      "51 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.10347, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.05029, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.17679, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.08204, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.10470, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.09674, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.08352, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    36] loss: 0.08543, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.07642, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.07844, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.08452, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.09413, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.07471, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.19203, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,    71] loss: 0.08720, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.04501, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.03759, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.11138, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.10786, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.11399, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.10606, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.05346, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.04839, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.03443, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.13187, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.17611, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   131] loss: 0.10417, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.08263, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.14042, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.10105, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.10800, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.07995, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.10355, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.07917, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.09928, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.08620, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.11785, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.21221, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.07040, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.12201, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.14641, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.05096, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.11849, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.06824, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.13188, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.13845, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.09143, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.05541, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.08143, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.06230, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.10287, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.09767, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.16204, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.04064, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.16224, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.12972, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.06152, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   286] loss: 0.14934, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.12522, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.13963, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.17415, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.09504, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.13560, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.07815, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.07162, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.13135, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.14357, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.10125, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.13768, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.14090, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.11087, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.07289, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.09664, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.10892, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.08360, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   376] loss: 0.19802, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.07608, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.10082, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.02535, adv_train_accuracy: 98.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3330078125\n",
      "pgd robustness: 0.2509765625\n",
      "duration: 157 s - train loss: 0.10527 - train accuracy: 95.99 - validation loss: 1.20858 - validation accuracy: 73.55 \n",
      "Finished Training\n",
      "52 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.15186, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.10447, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.09190, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.06477, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.08520, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.04630, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.10565, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.05516, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.03286, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.01698, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.05476, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.06172, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.07833, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.11504, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.05072, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.02555, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.11730, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.07512, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.05771, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.13090, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.04036, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.08806, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.06272, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.21745, adv_train_accuracy: 95.31, clean_train_accuracy : 98.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   121] loss: 0.10979, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.08799, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.13089, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.08864, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.09022, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.12236, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.05450, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.11575, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.07258, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.06692, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.03467, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.04294, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.11322, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.06245, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.07270, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05314, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.14762, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.13565, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.14805, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.16726, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.14152, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.11091, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.06470, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.06544, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.06498, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.08015, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.09741, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.06111, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.08131, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.08584, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.10757, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.09894, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   281] loss: 0.17091, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.06185, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.14692, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.05651, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.02410, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.06692, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.09829, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.13505, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.12520, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.10614, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.19768, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.16856, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.09426, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.11812, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.11204, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.07824, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.05849, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.16074, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.13080, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.11122, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.06166, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.05403, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.07187, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3115234375\n",
      "pgd robustness: 0.2666015625\n",
      "duration: 157 s - train loss: 0.10283 - train accuracy: 96.29 - validation loss: 1.24106 - validation accuracy: 73.39 \n",
      "Finished Training\n",
      "53 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.08711, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.10074, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.06285, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.06987, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.15221, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.05522, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.13791, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.19222, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.07915, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.03703, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.11373, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.06926, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.09151, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.06113, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.04601, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.15024, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.08494, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.07916, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.11176, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.04269, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.09007, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.07611, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.11438, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.05566, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.04191, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.11028, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.11299, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.05085, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.09020, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.10496, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.08138, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.07259, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.06887, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.14513, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.14020, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.06708, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.02721, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.07375, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.10293, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.22154, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.11971, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   206] loss: 0.20968, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.11407, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.15982, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.15066, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.10535, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.21194, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.12376, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.18488, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.11288, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.14636, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.06609, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.07002, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.06317, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   271] loss: 0.12179, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   276] loss: 0.15159, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.07817, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.08796, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.17399, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.16242, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.09020, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.05818, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.12589, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.05753, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.08505, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.10306, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.10580, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.17424, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.15717, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.11634, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.08523, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.06295, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.10738, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.13856, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.06178, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.06843, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.07799, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.09951, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.14150, adv_train_accuracy: 96.25, clean_train_accuracy : 98.75\n",
      "fgsm robustness: 0.337890625\n",
      "pgd robustness: 0.251953125\n",
      "duration: 157 s - train loss: 0.10289 - train accuracy: 96.14 - validation loss: 1.08613 - validation accuracy: 73.67 \n",
      "Finished Training\n",
      "54 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.15036, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.13148, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.14996, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.07491, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.04190, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.06843, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.05547, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.05518, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.11868, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.17729, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.15618, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.06241, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.11697, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.13218, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.04245, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.08817, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.03509, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.15121, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.13498, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.10885, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.08136, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.10288, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.10009, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.07635, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.03894, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.09351, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.14289, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.09409, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.12897, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.07016, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.07902, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.09238, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.05968, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.12221, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.09085, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.14173, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.12312, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   186] loss: 0.07113, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.14957, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.16948, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.10766, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.09898, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.12698, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.12233, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.06338, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.11031, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.05602, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.04712, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.05850, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.09766, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.15185, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.07979, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   261] loss: 0.09483, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.15717, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.10533, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.13590, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.14693, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.10924, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   291] loss: 0.10175, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.12110, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.04867, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.13470, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.08970, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.06554, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.12893, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.15081, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.06046, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.09389, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.04897, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.15824, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.12060, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.15480, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.11054, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.15406, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.16981, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.07017, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.14855, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.13933, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.11326, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3134765625\n",
      "pgd robustness: 0.2509765625\n",
      "duration: 157 s - train loss: 0.09626 - train accuracy: 96.47 - validation loss: 1.08406 - validation accuracy: 73.83 \n",
      "Finished Training\n",
      "55 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.13880, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.08184, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.11699, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.09848, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.06371, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.03599, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.08518, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.13585, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.09437, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.06074, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.07102, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.10262, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.10949, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.09558, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.09502, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.07958, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.07148, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.08734, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.08124, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.06406, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.10446, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.03398, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.02452, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.08387, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.03360, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.12100, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.09766, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.08010, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.11265, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.03673, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.10285, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.03960, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.12020, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.08465, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.04024, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.08168, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.06651, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.10695, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.22587, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05454, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.12617, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.09655, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.08197, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.15134, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.22104, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.16373, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.07511, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.09557, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   241] loss: 0.05507, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.19824, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.28240, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.23871, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.44935, adv_train_accuracy: 84.38, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.15727, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.24023, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.18179, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.17729, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.07135, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.18550, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.24390, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.18200, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.19361, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   311] loss: 0.14517, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.08814, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   321] loss: 0.19292, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.12064, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.12961, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.17718, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.10868, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.06030, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.13228, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.16252, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.13250, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.10600, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.06313, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   376] loss: 0.10401, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.14198, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.12651, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.13683, adv_train_accuracy: 95.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3056640625\n",
      "pgd robustness: 0.23828125\n",
      "duration: 157 s - train loss: 0.11546 - train accuracy: 95.74 - validation loss: 1.18103 - validation accuracy: 73.09 \n",
      "Finished Training\n",
      "56 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.12552, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.10791, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.11976, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.08834, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.10529, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.07898, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.04772, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.14027, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.07524, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.05094, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.09239, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.11271, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.06190, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.05023, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.10027, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.10270, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.10274, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.06617, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.11187, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.19728, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.05687, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.07914, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.05463, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.05891, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.10283, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.10939, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.14934, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.12860, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.11875, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.11928, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.15053, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.09958, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.11091, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.05805, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.11593, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.05951, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.10725, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.06438, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.05405, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.06397, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.10316, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.07964, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   211] loss: 0.06774, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.07671, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.06674, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.03347, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.06866, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.02886, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.05307, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.12975, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.13629, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.09468, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.08325, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.16052, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.05778, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.10947, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.09241, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.13503, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.08242, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.10033, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.06710, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.09104, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.06581, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.06648, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.09243, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.05005, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.09347, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.13813, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.08318, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.08721, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.09545, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.10839, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.06869, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.08404, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.14187, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.17136, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.08443, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.14650, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.07091, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3515625\n",
      "pgd robustness: 0.271484375\n",
      "duration: 156 s - train loss: 0.09311 - train accuracy: 96.59 - validation loss: 1.16827 - validation accuracy: 73.57 \n",
      "Finished Training\n",
      "57 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.03800, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.10704, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.14293, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.09080, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.06361, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.00863, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.03468, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.05684, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.07533, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.03180, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    51] loss: 0.02990, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.12968, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.06872, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.07366, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.04442, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.05917, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.06199, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.05602, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.05769, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.05105, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.04529, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.04720, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.03617, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.11384, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.13704, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.02983, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.08059, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.05986, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.03552, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.08962, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.14160, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.09579, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   161] loss: 0.10456, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.07001, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.11550, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.05247, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.06899, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.11778, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.06916, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   196] loss: 0.07555, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.08529, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.08266, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.11712, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.03799, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.07753, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.05711, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.04498, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.04414, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.10199, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.20071, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.08634, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.06275, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.05603, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.11900, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.03888, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.10396, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.12669, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.03445, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.09303, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.10342, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.01843, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.06332, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.09988, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.14437, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.10449, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.08825, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.05874, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.03666, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.07305, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.05062, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.09757, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.08933, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.07912, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.05357, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.17122, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.10126, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.05156, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.11221, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.16168, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3427734375\n",
      "pgd robustness: 0.234375\n",
      "duration: 156 s - train loss: 0.07902 - train accuracy: 97.06 - validation loss: 1.15806 - validation accuracy: 73.57 \n",
      "Finished Training\n",
      "58 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.06545, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.16812, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.05524, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.07429, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.05811, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.10725, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.07703, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.11311, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.10431, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.02664, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.04680, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.12415, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.10188, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.09732, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.03560, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,    76] loss: 0.04433, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.10229, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.04349, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,    91] loss: 0.02735, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.12627, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.16462, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.04075, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.03436, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.09553, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.09030, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.12507, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.04381, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   136] loss: 0.07546, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.11876, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.11750, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.22861, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.18266, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.05834, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.10508, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.09483, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.03410, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.09281, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.08362, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.09840, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.12705, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.08361, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.06333, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.13663, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.12385, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.14661, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.09026, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.06678, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.01928, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.06881, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.08532, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.08826, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.11760, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.07279, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.17288, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.11989, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.11698, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.11896, adv_train_accuracy: 95.31, clean_train_accuracy : 99.22\n",
      "[1,   286] loss: 0.11941, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.07260, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.06745, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.12071, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.14364, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.13573, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.09555, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.08474, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.10151, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.06517, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.11649, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.16101, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.09384, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.13230, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.08796, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.07593, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.08510, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.08533, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.04800, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.09477, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.07193, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.21251, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.30078125\n",
      "pgd robustness: 0.2587890625\n",
      "duration: 156 s - train loss: 0.09189 - train accuracy: 96.61 - validation loss: 1.22360 - validation accuracy: 73.33 \n",
      "Finished Training\n",
      "59 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.07857, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.06885, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.11736, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.10104, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.07733, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.08086, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.06702, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.10916, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.02814, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.15484, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.12487, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.03827, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.10490, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.06628, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.03854, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.09168, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.09046, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.11620, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.06329, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.06391, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.06046, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.05927, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.18698, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.12652, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.11775, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.08129, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   131] loss: 0.09505, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.07172, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.13323, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.06161, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.11344, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.13470, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.02501, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.07485, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.07534, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.06572, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.06017, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.12677, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.10395, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05964, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.09576, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.10532, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.04447, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.07602, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   221] loss: 0.04393, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   226] loss: 0.08659, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.07009, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.06998, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.08028, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.15404, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.10908, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.12101, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.07921, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.06142, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.09039, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.08346, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.09633, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.05739, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.11020, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.06423, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.11645, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.21238, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.06399, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.09530, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.09076, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.03753, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.14965, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.14129, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.04816, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.09842, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.08680, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.09079, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.09009, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.11162, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.15691, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.08726, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.17039, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,   386] loss: 0.08932, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.10896, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.337890625\n",
      "pgd robustness: 0.2490234375\n",
      "duration: 156 s - train loss: 0.08583 - train accuracy: 96.87 - validation loss: 1.13738 - validation accuracy: 73.22 \n",
      "Finished Training\n",
      "60 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.04643, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.14044, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.12573, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.06417, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.03971, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.07044, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.10965, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.14958, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.08039, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.04927, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.04995, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.09046, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.03830, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.07964, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.18697, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.06355, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.07531, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.06358, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.10379, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.01396, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.06474, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.10469, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.09267, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.09006, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.05754, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.14813, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.11367, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   136] loss: 0.06149, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.09992, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.09568, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.13949, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.06871, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.08648, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.13076, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.09091, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.09373, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.10283, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.03539, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.06891, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.07372, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.06591, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.10252, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.10065, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.02947, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.07886, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.13612, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.06612, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.06711, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.10879, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.13165, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.13202, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.12425, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.15342, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.09023, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.05983, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.08071, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.02592, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.09992, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.02888, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.03813, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.09196, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   306] loss: 0.06925, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.15889, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.09638, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.03967, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.15770, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.04874, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.10468, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.07249, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.05017, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.04830, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.03660, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.03189, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,   366] loss: 0.05524, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.03766, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.04757, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.05076, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.02718, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.02334, adv_train_accuracy: 98.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.2880859375\n",
      "pgd robustness: 0.2275390625\n",
      "duration: 156 s - train loss: 0.08452 - train accuracy: 96.93 - validation loss: 1.23669 - validation accuracy: 73.30 \n",
      "Finished Training\n",
      "61 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.06359, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.05259, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.09432, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.04720, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.09315, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.05603, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.09725, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.11140, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.06362, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.06281, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.09508, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.08798, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.10316, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.05169, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.08820, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.08285, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.03718, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.07833, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.20208, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.09716, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.07756, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.09781, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.08957, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.16309, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.05005, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.06679, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.04714, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.09276, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.06653, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.09595, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.08920, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.09283, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.15180, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.17957, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.10144, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.05349, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.07678, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.10740, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.06286, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.07220, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.07462, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.08527, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.03997, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.05496, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.14363, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.02930, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.02042, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.07431, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.02251, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.04319, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.07270, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.06554, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.17198, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   266] loss: 0.09600, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.11252, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.09630, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   281] loss: 0.09772, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.03667, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.10008, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.07341, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.05876, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   306] loss: 0.09864, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.14386, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.12916, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.02594, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,   326] loss: 0.05370, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.08666, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.05997, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.17321, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.09249, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.10226, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.07731, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.09230, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.09509, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.03753, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.14022, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.16063, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.08489, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   391] loss: 0.08878, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.294921875\n",
      "pgd robustness: 0.2431640625\n",
      "duration: 156 s - train loss: 0.08164 - train accuracy: 96.93 - validation loss: 1.19069 - validation accuracy: 72.67 \n",
      "Finished Training\n",
      "62 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.04306, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.03790, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.07561, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.14545, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.15989, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.11992, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.10574, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.04066, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.08872, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.04687, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.05201, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.07353, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.06937, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.09889, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.08133, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.10482, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.08970, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.10211, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.18004, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.14872, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.09750, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.04691, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.03318, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.07897, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.19137, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.10565, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.13322, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.10838, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.06547, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.08808, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.12814, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.11694, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.03849, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.07399, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.09011, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   176] loss: 0.09908, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.12505, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.08032, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.05773, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.02874, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.05281, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.14304, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.05110, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.06971, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.06834, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.09529, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.06216, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.06993, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.12835, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.11505, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.14450, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.05504, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.07370, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.05215, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.08985, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.06757, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.05654, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.17181, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.14307, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.04951, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.23687, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.10487, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.05633, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.08147, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   321] loss: 0.05576, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.18945, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.12802, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.11739, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.11236, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.06563, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.08044, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.16860, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.03975, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.11931, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.11673, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.08990, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.14150, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.10507, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.16417, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3212890625\n",
      "pgd robustness: 0.265625\n",
      "duration: 156 s - train loss: 0.09028 - train accuracy: 96.81 - validation loss: 1.24772 - validation accuracy: 72.85 \n",
      "Finished Training\n",
      "63 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.10414, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.02460, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.04339, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.02311, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.10794, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.11649, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.11585, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.05029, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.08593, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.14089, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.06095, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.06826, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.05808, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    66] loss: 0.14965, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.13162, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.06609, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.06580, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.05399, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.05701, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.04173, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   101] loss: 0.11583, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.05485, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.05303, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.06668, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.09946, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.06494, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.12618, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.04621, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.19747, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.15227, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.05591, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.06838, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.12363, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.10420, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.09296, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.10282, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.06725, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.04201, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.07582, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.06231, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.12779, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.05029, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.06778, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.07723, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.08574, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.07824, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.08075, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.15902, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.09343, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.05354, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.07745, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.06414, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.08292, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.07193, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.07535, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.05393, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.08440, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   286] loss: 0.11046, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.06393, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.07892, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.03357, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.04332, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.11112, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.08762, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.05194, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.04517, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.08065, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.09063, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.10048, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.05467, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.04941, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.06679, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.06313, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.13249, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.04003, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.08934, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.05958, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.05361, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.04936, adv_train_accuracy: 98.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3017578125\n",
      "pgd robustness: 0.27734375\n",
      "duration: 156 s - train loss: 0.07890 - train accuracy: 97.17 - validation loss: 1.23185 - validation accuracy: 73.61 \n",
      "Finished Training\n",
      "64 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.08973, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.03221, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.06141, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.04220, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.06666, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.04045, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.10252, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.03848, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.09647, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.05361, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.04612, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,    56] loss: 0.04554, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.11959, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.03808, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.08053, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.08199, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.07401, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,    86] loss: 0.01399, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.10659, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.06518, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.06802, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.07922, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.11203, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.07794, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.03453, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.07561, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.16998, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.06098, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.09177, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.08774, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   151] loss: 0.05811, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.16843, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.06065, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.20459, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.07384, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.05390, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.03036, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.02301, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.08784, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.03630, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.07952, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.13148, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.03697, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.07755, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.03946, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.16049, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.02752, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.07632, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.09446, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.03843, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.07606, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.05336, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.15024, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.12592, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.09403, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.08260, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.06213, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.10930, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.14053, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.10686, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.11714, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.04484, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.08922, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.05337, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.07269, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.04660, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.02107, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.09621, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.10788, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.11403, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.09229, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.10329, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.05318, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.11513, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.06395, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.07038, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.10515, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.08781, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.03324, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3046875\n",
      "pgd robustness: 0.2578125\n",
      "duration: 156 s - train loss: 0.08114 - train accuracy: 97.09 - validation loss: 1.31371 - validation accuracy: 72.69 \n",
      "Finished Training\n",
      "65 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.07170, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.04369, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.06500, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.02316, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.11313, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.09412, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.06451, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.04384, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.08618, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.07942, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.06694, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.10126, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.10026, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.08376, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,    71] loss: 0.08986, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.08806, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.08769, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.04403, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.08151, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.03699, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.07350, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.05672, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.03169, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.05853, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.03946, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.04956, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.05386, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.01828, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.04933, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.06669, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.02380, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.05209, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.13144, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.03119, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.06945, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.07885, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   181] loss: 0.15492, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.02805, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.05719, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   196] loss: 0.10408, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.03271, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.14191, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.07571, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.09666, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.03738, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.09189, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.09576, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   236] loss: 0.09587, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.02771, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.08103, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.08425, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.05584, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.01692, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.04994, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.06647, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.11783, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.07902, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.07213, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.06554, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.06520, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.04387, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.05631, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.06046, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.12695, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.10249, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.15836, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.09292, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.13310, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.06919, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.07911, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.13537, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.09713, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.13694, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.08599, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.10088, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.11838, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.05711, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.08124, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.17013, adv_train_accuracy: 91.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3154296875\n",
      "pgd robustness: 0.2548828125\n",
      "duration: 156 s - train loss: 0.07542 - train accuracy: 97.17 - validation loss: 1.30992 - validation accuracy: 73.21 \n",
      "Finished Training\n",
      "66 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.09679, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.09643, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.20397, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.05952, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.11239, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.07564, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.03965, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.03517, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.05197, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.03946, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.10064, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.07508, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.06418, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.11946, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.13896, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[1,    76] loss: 0.05036, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.13457, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.04949, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.09175, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.10469, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.09870, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.13286, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.10099, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.07801, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.04557, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.06472, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.10471, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.08528, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.06795, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.08991, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.08143, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.09988, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.06185, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.10981, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.10914, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.19117, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.07291, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.19174, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.12622, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.07481, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.05103, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.08485, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.04082, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.12431, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.05754, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.07692, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.18992, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.09263, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.07715, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.05188, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.07564, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.07050, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.05414, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.08356, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.06420, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.17222, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.02981, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.15534, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.11683, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.03888, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.05140, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.11486, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.05730, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.06974, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   321] loss: 0.05944, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.06233, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.05728, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.06263, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.12807, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.07259, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.09846, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.07413, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.06957, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.02385, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.02699, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,   376] loss: 0.06928, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.10825, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.12124, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.14319, adv_train_accuracy: 95.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.326171875\n",
      "pgd robustness: 0.2353515625\n",
      "duration: 156 s - train loss: 0.08947 - train accuracy: 96.78 - validation loss: 1.15058 - validation accuracy: 73.65 \n",
      "Finished Training\n",
      "67 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.08824, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.11337, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.07542, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.04891, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.03341, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.13718, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.03529, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.09699, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.11186, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.06510, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.08503, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.05164, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.09229, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.07713, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.02665, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.04903, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.06748, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.02500, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.02250, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.08091, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.05258, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.04770, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.04288, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.03309, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.01417, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.04969, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.06981, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.06420, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.11909, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.02995, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.06074, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.04992, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.05017, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.08415, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.03996, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.09964, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.06070, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.02703, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.06357, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.02862, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.04607, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.06229, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.05079, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.12045, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.04996, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.15686, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.10079, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.09971, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.07115, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.02242, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.16285, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.04419, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.06183, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.05882, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.07012, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.04267, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.09653, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.09755, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.05782, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.03437, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.01964, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.10063, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.06633, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.08834, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.07190, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.05045, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.13789, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.09765, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.10636, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.10929, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.10274, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.09163, adv_train_accuracy: 96.09, clean_train_accuracy : 99.22\n",
      "[1,   361] loss: 0.04386, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.06007, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.19052, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.11996, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.10838, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.07524, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.08344, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.31640625\n",
      "pgd robustness: 0.2353515625\n",
      "duration: 156 s - train loss: 0.07703 - train accuracy: 97.22 - validation loss: 1.16824 - validation accuracy: 72.77 \n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.09746, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.02832, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.06177, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.02296, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.04842, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.16340, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.10228, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.03996, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.04639, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.11228, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.07628, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.07534, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.07609, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.05212, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.06397, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.06903, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.05209, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.06657, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.06287, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.15968, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.09278, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.07226, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.07893, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.10837, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.10681, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.07839, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.13256, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.09474, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.05811, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.13094, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.10231, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.08010, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.03664, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.04330, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.11386, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.02662, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.13798, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.04821, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.08851, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.11823, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.05754, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.14550, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.07904, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.04787, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.06260, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.04624, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.07775, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.06148, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.08405, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.01074, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.16755, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.04626, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.03853, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.10567, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.06381, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.05282, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.07069, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.01146, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.06131, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.02788, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.03196, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.04495, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.03774, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.03898, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.08895, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.06722, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.02906, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.04553, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.21248, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.10850, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.08499, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.05560, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.09318, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.03614, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.04626, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.05621, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.04998, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.11309, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.04657, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.326171875\n",
      "pgd robustness: 0.2568359375\n",
      "duration: 156 s - train loss: 0.07551 - train accuracy: 97.23 - validation loss: 1.18004 - validation accuracy: 73.89 \n",
      "Finished Training\n",
      "69 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.03554, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.07616, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.04404, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.05495, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.06999, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.09974, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.05049, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.08606, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.06087, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.06999, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.03854, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.07148, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.04295, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.02153, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.06809, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.06930, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.06303, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    86] loss: 0.05741, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.02282, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.10600, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.07781, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.03401, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.01772, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.06094, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.04016, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.08471, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.04294, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.05456, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.10708, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.13936, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.07050, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.10823, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.12446, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.06610, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.20668, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.08519, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.10735, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.08287, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.06021, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.04870, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.08962, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.08495, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.05484, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.07245, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.01172, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.08393, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.05350, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.02644, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.06119, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.05089, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.05427, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.05827, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.05078, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.08346, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.09217, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.04629, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   281] loss: 0.10930, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.07120, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.02574, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.07467, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.13151, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.14308, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.02192, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.11815, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.04550, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.06077, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.03343, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.02731, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,   341] loss: 0.06423, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.06205, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.04330, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.12457, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.14991, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.07288, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.07610, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.07222, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.09621, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.02895, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.01455, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.328125\n",
      "pgd robustness: 0.265625\n",
      "duration: 156 s - train loss: 0.06900 - train accuracy: 97.65 - validation loss: 1.31461 - validation accuracy: 73.74 \n",
      "Finished Training\n",
      "70 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.04204, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.05757, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.07224, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.09263, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.10752, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.09283, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.02673, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.10125, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.08698, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.03539, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.10568, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.01102, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.12696, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.10842, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.04141, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.13269, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.05154, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.05510, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.05198, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.06352, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.04542, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   106] loss: 0.02702, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.12591, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.03005, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.08350, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.13359, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.05166, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.03026, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.02743, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.04109, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.07629, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   156] loss: 0.07642, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.04671, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.09437, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   171] loss: 0.04040, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.03719, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.07749, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.08787, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.13792, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.07352, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.06710, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.03746, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.11988, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.08990, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.05265, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.05282, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.09436, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.06127, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.03195, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.05730, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.02311, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.06555, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.09377, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.13466, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.10944, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.06362, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.07264, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.19502, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.10650, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.09914, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.11666, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.03123, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.08609, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.08227, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.08478, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.13496, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.07170, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.12390, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.04100, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.06640, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.05744, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.04153, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.05627, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.04404, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.12982, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.09465, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.12639, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.05325, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.24655, adv_train_accuracy: 95.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3291015625\n",
      "pgd robustness: 0.2734375\n",
      "duration: 156 s - train loss: 0.07156 - train accuracy: 97.48 - validation loss: 1.31747 - validation accuracy: 73.09 \n",
      "Finished Training\n",
      "71 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.10553, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.08209, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.04616, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.06488, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.03636, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.07586, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.05586, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.06001, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.05586, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.08676, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.08861, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.05006, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.08135, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.04322, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.02983, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.11272, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.09920, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.07429, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.19224, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.10547, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.06091, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.06682, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.00891, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.02639, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.07913, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.04216, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.08444, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.06578, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.05197, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.05476, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.04812, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.10466, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.12454, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.11566, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.11770, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   176] loss: 0.05809, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.09490, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.01439, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.09499, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.04582, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.04953, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.02334, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.12732, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.19035, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.11920, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.07198, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   231] loss: 0.15462, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.11939, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.09602, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.10013, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.12005, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   256] loss: 0.11272, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.05460, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.08600, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.11573, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.03262, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.11537, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.04942, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.17696, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.12615, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.21201, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.04340, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.09580, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.08307, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.11887, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.09977, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.08028, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.14241, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.04202, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.14113, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.04936, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.17125, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.14617, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.13407, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.11929, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.08472, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.11368, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.07972, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.13787, adv_train_accuracy: 95.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.31640625\n",
      "pgd robustness: 0.263671875\n",
      "duration: 156 s - train loss: 0.08292 - train accuracy: 97.06 - validation loss: 1.27746 - validation accuracy: 73.41 \n",
      "Finished Training\n",
      "72 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.11076, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.08589, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.11517, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.06389, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.07481, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.09494, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.06131, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.04351, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.08126, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.06093, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,    51] loss: 0.08405, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.09290, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.06831, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.11692, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.02745, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.04957, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.07715, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.04637, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.04889, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.03222, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.03714, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.02034, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.05931, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.07820, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.05565, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.05896, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.07112, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.05243, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.05045, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.03699, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.03212, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.10150, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.07510, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.04440, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.02883, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.04419, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.03432, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.05585, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.04109, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.03179, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.04308, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.04225, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.06189, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.01976, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.07797, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.08013, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.10857, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.07330, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.09575, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.07943, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.04996, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.11179, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.04240, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.07989, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.05309, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.04528, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.02443, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.16934, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.03333, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.10224, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.07514, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.03687, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.05993, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.12831, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.04096, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.13015, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.03951, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.14366, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   341] loss: 0.08448, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.04469, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.11072, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.09753, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.04748, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.04760, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.03973, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.05906, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.12103, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.07236, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.04800, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3173828125\n",
      "pgd robustness: 0.2548828125\n",
      "duration: 156 s - train loss: 0.07263 - train accuracy: 97.46 - validation loss: 1.17211 - validation accuracy: 73.22 \n",
      "Finished Training\n",
      "73 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.03432, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,     6] loss: 0.04058, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.09156, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.02055, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.07375, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.03534, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.02796, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.06258, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.07791, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.03054, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.03984, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.08198, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.02137, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.09411, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.09419, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.02993, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.10184, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.02328, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.02070, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.05836, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.02607, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.04994, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.04447, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.07301, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.22100, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.03095, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.10831, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.06979, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.02940, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.05296, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.07284, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.08543, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.07100, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.05348, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.07995, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.02419, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.02879, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.06137, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.04708, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05539, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.02067, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.04327, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.04578, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.03946, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.05252, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.08742, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.16635, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.05125, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.03950, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.07917, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.13481, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.05109, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.10249, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.14614, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.06765, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.04391, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.11248, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.08500, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.05027, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.06361, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.09558, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.14885, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.01439, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.14692, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.09270, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.12226, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.03568, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.06430, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.10455, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.03009, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.10501, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.07950, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.12589, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.06310, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.06816, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.07865, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.09619, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.10467, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.05422, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3125\n",
      "pgd robustness: 0.26171875\n",
      "duration: 156 s - train loss: 0.07150 - train accuracy: 97.42 - validation loss: 1.18418 - validation accuracy: 73.67 \n",
      "Finished Training\n",
      "74 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.08692, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.02131, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.04844, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    16] loss: 0.16826, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.05876, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.04192, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.04817, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.10171, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.03607, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.11152, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.06350, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.11879, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.11419, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.07106, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.10615, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.08021, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.09938, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.13676, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.05770, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.06529, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.05909, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.11565, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.04768, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.08641, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.03615, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.11469, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.12722, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.06671, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.03774, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   146] loss: 0.04943, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.07259, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.07599, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.10910, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.07095, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.05782, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   176] loss: 0.08354, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.07838, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.08869, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.04910, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.02961, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.21084, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.04039, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.08934, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.09109, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.06531, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.03914, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.13799, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.07924, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.06707, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.02351, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.01423, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.09536, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.12491, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.12005, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.04886, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.02038, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.07123, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.04363, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.03544, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.04467, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.05768, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.06707, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.03935, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.04485, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.09868, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.04175, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.16360, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.09154, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.10613, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.08199, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.13167, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.08735, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.05860, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.05412, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.07519, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.07391, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.02040, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.01897, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.04079, adv_train_accuracy: 98.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3427734375\n",
      "pgd robustness: 0.26953125\n",
      "duration: 156 s - train loss: 0.07109 - train accuracy: 97.50 - validation loss: 1.33603 - validation accuracy: 73.29 \n",
      "Finished Training\n",
      "75 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.04197, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.03302, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.07452, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.04086, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.02951, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.02859, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.03135, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.03191, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.01596, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.06306, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.04898, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.04087, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.12003, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.08001, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.03171, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.03344, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.02570, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.08276, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.06203, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.03344, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   101] loss: 0.01995, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.06145, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.06645, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.02450, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.02195, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.04114, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.02301, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.09059, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.07634, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.09336, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.06727, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.05329, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.07752, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.03965, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.06666, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.01305, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.07731, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.03910, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.12921, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05325, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.09372, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.02400, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.07597, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.03544, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.06169, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.13908, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.04776, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.09184, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.06044, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.08553, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.06447, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.05404, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.04582, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.04609, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.09362, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.07402, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.03705, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.02317, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,   291] loss: 0.03797, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.14664, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.14954, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.08925, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.13069, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.08257, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.03263, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.02282, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.16139, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.11089, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.13226, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.09474, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.09435, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.03327, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.07144, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.20867, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.06106, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.13195, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.11184, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.04040, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.06271, adv_train_accuracy: 98.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3125\n",
      "pgd robustness: 0.271484375\n",
      "duration: 156 s - train loss: 0.06425 - train accuracy: 97.64 - validation loss: 1.41800 - validation accuracy: 73.61 \n",
      "Finished Training\n",
      "76 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.04865, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.04190, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.02593, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.03462, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.08563, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.07512, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.01711, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.04437, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.02852, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.11040, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.01784, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.13899, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.04366, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.02396, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.09292, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.09921, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.05407, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.03415, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.08101, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.07012, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.07520, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.06658, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.03408, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.04003, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.12713, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.07003, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.03687, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.01184, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.05097, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.05278, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.11142, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.09125, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.10720, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.03967, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.11436, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.03270, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.02309, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   186] loss: 0.02929, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.02064, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.08945, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.10108, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.10040, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.05306, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.07501, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.03024, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.04340, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.05783, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.04302, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.03500, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.09771, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.04277, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.05103, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.04893, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.04300, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.05558, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.07446, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.06626, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.10884, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.05962, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.12180, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.04468, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   306] loss: 0.10536, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.13743, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.15106, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.04940, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.03773, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   331] loss: 0.09429, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.06081, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.08422, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.05530, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.05540, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.08619, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.09178, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.04248, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.04663, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.08952, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.09102, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.06969, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.10861, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3486328125\n",
      "pgd robustness: 0.2578125\n",
      "duration: 156 s - train loss: 0.06903 - train accuracy: 97.56 - validation loss: 1.36240 - validation accuracy: 73.37 \n",
      "Finished Training\n",
      "77 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.04921, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.04503, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.08570, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.07890, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.06748, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.05546, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.02679, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.06896, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.06394, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.02151, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.12344, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.11610, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.08974, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.00866, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.04019, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.04847, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.03740, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.01416, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.07804, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.02228, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.07367, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.11699, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.04227, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.07835, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.06320, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.07926, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.06485, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.03809, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.12556, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.06702, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.08238, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.03340, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.02133, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.07234, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.03966, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.04850, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.05681, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.06162, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.06445, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.12544, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.13408, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.07562, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.07116, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.06293, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.07072, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.04420, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.06890, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.02074, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.07579, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.14233, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.10068, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.02849, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.02380, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.07544, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   271] loss: 0.06727, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.07796, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   281] loss: 0.07847, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.07544, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.07437, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.02805, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.08037, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.03553, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.10564, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.08737, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.02651, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.03271, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.05051, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.09315, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.07787, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.05506, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.06067, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.07150, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.14621, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.07498, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.11060, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.06771, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.10171, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.07329, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.02398, adv_train_accuracy: 98.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.310546875\n",
      "pgd robustness: 0.248046875\n",
      "duration: 156 s - train loss: 0.06719 - train accuracy: 97.58 - validation loss: 1.45383 - validation accuracy: 72.48 \n",
      "Finished Training\n",
      "78 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.06396, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.09349, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.06176, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.03180, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.07290, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.10477, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.07527, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.11276, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.10107, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.04738, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.08285, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.07382, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.07212, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.01090, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.03642, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.09963, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.04797, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.08193, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.06476, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.05863, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.02559, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.03987, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.08385, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.14556, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.05053, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.02618, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.08130, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.06163, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.05028, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.05003, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.06311, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.01512, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.04074, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.04265, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.09331, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.02352, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.09009, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.08284, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.07111, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05579, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.06348, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.08469, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.08769, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.01907, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.01643, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.08325, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.05909, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.01019, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.07564, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.05746, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.05190, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.06440, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.04141, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.03959, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.06150, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.02248, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.02514, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.03879, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.04929, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.03564, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.05660, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.00722, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.05249, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.05690, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.07862, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.03274, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.04076, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.07885, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.09960, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.10435, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.12087, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   356] loss: 0.03753, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.07252, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.09281, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.09684, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.06032, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.07531, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.10368, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.06442, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3212890625\n",
      "pgd robustness: 0.2490234375\n",
      "duration: 156 s - train loss: 0.06258 - train accuracy: 97.84 - validation loss: 1.24265 - validation accuracy: 72.67 \n",
      "Finished Training\n",
      "79 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.10576, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.01602, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.08177, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.08331, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.06609, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.09854, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.09737, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.08830, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.10930, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.04980, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.05651, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.05086, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.13950, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.08314, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.06247, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.11562, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.14056, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.06397, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.03930, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.12734, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.04359, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.20785, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.08004, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.09929, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.04175, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.06435, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.07447, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.05006, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.08580, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.03624, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.09760, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.06389, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.05330, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.05460, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.04297, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.02787, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.09422, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.05219, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.05363, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.04748, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.07325, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.05168, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.05420, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.07560, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.04561, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.05073, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.01687, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.05286, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   241] loss: 0.07221, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.06343, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.02282, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.05602, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.19502, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.05427, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.18955, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.03447, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.05824, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.03007, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.05914, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.08658, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.11132, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.06979, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.06226, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.06158, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.13598, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.05438, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.10567, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.01898, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.13531, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.12265, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.05159, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.06866, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.05284, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.06632, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.07872, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.09785, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.03195, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.11705, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.06181, adv_train_accuracy: 98.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3046875\n",
      "pgd robustness: 0.2412109375\n",
      "duration: 156 s - train loss: 0.07344 - train accuracy: 97.36 - validation loss: 1.30041 - validation accuracy: 72.73 \n",
      "Finished Training\n",
      "80 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.10776, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.08333, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.02851, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.02953, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.06783, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.04998, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    31] loss: 0.02738, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.06756, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.08756, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.08486, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.05073, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.10072, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.06099, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.10869, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.03853, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.06401, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.03962, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.06486, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.02739, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.05733, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.03610, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.14864, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.02769, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.06104, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.02124, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.01538, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.09028, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.04738, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.11941, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.03727, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.10799, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.04586, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.06781, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.05352, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.05034, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.08331, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.07024, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.05036, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.07827, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.04669, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.05686, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.02623, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.06831, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.06340, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.03905, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.04620, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.06678, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.08658, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.06619, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.03988, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.05474, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.04249, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.04947, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.09307, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.05035, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.03465, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.02602, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.10983, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.04909, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.01569, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.03277, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.04072, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.02547, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.10299, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.08664, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.04886, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.01553, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.09610, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.06984, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.04594, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.00874, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.06130, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.05903, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.03217, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.02266, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.06059, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.10413, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.07652, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.15108, adv_train_accuracy: 95.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.2978515625\n",
      "pgd robustness: 0.2705078125\n",
      "duration: 155 s - train loss: 0.06174 - train accuracy: 97.82 - validation loss: 1.36036 - validation accuracy: 73.89 \n",
      "Finished Training\n",
      "81 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.03330, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.03667, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.04142, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.08532, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.04915, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.04628, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.04128, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.01184, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.10140, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.02479, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.03378, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.13995, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.04953, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.01869, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.05715, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.08043, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.02288, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.04920, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.02273, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.02382, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.06554, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.03482, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.02828, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   116] loss: 0.02023, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.07857, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.02471, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.00594, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.03894, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.06291, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.10522, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.07793, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.02154, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.06753, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.03634, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.04224, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.02097, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.06083, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.06728, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.04493, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.16097, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.06767, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.02723, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.06079, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.11293, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.17831, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.06435, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.04661, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.03214, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.01690, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.05563, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.05196, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.08185, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.08635, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.04111, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.09622, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.05298, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.05835, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.03774, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.08361, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.11694, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.03582, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.04016, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.06380, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.03191, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.08833, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.11177, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.10202, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.07446, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.05520, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.11006, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.09310, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.10070, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.06175, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.05456, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.05137, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.05986, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.03970, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.06330, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.03269, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3408203125\n",
      "pgd robustness: 0.291015625\n",
      "duration: 156 s - train loss: 0.06208 - train accuracy: 97.85 - validation loss: 1.24152 - validation accuracy: 73.81 \n",
      "Finished Training\n",
      "82 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.03640, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.05748, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.06404, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.01582, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.06598, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.04038, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.08562, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.05003, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.03962, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.03870, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.07571, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.01921, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.03311, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,    66] loss: 0.05606, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.03133, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.07647, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.07517, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.10950, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.08199, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.07718, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.09922, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.02891, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.11657, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.07080, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.06380, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.09855, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.03527, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.04705, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.03331, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.07605, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.13311, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.07201, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.07457, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.07761, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.01176, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.09106, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.03752, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.06273, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.03036, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05627, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   201] loss: 0.07609, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.04209, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.06954, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.11379, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.05976, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.06085, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.02876, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.11993, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.06859, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.04483, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.03242, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.04826, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.03906, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.06021, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.01745, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.09708, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.09661, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.04068, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.04573, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.06831, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.17331, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.12049, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.04309, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.02598, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.10435, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.04693, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.10834, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.06063, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.03925, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.07665, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.05099, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.05537, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.07456, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.07054, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.08029, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.05194, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.08529, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.10356, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.16345, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3427734375\n",
      "pgd robustness: 0.2548828125\n",
      "duration: 155 s - train loss: 0.06738 - train accuracy: 97.63 - validation loss: 1.21755 - validation accuracy: 74.02 \n",
      "Finished Training\n",
      "83 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.06270, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.06446, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.08988, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.14282, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.05561, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.04539, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.06343, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.04380, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.06096, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.07737, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.04536, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.05513, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.15384, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.05276, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.05270, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.06691, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.07370, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.07359, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.07059, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.07084, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.04221, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.07317, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.04046, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.03106, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.05982, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.09970, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.05881, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.05985, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.06342, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.11309, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.15502, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.04193, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.07682, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.08268, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.02589, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.02795, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.03820, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.05584, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.03303, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.07434, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.06432, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.04988, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.02216, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.06235, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.06333, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.13000, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.08182, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.10013, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.02180, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.08449, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.07989, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.07667, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.04965, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.06975, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.04373, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.02515, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.07041, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   286] loss: 0.07412, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.11050, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.20942, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.05062, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.10779, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.05795, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.10422, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.15916, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.11822, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.08300, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.03534, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.03073, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.06364, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.18955, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.06860, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.10607, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.03196, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.02602, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.02050, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.05293, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.03158, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.11303, adv_train_accuracy: 98.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.31640625\n",
      "pgd robustness: 0.26171875\n",
      "duration: 155 s - train loss: 0.06683 - train accuracy: 97.67 - validation loss: 1.30804 - validation accuracy: 73.22 \n",
      "Finished Training\n",
      "84 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.13078, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.10730, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.02772, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.02087, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.02660, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.05456, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.02927, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.04545, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.03845, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.11748, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.08711, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.08821, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.08607, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.02554, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.06166, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.03954, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.03957, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.02577, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.02228, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.10796, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.11163, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.04071, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   111] loss: 0.02459, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.02867, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.04695, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.08001, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.11991, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.07351, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.05494, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.02498, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.10330, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.03188, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.02973, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.04966, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.03189, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.04535, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.05350, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.03584, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.07788, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.09828, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.03856, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.08426, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.05656, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.12518, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.05781, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.03652, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.03645, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.03238, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.04001, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.05551, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.09596, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.09606, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.09023, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.10613, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.17030, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.11134, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.04218, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.06881, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.02976, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.10814, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.04917, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.12763, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.08372, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.07089, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.09206, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.06458, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.06402, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.03068, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.01221, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.16827, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.07596, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.08063, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.03230, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.05371, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   371] loss: 0.06482, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.03191, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.03666, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.06029, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.05512, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3193359375\n",
      "pgd robustness: 0.291015625\n",
      "duration: 155 s - train loss: 0.06195 - train accuracy: 97.80 - validation loss: 1.27847 - validation accuracy: 74.05 \n",
      "Finished Training\n",
      "85 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.05793, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.03535, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.08264, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.02534, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.01933, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.08731, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.11335, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.07170, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.09897, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.02188, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.03551, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.05075, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.07803, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.01958, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.06821, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.05104, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.06061, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.08653, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.06135, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.05271, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.00554, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.02927, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.05670, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.05895, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.03318, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.05102, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.07003, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.06091, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.04079, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.07001, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.04476, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.05248, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.03594, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.02228, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.04696, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.08945, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.03456, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.05226, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.03478, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.02173, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.05042, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.09140, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.06781, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.08190, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.01036, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.09977, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.05242, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.09557, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.07460, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.07245, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.03570, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.08512, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.10103, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.03743, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.10416, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.02939, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.03225, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.07096, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.11042, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.03208, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.05571, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.05226, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.15665, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.10117, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.03694, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.26197, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.04216, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.06791, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.08312, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   346] loss: 0.05276, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.06441, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.05851, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.06932, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.04146, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.02399, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,   376] loss: 0.07702, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.06460, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.02549, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.09734, adv_train_accuracy: 95.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.2998046875\n",
      "pgd robustness: 0.2841796875\n",
      "duration: 155 s - train loss: 0.05644 - train accuracy: 98.06 - validation loss: 1.47972 - validation accuracy: 72.25 \n",
      "Finished Training\n",
      "86 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.02734, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.08880, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.08643, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.10433, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.14688, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.07206, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.05254, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.11427, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.09961, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    46] loss: 0.07342, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.02196, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.11402, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.12376, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.01602, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.04156, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.08873, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.09352, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.07429, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.02338, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.06109, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.05323, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.03017, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.03547, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.01518, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.03536, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.05846, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.02506, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,   136] loss: 0.07684, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.04528, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.04581, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.09383, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.08987, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.05473, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.05815, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.05396, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.05244, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.05931, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.08206, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.07735, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05010, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.02531, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.03298, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.07772, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.02224, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.04100, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.04297, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.03689, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.03763, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.06367, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.10079, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   251] loss: 0.06204, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.09121, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.04558, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.11473, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.03575, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.04286, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.04512, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.06463, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.00996, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.06269, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.06622, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.12193, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.06451, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.05333, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.10240, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.04692, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.05804, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.10317, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.05790, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.15717, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.06235, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.08829, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.06298, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.12972, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.10360, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.03951, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.05791, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.07018, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.09293, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.33984375\n",
      "pgd robustness: 0.2373046875\n",
      "duration: 155 s - train loss: 0.06803 - train accuracy: 97.65 - validation loss: 1.29389 - validation accuracy: 73.75 \n",
      "Finished Training\n",
      "87 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.08268, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.09972, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.12215, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.02605, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.05845, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.05298, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.02750, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.10497, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.02534, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.01374, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.08176, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.02403, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.02505, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.06621, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.06576, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.04144, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.06444, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.03096, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.06693, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.05522, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.03956, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.02670, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.01082, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.11485, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.04891, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.07294, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   131] loss: 0.01774, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.01061, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.01392, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.04729, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.01977, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.05836, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.07310, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.05409, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.01617, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.09493, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.07008, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.03353, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.05937, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05033, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.05796, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.04344, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.02212, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.03832, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.04405, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.09790, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.04778, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.03451, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.06397, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.06429, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.03196, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.04017, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.18005, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.07843, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.03691, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.03324, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.05886, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.02196, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.02120, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.04297, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.13185, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.08751, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.06198, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.08248, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.06645, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.04271, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.08696, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.07179, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.03237, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.03724, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.13673, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.03495, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.04921, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.01808, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.01854, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.02482, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.04570, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.09005, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.12306, adv_train_accuracy: 95.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3564453125\n",
      "pgd robustness: 0.25\n",
      "duration: 155 s - train loss: 0.05356 - train accuracy: 98.15 - validation loss: 1.24197 - validation accuracy: 72.93 \n",
      "Finished Training\n",
      "88 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.02106, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.01262, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.02325, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.00912, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.06432, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.05896, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.04956, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.05198, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.06463, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.02338, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.05039, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.04628, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.07654, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.04795, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.02742, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.09908, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.05757, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.07066, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.12542, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.10045, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.08317, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.06444, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.04030, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.05187, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.07434, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.10500, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.01309, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.02437, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.10307, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.04695, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.05205, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.05942, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.11951, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.07553, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.01882, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.02982, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.06236, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.08602, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.05146, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.03110, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.08793, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.03955, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.05811, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   216] loss: 0.07603, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.02009, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.04095, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.04279, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.02000, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.04295, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.09157, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.03493, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.04930, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.02280, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.04322, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.07556, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.11389, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.02536, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.04147, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.01973, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.09631, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.06788, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   306] loss: 0.02717, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.01139, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.06407, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.07500, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.09069, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.02650, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.02733, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.06017, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.04091, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.06432, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.06116, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.02381, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.08370, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.11916, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.04839, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.05508, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.05600, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.10960, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.322265625\n",
      "pgd robustness: 0.2626953125\n",
      "duration: 155 s - train loss: 0.06118 - train accuracy: 97.97 - validation loss: 1.32118 - validation accuracy: 72.70 \n",
      "Finished Training\n",
      "89 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.08404, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.07434, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.06161, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.06003, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.03571, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.01931, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.11220, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.00812, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.04132, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.01964, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.03076, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.01684, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.05233, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.07424, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.08369, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.03642, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.01439, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.06381, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.02021, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.01889, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.04102, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.03975, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,   111] loss: 0.02558, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.04413, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.07763, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.02432, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.06308, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.01984, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.03399, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.02080, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.06084, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.02808, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.01133, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.01508, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.10970, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.07247, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.06416, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.07067, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.03396, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05147, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.02543, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.05577, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.04527, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.08817, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.04524, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.02392, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.06137, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.06467, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.02829, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.09202, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.01565, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.01603, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.05802, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.05223, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.05484, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.07701, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.08122, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.07572, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.16961, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.03238, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   301] loss: 0.05720, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.09334, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.08112, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.05175, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.03504, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.05051, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.01594, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.05063, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.03605, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.05781, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.03679, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.01614, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.03599, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.11622, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.05446, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.03080, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.02004, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.03041, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.24468, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.2802734375\n",
      "pgd robustness: 0.251953125\n",
      "duration: 156 s - train loss: 0.05902 - train accuracy: 97.95 - validation loss: 1.50382 - validation accuracy: 72.61 \n",
      "Finished Training\n",
      "90 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.07507, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.10386, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.13732, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.03150, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.00791, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.02119, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.00963, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.00899, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.03157, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.07519, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.06531, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.01336, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.04213, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.01660, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.01289, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.05778, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,    81] loss: 0.04596, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.03545, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.05279, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.00622, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.04187, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.02927, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.01642, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.04766, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.08028, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.02087, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.00398, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.05602, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.04538, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.01949, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.07683, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.04957, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.04985, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.05794, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.05183, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.06763, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.01235, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.02939, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.00793, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.03978, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.06195, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.04766, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.04479, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.04539, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.02198, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.02878, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.03053, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.05175, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.01888, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.07928, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.02094, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.08850, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.04217, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.04088, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.04835, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.06773, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.01193, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.04205, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.01961, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.05963, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.00445, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.03056, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.05250, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.05463, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.07489, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.07020, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.13320, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.04811, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.06105, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.06068, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.04424, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.09363, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.05981, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.01539, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.08997, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.07269, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.08507, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   386] loss: 0.04954, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.10217, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3046875\n",
      "pgd robustness: 0.2265625\n",
      "duration: 155 s - train loss: 0.05180 - train accuracy: 98.17 - validation loss: 1.52984 - validation accuracy: 72.11 \n",
      "Finished Training\n",
      "91 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.04385, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.11191, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.10527, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.02010, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.05240, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.02833, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.02888, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.04307, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.03525, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.12436, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.05696, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.01574, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.05808, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.04116, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.06185, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.05844, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.05041, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.04261, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.15075, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.02486, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.11640, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.02386, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.05073, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.14661, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.11993, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.05166, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.02093, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.03780, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.06074, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.05750, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.04164, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.06522, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.07382, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.08748, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.00970, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.05575, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.05357, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.09526, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.05480, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.08341, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.04005, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.04608, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.09538, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.06614, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.07317, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.05958, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.06369, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.02725, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.07732, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.04680, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.15011, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.03792, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.12083, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.07641, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.04269, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.07217, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.05811, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.07941, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.06510, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.03245, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.13221, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.07728, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.08961, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.06290, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.09257, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.11555, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.10250, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.09007, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.08826, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.05240, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.14088, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.04349, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.02827, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.06720, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.07432, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.06612, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.03320, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.02157, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.05956, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3076171875\n",
      "pgd robustness: 0.248046875\n",
      "duration: 155 s - train loss: 0.06410 - train accuracy: 97.74 - validation loss: 1.37216 - validation accuracy: 73.18 \n",
      "Finished Training\n",
      "92 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.03128, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.04875, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.06884, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.05684, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.02134, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.06774, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.03787, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.01976, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.03017, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.04327, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.07777, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.06017, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    61] loss: 0.06773, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.06123, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.06970, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.03378, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.06653, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.01744, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.04213, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.07743, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.03643, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.04812, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.10833, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.10951, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.01688, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.05533, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.06392, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.02340, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.01956, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.06885, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.08376, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.05053, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.09742, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.02848, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.08753, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.04399, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.03249, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.03269, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.02999, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.03413, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.02994, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.07791, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.04514, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.02558, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.04438, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.05032, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.08339, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.04309, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.05415, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.03968, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.08324, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.08471, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.14304, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.03247, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.09551, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.06936, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.07720, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.09252, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.08914, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.07939, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.06179, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.06642, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.04746, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.03168, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.03853, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.07119, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.08200, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.02894, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.13256, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.01881, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.07395, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.05357, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.14567, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.07494, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.03664, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.05265, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.07409, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.13784, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.19544, adv_train_accuracy: 95.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.330078125\n",
      "pgd robustness: 0.27734375\n",
      "duration: 155 s - train loss: 0.06145 - train accuracy: 97.93 - validation loss: 1.36040 - validation accuracy: 72.36 \n",
      "Finished Training\n",
      "93 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.04207, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.06864, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.08814, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.04899, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.05898, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.05043, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.08573, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.30233, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.06900, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.02688, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.06873, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.04973, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.12268, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.05893, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.07445, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.11125, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.06460, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.03486, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.06538, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.02455, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.02842, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,   106] loss: 0.06748, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.06431, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.04629, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.04723, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.04705, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.03706, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.03261, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.01213, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   146] loss: 0.05286, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.05559, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.07229, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.00980, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.03631, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.02812, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.07690, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   181] loss: 0.05618, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.03154, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.03096, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05211, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.06644, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.03022, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.08476, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.09633, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.03287, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.05475, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.07563, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.02619, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.04437, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.04002, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.06373, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.06671, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.02110, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.04770, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.04123, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.07749, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.04467, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.04562, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.03844, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.11200, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.01149, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.01618, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.03518, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.05903, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.00972, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.04321, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.05118, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.04220, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.08348, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.08794, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.05767, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.08335, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.01788, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.06234, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.07198, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.06858, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.05980, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.04761, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.03167, adv_train_accuracy: 98.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.28515625\n",
      "pgd robustness: 0.263671875\n",
      "duration: 155 s - train loss: 0.05364 - train accuracy: 98.19 - validation loss: 1.36670 - validation accuracy: 72.27 \n",
      "Finished Training\n",
      "94 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.02573, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.03942, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.03834, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.02993, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.03869, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.01903, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.01485, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.01074, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.02568, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.02172, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.00507, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.04405, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.01534, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.01471, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.02403, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.03125, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.06334, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.02087, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.03452, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.02604, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.05978, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.03252, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.01207, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.06191, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.05306, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.06704, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.03881, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.04779, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.18403, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.13051, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.09471, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.05051, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.09106, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.01753, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.03840, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.02268, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.04899, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.08717, adv_train_accuracy: 96.88, clean_train_accuracy : 99.22\n",
      "[1,   191] loss: 0.04761, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.03909, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.05715, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.03351, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.01546, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.05336, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.03606, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.01559, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   231] loss: 0.03984, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.03315, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.02265, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.04663, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.09647, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.06041, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.04837, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.07145, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.06232, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.01377, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.04331, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.07654, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.04287, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.02882, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.10997, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.01973, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.05733, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.07704, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.03971, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.06706, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.01729, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.02559, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.01856, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.05968, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.03689, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.10966, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.04240, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.01437, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.07497, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.03588, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.04715, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.03718, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.05271, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3203125\n",
      "pgd robustness: 0.2744140625\n",
      "duration: 155 s - train loss: 0.04994 - train accuracy: 98.28 - validation loss: 1.32647 - validation accuracy: 73.65 \n",
      "Finished Training\n",
      "95 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.01884, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.02027, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.04851, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.05242, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.03801, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.01938, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.02325, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.06252, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.07155, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.06161, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.10981, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.08391, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.04355, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.06493, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.03379, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.02178, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.07998, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.02453, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.04590, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.01048, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.06373, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.05135, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.06767, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.02570, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.11239, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.07010, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.03416, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.03625, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.08897, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.05298, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.03315, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.01933, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.03836, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.03885, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.02989, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.06914, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.03175, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.04361, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.06483, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.03573, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.08602, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.02506, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.05245, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.09495, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.06797, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.09115, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.08264, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.05214, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.03233, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.08621, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.03060, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.02377, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.03555, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.07133, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.02769, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.06557, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.07971, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.03038, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.04856, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.07682, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.05228, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.12165, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.09232, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   316] loss: 0.06398, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.11600, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.04489, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.05927, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.07315, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.04515, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.06333, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.01489, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.07211, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.01508, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.03606, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.04199, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.03885, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.06507, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.03649, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.13202, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3076171875\n",
      "pgd robustness: 0.24609375\n",
      "duration: 155 s - train loss: 0.06059 - train accuracy: 97.97 - validation loss: 1.41878 - validation accuracy: 72.61 \n",
      "Finished Training\n",
      "96 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.06181, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.02321, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.07282, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.07238, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.09471, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.07171, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.06302, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.03545, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.02228, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.02745, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,    51] loss: 0.07304, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.06044, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.07443, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.02615, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.01123, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.12357, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.04844, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.06311, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.07845, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.11338, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.02199, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.05341, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.04985, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.01329, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.13188, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.03564, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.12009, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.01320, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.04002, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.08014, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.01467, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.08638, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.02975, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.08215, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.03562, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.05314, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.05348, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.02510, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.02472, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.09217, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.02517, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.03679, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.04543, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.01757, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.02362, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.02145, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.01507, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.02163, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.04369, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.07245, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.03527, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.04726, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.04827, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.12871, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.06169, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.08633, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.03630, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.03625, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.02992, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.05583, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.02116, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.11993, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.02952, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.03311, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.08633, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.11663, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.03047, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.06760, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.04352, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.08602, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.08295, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.02832, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.06142, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.04444, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.02260, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.09061, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.07027, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.05664, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.04649, adv_train_accuracy: 98.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3193359375\n",
      "pgd robustness: 0.26171875\n",
      "duration: 155 s - train loss: 0.05572 - train accuracy: 98.03 - validation loss: 1.51223 - validation accuracy: 73.57 \n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.07610, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.05262, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.06749, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.02236, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.01884, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.01963, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.02116, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.07121, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.04688, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.02843, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.03286, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.05872, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.07220, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.03743, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.09747, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.03131, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.03563, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.03163, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.03520, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.03579, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.12389, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.04913, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   111] loss: 0.06835, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.06213, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.02516, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.09993, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.06116, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.00816, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.02895, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.01767, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.11179, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.01985, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.07188, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.03633, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.02489, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.06260, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.04699, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.03789, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.02790, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.10499, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.07180, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.06072, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.03157, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.04500, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.11785, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.03957, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.03243, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.04185, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.03230, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.04276, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.03536, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.03886, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.05978, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.07911, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.03012, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.01850, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.04477, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.02261, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.10243, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.01913, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.04317, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.02985, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.06952, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.02658, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.02613, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.03997, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.08486, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.02865, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.04422, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.04698, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.07316, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.11129, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.04128, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.11185, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.05585, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.09522, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.06815, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.03944, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.09233, adv_train_accuracy: 98.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.302734375\n",
      "pgd robustness: 0.28125\n",
      "duration: 155 s - train loss: 0.05348 - train accuracy: 98.20 - validation loss: 1.37295 - validation accuracy: 73.07 \n",
      "Finished Training\n",
      "98 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.08165, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.07898, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.02164, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.08487, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.05979, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.02164, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.03697, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.05624, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.01913, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.03492, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.06350, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.06031, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.15802, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.07382, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.11755, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.03871, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,    81] loss: 0.04542, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    86] loss: 0.03007, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.07122, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.04592, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.06160, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.03409, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.01549, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.05497, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.02762, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.04792, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.10282, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.02768, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.08579, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.03131, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.05528, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.06199, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.04616, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.09857, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.04474, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.03993, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.02533, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.05524, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.06963, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.09547, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.05779, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.02060, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.04415, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.05667, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.04057, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.06665, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.01143, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.09838, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.06033, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.04919, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.13257, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.04763, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.03842, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.03787, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.06644, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.02823, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.11472, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.13638, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.10560, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.07029, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.05846, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.01441, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.02672, adv_train_accuracy: 99.22, clean_train_accuracy : 99.22\n",
      "[1,   316] loss: 0.10107, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.08175, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.05719, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.02987, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.05062, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.03879, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.02569, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.08557, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.02070, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.05044, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.04074, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.09597, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.04802, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.12792, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.12272, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.08159, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3203125\n",
      "pgd robustness: 0.263671875\n",
      "duration: 155 s - train loss: 0.05649 - train accuracy: 98.04 - validation loss: 1.39598 - validation accuracy: 73.45 \n",
      "Finished Training\n",
      "99 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.03022, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.01988, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.02785, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.02840, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.05414, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.03154, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.08494, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.04620, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.08609, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.06375, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.03056, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.01562, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.05814, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.04052, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.03851, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.02790, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.03673, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.05323, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.00635, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.04544, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.02282, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.13008, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.07163, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.04352, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.05871, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.02709, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.04018, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.04240, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.03518, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.04352, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.03215, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.02076, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.02958, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.09223, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   171] loss: 0.03617, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.05822, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.01969, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.07563, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.01656, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.10612, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.16543, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.10958, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.06697, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.06829, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.05133, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.01986, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.04623, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.13761, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.07969, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.04353, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.04504, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.02842, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.08593, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.04031, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.06205, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.02273, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.04167, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.01231, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.03546, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.07791, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.04892, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.02411, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.05228, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.06636, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.10453, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.05758, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.07064, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.09770, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.02005, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.04905, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.06796, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.04500, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.04711, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.06335, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.10384, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.03380, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.10150, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.08089, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.02258, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.30859375\n",
      "pgd robustness: 0.2626953125\n",
      "duration: 155 s - train loss: 0.05549 - train accuracy: 98.09 - validation loss: 1.39265 - validation accuracy: 73.34 \n",
      "Finished Training\n",
      "100 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.03339, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.07444, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.07650, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.01020, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.02645, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.00523, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.04487, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,    36] loss: 0.13121, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.08804, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.06705, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.03941, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.03769, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.03816, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.00671, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.01129, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.04352, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.06492, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.06672, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.02778, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.04905, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.04003, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.02863, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.02617, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.02342, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.02000, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.03367, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.08283, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.02185, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.03279, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.01811, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.07426, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.08734, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.03642, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.01467, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.04306, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.07844, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.06013, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.04438, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.04882, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05479, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   201] loss: 0.08754, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.01043, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.12999, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.02930, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.06156, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.09216, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.10695, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.02667, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.06086, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.04731, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.07021, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   256] loss: 0.05746, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.01684, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.01426, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.03822, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.07901, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.09931, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.07881, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.05441, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.12023, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.07727, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.06515, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.11768, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.04735, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.06098, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.02202, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.04938, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.03069, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.05402, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.03220, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.01578, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.10516, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.00577, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.04717, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.07063, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.01422, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.08192, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.08775, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.04365, adv_train_accuracy: 97.50, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3466796875\n",
      "pgd robustness: 0.26171875\n",
      "duration: 155 s - train loss: 0.05404 - train accuracy: 98.13 - validation loss: 1.43116 - validation accuracy: 72.56 \n",
      "Finished Training\n",
      "101 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.09248, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.07722, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.02065, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.12136, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.04478, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.04202, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.02723, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.02063, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.00932, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.06630, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.03029, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.07661, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.03310, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.07259, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.05283, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.05595, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.11398, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.02970, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.01998, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.03548, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.03242, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.05314, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.00974, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.02037, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.01109, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.05852, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.03679, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.02613, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.04955, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.01025, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.03178, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.03359, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.02947, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   166] loss: 0.05785, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.06679, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.07549, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.05271, adv_train_accuracy: 98.44, clean_train_accuracy : 99.22\n",
      "[1,   186] loss: 0.06015, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.03213, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.05464, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.02801, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.03464, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.07604, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.04188, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.05842, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.05331, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.03444, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.03315, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.03604, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.02226, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.08049, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.04684, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.03445, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.03867, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.04385, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.01444, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.08987, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.01786, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.02436, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.09457, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.04121, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.07247, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.02898, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.04855, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.08828, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.05686, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.03385, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.03654, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   341] loss: 0.06727, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.06449, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.04076, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.03540, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.01511, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.06065, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.01481, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.06535, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.05534, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.03201, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.02424, adv_train_accuracy: 98.75, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.3359375\n",
      "pgd robustness: 0.279296875\n",
      "duration: 155 s - train loss: 0.04799 - train accuracy: 98.44 - validation loss: 1.38189 - validation accuracy: 72.50 \n",
      "Finished Training\n",
      "102 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.02554, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.05989, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.00825, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.01522, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    21] loss: 0.04842, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    26] loss: 0.01514, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,    31] loss: 0.02831, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    36] loss: 0.03399, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    41] loss: 0.02449, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    46] loss: 0.01086, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    51] loss: 0.08935, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    56] loss: 0.08641, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    61] loss: 0.07417, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,    66] loss: 0.12136, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,    71] loss: 0.03632, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    76] loss: 0.08272, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,    81] loss: 0.05110, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    86] loss: 0.03888, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,    91] loss: 0.01467, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,    96] loss: 0.05054, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   101] loss: 0.03816, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   106] loss: 0.05105, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   111] loss: 0.06700, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   116] loss: 0.01179, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   121] loss: 0.06595, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   126] loss: 0.05378, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   131] loss: 0.03234, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   136] loss: 0.02858, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   141] loss: 0.03987, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   146] loss: 0.04698, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   151] loss: 0.07365, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   156] loss: 0.04022, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   161] loss: 0.03717, adv_train_accuracy: 97.66, clean_train_accuracy : 99.22\n",
      "[1,   166] loss: 0.03156, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   171] loss: 0.01528, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   176] loss: 0.03330, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   181] loss: 0.10536, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   186] loss: 0.04963, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   191] loss: 0.01522, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   196] loss: 0.02178, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   201] loss: 0.05552, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   206] loss: 0.11600, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   211] loss: 0.11740, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   216] loss: 0.07010, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   221] loss: 0.00740, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   226] loss: 0.06612, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   231] loss: 0.04939, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   236] loss: 0.00932, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   241] loss: 0.03093, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   246] loss: 0.01915, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   251] loss: 0.03102, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   256] loss: 0.04131, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   261] loss: 0.08076, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   266] loss: 0.09176, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   271] loss: 0.02898, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   276] loss: 0.12022, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   281] loss: 0.06125, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   286] loss: 0.05020, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   291] loss: 0.05904, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   296] loss: 0.08786, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,   301] loss: 0.11050, adv_train_accuracy: 96.88, clean_train_accuracy : 100.00\n",
      "[1,   306] loss: 0.03040, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   311] loss: 0.02334, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   316] loss: 0.05045, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[1,   321] loss: 0.01930, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   326] loss: 0.04980, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   331] loss: 0.04852, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   336] loss: 0.00203, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   341] loss: 0.00640, adv_train_accuracy: 100.00, clean_train_accuracy : 100.00\n",
      "[1,   346] loss: 0.02713, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   351] loss: 0.07433, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   356] loss: 0.04131, adv_train_accuracy: 99.22, clean_train_accuracy : 100.00\n",
      "[1,   361] loss: 0.05086, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   366] loss: 0.06725, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   371] loss: 0.05047, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   376] loss: 0.01936, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   381] loss: 0.13663, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,   386] loss: 0.02837, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n",
      "[1,   391] loss: 0.10855, adv_train_accuracy: 96.25, clean_train_accuracy : 100.00\n",
      "fgsm robustness: 0.333984375\n",
      "pgd robustness: 0.26171875\n",
      "duration: 155 s - train loss: 0.04707 - train accuracy: 98.37 - validation loss: 1.39071 - validation accuracy: 72.86 \n",
      "Finished Training\n",
      "103 GPU MEMORY: 5044.0\n",
      "fast adversarial training\n",
      "[1,     1] loss: 0.04550, adv_train_accuracy: 97.66, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.03559, adv_train_accuracy: 98.44, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d0f1262911e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GPU MEMORY: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mget_gpu_memory_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mFILENAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'./experiment-models/{PRUNING_METHOD}-{TRAINING_METHOD}-{ratio}-{epoch}.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m#optimizer = train_stats['optimizer'][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msafe_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILENAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first try for experiment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'N/A'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-network-pruning/src/models.py\u001b[0m in \u001b[0;36mfit_fast\u001b[0;34m(self, train_loader, val_loader, epochs, device, eps, number_of_replays, patience, evaluate_robustness)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_replays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fast adversarial training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_fit_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_fast_with_double_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_replays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-network-pruning/src/training.py\u001b[0m in \u001b[0;36m_fit_fast\u001b[0;34m(model, train_loader, val_loader, epochs, device, eps, patience, evaluate_robustness)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mclean_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mclean_train_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0madv_train_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0macc_epoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-network-pruning/src/training.py\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(labels, outputs)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print (\"Pre Start GPU MEMORY: %s\" % get_gpu_memory_map())\n",
    "ARCHITECTURE = 'PreActResNet18'\n",
    "TRAINING_METHOD = 'fast'\n",
    "PRUNING_METHOD = 'unstructured_global_magnitude'\n",
    "ratios = [1,2,4,8,16,32,64]\n",
    "train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=False, batchsize=128)\n",
    "EPOCHS = 200\n",
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "#PATH = './experiment-models/unstructured_global_magnitude-fast-1-99.pt'\n",
    "#checkpoint = torch.load(PATH)\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "for ratio in ratios:\n",
    "    torch.cuda.empty_cache()\n",
    "    rate = 1-1/ratio\n",
    "    model.prune_magnitude_global_unstruct(rate, device)\n",
    "    for epoch in range(EPOCHS):\n",
    "        print (epoch, \"GPU MEMORY: %s\" % get_gpu_memory_map())\n",
    "        FILENAME = f'./experiment-models/{PRUNING_METHOD}-{TRAINING_METHOD}-{ratio}-{epoch}.pt'\n",
    "        model.fit_fast(train_loader, test_loader , 1, device, patience=None, evaluate_robustness=False)\n",
    "        #optimizer = train_stats['optimizer'][0]\n",
    "        safe_model(FILENAME, model, description='first try for experiment', loss='N/A',epoch=epoch+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train_stats.plot(y=['fgsm', 'pgd_robustness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'flush'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0mdata_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'write'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'write'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7f02ce7d4816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./train_stats'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_buffer_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'flush'"
     ]
    }
   ],
   "source": [
    "PATH = './train_stats'\n",
    "torch.save(PATH, model.train_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=False, batchsize= 256)\n",
    "model = CifarResNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73046875"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.728515625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 1.89768, adv_train_accuracy: 29.30, clean_train_accuracy : 41.41\n",
      "[1,     6] loss: 2.06801, adv_train_accuracy: 26.95, clean_train_accuracy : 40.23\n",
      "[1,    11] loss: 1.86141, adv_train_accuracy: 29.30, clean_train_accuracy : 46.48\n",
      "[1,    16] loss: 1.91393, adv_train_accuracy: 26.95, clean_train_accuracy : 46.09\n",
      "0.701171875\n",
      "0.720703125\n",
      "duration: 26 s - train loss: 1.90462 - train accuracy: 28.75 - validation loss: 1.59208 - validation accuracy: 41.48 \n",
      "[2,     1] loss: 1.87206, adv_train_accuracy: 30.08, clean_train_accuracy : 42.97\n",
      "[2,     6] loss: 1.90144, adv_train_accuracy: 29.30, clean_train_accuracy : 46.09\n",
      "[2,    11] loss: 1.86576, adv_train_accuracy: 27.34, clean_train_accuracy : 43.36\n",
      "[2,    16] loss: 1.90111, adv_train_accuracy: 26.17, clean_train_accuracy : 50.39\n",
      "0.73046875\n",
      "0.763671875\n",
      "duration: 26 s - train loss: 1.92003 - train accuracy: 27.60 - validation loss: 1.59478 - validation accuracy: 42.71 \n",
      "[3,     1] loss: 1.92471, adv_train_accuracy: 25.78, clean_train_accuracy : 42.58\n",
      "[3,     6] loss: 1.84841, adv_train_accuracy: 28.52, clean_train_accuracy : 44.53\n",
      "[3,    11] loss: 1.98565, adv_train_accuracy: 25.00, clean_train_accuracy : 37.11\n",
      "[3,    16] loss: 1.83215, adv_train_accuracy: 28.12, clean_train_accuracy : 39.06\n",
      "0.728515625\n",
      "0.72265625\n",
      "duration: 26 s - train loss: 1.90077 - train accuracy: 28.28 - validation loss: 1.56575 - validation accuracy: 44.32 \n",
      "[4,     1] loss: 1.83215, adv_train_accuracy: 29.30, clean_train_accuracy : 42.97\n",
      "[4,     6] loss: 1.82754, adv_train_accuracy: 30.86, clean_train_accuracy : 42.58\n",
      "[4,    11] loss: 1.81675, adv_train_accuracy: 32.03, clean_train_accuracy : 53.12\n",
      "[4,    16] loss: 1.85492, adv_train_accuracy: 29.30, clean_train_accuracy : 51.17\n",
      "0.732421875\n",
      "0.7421875\n",
      "duration: 26 s - train loss: 1.87661 - train accuracy: 29.63 - validation loss: 1.55110 - validation accuracy: 44.81 \n",
      "[5,     1] loss: 1.89138, adv_train_accuracy: 30.47, clean_train_accuracy : 45.70\n",
      "[5,     6] loss: 1.85527, adv_train_accuracy: 26.95, clean_train_accuracy : 44.92\n",
      "[5,    11] loss: 1.97469, adv_train_accuracy: 29.30, clean_train_accuracy : 41.80\n",
      "[5,    16] loss: 1.84227, adv_train_accuracy: 32.03, clean_train_accuracy : 52.34\n",
      "0.673828125\n",
      "0.697265625\n",
      "duration: 26 s - train loss: 1.87137 - train accuracy: 29.47 - validation loss: 1.52341 - validation accuracy: 46.65 \n",
      "[6,     1] loss: 1.96273, adv_train_accuracy: 27.34, clean_train_accuracy : 39.06\n",
      "[6,     6] loss: 1.87395, adv_train_accuracy: 32.81, clean_train_accuracy : 45.31\n",
      "[6,    11] loss: 1.81779, adv_train_accuracy: 35.16, clean_train_accuracy : 51.17\n",
      "[6,    16] loss: 1.88213, adv_train_accuracy: 28.52, clean_train_accuracy : 44.92\n",
      "0.705078125\n",
      "0.69921875\n",
      "duration: 26 s - train loss: 1.85600 - train accuracy: 29.96 - validation loss: 1.50287 - validation accuracy: 47.75 \n",
      "[7,     1] loss: 1.90962, adv_train_accuracy: 29.30, clean_train_accuracy : 48.05\n",
      "[7,     6] loss: 1.81792, adv_train_accuracy: 33.98, clean_train_accuracy : 50.00\n",
      "[7,    11] loss: 1.83227, adv_train_accuracy: 33.20, clean_train_accuracy : 48.05\n",
      "[7,    16] loss: 1.90106, adv_train_accuracy: 29.69, clean_train_accuracy : 46.88\n",
      "0.6796875\n",
      "0.701171875\n",
      "duration: 26 s - train loss: 1.84489 - train accuracy: 31.35 - validation loss: 1.49917 - validation accuracy: 46.95 \n",
      "[8,     1] loss: 1.72154, adv_train_accuracy: 31.64, clean_train_accuracy : 54.30\n",
      "[8,     6] loss: 1.76729, adv_train_accuracy: 31.64, clean_train_accuracy : 49.22\n",
      "[8,    11] loss: 1.87245, adv_train_accuracy: 30.86, clean_train_accuracy : 48.05\n",
      "[8,    16] loss: 1.79033, adv_train_accuracy: 29.30, clean_train_accuracy : 49.22\n",
      "0.693359375\n",
      "0.728515625\n",
      "duration: 26 s - train loss: 1.79523 - train accuracy: 32.07 - validation loss: 1.46730 - validation accuracy: 47.03 \n",
      "[9,     1] loss: 1.81952, adv_train_accuracy: 26.56, clean_train_accuracy : 50.00\n",
      "[9,     6] loss: 1.74806, adv_train_accuracy: 32.42, clean_train_accuracy : 51.56\n",
      "[9,    11] loss: 1.84122, adv_train_accuracy: 28.52, clean_train_accuracy : 45.70\n",
      "[9,    16] loss: 1.90098, adv_train_accuracy: 26.95, clean_train_accuracy : 43.36\n",
      "0.701171875\n",
      "0.712890625\n",
      "duration: 26 s - train loss: 1.85618 - train accuracy: 30.27 - validation loss: 1.50857 - validation accuracy: 47.48 \n",
      "[10,     1] loss: 1.84729, adv_train_accuracy: 35.55, clean_train_accuracy : 56.64\n",
      "[10,     6] loss: 1.78791, adv_train_accuracy: 34.38, clean_train_accuracy : 53.12\n",
      "[10,    11] loss: 1.81483, adv_train_accuracy: 28.91, clean_train_accuracy : 50.78\n",
      "[10,    16] loss: 1.90912, adv_train_accuracy: 26.17, clean_train_accuracy : 46.88\n",
      "0.69921875\n",
      "0.7109375\n",
      "duration: 26 s - train loss: 1.82229 - train accuracy: 31.58 - validation loss: 1.50358 - validation accuracy: 44.11 \n",
      "[11,     1] loss: 1.84170, adv_train_accuracy: 30.86, clean_train_accuracy : 46.88\n",
      "[11,     6] loss: 1.79409, adv_train_accuracy: 33.59, clean_train_accuracy : 47.66\n",
      "[11,    11] loss: 1.81117, adv_train_accuracy: 30.86, clean_train_accuracy : 51.17\n",
      "[11,    16] loss: 1.85218, adv_train_accuracy: 30.08, clean_train_accuracy : 49.61\n",
      "0.7421875\n",
      "0.7265625\n",
      "duration: 26 s - train loss: 1.81518 - train accuracy: 31.31 - validation loss: 1.45760 - validation accuracy: 47.58 \n",
      "[12,     1] loss: 1.81531, adv_train_accuracy: 31.64, clean_train_accuracy : 53.12\n",
      "[12,     6] loss: 1.92476, adv_train_accuracy: 30.86, clean_train_accuracy : 50.78\n",
      "[12,    11] loss: 1.95628, adv_train_accuracy: 22.66, clean_train_accuracy : 35.16\n",
      "[12,    16] loss: 1.81721, adv_train_accuracy: 27.73, clean_train_accuracy : 45.31\n",
      "0.6640625\n",
      "0.716796875\n",
      "duration: 26 s - train loss: 1.87119 - train accuracy: 30.12 - validation loss: 1.46559 - validation accuracy: 45.78 \n",
      "[13,     1] loss: 1.74432, adv_train_accuracy: 30.08, clean_train_accuracy : 49.61\n",
      "[13,     6] loss: 1.83071, adv_train_accuracy: 28.12, clean_train_accuracy : 48.05\n",
      "[13,    11] loss: 1.73539, adv_train_accuracy: 35.94, clean_train_accuracy : 51.17\n",
      "[13,    16] loss: 1.75180, adv_train_accuracy: 33.59, clean_train_accuracy : 53.12\n",
      "0.71484375\n",
      "0.6796875\n",
      "duration: 26 s - train loss: 1.79407 - train accuracy: 32.30 - validation loss: 1.46796 - validation accuracy: 48.73 \n",
      "[14,     1] loss: 1.85842, adv_train_accuracy: 30.08, clean_train_accuracy : 47.27\n",
      "[14,     6] loss: 1.82621, adv_train_accuracy: 35.16, clean_train_accuracy : 47.27\n",
      "[14,    11] loss: 1.75649, adv_train_accuracy: 32.42, clean_train_accuracy : 51.17\n",
      "[14,    16] loss: 1.77249, adv_train_accuracy: 35.94, clean_train_accuracy : 54.30\n",
      "0.666015625\n",
      "0.708984375\n",
      "duration: 26 s - train loss: 1.78871 - train accuracy: 32.73 - validation loss: 1.40232 - validation accuracy: 49.58 \n",
      "[15,     1] loss: 1.77549, adv_train_accuracy: 36.72, clean_train_accuracy : 52.73\n",
      "[15,     6] loss: 1.75434, adv_train_accuracy: 33.59, clean_train_accuracy : 51.17\n",
      "[15,    11] loss: 1.87604, adv_train_accuracy: 23.83, clean_train_accuracy : 50.00\n",
      "[15,    16] loss: 1.71120, adv_train_accuracy: 35.55, clean_train_accuracy : 51.95\n",
      "0.68359375\n",
      "0.712890625\n",
      "duration: 26 s - train loss: 1.76729 - train accuracy: 32.73 - validation loss: 1.39990 - validation accuracy: 48.98 \n",
      "[16,     1] loss: 1.75801, adv_train_accuracy: 37.11, clean_train_accuracy : 53.52\n",
      "[16,     6] loss: 1.98148, adv_train_accuracy: 27.34, clean_train_accuracy : 44.92\n",
      "[16,    11] loss: 1.92572, adv_train_accuracy: 27.34, clean_train_accuracy : 43.36\n",
      "[16,    16] loss: 1.82066, adv_train_accuracy: 28.91, clean_train_accuracy : 49.61\n",
      "0.685546875\n",
      "0.744140625\n",
      "duration: 26 s - train loss: 1.80018 - train accuracy: 32.66 - validation loss: 1.41845 - validation accuracy: 51.20 \n",
      "[17,     1] loss: 1.85995, adv_train_accuracy: 32.81, clean_train_accuracy : 47.66\n",
      "[17,     6] loss: 2.00464, adv_train_accuracy: 32.42, clean_train_accuracy : 46.48\n",
      "[17,    11] loss: 1.92397, adv_train_accuracy: 27.34, clean_train_accuracy : 44.53\n",
      "[17,    16] loss: 1.95737, adv_train_accuracy: 25.78, clean_train_accuracy : 45.70\n",
      "0.69140625\n",
      "0.70703125\n",
      "duration: 26 s - train loss: 1.95493 - train accuracy: 28.81 - validation loss: 1.48167 - validation accuracy: 47.15 \n",
      "[18,     1] loss: 1.69735, adv_train_accuracy: 35.94, clean_train_accuracy : 53.52\n",
      "[18,     6] loss: 1.97525, adv_train_accuracy: 33.20, clean_train_accuracy : 48.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 1.88019, adv_train_accuracy: 34.77, clean_train_accuracy : 49.61\n",
      "[18,    16] loss: 1.64940, adv_train_accuracy: 39.06, clean_train_accuracy : 55.08\n",
      "0.6875\n",
      "0.69921875\n",
      "duration: 26 s - train loss: 1.83444 - train accuracy: 32.71 - validation loss: 1.46453 - validation accuracy: 47.94 \n",
      "[19,     1] loss: 1.76931, adv_train_accuracy: 36.72, clean_train_accuracy : 57.03\n",
      "[19,     6] loss: 1.74468, adv_train_accuracy: 35.94, clean_train_accuracy : 53.52\n",
      "[19,    11] loss: 1.68434, adv_train_accuracy: 38.28, clean_train_accuracy : 54.30\n",
      "[19,    16] loss: 1.82455, adv_train_accuracy: 28.12, clean_train_accuracy : 48.44\n",
      "0.693359375\n",
      "0.697265625\n",
      "duration: 26 s - train loss: 1.79122 - train accuracy: 32.71 - validation loss: 1.39653 - validation accuracy: 50.52 \n",
      "[20,     1] loss: 1.77044, adv_train_accuracy: 32.81, clean_train_accuracy : 50.39\n",
      "[20,     6] loss: 1.81471, adv_train_accuracy: 33.20, clean_train_accuracy : 47.66\n",
      "[20,    11] loss: 1.67772, adv_train_accuracy: 39.45, clean_train_accuracy : 52.73\n",
      "[20,    16] loss: 1.76004, adv_train_accuracy: 33.20, clean_train_accuracy : 56.25\n",
      "0.689453125\n",
      "0.708984375\n",
      "duration: 26 s - train loss: 1.74567 - train accuracy: 33.85 - validation loss: 1.38067 - validation accuracy: 50.65 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2.199005</td>\n",
       "      <td>19.765625</td>\n",
       "      <td>1.971533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.04</td>\n",
       "      <td>158.850918</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2.307448</td>\n",
       "      <td>18.808594</td>\n",
       "      <td>1.949130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.58</td>\n",
       "      <td>185.245145</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2.201714</td>\n",
       "      <td>20.566406</td>\n",
       "      <td>1.791573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.99</td>\n",
       "      <td>211.538478</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2.089135</td>\n",
       "      <td>22.734375</td>\n",
       "      <td>1.791103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.43</td>\n",
       "      <td>237.923156</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2.069923</td>\n",
       "      <td>24.648438</td>\n",
       "      <td>1.794747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.95</td>\n",
       "      <td>264.267743</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2.036039</td>\n",
       "      <td>25.429688</td>\n",
       "      <td>1.739772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.52</td>\n",
       "      <td>290.581069</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2.094370</td>\n",
       "      <td>23.906250</td>\n",
       "      <td>2.008603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.72</td>\n",
       "      <td>316.976808</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2.115578</td>\n",
       "      <td>22.871094</td>\n",
       "      <td>1.705719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.46</td>\n",
       "      <td>343.439615</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2.021146</td>\n",
       "      <td>24.062500</td>\n",
       "      <td>1.686218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.90</td>\n",
       "      <td>369.819359</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.977749</td>\n",
       "      <td>25.410156</td>\n",
       "      <td>1.699897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.40</td>\n",
       "      <td>396.281337</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.952593</td>\n",
       "      <td>28.164062</td>\n",
       "      <td>1.650022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.51</td>\n",
       "      <td>422.639963</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.964369</td>\n",
       "      <td>25.722656</td>\n",
       "      <td>1.630495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.77</td>\n",
       "      <td>449.043573</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.944230</td>\n",
       "      <td>27.128906</td>\n",
       "      <td>1.671066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.41</td>\n",
       "      <td>475.389783</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.972054</td>\n",
       "      <td>26.640625</td>\n",
       "      <td>1.678443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.49</td>\n",
       "      <td>501.599178</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1.921947</td>\n",
       "      <td>27.832031</td>\n",
       "      <td>1.599092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.36</td>\n",
       "      <td>527.837276</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1.904618</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>1.592076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.48</td>\n",
       "      <td>26.309072</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>1.920025</td>\n",
       "      <td>27.597656</td>\n",
       "      <td>1.594776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.71</td>\n",
       "      <td>52.598836</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>1.900772</td>\n",
       "      <td>28.281250</td>\n",
       "      <td>1.565750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.32</td>\n",
       "      <td>78.917605</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>1.876608</td>\n",
       "      <td>29.628906</td>\n",
       "      <td>1.551102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.81</td>\n",
       "      <td>105.124337</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>1.871366</td>\n",
       "      <td>29.472656</td>\n",
       "      <td>1.523409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.65</td>\n",
       "      <td>131.351880</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>1.856000</td>\n",
       "      <td>29.960938</td>\n",
       "      <td>1.502870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.75</td>\n",
       "      <td>157.587234</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>1.844888</td>\n",
       "      <td>31.347656</td>\n",
       "      <td>1.499169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.95</td>\n",
       "      <td>183.799975</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>1.795234</td>\n",
       "      <td>32.070312</td>\n",
       "      <td>1.467305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.03</td>\n",
       "      <td>209.985157</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9</td>\n",
       "      <td>1.856178</td>\n",
       "      <td>30.273438</td>\n",
       "      <td>1.508567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.48</td>\n",
       "      <td>236.249125</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>1.822287</td>\n",
       "      <td>31.582031</td>\n",
       "      <td>1.503579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.11</td>\n",
       "      <td>262.416254</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11</td>\n",
       "      <td>1.815180</td>\n",
       "      <td>31.308594</td>\n",
       "      <td>1.457597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.58</td>\n",
       "      <td>288.738108</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12</td>\n",
       "      <td>1.871191</td>\n",
       "      <td>30.117188</td>\n",
       "      <td>1.465588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.78</td>\n",
       "      <td>315.155859</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13</td>\n",
       "      <td>1.794065</td>\n",
       "      <td>32.304688</td>\n",
       "      <td>1.467957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.73</td>\n",
       "      <td>341.440965</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>14</td>\n",
       "      <td>1.788715</td>\n",
       "      <td>32.734375</td>\n",
       "      <td>1.402320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.58</td>\n",
       "      <td>367.734353</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15</td>\n",
       "      <td>1.767291</td>\n",
       "      <td>32.734375</td>\n",
       "      <td>1.399898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.98</td>\n",
       "      <td>393.845826</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>1.800175</td>\n",
       "      <td>32.656250</td>\n",
       "      <td>1.418447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.20</td>\n",
       "      <td>420.301055</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>17</td>\n",
       "      <td>1.954935</td>\n",
       "      <td>28.808594</td>\n",
       "      <td>1.481668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.15</td>\n",
       "      <td>446.736875</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18</td>\n",
       "      <td>1.834437</td>\n",
       "      <td>32.714844</td>\n",
       "      <td>1.464529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.94</td>\n",
       "      <td>473.046767</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19</td>\n",
       "      <td>1.791221</td>\n",
       "      <td>32.714844</td>\n",
       "      <td>1.396526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.52</td>\n",
       "      <td>499.431938</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20</td>\n",
       "      <td>1.745671</td>\n",
       "      <td>33.847656</td>\n",
       "      <td>1.380673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.65</td>\n",
       "      <td>525.760739</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0      1   10.069616       10.019531         3.418694               NaN   \n",
       "1      2    3.292510        8.789062         2.192064               NaN   \n",
       "2      3    2.474881       13.281250         2.233554               NaN   \n",
       "3      4    2.347974       16.093750         2.084406               NaN   \n",
       "4      5    2.225618       17.734375         1.975296               NaN   \n",
       "5      6    2.199005       19.765625         1.971533               NaN   \n",
       "6      7    2.307448       18.808594         1.949130               NaN   \n",
       "7      8    2.201714       20.566406         1.791573               NaN   \n",
       "8      9    2.089135       22.734375         1.791103               NaN   \n",
       "9     10    2.069923       24.648438         1.794747               NaN   \n",
       "10    11    2.036039       25.429688         1.739772               NaN   \n",
       "11    12    2.094370       23.906250         2.008603               NaN   \n",
       "12    13    2.115578       22.871094         1.705719               NaN   \n",
       "13    14    2.021146       24.062500         1.686218               NaN   \n",
       "14    15    1.977749       25.410156         1.699897               NaN   \n",
       "15    16    1.952593       28.164062         1.650022               NaN   \n",
       "16    17    1.964369       25.722656         1.630495               NaN   \n",
       "17    18    1.944230       27.128906         1.671066               NaN   \n",
       "18    19    1.972054       26.640625         1.678443               NaN   \n",
       "19    20    1.921947       27.832031         1.599092               NaN   \n",
       "20     1    1.904618       28.750000         1.592076               NaN   \n",
       "21     2    1.920025       27.597656         1.594776               NaN   \n",
       "22     3    1.900772       28.281250         1.565750               NaN   \n",
       "23     4    1.876608       29.628906         1.551102               NaN   \n",
       "24     5    1.871366       29.472656         1.523409               NaN   \n",
       "25     6    1.856000       29.960938         1.502870               NaN   \n",
       "26     7    1.844888       31.347656         1.499169               NaN   \n",
       "27     8    1.795234       32.070312         1.467305               NaN   \n",
       "28     9    1.856178       30.273438         1.508567               NaN   \n",
       "29    10    1.822287       31.582031         1.503579               NaN   \n",
       "30    11    1.815180       31.308594         1.457597               NaN   \n",
       "31    12    1.871191       30.117188         1.465588               NaN   \n",
       "32    13    1.794065       32.304688         1.467957               NaN   \n",
       "33    14    1.788715       32.734375         1.402320               NaN   \n",
       "34    15    1.767291       32.734375         1.399898               NaN   \n",
       "35    16    1.800175       32.656250         1.418447               NaN   \n",
       "36    17    1.954935       28.808594         1.481668               NaN   \n",
       "37    18    1.834437       32.714844         1.464529               NaN   \n",
       "38    19    1.791221       32.714844         1.396526               NaN   \n",
       "39    20    1.745671       33.847656         1.380673               NaN   \n",
       "\n",
       "    l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0          NaN             NaN       NaN             NaN       NaN   \n",
       "1          NaN             NaN       NaN             NaN       NaN   \n",
       "2          NaN             NaN       NaN             NaN       NaN   \n",
       "3          NaN             NaN       NaN             NaN       NaN   \n",
       "4          NaN             NaN       NaN             NaN       NaN   \n",
       "5          NaN             NaN       NaN             NaN       NaN   \n",
       "6          NaN             NaN       NaN             NaN       NaN   \n",
       "7          NaN             NaN       NaN             NaN       NaN   \n",
       "8          NaN             NaN       NaN             NaN       NaN   \n",
       "9          NaN             NaN       NaN             NaN       NaN   \n",
       "10         NaN             NaN       NaN             NaN       NaN   \n",
       "11         NaN             NaN       NaN             NaN       NaN   \n",
       "12         NaN             NaN       NaN             NaN       NaN   \n",
       "13         NaN             NaN       NaN             NaN       NaN   \n",
       "14         NaN             NaN       NaN             NaN       NaN   \n",
       "15         NaN             NaN       NaN             NaN       NaN   \n",
       "16         NaN             NaN       NaN             NaN       NaN   \n",
       "17         NaN             NaN       NaN             NaN       NaN   \n",
       "18         NaN             NaN       NaN             NaN       NaN   \n",
       "19         NaN             NaN       NaN             NaN       NaN   \n",
       "20         NaN             NaN       NaN             NaN       NaN   \n",
       "21         NaN             NaN       NaN             NaN       NaN   \n",
       "22         NaN             NaN       NaN             NaN       NaN   \n",
       "23         NaN             NaN       NaN             NaN       NaN   \n",
       "24         NaN             NaN       NaN             NaN       NaN   \n",
       "25         NaN             NaN       NaN             NaN       NaN   \n",
       "26         NaN             NaN       NaN             NaN       NaN   \n",
       "27         NaN             NaN       NaN             NaN       NaN   \n",
       "28         NaN             NaN       NaN             NaN       NaN   \n",
       "29         NaN             NaN       NaN             NaN       NaN   \n",
       "30         NaN             NaN       NaN             NaN       NaN   \n",
       "31         NaN             NaN       NaN             NaN       NaN   \n",
       "32         NaN             NaN       NaN             NaN       NaN   \n",
       "33         NaN             NaN       NaN             NaN       NaN   \n",
       "34         NaN             NaN       NaN             NaN       NaN   \n",
       "35         NaN             NaN       NaN             NaN       NaN   \n",
       "36         NaN             NaN       NaN             NaN       NaN   \n",
       "37         NaN             NaN       NaN             NaN       NaN   \n",
       "38         NaN             NaN       NaN             NaN       NaN   \n",
       "39         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "    validation_accuracy    duration           criterion  \\\n",
       "0                 14.26   27.299788  CrossEntropyLoss()   \n",
       "1                 23.43   53.504930  CrossEntropyLoss()   \n",
       "2                 27.19   79.630913  CrossEntropyLoss()   \n",
       "3                 28.54  106.239956  CrossEntropyLoss()   \n",
       "4                 32.90  132.602924  CrossEntropyLoss()   \n",
       "5                 27.04  158.850918  CrossEntropyLoss()   \n",
       "6                 31.58  185.245145  CrossEntropyLoss()   \n",
       "7                 36.99  211.538478  CrossEntropyLoss()   \n",
       "8                 36.43  237.923156  CrossEntropyLoss()   \n",
       "9                 33.95  264.267743  CrossEntropyLoss()   \n",
       "10                39.52  290.581069  CrossEntropyLoss()   \n",
       "11                33.72  316.976808  CrossEntropyLoss()   \n",
       "12                38.46  343.439615  CrossEntropyLoss()   \n",
       "13                38.90  369.819359  CrossEntropyLoss()   \n",
       "14                40.40  396.281337  CrossEntropyLoss()   \n",
       "15                40.51  422.639963  CrossEntropyLoss()   \n",
       "16                40.77  449.043573  CrossEntropyLoss()   \n",
       "17                39.41  475.389783  CrossEntropyLoss()   \n",
       "18                39.49  501.599178  CrossEntropyLoss()   \n",
       "19                42.36  527.837276  CrossEntropyLoss()   \n",
       "20                41.48   26.309072  CrossEntropyLoss()   \n",
       "21                42.71   52.598836  CrossEntropyLoss()   \n",
       "22                44.32   78.917605  CrossEntropyLoss()   \n",
       "23                44.81  105.124337  CrossEntropyLoss()   \n",
       "24                46.65  131.351880  CrossEntropyLoss()   \n",
       "25                47.75  157.587234  CrossEntropyLoss()   \n",
       "26                46.95  183.799975  CrossEntropyLoss()   \n",
       "27                47.03  209.985157  CrossEntropyLoss()   \n",
       "28                47.48  236.249125  CrossEntropyLoss()   \n",
       "29                44.11  262.416254  CrossEntropyLoss()   \n",
       "30                47.58  288.738108  CrossEntropyLoss()   \n",
       "31                45.78  315.155859  CrossEntropyLoss()   \n",
       "32                48.73  341.440965  CrossEntropyLoss()   \n",
       "33                49.58  367.734353  CrossEntropyLoss()   \n",
       "34                48.98  393.845826  CrossEntropyLoss()   \n",
       "35                51.20  420.301055  CrossEntropyLoss()   \n",
       "36                47.15  446.736875  CrossEntropyLoss()   \n",
       "37                47.94  473.046767  CrossEntropyLoss()   \n",
       "38                50.52  499.431938  CrossEntropyLoss()   \n",
       "39                50.65  525.760739  CrossEntropyLoss()   \n",
       "\n",
       "                                            optimizer    method  \\\n",
       "0   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "5   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "6   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "7   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "8   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "9   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "10  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "11  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "12  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "13  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "14  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "15  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "16  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "17  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "18  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "19  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "20  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "21  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "22  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "23  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "24  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "25  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "26  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "27  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "28  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "29  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "30  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "31  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "32  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "33  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "34  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "35  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "36  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "37  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "38  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "39  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "    learning_rate batchsize  \n",
       "0             NaN       256  \n",
       "1             NaN       256  \n",
       "2             NaN       256  \n",
       "3             NaN       256  \n",
       "4             NaN       256  \n",
       "5             NaN       256  \n",
       "6             NaN       256  \n",
       "7             NaN       256  \n",
       "8             NaN       256  \n",
       "9             NaN       256  \n",
       "10            NaN       256  \n",
       "11            NaN       256  \n",
       "12            NaN       256  \n",
       "13            NaN       256  \n",
       "14            NaN       256  \n",
       "15            NaN       256  \n",
       "16            NaN       256  \n",
       "17            NaN       256  \n",
       "18            NaN       256  \n",
       "19            NaN       256  \n",
       "20            NaN       256  \n",
       "21            NaN       256  \n",
       "22            NaN       256  \n",
       "23            NaN       256  \n",
       "24            NaN       256  \n",
       "25            NaN       256  \n",
       "26            NaN       256  \n",
       "27            NaN       256  \n",
       "28            NaN       256  \n",
       "29            NaN       256  \n",
       "30            NaN       256  \n",
       "31            NaN       256  \n",
       "32            NaN       256  \n",
       "33            NaN       256  \n",
       "34            NaN       256  \n",
       "35            NaN       256  \n",
       "36            NaN       256  \n",
       "37            NaN       256  \n",
       "38            NaN       256  \n",
       "39            NaN       256  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67578125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.732421875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 1.68227, adv_train_accuracy: 37.11, clean_train_accuracy : 59.38\n",
      "[1,     6] loss: 1.60897, adv_train_accuracy: 37.50, clean_train_accuracy : 55.86\n",
      "[1,    11] loss: 1.77223, adv_train_accuracy: 35.94, clean_train_accuracy : 50.00\n",
      "[1,    16] loss: 1.68347, adv_train_accuracy: 33.59, clean_train_accuracy : 56.25\n",
      "0.65234375\n",
      "0.712890625\n",
      "duration: 24 s - train loss: 1.72010 - train accuracy: 34.02 - validation loss: 1.41090 - validation accuracy: 48.69 \n",
      "[2,     1] loss: 1.75781, adv_train_accuracy: 33.59, clean_train_accuracy : 50.39\n",
      "[2,     6] loss: 1.75958, adv_train_accuracy: 32.42, clean_train_accuracy : 52.34\n",
      "[2,    11] loss: 1.75052, adv_train_accuracy: 36.72, clean_train_accuracy : 56.25\n",
      "[2,    16] loss: 1.67068, adv_train_accuracy: 37.11, clean_train_accuracy : 55.86\n",
      "0.728515625\n",
      "0.73046875\n",
      "duration: 24 s - train loss: 1.72825 - train accuracy: 35.49 - validation loss: 1.35618 - validation accuracy: 50.99 \n",
      "[3,     1] loss: 1.73792, adv_train_accuracy: 32.42, clean_train_accuracy : 56.25\n",
      "[3,     6] loss: 1.69827, adv_train_accuracy: 37.11, clean_train_accuracy : 60.55\n",
      "[3,    11] loss: 1.67013, adv_train_accuracy: 35.94, clean_train_accuracy : 55.08\n",
      "[3,    16] loss: 1.62698, adv_train_accuracy: 35.94, clean_train_accuracy : 60.94\n",
      "0.671875\n",
      "0.66796875\n",
      "duration: 24 s - train loss: 1.71905 - train accuracy: 34.45 - validation loss: 1.33180 - validation accuracy: 52.38 \n",
      "[4,     1] loss: 1.67837, adv_train_accuracy: 37.50, clean_train_accuracy : 57.81\n",
      "[4,     6] loss: 1.63263, adv_train_accuracy: 38.67, clean_train_accuracy : 61.72\n",
      "[4,    11] loss: 1.85045, adv_train_accuracy: 31.64, clean_train_accuracy : 46.48\n",
      "[4,    16] loss: 1.75120, adv_train_accuracy: 32.81, clean_train_accuracy : 49.22\n",
      "0.72265625\n",
      "0.693359375\n",
      "duration: 24 s - train loss: 1.71364 - train accuracy: 36.05 - validation loss: 1.39006 - validation accuracy: 50.66 \n",
      "[5,     1] loss: 1.72663, adv_train_accuracy: 34.38, clean_train_accuracy : 52.34\n",
      "[5,     6] loss: 1.76047, adv_train_accuracy: 36.33, clean_train_accuracy : 52.73\n",
      "[5,    11] loss: 1.81445, adv_train_accuracy: 27.34, clean_train_accuracy : 53.91\n",
      "[5,    16] loss: 1.75007, adv_train_accuracy: 39.06, clean_train_accuracy : 56.64\n",
      "0.689453125\n",
      "0.685546875\n",
      "duration: 25 s - train loss: 1.71813 - train accuracy: 34.94 - validation loss: 1.34662 - validation accuracy: 53.25 \n",
      "[6,     1] loss: 1.70325, adv_train_accuracy: 35.94, clean_train_accuracy : 59.77\n",
      "[6,     6] loss: 1.69510, adv_train_accuracy: 34.77, clean_train_accuracy : 55.86\n",
      "[6,    11] loss: 1.71401, adv_train_accuracy: 36.72, clean_train_accuracy : 56.25\n",
      "[6,    16] loss: 1.65680, adv_train_accuracy: 33.98, clean_train_accuracy : 57.81\n",
      "0.693359375\n",
      "0.69140625\n",
      "duration: 25 s - train loss: 1.66820 - train accuracy: 36.02 - validation loss: 1.33215 - validation accuracy: 52.24 \n",
      "[7,     1] loss: 1.70784, adv_train_accuracy: 35.16, clean_train_accuracy : 56.25\n",
      "[7,     6] loss: 1.77905, adv_train_accuracy: 33.20, clean_train_accuracy : 54.69\n",
      "[7,    11] loss: 1.70004, adv_train_accuracy: 35.94, clean_train_accuracy : 55.08\n",
      "[7,    16] loss: 1.61912, adv_train_accuracy: 42.58, clean_train_accuracy : 59.77\n",
      "0.65234375\n",
      "0.67578125\n",
      "duration: 25 s - train loss: 1.70589 - train accuracy: 34.96 - validation loss: 1.30993 - validation accuracy: 53.72 \n",
      "[8,     1] loss: 1.66268, adv_train_accuracy: 36.33, clean_train_accuracy : 58.59\n",
      "[8,     6] loss: 1.58213, adv_train_accuracy: 39.45, clean_train_accuracy : 58.20\n",
      "[8,    11] loss: 1.70068, adv_train_accuracy: 36.33, clean_train_accuracy : 57.03\n",
      "[8,    16] loss: 1.66411, adv_train_accuracy: 33.59, clean_train_accuracy : 58.98\n",
      "0.685546875\n",
      "0.71875\n",
      "duration: 25 s - train loss: 1.67059 - train accuracy: 36.62 - validation loss: 1.32104 - validation accuracy: 55.89 \n",
      "[9,     1] loss: 1.58297, adv_train_accuracy: 40.62, clean_train_accuracy : 62.89\n",
      "[9,     6] loss: 1.68765, adv_train_accuracy: 35.16, clean_train_accuracy : 57.81\n",
      "[9,    11] loss: 1.70552, adv_train_accuracy: 37.11, clean_train_accuracy : 56.64\n",
      "[9,    16] loss: 1.66430, adv_train_accuracy: 35.16, clean_train_accuracy : 57.03\n",
      "0.681640625\n",
      "0.689453125\n",
      "duration: 25 s - train loss: 1.67198 - train accuracy: 36.62 - validation loss: 1.30325 - validation accuracy: 54.40 \n",
      "[10,     1] loss: 1.59732, adv_train_accuracy: 42.58, clean_train_accuracy : 63.67\n",
      "[10,     6] loss: 1.61286, adv_train_accuracy: 41.02, clean_train_accuracy : 62.89\n",
      "[10,    11] loss: 1.53690, adv_train_accuracy: 42.19, clean_train_accuracy : 62.11\n",
      "[10,    16] loss: 1.64598, adv_train_accuracy: 35.16, clean_train_accuracy : 58.59\n",
      "0.677734375\n",
      "0.697265625\n",
      "duration: 25 s - train loss: 1.63120 - train accuracy: 37.38 - validation loss: 1.28433 - validation accuracy: 53.23 \n",
      "[11,     1] loss: 1.56650, adv_train_accuracy: 43.36, clean_train_accuracy : 61.33\n",
      "[11,     6] loss: 1.60632, adv_train_accuracy: 38.28, clean_train_accuracy : 58.20\n",
      "[11,    11] loss: 1.69213, adv_train_accuracy: 37.50, clean_train_accuracy : 56.25\n",
      "[11,    16] loss: 1.60919, adv_train_accuracy: 38.28, clean_train_accuracy : 65.62\n",
      "0.73046875\n",
      "0.73828125\n",
      "duration: 25 s - train loss: 1.66930 - train accuracy: 36.33 - validation loss: 1.38551 - validation accuracy: 51.03 \n",
      "[12,     1] loss: 1.65506, adv_train_accuracy: 36.33, clean_train_accuracy : 55.08\n",
      "[12,     6] loss: 1.62354, adv_train_accuracy: 41.02, clean_train_accuracy : 59.38\n",
      "[12,    11] loss: 1.74071, adv_train_accuracy: 31.25, clean_train_accuracy : 51.56\n",
      "[12,    16] loss: 1.63512, adv_train_accuracy: 36.33, clean_train_accuracy : 60.94\n",
      "0.634765625\n",
      "0.66796875\n",
      "duration: 26 s - train loss: 1.65999 - train accuracy: 36.13 - validation loss: 1.28645 - validation accuracy: 56.61 \n",
      "[13,     1] loss: 1.57919, adv_train_accuracy: 40.62, clean_train_accuracy : 59.38\n",
      "[13,     6] loss: 1.49004, adv_train_accuracy: 41.02, clean_train_accuracy : 64.84\n",
      "[13,    11] loss: 1.66827, adv_train_accuracy: 39.45, clean_train_accuracy : 59.77\n",
      "[13,    16] loss: 1.69856, adv_train_accuracy: 38.28, clean_train_accuracy : 55.47\n",
      "0.697265625\n",
      "0.697265625\n",
      "duration: 26 s - train loss: 1.70565 - train accuracy: 36.62 - validation loss: 1.41320 - validation accuracy: 51.28 \n",
      "[14,     1] loss: 1.60549, adv_train_accuracy: 42.97, clean_train_accuracy : 63.28\n",
      "[14,     6] loss: 1.77381, adv_train_accuracy: 35.55, clean_train_accuracy : 54.30\n",
      "[14,    11] loss: 1.70112, adv_train_accuracy: 29.30, clean_train_accuracy : 53.52\n",
      "[14,    16] loss: 1.78352, adv_train_accuracy: 33.20, clean_train_accuracy : 52.73\n",
      "0.6953125\n",
      "0.6953125\n",
      "duration: 26 s - train loss: 1.72046 - train accuracy: 35.59 - validation loss: 1.31837 - validation accuracy: 54.67 \n",
      "[15,     1] loss: 1.80827, adv_train_accuracy: 29.30, clean_train_accuracy : 52.73\n",
      "[15,     6] loss: 1.73495, adv_train_accuracy: 32.81, clean_train_accuracy : 53.91\n",
      "[15,    11] loss: 1.54635, adv_train_accuracy: 43.36, clean_train_accuracy : 63.67\n",
      "[15,    16] loss: 1.72738, adv_train_accuracy: 33.98, clean_train_accuracy : 59.77\n",
      "0.658203125\n",
      "0.703125\n",
      "duration: 26 s - train loss: 1.69157 - train accuracy: 35.92 - validation loss: 1.30444 - validation accuracy: 55.30 \n",
      "[16,     1] loss: 1.62133, adv_train_accuracy: 34.77, clean_train_accuracy : 59.38\n",
      "[16,     6] loss: 1.58687, adv_train_accuracy: 40.62, clean_train_accuracy : 63.28\n",
      "[16,    11] loss: 1.66727, adv_train_accuracy: 39.06, clean_train_accuracy : 60.55\n",
      "[16,    16] loss: 1.69357, adv_train_accuracy: 39.45, clean_train_accuracy : 63.67\n",
      "0.669921875\n",
      "0.6796875\n",
      "duration: 26 s - train loss: 1.65298 - train accuracy: 37.52 - validation loss: 1.23840 - validation accuracy: 57.32 \n",
      "[17,     1] loss: 1.60913, adv_train_accuracy: 37.11, clean_train_accuracy : 55.08\n",
      "[17,     6] loss: 1.57402, adv_train_accuracy: 42.58, clean_train_accuracy : 55.47\n",
      "[17,    11] loss: 1.62560, adv_train_accuracy: 41.02, clean_train_accuracy : 59.77\n",
      "[17,    16] loss: 1.59340, adv_train_accuracy: 35.16, clean_train_accuracy : 65.62\n",
      "0.681640625\n",
      "0.6796875\n",
      "duration: 26 s - train loss: 1.63057 - train accuracy: 37.79 - validation loss: 1.20282 - validation accuracy: 56.40 \n",
      "[18,     1] loss: 1.65743, adv_train_accuracy: 42.97, clean_train_accuracy : 62.50\n",
      "[18,     6] loss: 1.60877, adv_train_accuracy: 35.16, clean_train_accuracy : 57.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 1.64666, adv_train_accuracy: 34.77, clean_train_accuracy : 54.69\n",
      "[18,    16] loss: 1.69380, adv_train_accuracy: 34.38, clean_train_accuracy : 58.59\n",
      "0.62890625\n",
      "0.64453125\n",
      "duration: 26 s - train loss: 1.65569 - train accuracy: 37.13 - validation loss: 1.23416 - validation accuracy: 55.72 \n",
      "[19,     1] loss: 1.63771, adv_train_accuracy: 36.33, clean_train_accuracy : 53.52\n",
      "[19,     6] loss: 1.73930, adv_train_accuracy: 39.06, clean_train_accuracy : 56.64\n",
      "[19,    11] loss: 1.73513, adv_train_accuracy: 38.28, clean_train_accuracy : 57.42\n",
      "[19,    16] loss: 1.53820, adv_train_accuracy: 39.84, clean_train_accuracy : 60.55\n",
      "0.701171875\n",
      "0.708984375\n",
      "duration: 26 s - train loss: 1.62709 - train accuracy: 38.05 - validation loss: 1.26147 - validation accuracy: 54.95 \n",
      "[20,     1] loss: 1.53243, adv_train_accuracy: 41.02, clean_train_accuracy : 59.77\n",
      "[20,     6] loss: 1.53170, adv_train_accuracy: 42.97, clean_train_accuracy : 60.16\n",
      "[20,    11] loss: 1.64540, adv_train_accuracy: 38.67, clean_train_accuracy : 63.28\n",
      "[20,    16] loss: 1.61956, adv_train_accuracy: 34.77, clean_train_accuracy : 61.33\n",
      "0.669921875\n",
      "0.708984375\n",
      "duration: 26 s - train loss: 1.60727 - train accuracy: 38.83 - validation loss: 1.23628 - validation accuracy: 56.87 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2.199005</td>\n",
       "      <td>19.765625</td>\n",
       "      <td>1.971533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.04</td>\n",
       "      <td>158.850918</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2.307448</td>\n",
       "      <td>18.808594</td>\n",
       "      <td>1.949130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.58</td>\n",
       "      <td>185.245145</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2.201714</td>\n",
       "      <td>20.566406</td>\n",
       "      <td>1.791573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.99</td>\n",
       "      <td>211.538478</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2.089135</td>\n",
       "      <td>22.734375</td>\n",
       "      <td>1.791103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.43</td>\n",
       "      <td>237.923156</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2.069923</td>\n",
       "      <td>24.648438</td>\n",
       "      <td>1.794747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.95</td>\n",
       "      <td>264.267743</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2.036039</td>\n",
       "      <td>25.429688</td>\n",
       "      <td>1.739772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.52</td>\n",
       "      <td>290.581069</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2.094370</td>\n",
       "      <td>23.906250</td>\n",
       "      <td>2.008603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.72</td>\n",
       "      <td>316.976808</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2.115578</td>\n",
       "      <td>22.871094</td>\n",
       "      <td>1.705719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.46</td>\n",
       "      <td>343.439615</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2.021146</td>\n",
       "      <td>24.062500</td>\n",
       "      <td>1.686218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.90</td>\n",
       "      <td>369.819359</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.977749</td>\n",
       "      <td>25.410156</td>\n",
       "      <td>1.699897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.40</td>\n",
       "      <td>396.281337</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.952593</td>\n",
       "      <td>28.164062</td>\n",
       "      <td>1.650022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.51</td>\n",
       "      <td>422.639963</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.964369</td>\n",
       "      <td>25.722656</td>\n",
       "      <td>1.630495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.77</td>\n",
       "      <td>449.043573</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.944230</td>\n",
       "      <td>27.128906</td>\n",
       "      <td>1.671066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.41</td>\n",
       "      <td>475.389783</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.972054</td>\n",
       "      <td>26.640625</td>\n",
       "      <td>1.678443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.49</td>\n",
       "      <td>501.599178</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1.921947</td>\n",
       "      <td>27.832031</td>\n",
       "      <td>1.599092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.36</td>\n",
       "      <td>527.837276</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1.904618</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>1.592076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.48</td>\n",
       "      <td>26.309072</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>1.920025</td>\n",
       "      <td>27.597656</td>\n",
       "      <td>1.594776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.71</td>\n",
       "      <td>52.598836</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>1.900772</td>\n",
       "      <td>28.281250</td>\n",
       "      <td>1.565750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.32</td>\n",
       "      <td>78.917605</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>1.876608</td>\n",
       "      <td>29.628906</td>\n",
       "      <td>1.551102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.81</td>\n",
       "      <td>105.124337</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>1.871366</td>\n",
       "      <td>29.472656</td>\n",
       "      <td>1.523409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.65</td>\n",
       "      <td>131.351880</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>1.856000</td>\n",
       "      <td>29.960938</td>\n",
       "      <td>1.502870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.75</td>\n",
       "      <td>157.587234</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>1.844888</td>\n",
       "      <td>31.347656</td>\n",
       "      <td>1.499169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.95</td>\n",
       "      <td>183.799975</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>1.795234</td>\n",
       "      <td>32.070312</td>\n",
       "      <td>1.467305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.03</td>\n",
       "      <td>209.985157</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9</td>\n",
       "      <td>1.856178</td>\n",
       "      <td>30.273438</td>\n",
       "      <td>1.508567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.48</td>\n",
       "      <td>236.249125</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>1.822287</td>\n",
       "      <td>31.582031</td>\n",
       "      <td>1.503579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.11</td>\n",
       "      <td>262.416254</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11</td>\n",
       "      <td>1.815180</td>\n",
       "      <td>31.308594</td>\n",
       "      <td>1.457597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.58</td>\n",
       "      <td>288.738108</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12</td>\n",
       "      <td>1.871191</td>\n",
       "      <td>30.117188</td>\n",
       "      <td>1.465588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.78</td>\n",
       "      <td>315.155859</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13</td>\n",
       "      <td>1.794065</td>\n",
       "      <td>32.304688</td>\n",
       "      <td>1.467957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.73</td>\n",
       "      <td>341.440965</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>14</td>\n",
       "      <td>1.788715</td>\n",
       "      <td>32.734375</td>\n",
       "      <td>1.402320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.58</td>\n",
       "      <td>367.734353</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15</td>\n",
       "      <td>1.767291</td>\n",
       "      <td>32.734375</td>\n",
       "      <td>1.399898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.98</td>\n",
       "      <td>393.845826</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>1.800175</td>\n",
       "      <td>32.656250</td>\n",
       "      <td>1.418447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.20</td>\n",
       "      <td>420.301055</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>17</td>\n",
       "      <td>1.954935</td>\n",
       "      <td>28.808594</td>\n",
       "      <td>1.481668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.15</td>\n",
       "      <td>446.736875</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18</td>\n",
       "      <td>1.834437</td>\n",
       "      <td>32.714844</td>\n",
       "      <td>1.464529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.94</td>\n",
       "      <td>473.046767</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19</td>\n",
       "      <td>1.791221</td>\n",
       "      <td>32.714844</td>\n",
       "      <td>1.396526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.52</td>\n",
       "      <td>499.431938</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20</td>\n",
       "      <td>1.745671</td>\n",
       "      <td>33.847656</td>\n",
       "      <td>1.380673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.65</td>\n",
       "      <td>525.760739</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1.720098</td>\n",
       "      <td>34.023438</td>\n",
       "      <td>1.410903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.69</td>\n",
       "      <td>24.061264</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>1.728251</td>\n",
       "      <td>35.488281</td>\n",
       "      <td>1.356180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.99</td>\n",
       "      <td>48.435961</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>1.719052</td>\n",
       "      <td>34.453125</td>\n",
       "      <td>1.331796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.38</td>\n",
       "      <td>72.968159</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>1.713636</td>\n",
       "      <td>36.054688</td>\n",
       "      <td>1.390061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.66</td>\n",
       "      <td>97.691658</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>1.718127</td>\n",
       "      <td>34.941406</td>\n",
       "      <td>1.346621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.25</td>\n",
       "      <td>122.697526</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6</td>\n",
       "      <td>1.668203</td>\n",
       "      <td>36.015625</td>\n",
       "      <td>1.332145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.24</td>\n",
       "      <td>147.984321</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7</td>\n",
       "      <td>1.705887</td>\n",
       "      <td>34.960938</td>\n",
       "      <td>1.309925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.72</td>\n",
       "      <td>173.414626</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>8</td>\n",
       "      <td>1.670592</td>\n",
       "      <td>36.621094</td>\n",
       "      <td>1.321043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.89</td>\n",
       "      <td>199.034546</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>9</td>\n",
       "      <td>1.671981</td>\n",
       "      <td>36.621094</td>\n",
       "      <td>1.303252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.40</td>\n",
       "      <td>224.728803</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10</td>\n",
       "      <td>1.631198</td>\n",
       "      <td>37.382812</td>\n",
       "      <td>1.284334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.23</td>\n",
       "      <td>250.299896</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>11</td>\n",
       "      <td>1.669304</td>\n",
       "      <td>36.328125</td>\n",
       "      <td>1.385515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.03</td>\n",
       "      <td>276.091615</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>12</td>\n",
       "      <td>1.659991</td>\n",
       "      <td>36.132812</td>\n",
       "      <td>1.286450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.61</td>\n",
       "      <td>302.143614</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>13</td>\n",
       "      <td>1.705648</td>\n",
       "      <td>36.621094</td>\n",
       "      <td>1.413204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.28</td>\n",
       "      <td>328.832347</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>14</td>\n",
       "      <td>1.720458</td>\n",
       "      <td>35.585938</td>\n",
       "      <td>1.318369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.67</td>\n",
       "      <td>355.217649</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>15</td>\n",
       "      <td>1.691575</td>\n",
       "      <td>35.917969</td>\n",
       "      <td>1.304443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.30</td>\n",
       "      <td>381.546299</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>16</td>\n",
       "      <td>1.652977</td>\n",
       "      <td>37.519531</td>\n",
       "      <td>1.238401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.32</td>\n",
       "      <td>407.989274</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>17</td>\n",
       "      <td>1.630573</td>\n",
       "      <td>37.792969</td>\n",
       "      <td>1.202822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.40</td>\n",
       "      <td>434.300141</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>18</td>\n",
       "      <td>1.655692</td>\n",
       "      <td>37.128906</td>\n",
       "      <td>1.234162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.72</td>\n",
       "      <td>460.731395</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>19</td>\n",
       "      <td>1.627087</td>\n",
       "      <td>38.046875</td>\n",
       "      <td>1.261473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.95</td>\n",
       "      <td>487.109388</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>20</td>\n",
       "      <td>1.607269</td>\n",
       "      <td>38.828125</td>\n",
       "      <td>1.236279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.87</td>\n",
       "      <td>513.387483</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0      1   10.069616       10.019531         3.418694               NaN   \n",
       "1      2    3.292510        8.789062         2.192064               NaN   \n",
       "2      3    2.474881       13.281250         2.233554               NaN   \n",
       "3      4    2.347974       16.093750         2.084406               NaN   \n",
       "4      5    2.225618       17.734375         1.975296               NaN   \n",
       "5      6    2.199005       19.765625         1.971533               NaN   \n",
       "6      7    2.307448       18.808594         1.949130               NaN   \n",
       "7      8    2.201714       20.566406         1.791573               NaN   \n",
       "8      9    2.089135       22.734375         1.791103               NaN   \n",
       "9     10    2.069923       24.648438         1.794747               NaN   \n",
       "10    11    2.036039       25.429688         1.739772               NaN   \n",
       "11    12    2.094370       23.906250         2.008603               NaN   \n",
       "12    13    2.115578       22.871094         1.705719               NaN   \n",
       "13    14    2.021146       24.062500         1.686218               NaN   \n",
       "14    15    1.977749       25.410156         1.699897               NaN   \n",
       "15    16    1.952593       28.164062         1.650022               NaN   \n",
       "16    17    1.964369       25.722656         1.630495               NaN   \n",
       "17    18    1.944230       27.128906         1.671066               NaN   \n",
       "18    19    1.972054       26.640625         1.678443               NaN   \n",
       "19    20    1.921947       27.832031         1.599092               NaN   \n",
       "20     1    1.904618       28.750000         1.592076               NaN   \n",
       "21     2    1.920025       27.597656         1.594776               NaN   \n",
       "22     3    1.900772       28.281250         1.565750               NaN   \n",
       "23     4    1.876608       29.628906         1.551102               NaN   \n",
       "24     5    1.871366       29.472656         1.523409               NaN   \n",
       "25     6    1.856000       29.960938         1.502870               NaN   \n",
       "26     7    1.844888       31.347656         1.499169               NaN   \n",
       "27     8    1.795234       32.070312         1.467305               NaN   \n",
       "28     9    1.856178       30.273438         1.508567               NaN   \n",
       "29    10    1.822287       31.582031         1.503579               NaN   \n",
       "30    11    1.815180       31.308594         1.457597               NaN   \n",
       "31    12    1.871191       30.117188         1.465588               NaN   \n",
       "32    13    1.794065       32.304688         1.467957               NaN   \n",
       "33    14    1.788715       32.734375         1.402320               NaN   \n",
       "34    15    1.767291       32.734375         1.399898               NaN   \n",
       "35    16    1.800175       32.656250         1.418447               NaN   \n",
       "36    17    1.954935       28.808594         1.481668               NaN   \n",
       "37    18    1.834437       32.714844         1.464529               NaN   \n",
       "38    19    1.791221       32.714844         1.396526               NaN   \n",
       "39    20    1.745671       33.847656         1.380673               NaN   \n",
       "40     1    1.720098       34.023438         1.410903               NaN   \n",
       "41     2    1.728251       35.488281         1.356180               NaN   \n",
       "42     3    1.719052       34.453125         1.331796               NaN   \n",
       "43     4    1.713636       36.054688         1.390061               NaN   \n",
       "44     5    1.718127       34.941406         1.346621               NaN   \n",
       "45     6    1.668203       36.015625         1.332145               NaN   \n",
       "46     7    1.705887       34.960938         1.309925               NaN   \n",
       "47     8    1.670592       36.621094         1.321043               NaN   \n",
       "48     9    1.671981       36.621094         1.303252               NaN   \n",
       "49    10    1.631198       37.382812         1.284334               NaN   \n",
       "50    11    1.669304       36.328125         1.385515               NaN   \n",
       "51    12    1.659991       36.132812         1.286450               NaN   \n",
       "52    13    1.705648       36.621094         1.413204               NaN   \n",
       "53    14    1.720458       35.585938         1.318369               NaN   \n",
       "54    15    1.691575       35.917969         1.304443               NaN   \n",
       "55    16    1.652977       37.519531         1.238401               NaN   \n",
       "56    17    1.630573       37.792969         1.202822               NaN   \n",
       "57    18    1.655692       37.128906         1.234162               NaN   \n",
       "58    19    1.627087       38.046875         1.261473               NaN   \n",
       "59    20    1.607269       38.828125         1.236279               NaN   \n",
       "\n",
       "    l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0          NaN             NaN       NaN             NaN       NaN   \n",
       "1          NaN             NaN       NaN             NaN       NaN   \n",
       "2          NaN             NaN       NaN             NaN       NaN   \n",
       "3          NaN             NaN       NaN             NaN       NaN   \n",
       "4          NaN             NaN       NaN             NaN       NaN   \n",
       "5          NaN             NaN       NaN             NaN       NaN   \n",
       "6          NaN             NaN       NaN             NaN       NaN   \n",
       "7          NaN             NaN       NaN             NaN       NaN   \n",
       "8          NaN             NaN       NaN             NaN       NaN   \n",
       "9          NaN             NaN       NaN             NaN       NaN   \n",
       "10         NaN             NaN       NaN             NaN       NaN   \n",
       "11         NaN             NaN       NaN             NaN       NaN   \n",
       "12         NaN             NaN       NaN             NaN       NaN   \n",
       "13         NaN             NaN       NaN             NaN       NaN   \n",
       "14         NaN             NaN       NaN             NaN       NaN   \n",
       "15         NaN             NaN       NaN             NaN       NaN   \n",
       "16         NaN             NaN       NaN             NaN       NaN   \n",
       "17         NaN             NaN       NaN             NaN       NaN   \n",
       "18         NaN             NaN       NaN             NaN       NaN   \n",
       "19         NaN             NaN       NaN             NaN       NaN   \n",
       "20         NaN             NaN       NaN             NaN       NaN   \n",
       "21         NaN             NaN       NaN             NaN       NaN   \n",
       "22         NaN             NaN       NaN             NaN       NaN   \n",
       "23         NaN             NaN       NaN             NaN       NaN   \n",
       "24         NaN             NaN       NaN             NaN       NaN   \n",
       "25         NaN             NaN       NaN             NaN       NaN   \n",
       "26         NaN             NaN       NaN             NaN       NaN   \n",
       "27         NaN             NaN       NaN             NaN       NaN   \n",
       "28         NaN             NaN       NaN             NaN       NaN   \n",
       "29         NaN             NaN       NaN             NaN       NaN   \n",
       "30         NaN             NaN       NaN             NaN       NaN   \n",
       "31         NaN             NaN       NaN             NaN       NaN   \n",
       "32         NaN             NaN       NaN             NaN       NaN   \n",
       "33         NaN             NaN       NaN             NaN       NaN   \n",
       "34         NaN             NaN       NaN             NaN       NaN   \n",
       "35         NaN             NaN       NaN             NaN       NaN   \n",
       "36         NaN             NaN       NaN             NaN       NaN   \n",
       "37         NaN             NaN       NaN             NaN       NaN   \n",
       "38         NaN             NaN       NaN             NaN       NaN   \n",
       "39         NaN             NaN       NaN             NaN       NaN   \n",
       "40         NaN             NaN       NaN             NaN       NaN   \n",
       "41         NaN             NaN       NaN             NaN       NaN   \n",
       "42         NaN             NaN       NaN             NaN       NaN   \n",
       "43         NaN             NaN       NaN             NaN       NaN   \n",
       "44         NaN             NaN       NaN             NaN       NaN   \n",
       "45         NaN             NaN       NaN             NaN       NaN   \n",
       "46         NaN             NaN       NaN             NaN       NaN   \n",
       "47         NaN             NaN       NaN             NaN       NaN   \n",
       "48         NaN             NaN       NaN             NaN       NaN   \n",
       "49         NaN             NaN       NaN             NaN       NaN   \n",
       "50         NaN             NaN       NaN             NaN       NaN   \n",
       "51         NaN             NaN       NaN             NaN       NaN   \n",
       "52         NaN             NaN       NaN             NaN       NaN   \n",
       "53         NaN             NaN       NaN             NaN       NaN   \n",
       "54         NaN             NaN       NaN             NaN       NaN   \n",
       "55         NaN             NaN       NaN             NaN       NaN   \n",
       "56         NaN             NaN       NaN             NaN       NaN   \n",
       "57         NaN             NaN       NaN             NaN       NaN   \n",
       "58         NaN             NaN       NaN             NaN       NaN   \n",
       "59         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "    validation_accuracy    duration           criterion  \\\n",
       "0                 14.26   27.299788  CrossEntropyLoss()   \n",
       "1                 23.43   53.504930  CrossEntropyLoss()   \n",
       "2                 27.19   79.630913  CrossEntropyLoss()   \n",
       "3                 28.54  106.239956  CrossEntropyLoss()   \n",
       "4                 32.90  132.602924  CrossEntropyLoss()   \n",
       "5                 27.04  158.850918  CrossEntropyLoss()   \n",
       "6                 31.58  185.245145  CrossEntropyLoss()   \n",
       "7                 36.99  211.538478  CrossEntropyLoss()   \n",
       "8                 36.43  237.923156  CrossEntropyLoss()   \n",
       "9                 33.95  264.267743  CrossEntropyLoss()   \n",
       "10                39.52  290.581069  CrossEntropyLoss()   \n",
       "11                33.72  316.976808  CrossEntropyLoss()   \n",
       "12                38.46  343.439615  CrossEntropyLoss()   \n",
       "13                38.90  369.819359  CrossEntropyLoss()   \n",
       "14                40.40  396.281337  CrossEntropyLoss()   \n",
       "15                40.51  422.639963  CrossEntropyLoss()   \n",
       "16                40.77  449.043573  CrossEntropyLoss()   \n",
       "17                39.41  475.389783  CrossEntropyLoss()   \n",
       "18                39.49  501.599178  CrossEntropyLoss()   \n",
       "19                42.36  527.837276  CrossEntropyLoss()   \n",
       "20                41.48   26.309072  CrossEntropyLoss()   \n",
       "21                42.71   52.598836  CrossEntropyLoss()   \n",
       "22                44.32   78.917605  CrossEntropyLoss()   \n",
       "23                44.81  105.124337  CrossEntropyLoss()   \n",
       "24                46.65  131.351880  CrossEntropyLoss()   \n",
       "25                47.75  157.587234  CrossEntropyLoss()   \n",
       "26                46.95  183.799975  CrossEntropyLoss()   \n",
       "27                47.03  209.985157  CrossEntropyLoss()   \n",
       "28                47.48  236.249125  CrossEntropyLoss()   \n",
       "29                44.11  262.416254  CrossEntropyLoss()   \n",
       "30                47.58  288.738108  CrossEntropyLoss()   \n",
       "31                45.78  315.155859  CrossEntropyLoss()   \n",
       "32                48.73  341.440965  CrossEntropyLoss()   \n",
       "33                49.58  367.734353  CrossEntropyLoss()   \n",
       "34                48.98  393.845826  CrossEntropyLoss()   \n",
       "35                51.20  420.301055  CrossEntropyLoss()   \n",
       "36                47.15  446.736875  CrossEntropyLoss()   \n",
       "37                47.94  473.046767  CrossEntropyLoss()   \n",
       "38                50.52  499.431938  CrossEntropyLoss()   \n",
       "39                50.65  525.760739  CrossEntropyLoss()   \n",
       "40                48.69   24.061264  CrossEntropyLoss()   \n",
       "41                50.99   48.435961  CrossEntropyLoss()   \n",
       "42                52.38   72.968159  CrossEntropyLoss()   \n",
       "43                50.66   97.691658  CrossEntropyLoss()   \n",
       "44                53.25  122.697526  CrossEntropyLoss()   \n",
       "45                52.24  147.984321  CrossEntropyLoss()   \n",
       "46                53.72  173.414626  CrossEntropyLoss()   \n",
       "47                55.89  199.034546  CrossEntropyLoss()   \n",
       "48                54.40  224.728803  CrossEntropyLoss()   \n",
       "49                53.23  250.299896  CrossEntropyLoss()   \n",
       "50                51.03  276.091615  CrossEntropyLoss()   \n",
       "51                56.61  302.143614  CrossEntropyLoss()   \n",
       "52                51.28  328.832347  CrossEntropyLoss()   \n",
       "53                54.67  355.217649  CrossEntropyLoss()   \n",
       "54                55.30  381.546299  CrossEntropyLoss()   \n",
       "55                57.32  407.989274  CrossEntropyLoss()   \n",
       "56                56.40  434.300141  CrossEntropyLoss()   \n",
       "57                55.72  460.731395  CrossEntropyLoss()   \n",
       "58                54.95  487.109388  CrossEntropyLoss()   \n",
       "59                56.87  513.387483  CrossEntropyLoss()   \n",
       "\n",
       "                                            optimizer    method  \\\n",
       "0   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "5   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "6   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "7   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "8   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "9   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "10  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "11  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "12  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "13  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "14  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "15  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "16  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "17  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "18  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "19  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "20  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "21  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "22  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "23  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "24  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "25  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "26  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "27  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "28  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "29  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "30  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "31  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "32  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "33  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "34  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "35  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "36  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "37  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "38  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "39  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "40  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "41  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "42  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "43  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "44  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "45  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "46  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "47  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "48  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "49  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "50  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "51  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "52  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "53  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "54  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "55  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "56  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "57  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "58  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "59  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "    learning_rate batchsize  \n",
       "0             NaN       256  \n",
       "1             NaN       256  \n",
       "2             NaN       256  \n",
       "3             NaN       256  \n",
       "4             NaN       256  \n",
       "5             NaN       256  \n",
       "6             NaN       256  \n",
       "7             NaN       256  \n",
       "8             NaN       256  \n",
       "9             NaN       256  \n",
       "10            NaN       256  \n",
       "11            NaN       256  \n",
       "12            NaN       256  \n",
       "13            NaN       256  \n",
       "14            NaN       256  \n",
       "15            NaN       256  \n",
       "16            NaN       256  \n",
       "17            NaN       256  \n",
       "18            NaN       256  \n",
       "19            NaN       256  \n",
       "20            NaN       256  \n",
       "21            NaN       256  \n",
       "22            NaN       256  \n",
       "23            NaN       256  \n",
       "24            NaN       256  \n",
       "25            NaN       256  \n",
       "26            NaN       256  \n",
       "27            NaN       256  \n",
       "28            NaN       256  \n",
       "29            NaN       256  \n",
       "30            NaN       256  \n",
       "31            NaN       256  \n",
       "32            NaN       256  \n",
       "33            NaN       256  \n",
       "34            NaN       256  \n",
       "35            NaN       256  \n",
       "36            NaN       256  \n",
       "37            NaN       256  \n",
       "38            NaN       256  \n",
       "39            NaN       256  \n",
       "40            NaN       256  \n",
       "41            NaN       256  \n",
       "42            NaN       256  \n",
       "43            NaN       256  \n",
       "44            NaN       256  \n",
       "45            NaN       256  \n",
       "46            NaN       256  \n",
       "47            NaN       256  \n",
       "48            NaN       256  \n",
       "49            NaN       256  \n",
       "50            NaN       256  \n",
       "51            NaN       256  \n",
       "52            NaN       256  \n",
       "53            NaN       256  \n",
       "54            NaN       256  \n",
       "55            NaN       256  \n",
       "56            NaN       256  \n",
       "57            NaN       256  \n",
       "58            NaN       256  \n",
       "59            NaN       256  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.689453125"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.673828125"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 1.52565, adv_train_accuracy: 41.02, clean_train_accuracy : 66.80\n",
      "[1,     6] loss: 1.58863, adv_train_accuracy: 37.11, clean_train_accuracy : 64.84\n",
      "[1,    11] loss: 1.55582, adv_train_accuracy: 40.23, clean_train_accuracy : 64.45\n",
      "[1,    16] loss: 1.59265, adv_train_accuracy: 41.02, clean_train_accuracy : 59.77\n",
      "0.640625\n",
      "0.693359375\n",
      "duration: 26 s - train loss: 1.59359 - train accuracy: 39.77 - validation loss: 1.21048 - validation accuracy: 57.81 \n",
      "[2,     1] loss: 1.65444, adv_train_accuracy: 39.45, clean_train_accuracy : 61.72\n",
      "[2,     6] loss: 1.72484, adv_train_accuracy: 34.77, clean_train_accuracy : 59.77\n",
      "[2,    11] loss: 1.58743, adv_train_accuracy: 35.94, clean_train_accuracy : 57.81\n",
      "[2,    16] loss: 1.59266, adv_train_accuracy: 39.06, clean_train_accuracy : 62.11\n",
      "0.6796875\n",
      "0.705078125\n",
      "duration: 26 s - train loss: 1.58398 - train accuracy: 39.73 - validation loss: 1.18526 - validation accuracy: 59.23 \n",
      "[3,     1] loss: 1.57432, adv_train_accuracy: 41.41, clean_train_accuracy : 63.67\n",
      "[3,     6] loss: 1.63140, adv_train_accuracy: 38.67, clean_train_accuracy : 61.33\n",
      "[3,    11] loss: 1.46922, adv_train_accuracy: 43.36, clean_train_accuracy : 65.62\n",
      "[3,    16] loss: 1.57242, adv_train_accuracy: 39.45, clean_train_accuracy : 58.20\n",
      "0.669921875\n",
      "0.712890625\n",
      "duration: 26 s - train loss: 1.56700 - train accuracy: 40.06 - validation loss: 1.21864 - validation accuracy: 55.48 \n",
      "[4,     1] loss: 1.61637, adv_train_accuracy: 39.06, clean_train_accuracy : 55.86\n",
      "[4,     6] loss: 1.59955, adv_train_accuracy: 41.41, clean_train_accuracy : 62.11\n",
      "[4,    11] loss: 1.56163, adv_train_accuracy: 42.58, clean_train_accuracy : 67.58\n",
      "[4,    16] loss: 1.46182, adv_train_accuracy: 40.23, clean_train_accuracy : 67.97\n",
      "0.66796875\n",
      "0.66015625\n",
      "duration: 26 s - train loss: 1.58114 - train accuracy: 40.23 - validation loss: 1.23861 - validation accuracy: 57.42 \n",
      "[5,     1] loss: 1.53004, adv_train_accuracy: 40.23, clean_train_accuracy : 64.84\n",
      "[5,     6] loss: 1.52207, adv_train_accuracy: 37.50, clean_train_accuracy : 60.16\n",
      "[5,    11] loss: 1.60821, adv_train_accuracy: 42.19, clean_train_accuracy : 61.33\n",
      "[5,    16] loss: 1.58335, adv_train_accuracy: 41.41, clean_train_accuracy : 62.89\n",
      "0.666015625\n",
      "0.671875\n",
      "duration: 26 s - train loss: 1.58191 - train accuracy: 39.63 - validation loss: 1.18707 - validation accuracy: 58.21 \n",
      "[6,     1] loss: 1.54237, adv_train_accuracy: 41.02, clean_train_accuracy : 62.11\n",
      "[6,     6] loss: 1.63669, adv_train_accuracy: 34.38, clean_train_accuracy : 66.02\n",
      "[6,    11] loss: 1.66276, adv_train_accuracy: 39.45, clean_train_accuracy : 61.72\n",
      "[6,    16] loss: 1.61511, adv_train_accuracy: 38.28, clean_train_accuracy : 58.59\n",
      "0.65625\n",
      "0.693359375\n",
      "duration: 26 s - train loss: 1.56604 - train accuracy: 39.98 - validation loss: 1.23535 - validation accuracy: 56.47 \n",
      "[7,     1] loss: 1.68528, adv_train_accuracy: 38.28, clean_train_accuracy : 62.89\n",
      "[7,     6] loss: 1.48703, adv_train_accuracy: 44.53, clean_train_accuracy : 70.31\n",
      "[7,    11] loss: 1.62897, adv_train_accuracy: 38.67, clean_train_accuracy : 59.38\n",
      "[7,    16] loss: 1.60934, adv_train_accuracy: 39.45, clean_train_accuracy : 69.92\n",
      "0.6640625\n",
      "0.65234375\n",
      "duration: 26 s - train loss: 1.56439 - train accuracy: 41.25 - validation loss: 1.23307 - validation accuracy: 57.46 \n",
      "[8,     1] loss: 1.56962, adv_train_accuracy: 40.23, clean_train_accuracy : 58.59\n",
      "[8,     6] loss: 1.42704, adv_train_accuracy: 46.88, clean_train_accuracy : 71.48\n",
      "[8,    11] loss: 1.57872, adv_train_accuracy: 37.50, clean_train_accuracy : 61.72\n",
      "[8,    16] loss: 1.54139, adv_train_accuracy: 40.62, clean_train_accuracy : 65.62\n",
      "0.67578125\n",
      "0.71484375\n",
      "duration: 26 s - train loss: 1.55347 - train accuracy: 40.64 - validation loss: 1.17952 - validation accuracy: 59.29 \n",
      "[9,     1] loss: 1.47184, adv_train_accuracy: 45.70, clean_train_accuracy : 69.53\n",
      "[9,     6] loss: 1.57578, adv_train_accuracy: 37.89, clean_train_accuracy : 64.45\n",
      "[9,    11] loss: 1.52313, adv_train_accuracy: 41.41, clean_train_accuracy : 62.89\n",
      "[9,    16] loss: 1.53116, adv_train_accuracy: 40.23, clean_train_accuracy : 68.75\n",
      "0.666015625\n",
      "0.671875\n",
      "duration: 26 s - train loss: 1.53506 - train accuracy: 40.90 - validation loss: 1.12878 - validation accuracy: 60.26 \n",
      "[10,     1] loss: 1.55691, adv_train_accuracy: 39.84, clean_train_accuracy : 67.97\n",
      "[10,     6] loss: 1.53225, adv_train_accuracy: 43.75, clean_train_accuracy : 66.80\n",
      "[10,    11] loss: 1.55379, adv_train_accuracy: 39.84, clean_train_accuracy : 65.62\n",
      "[10,    16] loss: 1.54055, adv_train_accuracy: 40.23, clean_train_accuracy : 67.19\n",
      "0.66796875\n",
      "0.681640625\n",
      "duration: 26 s - train loss: 1.52425 - train accuracy: 41.17 - validation loss: 1.17794 - validation accuracy: 57.52 \n",
      "[11,     1] loss: 1.48985, adv_train_accuracy: 43.36, clean_train_accuracy : 70.31\n",
      "[11,     6] loss: 1.59717, adv_train_accuracy: 38.28, clean_train_accuracy : 67.58\n",
      "[11,    11] loss: 1.50584, adv_train_accuracy: 40.62, clean_train_accuracy : 71.48\n",
      "[11,    16] loss: 1.64292, adv_train_accuracy: 39.45, clean_train_accuracy : 58.20\n",
      "0.65625\n",
      "0.66796875\n",
      "duration: 26 s - train loss: 1.54326 - train accuracy: 41.04 - validation loss: 1.14563 - validation accuracy: 60.69 \n",
      "[12,     1] loss: 1.51758, adv_train_accuracy: 43.36, clean_train_accuracy : 66.80\n",
      "[12,     6] loss: 1.46469, adv_train_accuracy: 44.53, clean_train_accuracy : 64.84\n",
      "[12,    11] loss: 1.54794, adv_train_accuracy: 45.31, clean_train_accuracy : 67.58\n",
      "[12,    16] loss: 1.41516, adv_train_accuracy: 42.97, clean_train_accuracy : 72.27\n",
      "0.6328125\n",
      "0.646484375\n",
      "duration: 26 s - train loss: 1.49739 - train accuracy: 42.38 - validation loss: 1.10965 - validation accuracy: 60.87 \n",
      "[13,     1] loss: 1.54246, adv_train_accuracy: 37.50, clean_train_accuracy : 66.41\n",
      "[13,     6] loss: 1.46159, adv_train_accuracy: 47.27, clean_train_accuracy : 72.27\n",
      "[13,    11] loss: 1.52732, adv_train_accuracy: 37.50, clean_train_accuracy : 64.84\n",
      "[13,    16] loss: 1.51466, adv_train_accuracy: 41.41, clean_train_accuracy : 70.31\n",
      "0.66015625\n",
      "0.625\n",
      "duration: 26 s - train loss: 1.52508 - train accuracy: 41.58 - validation loss: 1.13673 - validation accuracy: 61.39 \n",
      "[14,     1] loss: 1.51182, adv_train_accuracy: 39.06, clean_train_accuracy : 63.67\n",
      "[14,     6] loss: 1.52363, adv_train_accuracy: 43.36, clean_train_accuracy : 66.41\n",
      "[14,    11] loss: 1.48139, adv_train_accuracy: 42.58, clean_train_accuracy : 71.88\n",
      "[14,    16] loss: 1.57689, adv_train_accuracy: 41.41, clean_train_accuracy : 63.67\n",
      "0.658203125\n",
      "0.65234375\n",
      "duration: 26 s - train loss: 1.50699 - train accuracy: 42.19 - validation loss: 1.10901 - validation accuracy: 61.88 \n",
      "[15,     1] loss: 1.46653, adv_train_accuracy: 45.70, clean_train_accuracy : 68.36\n",
      "[15,     6] loss: 1.36499, adv_train_accuracy: 46.88, clean_train_accuracy : 71.88\n",
      "[15,    11] loss: 1.46860, adv_train_accuracy: 43.36, clean_train_accuracy : 67.97\n",
      "[15,    16] loss: 1.52110, adv_train_accuracy: 41.41, clean_train_accuracy : 67.97\n",
      "0.6328125\n",
      "0.666015625\n",
      "duration: 26 s - train loss: 1.49721 - train accuracy: 42.93 - validation loss: 1.14720 - validation accuracy: 60.95 \n",
      "[16,     1] loss: 1.44355, adv_train_accuracy: 42.97, clean_train_accuracy : 73.05\n",
      "[16,     6] loss: 1.36659, adv_train_accuracy: 44.53, clean_train_accuracy : 75.39\n",
      "[16,    11] loss: 1.54280, adv_train_accuracy: 43.75, clean_train_accuracy : 69.92\n",
      "[16,    16] loss: 1.49424, adv_train_accuracy: 41.02, clean_train_accuracy : 67.19\n",
      "0.65234375\n",
      "0.671875\n",
      "duration: 26 s - train loss: 1.49802 - train accuracy: 41.93 - validation loss: 1.14875 - validation accuracy: 60.31 \n",
      "[17,     1] loss: 1.38120, adv_train_accuracy: 44.53, clean_train_accuracy : 73.44\n",
      "[17,     6] loss: 1.46657, adv_train_accuracy: 43.36, clean_train_accuracy : 70.31\n",
      "[17,    11] loss: 1.43065, adv_train_accuracy: 41.02, clean_train_accuracy : 67.97\n",
      "[17,    16] loss: 1.41421, adv_train_accuracy: 48.44, clean_train_accuracy : 73.83\n",
      "0.6328125\n",
      "0.6953125\n",
      "duration: 26 s - train loss: 1.48244 - train accuracy: 43.22 - validation loss: 1.09119 - validation accuracy: 63.22 \n",
      "[18,     1] loss: 1.57727, adv_train_accuracy: 42.58, clean_train_accuracy : 70.70\n",
      "[18,     6] loss: 1.41714, adv_train_accuracy: 44.92, clean_train_accuracy : 67.19\n",
      "[18,    11] loss: 1.45356, adv_train_accuracy: 43.75, clean_train_accuracy : 74.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    16] loss: 1.47374, adv_train_accuracy: 42.97, clean_train_accuracy : 69.92\n",
      "0.669921875\n",
      "0.681640625\n",
      "duration: 26 s - train loss: 1.49279 - train accuracy: 42.17 - validation loss: 1.13008 - validation accuracy: 61.01 \n",
      "[19,     1] loss: 1.51225, adv_train_accuracy: 37.89, clean_train_accuracy : 66.02\n",
      "[19,     6] loss: 1.50439, adv_train_accuracy: 40.62, clean_train_accuracy : 66.80\n",
      "[19,    11] loss: 1.45104, adv_train_accuracy: 42.58, clean_train_accuracy : 68.75\n",
      "[19,    16] loss: 1.49299, adv_train_accuracy: 39.06, clean_train_accuracy : 70.70\n",
      "0.638671875\n",
      "0.671875\n",
      "duration: 26 s - train loss: 1.48920 - train accuracy: 43.59 - validation loss: 1.10397 - validation accuracy: 62.82 \n",
      "[20,     1] loss: 1.43671, adv_train_accuracy: 44.14, clean_train_accuracy : 70.70\n",
      "[20,     6] loss: 1.45057, adv_train_accuracy: 44.92, clean_train_accuracy : 66.80\n",
      "[20,    11] loss: 1.42359, adv_train_accuracy: 46.09, clean_train_accuracy : 69.14\n",
      "[20,    16] loss: 1.43523, adv_train_accuracy: 42.19, clean_train_accuracy : 73.05\n",
      "0.671875\n",
      "0.681640625\n",
      "duration: 26 s - train loss: 1.45504 - train accuracy: 43.75 - validation loss: 1.04272 - validation accuracy: 62.69 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>16</td>\n",
       "      <td>1.498022</td>\n",
       "      <td>41.933594</td>\n",
       "      <td>1.148745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.31</td>\n",
       "      <td>421.287490</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>17</td>\n",
       "      <td>1.482442</td>\n",
       "      <td>43.222656</td>\n",
       "      <td>1.091187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.22</td>\n",
       "      <td>447.576633</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>18</td>\n",
       "      <td>1.492787</td>\n",
       "      <td>42.167969</td>\n",
       "      <td>1.130076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.01</td>\n",
       "      <td>473.902789</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>19</td>\n",
       "      <td>1.489198</td>\n",
       "      <td>43.593750</td>\n",
       "      <td>1.103975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.82</td>\n",
       "      <td>500.281428</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>20</td>\n",
       "      <td>1.455041</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.69</td>\n",
       "      <td>526.602255</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0      1   10.069616       10.019531         3.418694               NaN   \n",
       "1      2    3.292510        8.789062         2.192064               NaN   \n",
       "2      3    2.474881       13.281250         2.233554               NaN   \n",
       "3      4    2.347974       16.093750         2.084406               NaN   \n",
       "4      5    2.225618       17.734375         1.975296               NaN   \n",
       "..   ...         ...             ...              ...               ...   \n",
       "75    16    1.498022       41.933594         1.148745               NaN   \n",
       "76    17    1.482442       43.222656         1.091187               NaN   \n",
       "77    18    1.492787       42.167969         1.130076               NaN   \n",
       "78    19    1.489198       43.593750         1.103975               NaN   \n",
       "79    20    1.455041       43.750000         1.042716               NaN   \n",
       "\n",
       "    l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0          NaN             NaN       NaN             NaN       NaN   \n",
       "1          NaN             NaN       NaN             NaN       NaN   \n",
       "2          NaN             NaN       NaN             NaN       NaN   \n",
       "3          NaN             NaN       NaN             NaN       NaN   \n",
       "4          NaN             NaN       NaN             NaN       NaN   \n",
       "..         ...             ...       ...             ...       ...   \n",
       "75         NaN             NaN       NaN             NaN       NaN   \n",
       "76         NaN             NaN       NaN             NaN       NaN   \n",
       "77         NaN             NaN       NaN             NaN       NaN   \n",
       "78         NaN             NaN       NaN             NaN       NaN   \n",
       "79         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "    validation_accuracy    duration           criterion  \\\n",
       "0                 14.26   27.299788  CrossEntropyLoss()   \n",
       "1                 23.43   53.504930  CrossEntropyLoss()   \n",
       "2                 27.19   79.630913  CrossEntropyLoss()   \n",
       "3                 28.54  106.239956  CrossEntropyLoss()   \n",
       "4                 32.90  132.602924  CrossEntropyLoss()   \n",
       "..                  ...         ...                 ...   \n",
       "75                60.31  421.287490  CrossEntropyLoss()   \n",
       "76                63.22  447.576633  CrossEntropyLoss()   \n",
       "77                61.01  473.902789  CrossEntropyLoss()   \n",
       "78                62.82  500.281428  CrossEntropyLoss()   \n",
       "79                62.69  526.602255  CrossEntropyLoss()   \n",
       "\n",
       "                                            optimizer    method  \\\n",
       "0   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                ...       ...   \n",
       "75  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "76  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "77  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "78  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "79  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "    learning_rate batchsize  \n",
       "0             NaN       256  \n",
       "1             NaN       256  \n",
       "2             NaN       256  \n",
       "3             NaN       256  \n",
       "4             NaN       256  \n",
       "..            ...       ...  \n",
       "75            NaN       256  \n",
       "76            NaN       256  \n",
       "77            NaN       256  \n",
       "78            NaN       256  \n",
       "79            NaN       256  \n",
       "\n",
       "[80 rows x 17 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6796875"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.693359375"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 1.50411, adv_train_accuracy: 44.14, clean_train_accuracy : 71.09\n",
      "[1,     6] loss: 1.49695, adv_train_accuracy: 41.02, clean_train_accuracy : 67.58\n",
      "[1,    11] loss: 1.39711, adv_train_accuracy: 45.70, clean_train_accuracy : 73.44\n",
      "[1,    16] loss: 1.41901, adv_train_accuracy: 44.14, clean_train_accuracy : 68.75\n",
      "0.66015625\n",
      "0.66015625\n",
      "duration: 26 s - train loss: 1.42912 - train accuracy: 45.21 - validation loss: 1.09451 - validation accuracy: 60.20 \n",
      "[2,     1] loss: 1.50919, adv_train_accuracy: 41.80, clean_train_accuracy : 64.45\n",
      "[2,     6] loss: 1.41298, adv_train_accuracy: 50.39, clean_train_accuracy : 76.17\n",
      "[2,    11] loss: 1.36800, adv_train_accuracy: 48.05, clean_train_accuracy : 76.56\n",
      "[2,    16] loss: 1.41585, adv_train_accuracy: 48.83, clean_train_accuracy : 72.66\n",
      "0.6640625\n",
      "0.650390625\n",
      "duration: 26 s - train loss: 1.45949 - train accuracy: 44.18 - validation loss: 1.10071 - validation accuracy: 62.40 \n",
      "[3,     1] loss: 1.46856, adv_train_accuracy: 41.80, clean_train_accuracy : 73.05\n",
      "[3,     6] loss: 1.40231, adv_train_accuracy: 44.53, clean_train_accuracy : 71.88\n",
      "[3,    11] loss: 1.55747, adv_train_accuracy: 40.23, clean_train_accuracy : 67.58\n",
      "[3,    16] loss: 1.51378, adv_train_accuracy: 42.19, clean_train_accuracy : 70.70\n",
      "0.619140625\n",
      "duration: 26 s - train loss: 1.42840 - train accuracy: 45.55 - validation loss: 1.07904 - validation accuracy: 63.08 \n",
      "[8,     1] loss: 1.47100, adv_train_accuracy: 42.97, clean_train_accuracy : 70.31\n",
      "[8,     6] loss: 1.37347, adv_train_accuracy: 51.95, clean_train_accuracy : 72.27\n",
      "[8,    11] loss: 1.36442, adv_train_accuracy: 47.27, clean_train_accuracy : 75.00\n",
      "[8,    16] loss: 1.49278, adv_train_accuracy: 42.97, clean_train_accuracy : 72.66\n",
      "0.662109375\n",
      "0.6796875\n",
      "duration: 26 s - train loss: 1.42052 - train accuracy: 46.21 - validation loss: 1.13471 - validation accuracy: 60.77 \n",
      "[9,     1] loss: 1.64286, adv_train_accuracy: 40.23, clean_train_accuracy : 61.72\n",
      "[9,     6] loss: 1.55188, adv_train_accuracy: 44.53, clean_train_accuracy : 68.36\n",
      "[9,    11] loss: 1.63905, adv_train_accuracy: 39.84, clean_train_accuracy : 68.75\n",
      "[9,    16] loss: 1.66557, adv_train_accuracy: 37.89, clean_train_accuracy : 67.19\n",
      "0.771484375\n",
      "0.771484375\n",
      "duration: 26 s - train loss: 1.68405 - train accuracy: 38.14 - validation loss: 1.41929 - validation accuracy: 51.04 \n",
      "[10,     1] loss: 1.72582, adv_train_accuracy: 35.94, clean_train_accuracy : 64.84\n",
      "[10,     6] loss: 1.61893, adv_train_accuracy: 37.11, clean_train_accuracy : 67.58\n",
      "[10,    11] loss: 1.57143, adv_train_accuracy: 36.72, clean_train_accuracy : 62.50\n",
      "[10,    16] loss: 1.61971, adv_train_accuracy: 39.45, clean_train_accuracy : 61.72\n",
      "0.673828125\n",
      "0.681640625\n",
      "duration: 26 s - train loss: 1.65110 - train accuracy: 37.64 - validation loss: 1.19927 - validation accuracy: 58.57 \n",
      "[11,     1] loss: 1.48406, adv_train_accuracy: 42.19, clean_train_accuracy : 67.97\n",
      "[11,     6] loss: 1.60658, adv_train_accuracy: 41.41, clean_train_accuracy : 61.33\n",
      "[11,    11] loss: 1.55749, adv_train_accuracy: 39.06, clean_train_accuracy : 64.84\n",
      "[11,    16] loss: 1.50544, adv_train_accuracy: 38.28, clean_train_accuracy : 67.58\n",
      "0.65234375\n",
      "0.6484375\n",
      "duration: 26 s - train loss: 1.50647 - train accuracy: 41.13 - validation loss: 1.08921 - validation accuracy: 63.16 \n",
      "[12,     1] loss: 1.47493, adv_train_accuracy: 46.48, clean_train_accuracy : 69.92\n",
      "[12,     6] loss: 1.45910, adv_train_accuracy: 44.53, clean_train_accuracy : 74.22\n",
      "[12,    11] loss: 1.36077, adv_train_accuracy: 47.66, clean_train_accuracy : 77.34\n",
      "[12,    16] loss: 1.46129, adv_train_accuracy: 45.31, clean_train_accuracy : 73.44\n",
      "0.671875\n",
      "0.658203125\n",
      "duration: 26 s - train loss: 1.46979 - train accuracy: 44.30 - validation loss: 1.09649 - validation accuracy: 61.61 \n",
      "[13,     1] loss: 1.41892, adv_train_accuracy: 45.31, clean_train_accuracy : 66.41\n",
      "[13,     6] loss: 1.39882, adv_train_accuracy: 47.66, clean_train_accuracy : 68.36\n",
      "[13,    11] loss: 1.42028, adv_train_accuracy: 47.27, clean_train_accuracy : 71.88\n",
      "[13,    16] loss: 1.44481, adv_train_accuracy: 44.14, clean_train_accuracy : 75.78\n",
      "0.669921875\n",
      "0.669921875\n",
      "duration: 26 s - train loss: 1.43430 - train accuracy: 45.16 - validation loss: 1.06661 - validation accuracy: 61.38 \n",
      "[14,     1] loss: 1.35054, adv_train_accuracy: 46.48, clean_train_accuracy : 75.39\n",
      "[14,     6] loss: 1.39898, adv_train_accuracy: 44.53, clean_train_accuracy : 73.83\n",
      "[14,    11] loss: 1.36600, adv_train_accuracy: 47.27, clean_train_accuracy : 71.88\n",
      "[14,    16] loss: 1.34961, adv_train_accuracy: 46.09, clean_train_accuracy : 73.05\n",
      "0.646484375\n",
      "0.681640625\n",
      "duration: 26 s - train loss: 1.38125 - train accuracy: 46.37 - validation loss: 1.01693 - validation accuracy: 64.47 \n",
      "[15,     1] loss: 1.43413, adv_train_accuracy: 43.75, clean_train_accuracy : 71.09\n",
      "[15,     6] loss: 1.35556, adv_train_accuracy: 48.44, clean_train_accuracy : 76.95\n",
      "[15,    11] loss: 1.34568, adv_train_accuracy: 44.53, clean_train_accuracy : 71.09\n",
      "[15,    16] loss: 1.40316, adv_train_accuracy: 49.22, clean_train_accuracy : 75.00\n",
      "0.595703125\n",
      "0.669921875\n",
      "duration: 26 s - train loss: 1.38833 - train accuracy: 46.82 - validation loss: 1.04920 - validation accuracy: 63.14 \n",
      "[16,     1] loss: 1.35888, adv_train_accuracy: 46.09, clean_train_accuracy : 73.05\n",
      "[16,     6] loss: 1.31463, adv_train_accuracy: 44.14, clean_train_accuracy : 71.48\n",
      "[16,    11] loss: 1.35681, adv_train_accuracy: 43.36, clean_train_accuracy : 74.22\n",
      "[16,    16] loss: 1.30911, adv_train_accuracy: 44.53, clean_train_accuracy : 78.52\n",
      "0.685546875\n",
      "0.69921875\n",
      "duration: 26 s - train loss: 1.35893 - train accuracy: 46.76 - validation loss: 1.01295 - validation accuracy: 65.68 \n",
      "[17,     1] loss: 1.31930, adv_train_accuracy: 48.05, clean_train_accuracy : 76.95\n",
      "[17,     6] loss: 1.34532, adv_train_accuracy: 51.17, clean_train_accuracy : 78.52\n",
      "[17,    11] loss: 1.39824, adv_train_accuracy: 48.83, clean_train_accuracy : 69.53\n",
      "[17,    16] loss: 1.29992, adv_train_accuracy: 50.39, clean_train_accuracy : 76.95\n",
      "0.63671875\n",
      "0.6796875\n",
      "duration: 26 s - train loss: 1.36665 - train accuracy: 48.28 - validation loss: 0.99990 - validation accuracy: 67.17 \n",
      "[18,     1] loss: 1.31287, adv_train_accuracy: 44.53, clean_train_accuracy : 77.73\n",
      "[18,     6] loss: 1.35899, adv_train_accuracy: 49.61, clean_train_accuracy : 72.27\n",
      "[18,    11] loss: 1.25710, adv_train_accuracy: 52.73, clean_train_accuracy : 76.56\n",
      "[18,    16] loss: 1.31597, adv_train_accuracy: 46.09, clean_train_accuracy : 75.00\n",
      "0.673828125\n",
      "0.67578125\n",
      "duration: 26 s - train loss: 1.39332 - train accuracy: 47.25 - validation loss: 1.02198 - validation accuracy: 65.79 \n",
      "[19,     1] loss: 1.24383, adv_train_accuracy: 53.52, clean_train_accuracy : 79.69\n",
      "[19,     6] loss: 1.25848, adv_train_accuracy: 52.73, clean_train_accuracy : 80.86\n",
      "[19,    11] loss: 1.38909, adv_train_accuracy: 47.27, clean_train_accuracy : 80.47\n",
      "[19,    16] loss: 1.40722, adv_train_accuracy: 44.92, clean_train_accuracy : 75.00\n",
      "0.638671875\n",
      "0.685546875\n",
      "duration: 26 s - train loss: 1.34793 - train accuracy: 48.18 - validation loss: 1.00972 - validation accuracy: 65.88 \n",
      "[20,     1] loss: 1.30854, adv_train_accuracy: 49.61, clean_train_accuracy : 77.34\n",
      "[20,     6] loss: 1.23416, adv_train_accuracy: 53.12, clean_train_accuracy : 80.08\n",
      "[20,    11] loss: 1.26091, adv_train_accuracy: 50.78, clean_train_accuracy : 81.25\n",
      "[20,    16] loss: 1.40645, adv_train_accuracy: 49.61, clean_train_accuracy : 72.66\n",
      "0.634765625\n",
      "0.6484375\n",
      "duration: 26 s - train loss: 1.32951 - train accuracy: 48.98 - validation loss: 1.00623 - validation accuracy: 65.55 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>16</td>\n",
       "      <td>1.358931</td>\n",
       "      <td>46.757812</td>\n",
       "      <td>1.012950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.68</td>\n",
       "      <td>423.032934</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>17</td>\n",
       "      <td>1.366647</td>\n",
       "      <td>48.281250</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.17</td>\n",
       "      <td>449.495956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>18</td>\n",
       "      <td>1.393320</td>\n",
       "      <td>47.246094</td>\n",
       "      <td>1.021983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.79</td>\n",
       "      <td>475.847281</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>19</td>\n",
       "      <td>1.347932</td>\n",
       "      <td>48.183594</td>\n",
       "      <td>1.009724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.88</td>\n",
       "      <td>502.166666</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>20</td>\n",
       "      <td>1.329505</td>\n",
       "      <td>48.984375</td>\n",
       "      <td>1.006226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.55</td>\n",
       "      <td>528.544187</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0      1   10.069616       10.019531         3.418694               NaN   \n",
       "1      2    3.292510        8.789062         2.192064               NaN   \n",
       "2      3    2.474881       13.281250         2.233554               NaN   \n",
       "3      4    2.347974       16.093750         2.084406               NaN   \n",
       "4      5    2.225618       17.734375         1.975296               NaN   \n",
       "..   ...         ...             ...              ...               ...   \n",
       "95    16    1.358931       46.757812         1.012950               NaN   \n",
       "96    17    1.366647       48.281250         0.999900               NaN   \n",
       "97    18    1.393320       47.246094         1.021983               NaN   \n",
       "98    19    1.347932       48.183594         1.009724               NaN   \n",
       "99    20    1.329505       48.984375         1.006226               NaN   \n",
       "\n",
       "    l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0          NaN             NaN       NaN             NaN       NaN   \n",
       "1          NaN             NaN       NaN             NaN       NaN   \n",
       "2          NaN             NaN       NaN             NaN       NaN   \n",
       "3          NaN             NaN       NaN             NaN       NaN   \n",
       "4          NaN             NaN       NaN             NaN       NaN   \n",
       "..         ...             ...       ...             ...       ...   \n",
       "95         NaN             NaN       NaN             NaN       NaN   \n",
       "96         NaN             NaN       NaN             NaN       NaN   \n",
       "97         NaN             NaN       NaN             NaN       NaN   \n",
       "98         NaN             NaN       NaN             NaN       NaN   \n",
       "99         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "    validation_accuracy    duration           criterion  \\\n",
       "0                 14.26   27.299788  CrossEntropyLoss()   \n",
       "1                 23.43   53.504930  CrossEntropyLoss()   \n",
       "2                 27.19   79.630913  CrossEntropyLoss()   \n",
       "3                 28.54  106.239956  CrossEntropyLoss()   \n",
       "4                 32.90  132.602924  CrossEntropyLoss()   \n",
       "..                  ...         ...                 ...   \n",
       "95                65.68  423.032934  CrossEntropyLoss()   \n",
       "96                67.17  449.495956  CrossEntropyLoss()   \n",
       "97                65.79  475.847281  CrossEntropyLoss()   \n",
       "98                65.88  502.166666  CrossEntropyLoss()   \n",
       "99                65.55  528.544187  CrossEntropyLoss()   \n",
       "\n",
       "                                            optimizer    method  \\\n",
       "0   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                ...       ...   \n",
       "95  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "96  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "97  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "98  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "99  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "    learning_rate batchsize  \n",
       "0             NaN       256  \n",
       "1             NaN       256  \n",
       "2             NaN       256  \n",
       "3             NaN       256  \n",
       "4             NaN       256  \n",
       "..            ...       ...  \n",
       "95            NaN       256  \n",
       "96            NaN       256  \n",
       "97            NaN       256  \n",
       "98            NaN       256  \n",
       "99            NaN       256  \n",
       "\n",
       "[100 rows x 17 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6015625"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.666015625"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 1.33263, adv_train_accuracy: 47.27, clean_train_accuracy : 75.00\n",
      "[1,     6] loss: 1.39286, adv_train_accuracy: 44.14, clean_train_accuracy : 76.17\n",
      "[1,    11] loss: 1.42715, adv_train_accuracy: 49.61, clean_train_accuracy : 76.56\n",
      "[1,    16] loss: 1.30952, adv_train_accuracy: 51.56, clean_train_accuracy : 77.34\n",
      "0.634765625\n",
      "0.658203125\n",
      "duration: 26 s - train loss: 1.34981 - train accuracy: 47.85 - validation loss: 1.06058 - validation accuracy: 65.63 \n",
      "[2,     1] loss: 1.37787, adv_train_accuracy: 46.88, clean_train_accuracy : 73.83\n",
      "[2,     6] loss: 1.34088, adv_train_accuracy: 48.05, clean_train_accuracy : 78.91\n",
      "[2,    11] loss: 1.24699, adv_train_accuracy: 48.44, clean_train_accuracy : 75.78\n",
      "[2,    16] loss: 1.29017, adv_train_accuracy: 47.66, clean_train_accuracy : 75.39\n",
      "0.66796875\n",
      "0.642578125\n",
      "duration: 26 s - train loss: 1.33071 - train accuracy: 48.57 - validation loss: 1.02726 - validation accuracy: 64.12 \n",
      "[3,     1] loss: 1.38440, adv_train_accuracy: 49.61, clean_train_accuracy : 77.73\n",
      "[3,     6] loss: 1.32655, adv_train_accuracy: 48.83, clean_train_accuracy : 79.30\n",
      "[3,    11] loss: 1.35188, adv_train_accuracy: 44.53, clean_train_accuracy : 77.73\n",
      "[3,    16] loss: 1.38244, adv_train_accuracy: 48.05, clean_train_accuracy : 80.86\n",
      "0.6328125\n",
      "0.63671875\n",
      "duration: 26 s - train loss: 1.32665 - train accuracy: 49.61 - validation loss: 0.96377 - validation accuracy: 66.79 \n",
      "[4,     1] loss: 1.36217, adv_train_accuracy: 46.48, clean_train_accuracy : 77.34\n",
      "[4,     6] loss: 1.31493, adv_train_accuracy: 51.17, clean_train_accuracy : 76.17\n",
      "[4,    11] loss: 1.33155, adv_train_accuracy: 46.48, clean_train_accuracy : 76.95\n",
      "[4,    16] loss: 1.50973, adv_train_accuracy: 46.09, clean_train_accuracy : 72.27\n",
      "0.619140625\n",
      "0.673828125\n",
      "duration: 26 s - train loss: 1.35287 - train accuracy: 48.16 - validation loss: 1.01335 - validation accuracy: 65.53 \n",
      "[5,     1] loss: 1.28820, adv_train_accuracy: 49.61, clean_train_accuracy : 80.47\n",
      "[5,     6] loss: 1.45554, adv_train_accuracy: 45.70, clean_train_accuracy : 79.30\n",
      "[5,    11] loss: 1.31951, adv_train_accuracy: 50.39, clean_train_accuracy : 78.91\n",
      "[5,    16] loss: 1.27898, adv_train_accuracy: 50.39, clean_train_accuracy : 77.73\n",
      "0.625\n",
      "0.662109375\n",
      "duration: 26 s - train loss: 1.32101 - train accuracy: 49.51 - validation loss: 0.94363 - validation accuracy: 67.33 \n",
      "[6,     1] loss: 1.27888, adv_train_accuracy: 48.44, clean_train_accuracy : 80.86\n",
      "[6,     6] loss: 1.44668, adv_train_accuracy: 46.48, clean_train_accuracy : 76.56\n",
      "[6,    11] loss: 1.38964, adv_train_accuracy: 45.31, clean_train_accuracy : 73.05\n",
      "[6,    16] loss: 1.38653, adv_train_accuracy: 50.00, clean_train_accuracy : 74.22\n",
      "0.59375\n",
      "0.65625\n",
      "duration: 26 s - train loss: 1.32396 - train accuracy: 49.20 - validation loss: 0.97385 - validation accuracy: 67.03 \n",
      "[7,     1] loss: 1.43453, adv_train_accuracy: 42.97, clean_train_accuracy : 76.56\n",
      "[7,     6] loss: 1.25135, adv_train_accuracy: 50.78, clean_train_accuracy : 82.42\n",
      "[7,    11] loss: 1.26145, adv_train_accuracy: 55.08, clean_train_accuracy : 77.73\n",
      "[7,    16] loss: 1.35313, adv_train_accuracy: 48.05, clean_train_accuracy : 76.95\n",
      "0.654296875\n",
      "0.681640625\n",
      "duration: 26 s - train loss: 1.31838 - train accuracy: 48.83 - validation loss: 0.96476 - validation accuracy: 67.19 \n",
      "[8,     1] loss: 1.24882, adv_train_accuracy: 53.12, clean_train_accuracy : 80.08\n",
      "[8,     6] loss: 1.25125, adv_train_accuracy: 54.69, clean_train_accuracy : 77.73\n",
      "[8,    11] loss: 1.26646, adv_train_accuracy: 51.56, clean_train_accuracy : 78.52\n",
      "[8,    16] loss: 1.21520, adv_train_accuracy: 51.17, clean_train_accuracy : 83.98\n",
      "0.65625\n",
      "0.69921875\n",
      "duration: 26 s - train loss: 1.26162 - train accuracy: 50.33 - validation loss: 0.96595 - validation accuracy: 66.93 \n",
      "[9,     1] loss: 1.26279, adv_train_accuracy: 51.95, clean_train_accuracy : 80.08\n",
      "[9,     6] loss: 1.30166, adv_train_accuracy: 49.22, clean_train_accuracy : 80.08\n",
      "[9,    11] loss: 1.34065, adv_train_accuracy: 50.78, clean_train_accuracy : 76.95\n",
      "[9,    16] loss: 1.30862, adv_train_accuracy: 51.95, clean_train_accuracy : 76.95\n",
      "0.59765625\n",
      "0.685546875\n",
      "duration: 26 s - train loss: 1.28335 - train accuracy: 51.58 - validation loss: 0.97025 - validation accuracy: 66.55 \n",
      "[10,     1] loss: 1.30872, adv_train_accuracy: 46.48, clean_train_accuracy : 76.95\n",
      "[10,     6] loss: 1.23113, adv_train_accuracy: 51.17, clean_train_accuracy : 78.91\n",
      "[10,    11] loss: 1.26660, adv_train_accuracy: 50.00, clean_train_accuracy : 80.08\n",
      "[10,    16] loss: 1.21450, adv_train_accuracy: 51.95, clean_train_accuracy : 78.52\n",
      "0.658203125\n",
      "0.673828125\n",
      "duration: 26 s - train loss: 1.25318 - train accuracy: 50.78 - validation loss: 0.95074 - validation accuracy: 67.71 \n",
      "[11,     1] loss: 1.19559, adv_train_accuracy: 55.47, clean_train_accuracy : 85.55\n",
      "[11,     6] loss: 1.28173, adv_train_accuracy: 52.73, clean_train_accuracy : 79.69\n",
      "[11,    11] loss: 1.19508, adv_train_accuracy: 54.69, clean_train_accuracy : 85.16\n",
      "[11,    16] loss: 1.35080, adv_train_accuracy: 47.27, clean_train_accuracy : 79.30\n",
      "0.630859375\n",
      "0.642578125\n",
      "duration: 26 s - train loss: 1.23363 - train accuracy: 52.42 - validation loss: 0.93657 - validation accuracy: 66.75 \n",
      "[12,     1] loss: 1.33361, adv_train_accuracy: 46.09, clean_train_accuracy : 70.70\n",
      "[12,     6] loss: 1.30417, adv_train_accuracy: 46.88, clean_train_accuracy : 77.73\n",
      "[12,    11] loss: 1.29041, adv_train_accuracy: 50.00, clean_train_accuracy : 78.12\n",
      "[12,    16] loss: 1.35696, adv_train_accuracy: 49.22, clean_train_accuracy : 74.22\n",
      "0.623046875\n",
      "0.66796875\n",
      "duration: 26 s - train loss: 1.25102 - train accuracy: 50.84 - validation loss: 0.96800 - validation accuracy: 66.62 \n",
      "[13,     1] loss: 1.26136, adv_train_accuracy: 54.69, clean_train_accuracy : 80.08\n",
      "[13,     6] loss: 1.33796, adv_train_accuracy: 44.92, clean_train_accuracy : 76.56\n",
      "[13,    11] loss: 1.35374, adv_train_accuracy: 48.05, clean_train_accuracy : 79.30\n",
      "[13,    16] loss: 1.44461, adv_train_accuracy: 47.27, clean_train_accuracy : 77.34\n",
      "0.640625\n",
      "0.705078125\n",
      "duration: 26 s - train loss: 1.33950 - train accuracy: 48.55 - validation loss: 0.96675 - validation accuracy: 66.39 \n",
      "[14,     1] loss: 1.27244, adv_train_accuracy: 52.34, clean_train_accuracy : 80.47\n",
      "[14,     6] loss: 1.32738, adv_train_accuracy: 46.88, clean_train_accuracy : 73.83\n",
      "[14,    11] loss: 1.50550, adv_train_accuracy: 41.80, clean_train_accuracy : 77.73\n",
      "[14,    16] loss: 1.33811, adv_train_accuracy: 47.66, clean_train_accuracy : 75.00\n",
      "0.630859375\n",
      "0.638671875\n",
      "duration: 26 s - train loss: 1.33109 - train accuracy: 48.93 - validation loss: 0.99651 - validation accuracy: 65.22 \n",
      "[15,     1] loss: 1.32594, adv_train_accuracy: 48.44, clean_train_accuracy : 78.52\n",
      "[15,     6] loss: 1.24610, adv_train_accuracy: 50.78, clean_train_accuracy : 76.17\n",
      "[15,    11] loss: 1.21644, adv_train_accuracy: 49.22, clean_train_accuracy : 80.86\n",
      "[15,    16] loss: 1.23252, adv_train_accuracy: 53.12, clean_train_accuracy : 79.30\n",
      "0.638671875\n",
      "0.689453125\n",
      "duration: 26 s - train loss: 1.25883 - train accuracy: 49.73 - validation loss: 0.94731 - validation accuracy: 68.25 \n",
      "[16,     1] loss: 1.20775, adv_train_accuracy: 49.61, clean_train_accuracy : 80.08\n",
      "[16,     6] loss: 1.18185, adv_train_accuracy: 57.03, clean_train_accuracy : 83.20\n",
      "[16,    11] loss: 1.33755, adv_train_accuracy: 49.22, clean_train_accuracy : 75.39\n",
      "[16,    16] loss: 1.30959, adv_train_accuracy: 46.48, clean_train_accuracy : 78.52\n",
      "0.662109375\n",
      "0.693359375\n",
      "duration: 26 s - train loss: 1.25168 - train accuracy: 51.48 - validation loss: 0.98703 - validation accuracy: 66.55 \n",
      "[17,     1] loss: 1.21633, adv_train_accuracy: 49.22, clean_train_accuracy : 83.20\n",
      "[17,     6] loss: 1.32756, adv_train_accuracy: 51.56, clean_train_accuracy : 79.69\n",
      "[17,    11] loss: 1.29059, adv_train_accuracy: 52.34, clean_train_accuracy : 80.47\n",
      "[17,    16] loss: 1.36550, adv_train_accuracy: 47.27, clean_train_accuracy : 75.78\n",
      "0.65625\n",
      "0.703125\n",
      "duration: 26 s - train loss: 1.27959 - train accuracy: 50.78 - validation loss: 0.92828 - validation accuracy: 67.79 \n",
      "[18,     1] loss: 1.18183, adv_train_accuracy: 50.78, clean_train_accuracy : 80.86\n",
      "[18,     6] loss: 1.19850, adv_train_accuracy: 51.17, clean_train_accuracy : 82.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 1.25184, adv_train_accuracy: 50.39, clean_train_accuracy : 78.12\n",
      "[18,    16] loss: 1.21901, adv_train_accuracy: 51.56, clean_train_accuracy : 83.59\n",
      "0.630859375\n",
      "0.6796875\n",
      "duration: 26 s - train loss: 1.23225 - train accuracy: 51.89 - validation loss: 0.96147 - validation accuracy: 67.35 \n",
      "[19,     1] loss: 1.21977, adv_train_accuracy: 51.17, clean_train_accuracy : 82.81\n",
      "[19,     6] loss: 1.28869, adv_train_accuracy: 48.83, clean_train_accuracy : 78.12\n",
      "[19,    11] loss: 1.12677, adv_train_accuracy: 51.17, clean_train_accuracy : 83.20\n",
      "[19,    16] loss: 1.32238, adv_train_accuracy: 53.52, clean_train_accuracy : 79.69\n",
      "0.658203125\n",
      "0.65234375\n",
      "duration: 26 s - train loss: 1.23068 - train accuracy: 52.38 - validation loss: 0.96737 - validation accuracy: 65.51 \n",
      "[20,     1] loss: 1.18006, adv_train_accuracy: 55.08, clean_train_accuracy : 82.03\n",
      "[20,     6] loss: 1.16888, adv_train_accuracy: 53.91, clean_train_accuracy : 82.03\n",
      "[20,    11] loss: 1.24370, adv_train_accuracy: 51.56, clean_train_accuracy : 78.52\n",
      "[20,    16] loss: 1.07194, adv_train_accuracy: 54.69, clean_train_accuracy : 86.33\n",
      "0.611328125\n",
      "0.66015625\n",
      "duration: 26 s - train loss: 1.20154 - train accuracy: 53.54 - validation loss: 0.91944 - validation accuracy: 69.23 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>16</td>\n",
       "      <td>1.251685</td>\n",
       "      <td>51.484375</td>\n",
       "      <td>0.987034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.55</td>\n",
       "      <td>421.746048</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>17</td>\n",
       "      <td>1.279591</td>\n",
       "      <td>50.781250</td>\n",
       "      <td>0.928279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.79</td>\n",
       "      <td>447.976815</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>18</td>\n",
       "      <td>1.232246</td>\n",
       "      <td>51.894531</td>\n",
       "      <td>0.961465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.35</td>\n",
       "      <td>474.279655</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>19</td>\n",
       "      <td>1.230676</td>\n",
       "      <td>52.382812</td>\n",
       "      <td>0.967372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.51</td>\n",
       "      <td>500.522663</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>20</td>\n",
       "      <td>1.201542</td>\n",
       "      <td>53.535156</td>\n",
       "      <td>0.919443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.23</td>\n",
       "      <td>526.729007</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "115    16    1.251685       51.484375         0.987034               NaN   \n",
       "116    17    1.279591       50.781250         0.928279               NaN   \n",
       "117    18    1.232246       51.894531         0.961465               NaN   \n",
       "118    19    1.230676       52.382812         0.967372               NaN   \n",
       "119    20    1.201542       53.535156         0.919443               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "115         NaN             NaN       NaN             NaN       NaN   \n",
       "116         NaN             NaN       NaN             NaN       NaN   \n",
       "117         NaN             NaN       NaN             NaN       NaN   \n",
       "118         NaN             NaN       NaN             NaN       NaN   \n",
       "119         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "115                66.55  421.746048  CrossEntropyLoss()   \n",
       "116                67.79  447.976815  CrossEntropyLoss()   \n",
       "117                67.35  474.279655  CrossEntropyLoss()   \n",
       "118                65.51  500.522663  CrossEntropyLoss()   \n",
       "119                69.23  526.729007  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "115  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "116  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "117  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "118  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "119  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "115            NaN       256  \n",
       "116            NaN       256  \n",
       "117            NaN       256  \n",
       "118            NaN       256  \n",
       "119            NaN       256  \n",
       "\n",
       "[120 rows x 17 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.646484375"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67578125"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 1.21576, adv_train_accuracy: 52.34, clean_train_accuracy : 82.03\n",
      "[1,     6] loss: 1.27279, adv_train_accuracy: 49.22, clean_train_accuracy : 74.61\n",
      "[1,    11] loss: 1.04234, adv_train_accuracy: 60.94, clean_train_accuracy : 84.38\n",
      "[1,    16] loss: 1.13040, adv_train_accuracy: 55.86, clean_train_accuracy : 86.72\n",
      "0.63671875\n",
      "0.708984375\n",
      "duration: 26 s - train loss: 1.17831 - train accuracy: 53.67 - validation loss: 0.89072 - validation accuracy: 69.61 \n",
      "[2,     1] loss: 1.04852, adv_train_accuracy: 60.16, clean_train_accuracy : 87.11\n",
      "[2,     6] loss: 1.14355, adv_train_accuracy: 57.81, clean_train_accuracy : 82.03\n",
      "[2,    11] loss: 1.26960, adv_train_accuracy: 50.39, clean_train_accuracy : 82.81\n",
      "[2,    16] loss: 1.27066, adv_train_accuracy: 51.17, clean_train_accuracy : 80.08\n",
      "0.654296875\n",
      "0.662109375\n",
      "duration: 26 s - train loss: 1.20619 - train accuracy: 53.05 - validation loss: 0.94099 - validation accuracy: 67.05 \n",
      "[3,     1] loss: 1.18322, adv_train_accuracy: 57.03, clean_train_accuracy : 82.03\n",
      "[3,     6] loss: 1.16019, adv_train_accuracy: 53.12, clean_train_accuracy : 81.64\n",
      "[3,    11] loss: 1.16878, adv_train_accuracy: 55.08, clean_train_accuracy : 82.81\n",
      "[3,    16] loss: 1.23376, adv_train_accuracy: 52.73, clean_train_accuracy : 79.69\n",
      "0.67578125\n",
      "0.71875\n",
      "duration: 26 s - train loss: 1.18205 - train accuracy: 53.42 - validation loss: 0.97419 - validation accuracy: 67.33 \n",
      "[4,     1] loss: 1.24587, adv_train_accuracy: 53.52, clean_train_accuracy : 82.42\n",
      "[4,     6] loss: 1.26557, adv_train_accuracy: 52.34, clean_train_accuracy : 78.91\n",
      "[4,    11] loss: 1.32357, adv_train_accuracy: 44.92, clean_train_accuracy : 80.47\n",
      "[4,    16] loss: 1.28597, adv_train_accuracy: 48.44, clean_train_accuracy : 82.42\n",
      "0.626953125\n",
      "0.640625\n",
      "duration: 26 s - train loss: 1.22960 - train accuracy: 52.11 - validation loss: 0.91955 - validation accuracy: 68.98 \n",
      "[5,     1] loss: 1.78379, adv_train_accuracy: 50.39, clean_train_accuracy : 75.78\n",
      "[5,     6] loss: 1.49881, adv_train_accuracy: 40.23, clean_train_accuracy : 68.75\n",
      "[5,    11] loss: 1.87216, adv_train_accuracy: 36.72, clean_train_accuracy : 71.48\n",
      "[5,    16] loss: 1.63450, adv_train_accuracy: 41.80, clean_train_accuracy : 74.61\n",
      "0.650390625\n",
      "0.732421875\n",
      "duration: 26 s - train loss: 1.49709 - train accuracy: 44.94 - validation loss: 1.06318 - validation accuracy: 63.67 \n",
      "[6,     1] loss: 1.38358, adv_train_accuracy: 46.48, clean_train_accuracy : 76.17\n",
      "[6,     6] loss: 1.45106, adv_train_accuracy: 42.58, clean_train_accuracy : 77.34\n",
      "[6,    11] loss: 1.38720, adv_train_accuracy: 46.88, clean_train_accuracy : 76.56\n",
      "[6,    16] loss: 1.32563, adv_train_accuracy: 51.56, clean_train_accuracy : 79.30\n",
      "0.599609375\n",
      "0.669921875\n",
      "duration: 26 s - train loss: 1.37629 - train accuracy: 47.11 - validation loss: 0.94884 - validation accuracy: 66.63 \n",
      "[7,     1] loss: 1.19014, adv_train_accuracy: 54.69, clean_train_accuracy : 81.64\n",
      "[7,     6] loss: 1.26379, adv_train_accuracy: 54.30, clean_train_accuracy : 80.08\n",
      "[7,    11] loss: 1.31512, adv_train_accuracy: 51.17, clean_train_accuracy : 78.52\n",
      "[7,    16] loss: 1.17943, adv_train_accuracy: 53.91, clean_train_accuracy : 80.86\n",
      "0.634765625\n",
      "0.705078125\n",
      "duration: 26 s - train loss: 1.23416 - train accuracy: 53.14 - validation loss: 0.94352 - validation accuracy: 66.46 \n",
      "[8,     1] loss: 1.21912, adv_train_accuracy: 52.34, clean_train_accuracy : 77.34\n",
      "[8,     6] loss: 1.21558, adv_train_accuracy: 53.91, clean_train_accuracy : 85.94\n",
      "[8,    11] loss: 1.19957, adv_train_accuracy: 53.52, clean_train_accuracy : 80.86\n",
      "[8,    16] loss: 1.33896, adv_train_accuracy: 48.83, clean_train_accuracy : 80.08\n",
      "0.626953125\n",
      "0.6953125\n",
      "duration: 26 s - train loss: 1.19705 - train accuracy: 53.48 - validation loss: 0.93916 - validation accuracy: 66.96 \n",
      "[9,     1] loss: 1.04809, adv_train_accuracy: 57.42, clean_train_accuracy : 84.77\n",
      "[9,     6] loss: 1.05750, adv_train_accuracy: 56.64, clean_train_accuracy : 86.33\n",
      "[9,    11] loss: 1.03485, adv_train_accuracy: 60.16, clean_train_accuracy : 89.45\n",
      "[9,    16] loss: 1.12306, adv_train_accuracy: 57.42, clean_train_accuracy : 85.94\n",
      "0.61328125\n",
      "0.677734375\n",
      "duration: 26 s - train loss: 1.15292 - train accuracy: 55.39 - validation loss: 0.86722 - validation accuracy: 69.59 \n",
      "[10,     1] loss: 1.12463, adv_train_accuracy: 55.47, clean_train_accuracy : 84.38\n",
      "[10,     6] loss: 1.11033, adv_train_accuracy: 55.47, clean_train_accuracy : 84.77\n",
      "[10,    11] loss: 1.06841, adv_train_accuracy: 54.69, clean_train_accuracy : 87.11\n",
      "[10,    16] loss: 1.12413, adv_train_accuracy: 54.30, clean_train_accuracy : 85.55\n",
      "0.63671875\n",
      "0.71875\n",
      "duration: 26 s - train loss: 1.15552 - train accuracy: 55.74 - validation loss: 0.91628 - validation accuracy: 67.59 \n",
      "[11,     1] loss: 1.09418, adv_train_accuracy: 59.38, clean_train_accuracy : 79.30\n",
      "[11,     6] loss: 1.05560, adv_train_accuracy: 62.11, clean_train_accuracy : 83.98\n",
      "[11,    11] loss: 1.28160, adv_train_accuracy: 51.56, clean_train_accuracy : 81.25\n",
      "[11,    16] loss: 1.13593, adv_train_accuracy: 55.86, clean_train_accuracy : 87.11\n",
      "0.640625\n",
      "0.673828125\n",
      "duration: 26 s - train loss: 1.13300 - train accuracy: 56.15 - validation loss: 0.89326 - validation accuracy: 69.72 \n",
      "[12,     1] loss: 1.12465, adv_train_accuracy: 57.42, clean_train_accuracy : 84.38\n",
      "[12,     6] loss: 1.15264, adv_train_accuracy: 57.03, clean_train_accuracy : 85.55\n",
      "[12,    11] loss: 1.22383, adv_train_accuracy: 53.91, clean_train_accuracy : 82.03\n",
      "[12,    16] loss: 1.13188, adv_train_accuracy: 55.08, clean_train_accuracy : 84.38\n",
      "0.62109375\n",
      "0.677734375\n",
      "duration: 26 s - train loss: 1.15013 - train accuracy: 56.09 - validation loss: 0.90711 - validation accuracy: 69.29 \n",
      "[13,     1] loss: 1.21234, adv_train_accuracy: 53.91, clean_train_accuracy : 83.20\n",
      "[13,     6] loss: 1.11853, adv_train_accuracy: 54.30, clean_train_accuracy : 81.25\n",
      "[13,    11] loss: 1.07393, adv_train_accuracy: 59.77, clean_train_accuracy : 86.33\n",
      "[13,    16] loss: 1.17706, adv_train_accuracy: 50.39, clean_train_accuracy : 82.42\n",
      "0.642578125\n",
      "0.654296875\n",
      "duration: 26 s - train loss: 1.13179 - train accuracy: 54.92 - validation loss: 0.90733 - validation accuracy: 69.36 \n",
      "[14,     1] loss: 1.16762, adv_train_accuracy: 51.17, clean_train_accuracy : 87.11\n",
      "[14,     6] loss: 1.12172, adv_train_accuracy: 55.08, clean_train_accuracy : 87.11\n",
      "[14,    11] loss: 1.10742, adv_train_accuracy: 55.86, clean_train_accuracy : 82.03\n",
      "[14,    16] loss: 1.08439, adv_train_accuracy: 57.03, clean_train_accuracy : 83.98\n",
      "0.611328125\n",
      "0.62890625\n",
      "duration: 26 s - train loss: 1.10922 - train accuracy: 55.41 - validation loss: 0.85496 - validation accuracy: 70.63 \n",
      "[15,     1] loss: 1.19444, adv_train_accuracy: 49.61, clean_train_accuracy : 83.20\n",
      "[15,     6] loss: 1.09259, adv_train_accuracy: 57.81, clean_train_accuracy : 85.16\n",
      "[15,    11] loss: 1.14478, adv_train_accuracy: 54.30, clean_train_accuracy : 87.11\n",
      "[15,    16] loss: 1.10939, adv_train_accuracy: 55.86, clean_train_accuracy : 84.77\n",
      "0.66796875\n",
      "0.662109375\n",
      "duration: 26 s - train loss: 1.10694 - train accuracy: 56.64 - validation loss: 0.88936 - validation accuracy: 68.78 \n",
      "[16,     1] loss: 1.05872, adv_train_accuracy: 59.77, clean_train_accuracy : 85.16\n",
      "[16,     6] loss: 1.08393, adv_train_accuracy: 57.81, clean_train_accuracy : 84.77\n",
      "[16,    11] loss: 1.15792, adv_train_accuracy: 53.52, clean_train_accuracy : 82.81\n",
      "[16,    16] loss: 1.04679, adv_train_accuracy: 59.77, clean_train_accuracy : 85.16\n",
      "0.638671875\n",
      "0.65234375\n",
      "duration: 26 s - train loss: 1.10537 - train accuracy: 56.72 - validation loss: 0.90043 - validation accuracy: 68.24 \n",
      "[17,     1] loss: 1.08461, adv_train_accuracy: 53.91, clean_train_accuracy : 87.11\n",
      "[17,     6] loss: 1.12102, adv_train_accuracy: 52.34, clean_train_accuracy : 85.94\n",
      "[17,    11] loss: 0.98366, adv_train_accuracy: 57.03, clean_train_accuracy : 87.89\n",
      "[17,    16] loss: 1.13525, adv_train_accuracy: 55.08, clean_train_accuracy : 85.94\n",
      "0.6328125\n",
      "0.669921875\n",
      "duration: 26 s - train loss: 1.07997 - train accuracy: 57.68 - validation loss: 0.88175 - validation accuracy: 67.89 \n",
      "[18,     1] loss: 1.07602, adv_train_accuracy: 57.42, clean_train_accuracy : 80.08\n",
      "[18,     6] loss: 1.11218, adv_train_accuracy: 53.91, clean_train_accuracy : 81.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 1.08912, adv_train_accuracy: 59.38, clean_train_accuracy : 83.98\n",
      "[18,    16] loss: 1.13742, adv_train_accuracy: 57.42, clean_train_accuracy : 83.20\n",
      "0.658203125\n",
      "0.703125\n",
      "duration: 26 s - train loss: 1.07859 - train accuracy: 57.46 - validation loss: 0.94345 - validation accuracy: 67.91 \n",
      "[19,     1] loss: 1.07441, adv_train_accuracy: 62.11, clean_train_accuracy : 84.77\n",
      "[19,     6] loss: 0.97323, adv_train_accuracy: 59.77, clean_train_accuracy : 91.41\n",
      "[19,    11] loss: 1.04711, adv_train_accuracy: 56.25, clean_train_accuracy : 85.94\n",
      "[19,    16] loss: 0.95341, adv_train_accuracy: 62.89, clean_train_accuracy : 86.72\n",
      "0.638671875\n",
      "0.673828125\n",
      "duration: 26 s - train loss: 1.04023 - train accuracy: 59.22 - validation loss: 0.88106 - validation accuracy: 69.58 \n",
      "[20,     1] loss: 0.99843, adv_train_accuracy: 63.67, clean_train_accuracy : 86.72\n",
      "[20,     6] loss: 1.00662, adv_train_accuracy: 58.20, clean_train_accuracy : 85.55\n",
      "[20,    11] loss: 0.97135, adv_train_accuracy: 62.11, clean_train_accuracy : 89.06\n",
      "[20,    16] loss: 1.09130, adv_train_accuracy: 53.52, clean_train_accuracy : 91.02\n",
      "0.6171875\n",
      "0.666015625\n",
      "duration: 26 s - train loss: 1.06873 - train accuracy: 57.70 - validation loss: 0.90577 - validation accuracy: 67.73 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>16</td>\n",
       "      <td>1.105373</td>\n",
       "      <td>56.718750</td>\n",
       "      <td>0.900433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.24</td>\n",
       "      <td>419.668746</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>17</td>\n",
       "      <td>1.079970</td>\n",
       "      <td>57.675781</td>\n",
       "      <td>0.881752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.89</td>\n",
       "      <td>445.909679</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>18</td>\n",
       "      <td>1.078593</td>\n",
       "      <td>57.460938</td>\n",
       "      <td>0.943455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.91</td>\n",
       "      <td>472.059712</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>19</td>\n",
       "      <td>1.040229</td>\n",
       "      <td>59.218750</td>\n",
       "      <td>0.881060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.58</td>\n",
       "      <td>498.136842</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>20</td>\n",
       "      <td>1.068733</td>\n",
       "      <td>57.695312</td>\n",
       "      <td>0.905772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.73</td>\n",
       "      <td>524.300686</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "135    16    1.105373       56.718750         0.900433               NaN   \n",
       "136    17    1.079970       57.675781         0.881752               NaN   \n",
       "137    18    1.078593       57.460938         0.943455               NaN   \n",
       "138    19    1.040229       59.218750         0.881060               NaN   \n",
       "139    20    1.068733       57.695312         0.905772               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "135         NaN             NaN       NaN             NaN       NaN   \n",
       "136         NaN             NaN       NaN             NaN       NaN   \n",
       "137         NaN             NaN       NaN             NaN       NaN   \n",
       "138         NaN             NaN       NaN             NaN       NaN   \n",
       "139         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "135                68.24  419.668746  CrossEntropyLoss()   \n",
       "136                67.89  445.909679  CrossEntropyLoss()   \n",
       "137                67.91  472.059712  CrossEntropyLoss()   \n",
       "138                69.58  498.136842  CrossEntropyLoss()   \n",
       "139                67.73  524.300686  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "135  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "136  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "137  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "138  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "139  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "135            NaN       256  \n",
       "136            NaN       256  \n",
       "137            NaN       256  \n",
       "138            NaN       256  \n",
       "139            NaN       256  \n",
       "\n",
       "[140 rows x 17 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.607421875"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.677734375"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 1.07967, adv_train_accuracy: 57.42, clean_train_accuracy : 85.94\n",
      "[1,     6] loss: 0.97822, adv_train_accuracy: 60.16, clean_train_accuracy : 84.77\n",
      "[1,    11] loss: 1.14984, adv_train_accuracy: 55.08, clean_train_accuracy : 82.42\n",
      "[1,    16] loss: 1.19714, adv_train_accuracy: 55.08, clean_train_accuracy : 84.38\n",
      "0.59375\n",
      "0.642578125\n",
      "duration: 26 s - train loss: 1.08156 - train accuracy: 57.27 - validation loss: 0.84474 - validation accuracy: 71.89 \n",
      "[2,     1] loss: 0.95498, adv_train_accuracy: 60.16, clean_train_accuracy : 90.23\n",
      "[2,     6] loss: 0.98254, adv_train_accuracy: 61.72, clean_train_accuracy : 89.84\n",
      "[2,    11] loss: 1.11601, adv_train_accuracy: 56.25, clean_train_accuracy : 82.42\n",
      "[2,    16] loss: 0.98263, adv_train_accuracy: 60.55, clean_train_accuracy : 87.89\n",
      "0.615234375\n",
      "0.685546875\n",
      "duration: 26 s - train loss: 1.05808 - train accuracy: 58.24 - validation loss: 0.89936 - validation accuracy: 69.91 \n",
      "[3,     1] loss: 0.94512, adv_train_accuracy: 62.50, clean_train_accuracy : 90.23\n",
      "[3,     6] loss: 1.16272, adv_train_accuracy: 56.64, clean_train_accuracy : 83.59\n",
      "[3,    11] loss: 1.06298, adv_train_accuracy: 56.64, clean_train_accuracy : 91.02\n",
      "[3,    16] loss: 1.01279, adv_train_accuracy: 57.03, clean_train_accuracy : 92.19\n",
      "0.64453125\n",
      "0.720703125\n",
      "duration: 26 s - train loss: 1.04033 - train accuracy: 58.95 - validation loss: 0.90887 - validation accuracy: 66.89 \n",
      "[4,     1] loss: 1.03317, adv_train_accuracy: 58.20, clean_train_accuracy : 86.33\n",
      "[4,     6] loss: 1.06572, adv_train_accuracy: 59.77, clean_train_accuracy : 88.67\n",
      "[4,    11] loss: 0.97861, adv_train_accuracy: 63.67, clean_train_accuracy : 87.11\n",
      "[4,    16] loss: 0.99342, adv_train_accuracy: 61.33, clean_train_accuracy : 87.11\n",
      "0.595703125\n",
      "0.66796875\n",
      "duration: 26 s - train loss: 1.00874 - train accuracy: 60.47 - validation loss: 0.85558 - validation accuracy: 69.71 \n",
      "[5,     1] loss: 0.95292, adv_train_accuracy: 64.45, clean_train_accuracy : 86.33\n",
      "[5,     6] loss: 0.91793, adv_train_accuracy: 63.28, clean_train_accuracy : 91.80\n",
      "[5,    11] loss: 0.96122, adv_train_accuracy: 64.84, clean_train_accuracy : 88.67\n",
      "[5,    16] loss: 0.92535, adv_train_accuracy: 62.50, clean_train_accuracy : 93.75\n",
      "0.611328125\n",
      "0.638671875\n",
      "duration: 26 s - train loss: 0.98834 - train accuracy: 60.90 - validation loss: 0.86461 - validation accuracy: 70.05 \n",
      "[6,     1] loss: 0.95891, adv_train_accuracy: 66.02, clean_train_accuracy : 90.62\n",
      "[6,     6] loss: 0.99805, adv_train_accuracy: 61.33, clean_train_accuracy : 87.11\n",
      "[6,    11] loss: 0.99139, adv_train_accuracy: 63.67, clean_train_accuracy : 89.84\n",
      "[6,    16] loss: 1.01494, adv_train_accuracy: 62.11, clean_train_accuracy : 87.50\n",
      "0.638671875\n",
      "0.671875\n",
      "duration: 26 s - train loss: 1.00367 - train accuracy: 61.09 - validation loss: 0.88593 - validation accuracy: 69.47 \n",
      "[7,     1] loss: 0.95291, adv_train_accuracy: 69.92, clean_train_accuracy : 92.19\n",
      "[7,     6] loss: 0.91610, adv_train_accuracy: 62.50, clean_train_accuracy : 89.84\n",
      "[7,    11] loss: 1.01759, adv_train_accuracy: 58.98, clean_train_accuracy : 89.84\n",
      "[7,    16] loss: 1.00396, adv_train_accuracy: 60.94, clean_train_accuracy : 87.89\n",
      "0.626953125\n",
      "0.66015625\n",
      "duration: 26 s - train loss: 0.99808 - train accuracy: 61.07 - validation loss: 0.85791 - validation accuracy: 70.96 \n",
      "[8,     1] loss: 0.92300, adv_train_accuracy: 64.84, clean_train_accuracy : 90.23\n",
      "[8,     6] loss: 1.03265, adv_train_accuracy: 57.42, clean_train_accuracy : 88.67\n",
      "[8,    11] loss: 1.01625, adv_train_accuracy: 60.55, clean_train_accuracy : 87.11\n",
      "[8,    16] loss: 0.91513, adv_train_accuracy: 62.50, clean_train_accuracy : 86.72\n",
      "0.634765625\n",
      "0.732421875\n",
      "duration: 26 s - train loss: 1.01339 - train accuracy: 60.23 - validation loss: 0.86707 - validation accuracy: 70.22 \n",
      "[9,     1] loss: 0.96000, adv_train_accuracy: 60.16, clean_train_accuracy : 90.62\n",
      "[9,     6] loss: 0.91153, adv_train_accuracy: 65.62, clean_train_accuracy : 90.23\n",
      "[9,    11] loss: 1.05495, adv_train_accuracy: 57.03, clean_train_accuracy : 87.50\n",
      "[9,    16] loss: 0.97640, adv_train_accuracy: 60.55, clean_train_accuracy : 91.80\n",
      "0.6328125\n",
      "0.6640625\n",
      "duration: 26 s - train loss: 0.99722 - train accuracy: 61.60 - validation loss: 0.86766 - validation accuracy: 70.05 \n",
      "[10,     1] loss: 1.01874, adv_train_accuracy: 60.16, clean_train_accuracy : 87.50\n",
      "[10,     6] loss: 0.96138, adv_train_accuracy: 61.33, clean_train_accuracy : 89.06\n",
      "[10,    11] loss: 0.92823, adv_train_accuracy: 60.55, clean_train_accuracy : 91.02\n",
      "[10,    16] loss: 0.99498, adv_train_accuracy: 59.77, clean_train_accuracy : 88.67\n",
      "0.6171875\n",
      "0.654296875\n",
      "duration: 26 s - train loss: 0.97240 - train accuracy: 61.76 - validation loss: 0.92013 - validation accuracy: 68.48 \n",
      "[11,     1] loss: 0.98762, adv_train_accuracy: 62.89, clean_train_accuracy : 85.94\n",
      "[11,     6] loss: 0.93433, adv_train_accuracy: 57.42, clean_train_accuracy : 86.72\n",
      "[11,    11] loss: 0.85417, adv_train_accuracy: 65.62, clean_train_accuracy : 92.19\n",
      "[11,    16] loss: 1.01743, adv_train_accuracy: 59.38, clean_train_accuracy : 88.67\n",
      "0.642578125\n",
      "0.69140625\n",
      "duration: 26 s - train loss: 0.98325 - train accuracy: 61.13 - validation loss: 0.89255 - validation accuracy: 69.16 \n",
      "[12,     1] loss: 0.91803, adv_train_accuracy: 65.23, clean_train_accuracy : 89.06\n",
      "[12,     6] loss: 0.91395, adv_train_accuracy: 64.84, clean_train_accuracy : 89.45\n",
      "[12,    11] loss: 0.86533, adv_train_accuracy: 65.23, clean_train_accuracy : 91.41\n",
      "[12,    16] loss: 1.05935, adv_train_accuracy: 61.72, clean_train_accuracy : 88.28\n",
      "0.66015625\n",
      "0.712890625\n",
      "duration: 26 s - train loss: 0.95306 - train accuracy: 62.23 - validation loss: 0.89348 - validation accuracy: 68.36 \n",
      "[13,     1] loss: 0.98845, adv_train_accuracy: 57.81, clean_train_accuracy : 90.23\n",
      "[13,     6] loss: 0.92600, adv_train_accuracy: 61.33, clean_train_accuracy : 87.89\n",
      "[13,    11] loss: 0.95367, adv_train_accuracy: 62.50, clean_train_accuracy : 90.62\n",
      "[13,    16] loss: 1.00346, adv_train_accuracy: 57.03, clean_train_accuracy : 90.62\n",
      "0.642578125\n",
      "0.640625\n",
      "duration: 26 s - train loss: 0.93790 - train accuracy: 62.75 - validation loss: 0.85127 - validation accuracy: 71.32 \n",
      "[14,     1] loss: 1.06399, adv_train_accuracy: 61.72, clean_train_accuracy : 90.62\n",
      "[14,     6] loss: 0.91357, adv_train_accuracy: 62.50, clean_train_accuracy : 90.62\n",
      "[14,    11] loss: 0.99875, adv_train_accuracy: 59.38, clean_train_accuracy : 91.41\n",
      "[14,    16] loss: 0.91830, adv_train_accuracy: 60.16, clean_train_accuracy : 92.58\n",
      "0.60546875\n",
      "0.68359375\n",
      "duration: 25 s - train loss: 0.95398 - train accuracy: 62.03 - validation loss: 0.86784 - validation accuracy: 69.84 \n",
      "[15,     1] loss: 0.92308, adv_train_accuracy: 64.84, clean_train_accuracy : 88.67\n",
      "[15,     6] loss: 0.80703, adv_train_accuracy: 66.41, clean_train_accuracy : 93.36\n",
      "[15,    11] loss: 0.96332, adv_train_accuracy: 62.11, clean_train_accuracy : 87.50\n",
      "[15,    16] loss: 0.97944, adv_train_accuracy: 62.89, clean_train_accuracy : 89.06\n",
      "0.62109375\n",
      "0.67578125\n",
      "duration: 26 s - train loss: 0.91088 - train accuracy: 64.10 - validation loss: 0.87150 - validation accuracy: 69.75 \n",
      "[16,     1] loss: 0.98461, adv_train_accuracy: 64.45, clean_train_accuracy : 91.80\n",
      "[16,     6] loss: 0.92101, adv_train_accuracy: 65.23, clean_train_accuracy : 89.06\n",
      "[16,    11] loss: 0.96812, adv_train_accuracy: 61.33, clean_train_accuracy : 85.94\n",
      "[16,    16] loss: 0.82039, adv_train_accuracy: 66.41, clean_train_accuracy : 93.36\n",
      "0.63671875\n",
      "0.69140625\n",
      "duration: 26 s - train loss: 0.95091 - train accuracy: 63.55 - validation loss: 0.85637 - validation accuracy: 70.65 \n",
      "[17,     1] loss: 0.91854, adv_train_accuracy: 67.19, clean_train_accuracy : 89.84\n",
      "[17,     6] loss: 0.97157, adv_train_accuracy: 60.55, clean_train_accuracy : 89.06\n",
      "[17,    11] loss: 1.08055, adv_train_accuracy: 62.89, clean_train_accuracy : 87.50\n",
      "[17,    16] loss: 0.93492, adv_train_accuracy: 66.02, clean_train_accuracy : 88.67\n",
      "0.646484375\n",
      "0.716796875\n",
      "duration: 26 s - train loss: 0.93282 - train accuracy: 64.28 - validation loss: 0.86056 - validation accuracy: 70.14 \n",
      "[18,     1] loss: 0.95719, adv_train_accuracy: 62.11, clean_train_accuracy : 90.23\n",
      "[18,     6] loss: 0.71832, adv_train_accuracy: 71.09, clean_train_accuracy : 93.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 0.98170, adv_train_accuracy: 60.55, clean_train_accuracy : 91.41\n",
      "[18,    16] loss: 0.96298, adv_train_accuracy: 60.94, clean_train_accuracy : 89.84\n",
      "0.66796875\n",
      "0.72265625\n",
      "duration: 26 s - train loss: 0.91901 - train accuracy: 63.32 - validation loss: 0.89037 - validation accuracy: 69.97 \n",
      "[19,     1] loss: 0.96723, adv_train_accuracy: 63.67, clean_train_accuracy : 89.84\n",
      "[19,     6] loss: 0.84840, adv_train_accuracy: 62.89, clean_train_accuracy : 93.36\n",
      "[19,    11] loss: 0.93357, adv_train_accuracy: 64.84, clean_train_accuracy : 92.19\n",
      "[19,    16] loss: 0.81831, adv_train_accuracy: 68.36, clean_train_accuracy : 91.41\n",
      "0.65234375\n",
      "0.66015625\n",
      "duration: 26 s - train loss: 0.92387 - train accuracy: 63.75 - validation loss: 0.80815 - validation accuracy: 71.44 \n",
      "[20,     1] loss: 0.84031, adv_train_accuracy: 65.62, clean_train_accuracy : 89.84\n",
      "[20,     6] loss: 0.88464, adv_train_accuracy: 64.45, clean_train_accuracy : 91.80\n",
      "[20,    11] loss: 0.84951, adv_train_accuracy: 60.55, clean_train_accuracy : 92.19\n",
      "[20,    16] loss: 0.92161, adv_train_accuracy: 62.50, clean_train_accuracy : 89.45\n",
      "0.60546875\n",
      "0.703125\n",
      "duration: 26 s - train loss: 0.87420 - train accuracy: 63.93 - validation loss: 0.86645 - validation accuracy: 70.23 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>16</td>\n",
       "      <td>0.950915</td>\n",
       "      <td>63.554688</td>\n",
       "      <td>0.856370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.65</td>\n",
       "      <td>418.153418</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>17</td>\n",
       "      <td>0.932820</td>\n",
       "      <td>64.277344</td>\n",
       "      <td>0.860561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.14</td>\n",
       "      <td>444.185078</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>18</td>\n",
       "      <td>0.919010</td>\n",
       "      <td>63.320312</td>\n",
       "      <td>0.890369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.97</td>\n",
       "      <td>470.291247</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>19</td>\n",
       "      <td>0.923873</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>0.808147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.44</td>\n",
       "      <td>496.387788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>20</td>\n",
       "      <td>0.874197</td>\n",
       "      <td>63.925781</td>\n",
       "      <td>0.866450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.23</td>\n",
       "      <td>522.492948</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "155    16    0.950915       63.554688         0.856370               NaN   \n",
       "156    17    0.932820       64.277344         0.860561               NaN   \n",
       "157    18    0.919010       63.320312         0.890369               NaN   \n",
       "158    19    0.923873       63.750000         0.808147               NaN   \n",
       "159    20    0.874197       63.925781         0.866450               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "155         NaN             NaN       NaN             NaN       NaN   \n",
       "156         NaN             NaN       NaN             NaN       NaN   \n",
       "157         NaN             NaN       NaN             NaN       NaN   \n",
       "158         NaN             NaN       NaN             NaN       NaN   \n",
       "159         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "155                70.65  418.153418  CrossEntropyLoss()   \n",
       "156                70.14  444.185078  CrossEntropyLoss()   \n",
       "157                69.97  470.291247  CrossEntropyLoss()   \n",
       "158                71.44  496.387788  CrossEntropyLoss()   \n",
       "159                70.23  522.492948  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "155  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "156  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "157  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "158  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "159  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "155            NaN       256  \n",
       "156            NaN       256  \n",
       "157            NaN       256  \n",
       "158            NaN       256  \n",
       "159            NaN       256  \n",
       "\n",
       "[160 rows x 17 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6171875"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.708984375"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 0.96365, adv_train_accuracy: 60.55, clean_train_accuracy : 91.80\n",
      "[1,     6] loss: 0.98749, adv_train_accuracy: 59.38, clean_train_accuracy : 88.28\n",
      "[1,    11] loss: 0.83071, adv_train_accuracy: 67.19, clean_train_accuracy : 94.92\n",
      "[1,    16] loss: 0.89571, adv_train_accuracy: 64.06, clean_train_accuracy : 92.58\n",
      "0.650390625\n",
      "0.720703125\n",
      "duration: 26 s - train loss: 0.88619 - train accuracy: 64.59 - validation loss: 0.80657 - validation accuracy: 72.25 \n",
      "[2,     1] loss: 0.87608, adv_train_accuracy: 66.80, clean_train_accuracy : 92.58\n",
      "[2,     6] loss: 0.81441, adv_train_accuracy: 67.19, clean_train_accuracy : 94.14\n",
      "[2,    11] loss: 0.94616, adv_train_accuracy: 63.28, clean_train_accuracy : 92.19\n",
      "[2,    16] loss: 0.95136, adv_train_accuracy: 62.11, clean_train_accuracy : 89.84\n",
      "0.619140625\n",
      "0.71875\n",
      "duration: 26 s - train loss: 0.86666 - train accuracy: 65.98 - validation loss: 0.87497 - validation accuracy: 70.30 \n",
      "[3,     1] loss: 0.78451, adv_train_accuracy: 67.58, clean_train_accuracy : 93.75\n",
      "[3,     6] loss: 0.82922, adv_train_accuracy: 66.80, clean_train_accuracy : 94.53\n",
      "[3,    11] loss: 0.85595, adv_train_accuracy: 66.41, clean_train_accuracy : 92.58\n",
      "[3,    16] loss: 0.87138, adv_train_accuracy: 65.62, clean_train_accuracy : 92.19\n",
      "0.66796875\n",
      "0.693359375\n",
      "duration: 26 s - train loss: 0.85036 - train accuracy: 65.45 - validation loss: 0.89042 - validation accuracy: 69.58 \n",
      "[4,     1] loss: 0.82743, adv_train_accuracy: 66.80, clean_train_accuracy : 94.53\n",
      "[4,     6] loss: 0.88877, adv_train_accuracy: 65.23, clean_train_accuracy : 91.41\n",
      "[4,    11] loss: 0.91631, adv_train_accuracy: 64.84, clean_train_accuracy : 92.58\n",
      "[4,    16] loss: 0.92057, adv_train_accuracy: 62.50, clean_train_accuracy : 88.67\n",
      "0.640625\n",
      "0.6953125\n",
      "duration: 26 s - train loss: 0.90423 - train accuracy: 64.65 - validation loss: 0.84217 - validation accuracy: 71.21 \n",
      "[5,     1] loss: 0.93011, adv_train_accuracy: 63.28, clean_train_accuracy : 90.23\n",
      "[5,     6] loss: 0.79604, adv_train_accuracy: 64.84, clean_train_accuracy : 92.97\n",
      "[5,    11] loss: 0.78686, adv_train_accuracy: 69.14, clean_train_accuracy : 93.36\n",
      "[5,    16] loss: 0.78011, adv_train_accuracy: 68.75, clean_train_accuracy : 92.58\n",
      "0.623046875\n",
      "0.681640625\n",
      "duration: 26 s - train loss: 0.84907 - train accuracy: 66.46 - validation loss: 0.85828 - validation accuracy: 70.21 \n",
      "[6,     1] loss: 0.82085, adv_train_accuracy: 70.31, clean_train_accuracy : 92.97\n",
      "[6,     6] loss: 0.86247, adv_train_accuracy: 66.02, clean_train_accuracy : 89.45\n",
      "[6,    11] loss: 0.76018, adv_train_accuracy: 73.44, clean_train_accuracy : 91.02\n",
      "[6,    16] loss: 0.73099, adv_train_accuracy: 73.44, clean_train_accuracy : 95.70\n",
      "0.63671875\n",
      "0.71484375\n",
      "duration: 26 s - train loss: 0.82813 - train accuracy: 67.56 - validation loss: 0.82327 - validation accuracy: 72.12 \n",
      "[7,     1] loss: 0.81703, adv_train_accuracy: 67.19, clean_train_accuracy : 94.14\n",
      "[7,     6] loss: 0.82108, adv_train_accuracy: 67.19, clean_train_accuracy : 92.58\n",
      "[7,    11] loss: 0.90235, adv_train_accuracy: 62.89, clean_train_accuracy : 92.58\n",
      "[7,    16] loss: 0.86792, adv_train_accuracy: 67.19, clean_train_accuracy : 94.14\n",
      "0.640625\n",
      "0.705078125\n",
      "duration: 26 s - train loss: 0.84263 - train accuracy: 66.02 - validation loss: 0.88764 - validation accuracy: 70.06 \n",
      "[8,     1] loss: 0.76560, adv_train_accuracy: 69.92, clean_train_accuracy : 95.70\n",
      "[8,     6] loss: 0.90083, adv_train_accuracy: 61.33, clean_train_accuracy : 92.58\n",
      "[8,    11] loss: 0.84365, adv_train_accuracy: 65.62, clean_train_accuracy : 93.75\n",
      "[8,    16] loss: 0.91460, adv_train_accuracy: 63.67, clean_train_accuracy : 91.41\n",
      "0.64453125\n",
      "0.703125\n",
      "duration: 25 s - train loss: 0.87629 - train accuracy: 65.43 - validation loss: 0.91184 - validation accuracy: 68.03 \n",
      "[9,     1] loss: 1.01768, adv_train_accuracy: 61.72, clean_train_accuracy : 89.84\n",
      "[9,     6] loss: 0.68143, adv_train_accuracy: 73.05, clean_train_accuracy : 96.88\n",
      "[9,    11] loss: 0.78615, adv_train_accuracy: 68.75, clean_train_accuracy : 92.58\n",
      "[9,    16] loss: 0.87450, adv_train_accuracy: 67.97, clean_train_accuracy : 92.97\n",
      "0.640625\n",
      "0.69921875\n",
      "duration: 26 s - train loss: 0.83072 - train accuracy: 67.62 - validation loss: 0.91515 - validation accuracy: 68.52 \n",
      "[10,     1] loss: 0.77810, adv_train_accuracy: 73.05, clean_train_accuracy : 95.31\n",
      "[10,     6] loss: 0.79920, adv_train_accuracy: 70.70, clean_train_accuracy : 94.92\n",
      "[10,    11] loss: 0.77483, adv_train_accuracy: 67.19, clean_train_accuracy : 95.31\n",
      "[10,    16] loss: 0.70258, adv_train_accuracy: 71.48, clean_train_accuracy : 92.58\n",
      "0.623046875\n",
      "0.7109375\n",
      "duration: 26 s - train loss: 0.83256 - train accuracy: 67.32 - validation loss: 0.83685 - validation accuracy: 71.96 \n",
      "[11,     1] loss: 0.77043, adv_train_accuracy: 68.75, clean_train_accuracy : 93.36\n",
      "[11,     6] loss: 0.77690, adv_train_accuracy: 67.58, clean_train_accuracy : 93.75\n",
      "[11,    11] loss: 0.81598, adv_train_accuracy: 68.36, clean_train_accuracy : 93.36\n",
      "[11,    16] loss: 0.72822, adv_train_accuracy: 70.70, clean_train_accuracy : 94.14\n",
      "0.6171875\n",
      "0.69140625\n",
      "duration: 26 s - train loss: 0.79459 - train accuracy: 68.16 - validation loss: 0.88516 - validation accuracy: 68.96 \n",
      "[12,     1] loss: 0.82532, adv_train_accuracy: 70.70, clean_train_accuracy : 92.58\n",
      "[12,     6] loss: 0.78830, adv_train_accuracy: 66.02, clean_train_accuracy : 95.31\n",
      "[12,    11] loss: 0.76773, adv_train_accuracy: 70.31, clean_train_accuracy : 92.97\n",
      "[12,    16] loss: 0.79158, adv_train_accuracy: 67.97, clean_train_accuracy : 87.50\n",
      "0.63671875\n",
      "0.689453125\n",
      "duration: 26 s - train loss: 0.81270 - train accuracy: 67.62 - validation loss: 0.82287 - validation accuracy: 71.09 \n",
      "[13,     1] loss: 0.70243, adv_train_accuracy: 75.39, clean_train_accuracy : 92.19\n",
      "[13,     6] loss: 0.83501, adv_train_accuracy: 67.19, clean_train_accuracy : 94.14\n",
      "[13,    11] loss: 0.69460, adv_train_accuracy: 72.66, clean_train_accuracy : 96.48\n",
      "[13,    16] loss: 0.78163, adv_train_accuracy: 70.70, clean_train_accuracy : 94.53\n",
      "0.623046875\n",
      "0.69140625\n",
      "duration: 26 s - train loss: 0.78081 - train accuracy: 68.98 - validation loss: 0.81920 - validation accuracy: 72.19 \n",
      "[14,     1] loss: 0.77457, adv_train_accuracy: 69.14, clean_train_accuracy : 92.19\n",
      "[14,     6] loss: 0.74582, adv_train_accuracy: 69.53, clean_train_accuracy : 92.58\n",
      "[14,    11] loss: 0.85961, adv_train_accuracy: 64.06, clean_train_accuracy : 93.36\n",
      "[14,    16] loss: 0.83721, adv_train_accuracy: 67.19, clean_train_accuracy : 96.48\n",
      "0.630859375\n",
      "0.708984375\n",
      "duration: 26 s - train loss: 0.79048 - train accuracy: 68.30 - validation loss: 0.88854 - validation accuracy: 69.81 \n",
      "[15,     1] loss: 0.68241, adv_train_accuracy: 74.22, clean_train_accuracy : 94.92\n",
      "[15,     6] loss: 0.83755, adv_train_accuracy: 66.02, clean_train_accuracy : 93.75\n",
      "[15,    11] loss: 0.79071, adv_train_accuracy: 67.97, clean_train_accuracy : 90.62\n",
      "[15,    16] loss: 0.77827, adv_train_accuracy: 71.09, clean_train_accuracy : 94.92\n",
      "0.65625\n",
      "0.7109375\n",
      "duration: 26 s - train loss: 0.74999 - train accuracy: 70.02 - validation loss: 0.81505 - validation accuracy: 71.31 \n",
      "[16,     1] loss: 0.76672, adv_train_accuracy: 70.31, clean_train_accuracy : 94.14\n",
      "[16,     6] loss: 0.74262, adv_train_accuracy: 68.36, clean_train_accuracy : 93.36\n",
      "[16,    11] loss: 0.71562, adv_train_accuracy: 71.09, clean_train_accuracy : 94.14\n",
      "[16,    16] loss: 0.79536, adv_train_accuracy: 72.66, clean_train_accuracy : 92.97\n",
      "0.65234375\n",
      "0.724609375\n",
      "duration: 26 s - train loss: 0.74604 - train accuracy: 70.20 - validation loss: 0.85777 - validation accuracy: 71.64 \n",
      "[17,     1] loss: 0.69874, adv_train_accuracy: 72.27, clean_train_accuracy : 93.36\n",
      "[17,     6] loss: 0.77352, adv_train_accuracy: 68.36, clean_train_accuracy : 92.97\n",
      "[17,    11] loss: 0.78920, adv_train_accuracy: 70.70, clean_train_accuracy : 94.92\n",
      "[17,    16] loss: 0.69927, adv_train_accuracy: 71.88, clean_train_accuracy : 94.53\n",
      "0.626953125\n",
      "0.701171875\n",
      "duration: 26 s - train loss: 0.74882 - train accuracy: 70.55 - validation loss: 0.84682 - validation accuracy: 71.79 \n",
      "[18,     1] loss: 0.68979, adv_train_accuracy: 70.70, clean_train_accuracy : 94.53\n",
      "[18,     6] loss: 0.72420, adv_train_accuracy: 65.23, clean_train_accuracy : 96.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 0.85724, adv_train_accuracy: 62.89, clean_train_accuracy : 93.36\n",
      "[18,    16] loss: 0.88682, adv_train_accuracy: 66.80, clean_train_accuracy : 96.09\n",
      "0.6328125\n",
      "0.69140625\n",
      "duration: 25 s - train loss: 0.77000 - train accuracy: 69.47 - validation loss: 0.80986 - validation accuracy: 72.00 \n",
      "[19,     1] loss: 0.77270, adv_train_accuracy: 69.53, clean_train_accuracy : 92.97\n",
      "[19,     6] loss: 0.73194, adv_train_accuracy: 67.58, clean_train_accuracy : 96.48\n",
      "[19,    11] loss: 0.76781, adv_train_accuracy: 69.53, clean_train_accuracy : 94.53\n",
      "[19,    16] loss: 0.73052, adv_train_accuracy: 66.80, clean_train_accuracy : 93.75\n",
      "0.626953125\n",
      "0.728515625\n",
      "duration: 26 s - train loss: 0.74533 - train accuracy: 70.41 - validation loss: 0.87843 - validation accuracy: 69.92 \n",
      "[20,     1] loss: 0.82348, adv_train_accuracy: 68.36, clean_train_accuracy : 93.75\n",
      "[20,     6] loss: 0.76649, adv_train_accuracy: 67.19, clean_train_accuracy : 96.09\n",
      "[20,    11] loss: 0.67070, adv_train_accuracy: 73.83, clean_train_accuracy : 96.88\n",
      "[20,    16] loss: 0.67503, adv_train_accuracy: 76.56, clean_train_accuracy : 96.09\n",
      "0.642578125\n",
      "0.6875\n",
      "duration: 26 s - train loss: 0.75661 - train accuracy: 70.76 - validation loss: 0.94395 - validation accuracy: 68.45 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>16</td>\n",
       "      <td>0.746039</td>\n",
       "      <td>70.195312</td>\n",
       "      <td>0.857765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.64</td>\n",
       "      <td>417.692805</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>17</td>\n",
       "      <td>0.748815</td>\n",
       "      <td>70.546875</td>\n",
       "      <td>0.846822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.79</td>\n",
       "      <td>443.754564</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>18</td>\n",
       "      <td>0.769998</td>\n",
       "      <td>69.472656</td>\n",
       "      <td>0.809857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.00</td>\n",
       "      <td>469.738376</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>19</td>\n",
       "      <td>0.745331</td>\n",
       "      <td>70.410156</td>\n",
       "      <td>0.878433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.92</td>\n",
       "      <td>495.880868</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>20</td>\n",
       "      <td>0.756608</td>\n",
       "      <td>70.761719</td>\n",
       "      <td>0.943955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.45</td>\n",
       "      <td>522.012512</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "175    16    0.746039       70.195312         0.857765               NaN   \n",
       "176    17    0.748815       70.546875         0.846822               NaN   \n",
       "177    18    0.769998       69.472656         0.809857               NaN   \n",
       "178    19    0.745331       70.410156         0.878433               NaN   \n",
       "179    20    0.756608       70.761719         0.943955               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "175         NaN             NaN       NaN             NaN       NaN   \n",
       "176         NaN             NaN       NaN             NaN       NaN   \n",
       "177         NaN             NaN       NaN             NaN       NaN   \n",
       "178         NaN             NaN       NaN             NaN       NaN   \n",
       "179         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "175                71.64  417.692805  CrossEntropyLoss()   \n",
       "176                71.79  443.754564  CrossEntropyLoss()   \n",
       "177                72.00  469.738376  CrossEntropyLoss()   \n",
       "178                69.92  495.880868  CrossEntropyLoss()   \n",
       "179                68.45  522.012512  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "175  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "176  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "177  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "178  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "179  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "175            NaN       256  \n",
       "176            NaN       256  \n",
       "177            NaN       256  \n",
       "178            NaN       256  \n",
       "179            NaN       256  \n",
       "\n",
       "[180 rows x 17 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.654296875"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.701171875"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 0.76576, adv_train_accuracy: 69.92, clean_train_accuracy : 97.66\n",
      "[1,     6] loss: 0.64834, adv_train_accuracy: 75.39, clean_train_accuracy : 95.31\n",
      "[1,    11] loss: 0.90028, adv_train_accuracy: 64.45, clean_train_accuracy : 92.19\n",
      "[1,    16] loss: 0.68982, adv_train_accuracy: 75.78, clean_train_accuracy : 97.27\n",
      "0.6640625\n",
      "0.697265625\n",
      "duration: 26 s - train loss: 0.74073 - train accuracy: 71.82 - validation loss: 0.85591 - validation accuracy: 72.08 \n",
      "[2,     1] loss: 0.66916, adv_train_accuracy: 72.66, clean_train_accuracy : 96.09\n",
      "[2,     6] loss: 0.87002, adv_train_accuracy: 66.41, clean_train_accuracy : 92.19\n",
      "[2,    11] loss: 0.74187, adv_train_accuracy: 70.70, clean_train_accuracy : 96.09\n",
      "[2,    16] loss: 0.77975, adv_train_accuracy: 67.19, clean_train_accuracy : 96.09\n",
      "0.701171875\n",
      "0.72265625\n",
      "duration: 26 s - train loss: 0.76114 - train accuracy: 69.00 - validation loss: 0.94977 - validation accuracy: 67.78 \n",
      "[3,     1] loss: 0.80569, adv_train_accuracy: 69.53, clean_train_accuracy : 94.14\n",
      "[3,     6] loss: 0.71227, adv_train_accuracy: 71.09, clean_train_accuracy : 92.58\n",
      "[3,    11] loss: 0.62323, adv_train_accuracy: 77.34, clean_train_accuracy : 96.48\n",
      "[3,    16] loss: 0.76840, adv_train_accuracy: 69.14, clean_train_accuracy : 95.31\n",
      "0.6484375\n",
      "0.728515625\n",
      "duration: 26 s - train loss: 0.73010 - train accuracy: 70.61 - validation loss: 0.93866 - validation accuracy: 68.66 \n",
      "[4,     1] loss: 0.70786, adv_train_accuracy: 70.31, clean_train_accuracy : 95.31\n",
      "[4,     6] loss: 0.71775, adv_train_accuracy: 70.31, clean_train_accuracy : 95.70\n",
      "[4,    11] loss: 0.65045, adv_train_accuracy: 73.44, clean_train_accuracy : 96.09\n",
      "[4,    16] loss: 0.84889, adv_train_accuracy: 69.14, clean_train_accuracy : 91.41\n",
      "0.634765625\n",
      "0.73046875\n",
      "duration: 26 s - train loss: 0.71751 - train accuracy: 71.31 - validation loss: 0.90027 - validation accuracy: 70.20 \n",
      "[5,     1] loss: 0.75717, adv_train_accuracy: 69.92, clean_train_accuracy : 95.31\n",
      "[5,     6] loss: 0.68036, adv_train_accuracy: 72.27, clean_train_accuracy : 95.31\n",
      "[5,    11] loss: 0.63067, adv_train_accuracy: 73.83, clean_train_accuracy : 96.09\n",
      "[5,    16] loss: 0.74091, adv_train_accuracy: 69.92, clean_train_accuracy : 92.97\n",
      "0.6328125\n",
      "0.6953125\n",
      "duration: 26 s - train loss: 0.70130 - train accuracy: 71.52 - validation loss: 0.88398 - validation accuracy: 70.17 \n",
      "[6,     1] loss: 0.67355, adv_train_accuracy: 73.44, clean_train_accuracy : 92.97\n",
      "[6,     6] loss: 0.71790, adv_train_accuracy: 68.75, clean_train_accuracy : 95.31\n",
      "[6,    11] loss: 0.76458, adv_train_accuracy: 68.36, clean_train_accuracy : 89.84\n",
      "[6,    16] loss: 0.68913, adv_train_accuracy: 73.44, clean_train_accuracy : 93.36\n",
      "0.671875\n",
      "0.693359375\n",
      "duration: 26 s - train loss: 0.71993 - train accuracy: 70.90 - validation loss: 0.78195 - validation accuracy: 73.01 \n",
      "[7,     1] loss: 0.68085, adv_train_accuracy: 71.88, clean_train_accuracy : 94.92\n",
      "[7,     6] loss: 0.71757, adv_train_accuracy: 71.09, clean_train_accuracy : 96.09\n",
      "[7,    11] loss: 0.73942, adv_train_accuracy: 70.70, clean_train_accuracy : 95.31\n",
      "[7,    16] loss: 0.69624, adv_train_accuracy: 70.31, clean_train_accuracy : 93.75\n",
      "0.62890625\n",
      "0.6875\n",
      "duration: 26 s - train loss: 0.66298 - train accuracy: 73.01 - validation loss: 0.84190 - validation accuracy: 72.31 \n",
      "[8,     1] loss: 0.56591, adv_train_accuracy: 78.12, clean_train_accuracy : 98.05\n",
      "[8,     6] loss: 0.64860, adv_train_accuracy: 71.48, clean_train_accuracy : 95.70\n",
      "[8,    11] loss: 0.62749, adv_train_accuracy: 76.95, clean_train_accuracy : 96.88\n",
      "[8,    16] loss: 0.69712, adv_train_accuracy: 74.22, clean_train_accuracy : 95.31\n",
      "0.6640625\n",
      "0.736328125\n",
      "duration: 26 s - train loss: 0.63830 - train accuracy: 74.90 - validation loss: 0.85140 - validation accuracy: 71.83 \n",
      "[9,     1] loss: 0.61797, adv_train_accuracy: 75.78, clean_train_accuracy : 95.70\n",
      "[9,     6] loss: 0.68020, adv_train_accuracy: 68.36, clean_train_accuracy : 94.14\n",
      "[9,    11] loss: 0.70900, adv_train_accuracy: 71.09, clean_train_accuracy : 94.92\n",
      "[9,    16] loss: 0.64520, adv_train_accuracy: 71.48, clean_train_accuracy : 95.31\n",
      "0.662109375\n",
      "0.701171875\n",
      "duration: 26 s - train loss: 0.65965 - train accuracy: 72.54 - validation loss: 0.87037 - validation accuracy: 70.44 \n",
      "[10,     1] loss: 0.56720, adv_train_accuracy: 75.78, clean_train_accuracy : 97.66\n",
      "[10,     6] loss: 0.61575, adv_train_accuracy: 75.39, clean_train_accuracy : 96.88\n",
      "[10,    11] loss: 0.65104, adv_train_accuracy: 73.83, clean_train_accuracy : 94.92\n",
      "[10,    16] loss: 0.61637, adv_train_accuracy: 73.44, clean_train_accuracy : 97.66\n",
      "0.64453125\n",
      "0.73828125\n",
      "duration: 26 s - train loss: 0.63275 - train accuracy: 74.08 - validation loss: 0.81368 - validation accuracy: 72.88 \n",
      "[11,     1] loss: 0.52047, adv_train_accuracy: 78.91, clean_train_accuracy : 98.44\n",
      "[11,     6] loss: 0.70734, adv_train_accuracy: 70.31, clean_train_accuracy : 95.70\n",
      "[11,    11] loss: 0.63824, adv_train_accuracy: 74.61, clean_train_accuracy : 96.48\n",
      "[11,    16] loss: 0.57667, adv_train_accuracy: 78.12, clean_train_accuracy : 96.09\n",
      "0.673828125\n",
      "0.712890625\n",
      "duration: 26 s - train loss: 0.62457 - train accuracy: 74.59 - validation loss: 0.83645 - validation accuracy: 71.87 \n",
      "[12,     1] loss: 0.66786, adv_train_accuracy: 74.22, clean_train_accuracy : 94.53\n",
      "[12,     6] loss: 0.60334, adv_train_accuracy: 75.39, clean_train_accuracy : 97.66\n",
      "[12,    11] loss: 0.62842, adv_train_accuracy: 75.00, clean_train_accuracy : 96.09\n",
      "[12,    16] loss: 0.59539, adv_train_accuracy: 77.34, clean_train_accuracy : 96.88\n",
      "0.64453125\n",
      "0.681640625\n",
      "duration: 26 s - train loss: 0.63422 - train accuracy: 74.86 - validation loss: 0.83809 - validation accuracy: 70.49 \n",
      "[13,     1] loss: 0.66642, adv_train_accuracy: 73.05, clean_train_accuracy : 97.27\n",
      "[13,     6] loss: 0.66662, adv_train_accuracy: 77.73, clean_train_accuracy : 96.88\n",
      "[13,    11] loss: 0.65699, adv_train_accuracy: 72.27, clean_train_accuracy : 96.48\n",
      "[13,    16] loss: 0.74030, adv_train_accuracy: 75.00, clean_train_accuracy : 94.92\n",
      "0.65234375\n",
      "0.705078125\n",
      "duration: 26 s - train loss: 0.68347 - train accuracy: 73.26 - validation loss: 0.82514 - validation accuracy: 71.41 \n",
      "[14,     1] loss: 0.62449, adv_train_accuracy: 78.12, clean_train_accuracy : 97.27\n",
      "[14,     6] loss: 0.68919, adv_train_accuracy: 73.44, clean_train_accuracy : 94.14\n",
      "[14,    11] loss: 0.55387, adv_train_accuracy: 77.34, clean_train_accuracy : 98.05\n",
      "[14,    16] loss: 0.64389, adv_train_accuracy: 74.22, clean_train_accuracy : 95.70\n",
      "0.646484375\n",
      "0.697265625\n",
      "duration: 26 s - train loss: 0.63495 - train accuracy: 74.30 - validation loss: 0.90300 - validation accuracy: 69.46 \n",
      "[15,     1] loss: 0.59167, adv_train_accuracy: 78.91, clean_train_accuracy : 94.92\n",
      "[15,     6] loss: 0.61585, adv_train_accuracy: 75.78, clean_train_accuracy : 96.09\n",
      "[15,    11] loss: 0.72216, adv_train_accuracy: 71.09, clean_train_accuracy : 95.31\n",
      "[15,    16] loss: 0.68055, adv_train_accuracy: 70.70, clean_train_accuracy : 94.92\n",
      "0.673828125\n",
      "0.720703125\n",
      "duration: 26 s - train loss: 0.65728 - train accuracy: 74.14 - validation loss: 0.81401 - validation accuracy: 72.87 \n",
      "[16,     1] loss: 0.57111, adv_train_accuracy: 76.95, clean_train_accuracy : 95.70\n",
      "[16,     6] loss: 0.70381, adv_train_accuracy: 70.31, clean_train_accuracy : 96.09\n",
      "[16,    11] loss: 0.63331, adv_train_accuracy: 72.27, clean_train_accuracy : 98.05\n",
      "[16,    16] loss: 0.58849, adv_train_accuracy: 74.22, clean_train_accuracy : 97.27\n",
      "0.689453125\n",
      "0.755859375\n",
      "duration: 26 s - train loss: 0.62227 - train accuracy: 74.55 - validation loss: 0.88548 - validation accuracy: 71.29 \n",
      "[17,     1] loss: 0.55858, adv_train_accuracy: 77.34, clean_train_accuracy : 97.27\n",
      "[17,     6] loss: 0.71810, adv_train_accuracy: 70.31, clean_train_accuracy : 95.31\n",
      "[17,    11] loss: 0.64964, adv_train_accuracy: 74.22, clean_train_accuracy : 97.66\n",
      "[17,    16] loss: 0.56108, adv_train_accuracy: 78.91, clean_train_accuracy : 96.48\n",
      "0.671875\n",
      "0.6953125\n",
      "duration: 25 s - train loss: 0.62598 - train accuracy: 75.04 - validation loss: 0.90360 - validation accuracy: 68.76 \n",
      "[18,     1] loss: 0.60787, adv_train_accuracy: 73.05, clean_train_accuracy : 96.48\n",
      "[18,     6] loss: 0.79506, adv_train_accuracy: 69.14, clean_train_accuracy : 96.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 0.68884, adv_train_accuracy: 73.05, clean_train_accuracy : 97.27\n",
      "[18,    16] loss: 0.64069, adv_train_accuracy: 76.17, clean_train_accuracy : 96.48\n",
      "0.646484375\n",
      "0.748046875\n",
      "duration: 26 s - train loss: 0.65606 - train accuracy: 74.16 - validation loss: 0.81519 - validation accuracy: 73.09 \n",
      "[19,     1] loss: 0.60033, adv_train_accuracy: 80.86, clean_train_accuracy : 97.66\n",
      "[19,     6] loss: 0.60036, adv_train_accuracy: 76.17, clean_train_accuracy : 96.48\n",
      "[19,    11] loss: 0.61065, adv_train_accuracy: 73.83, clean_train_accuracy : 94.53\n",
      "[19,    16] loss: 0.62909, adv_train_accuracy: 74.22, clean_train_accuracy : 96.09\n",
      "0.67578125\n",
      "0.716796875\n",
      "duration: 26 s - train loss: 0.65540 - train accuracy: 74.90 - validation loss: 0.91048 - validation accuracy: 70.35 \n",
      "[20,     1] loss: 0.75918, adv_train_accuracy: 69.14, clean_train_accuracy : 94.53\n",
      "[20,     6] loss: 0.57296, adv_train_accuracy: 78.91, clean_train_accuracy : 94.14\n",
      "[20,    11] loss: 0.76081, adv_train_accuracy: 70.70, clean_train_accuracy : 96.09\n",
      "[20,    16] loss: 0.67183, adv_train_accuracy: 74.22, clean_train_accuracy : 96.48\n",
      "0.677734375\n",
      "0.681640625\n",
      "duration: 26 s - train loss: 0.71611 - train accuracy: 71.50 - validation loss: 0.86341 - validation accuracy: 70.72 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>16</td>\n",
       "      <td>0.622273</td>\n",
       "      <td>74.550781</td>\n",
       "      <td>0.885481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.29</td>\n",
       "      <td>417.713232</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>17</td>\n",
       "      <td>0.625979</td>\n",
       "      <td>75.039062</td>\n",
       "      <td>0.903601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.76</td>\n",
       "      <td>443.682465</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>18</td>\n",
       "      <td>0.656056</td>\n",
       "      <td>74.160156</td>\n",
       "      <td>0.815195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.09</td>\n",
       "      <td>469.757959</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>19</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>74.902344</td>\n",
       "      <td>0.910476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.35</td>\n",
       "      <td>495.855919</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>20</td>\n",
       "      <td>0.716112</td>\n",
       "      <td>71.503906</td>\n",
       "      <td>0.863413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.72</td>\n",
       "      <td>521.954188</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "195    16    0.622273       74.550781         0.885481               NaN   \n",
       "196    17    0.625979       75.039062         0.903601               NaN   \n",
       "197    18    0.656056       74.160156         0.815195               NaN   \n",
       "198    19    0.655400       74.902344         0.910476               NaN   \n",
       "199    20    0.716112       71.503906         0.863413               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "195         NaN             NaN       NaN             NaN       NaN   \n",
       "196         NaN             NaN       NaN             NaN       NaN   \n",
       "197         NaN             NaN       NaN             NaN       NaN   \n",
       "198         NaN             NaN       NaN             NaN       NaN   \n",
       "199         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "195                71.29  417.713232  CrossEntropyLoss()   \n",
       "196                68.76  443.682465  CrossEntropyLoss()   \n",
       "197                73.09  469.757959  CrossEntropyLoss()   \n",
       "198                70.35  495.855919  CrossEntropyLoss()   \n",
       "199                70.72  521.954188  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "195  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "196  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "197  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "198  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "199  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "195            NaN       256  \n",
       "196            NaN       256  \n",
       "197            NaN       256  \n",
       "198            NaN       256  \n",
       "199            NaN       256  \n",
       "\n",
       "[200 rows x 17 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.662109375"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.724609375"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 0.65127, adv_train_accuracy: 72.27, clean_train_accuracy : 96.48\n",
      "[1,     6] loss: 0.64358, adv_train_accuracy: 73.05, clean_train_accuracy : 95.31\n",
      "[1,    11] loss: 0.65540, adv_train_accuracy: 70.70, clean_train_accuracy : 94.92\n",
      "[1,    16] loss: 0.63059, adv_train_accuracy: 76.95, clean_train_accuracy : 96.88\n",
      "0.666015625\n",
      "0.740234375\n",
      "duration: 26 s - train loss: 0.65100 - train accuracy: 73.67 - validation loss: 0.90752 - validation accuracy: 70.18 \n",
      "[2,     1] loss: 0.74574, adv_train_accuracy: 73.05, clean_train_accuracy : 95.31\n",
      "[2,     6] loss: 0.62668, adv_train_accuracy: 75.39, clean_train_accuracy : 95.31\n",
      "[2,    11] loss: 0.58703, adv_train_accuracy: 75.39, clean_train_accuracy : 98.83\n",
      "[2,    16] loss: 0.53650, adv_train_accuracy: 79.30, clean_train_accuracy : 96.48\n",
      "0.640625\n",
      "0.724609375\n",
      "duration: 25 s - train loss: 0.59727 - train accuracy: 76.11 - validation loss: 0.84494 - validation accuracy: 73.09 \n",
      "[3,     1] loss: 0.51648, adv_train_accuracy: 80.08, clean_train_accuracy : 97.27\n",
      "[3,     6] loss: 0.51341, adv_train_accuracy: 83.98, clean_train_accuracy : 96.88\n",
      "[3,    11] loss: 0.61893, adv_train_accuracy: 73.83, clean_train_accuracy : 96.09\n",
      "[3,    16] loss: 0.62136, adv_train_accuracy: 77.34, clean_train_accuracy : 96.48\n",
      "0.662109375\n",
      "0.720703125\n",
      "duration: 26 s - train loss: 0.57271 - train accuracy: 77.34 - validation loss: 0.84946 - validation accuracy: 72.18 \n",
      "[4,     1] loss: 0.53230, adv_train_accuracy: 80.08, clean_train_accuracy : 98.05\n",
      "[4,     6] loss: 0.53954, adv_train_accuracy: 80.47, clean_train_accuracy : 98.05\n",
      "[4,    11] loss: 0.46530, adv_train_accuracy: 78.91, clean_train_accuracy : 99.22\n",
      "[4,    16] loss: 0.53793, adv_train_accuracy: 76.56, clean_train_accuracy : 97.27\n",
      "0.658203125\n",
      "0.732421875\n",
      "duration: 25 s - train loss: 0.54261 - train accuracy: 78.18 - validation loss: 0.91442 - validation accuracy: 70.99 \n",
      "[5,     1] loss: 0.61448, adv_train_accuracy: 77.73, clean_train_accuracy : 98.44\n",
      "[5,     6] loss: 0.49162, adv_train_accuracy: 79.30, clean_train_accuracy : 98.44\n",
      "[5,    11] loss: 0.50148, adv_train_accuracy: 79.69, clean_train_accuracy : 98.05\n",
      "[5,    16] loss: 0.49927, adv_train_accuracy: 81.25, clean_train_accuracy : 96.88\n",
      "0.685546875\n",
      "0.693359375\n",
      "duration: 26 s - train loss: 0.58487 - train accuracy: 76.50 - validation loss: 0.96041 - validation accuracy: 69.05 \n",
      "[6,     1] loss: 0.57483, adv_train_accuracy: 75.78, clean_train_accuracy : 97.27\n",
      "[6,     6] loss: 0.57040, adv_train_accuracy: 77.73, clean_train_accuracy : 97.27\n",
      "[6,    11] loss: 0.59451, adv_train_accuracy: 78.12, clean_train_accuracy : 96.09\n",
      "[6,    16] loss: 0.57403, adv_train_accuracy: 74.22, clean_train_accuracy : 97.27\n",
      "0.66796875\n",
      "0.751953125\n",
      "duration: 25 s - train loss: 0.55546 - train accuracy: 77.66 - validation loss: 0.87266 - validation accuracy: 72.19 \n",
      "[7,     1] loss: 0.53859, adv_train_accuracy: 76.56, clean_train_accuracy : 98.05\n",
      "[7,     6] loss: 0.52006, adv_train_accuracy: 80.86, clean_train_accuracy : 98.05\n",
      "[7,    11] loss: 0.50354, adv_train_accuracy: 76.95, clean_train_accuracy : 99.22\n",
      "[7,    16] loss: 0.65357, adv_train_accuracy: 77.73, clean_train_accuracy : 97.66\n",
      "0.712890625\n",
      "0.755859375\n",
      "duration: 25 s - train loss: 0.53740 - train accuracy: 78.34 - validation loss: 0.98458 - validation accuracy: 69.21 \n",
      "[8,     1] loss: 0.57344, adv_train_accuracy: 76.17, clean_train_accuracy : 96.88\n",
      "[8,     6] loss: 0.63041, adv_train_accuracy: 75.78, clean_train_accuracy : 96.09\n",
      "[8,    11] loss: 0.49286, adv_train_accuracy: 79.69, clean_train_accuracy : 96.88\n",
      "[8,    16] loss: 0.47845, adv_train_accuracy: 82.03, clean_train_accuracy : 99.22\n",
      "0.6796875\n",
      "0.751953125\n",
      "duration: 25 s - train loss: 0.54677 - train accuracy: 78.65 - validation loss: 0.90083 - validation accuracy: 71.57 \n",
      "[9,     1] loss: 0.53889, adv_train_accuracy: 77.34, clean_train_accuracy : 97.66\n",
      "[9,     6] loss: 0.54933, adv_train_accuracy: 78.12, clean_train_accuracy : 98.44\n",
      "[9,    11] loss: 0.49499, adv_train_accuracy: 78.91, clean_train_accuracy : 97.66\n",
      "[9,    16] loss: 0.48497, adv_train_accuracy: 82.42, clean_train_accuracy : 98.44\n",
      "0.67578125\n",
      "0.724609375\n",
      "duration: 26 s - train loss: 0.55307 - train accuracy: 77.64 - validation loss: 0.87262 - validation accuracy: 71.99 \n",
      "[10,     1] loss: 0.40983, adv_train_accuracy: 86.33, clean_train_accuracy : 98.44\n",
      "[10,     6] loss: 0.48862, adv_train_accuracy: 79.30, clean_train_accuracy : 95.70\n",
      "[10,    11] loss: 0.40077, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[10,    16] loss: 0.46339, adv_train_accuracy: 79.30, clean_train_accuracy : 98.05\n",
      "0.67578125\n",
      "0.703125\n",
      "duration: 25 s - train loss: 0.46952 - train accuracy: 80.66 - validation loss: 0.87255 - validation accuracy: 72.42 \n",
      "[11,     1] loss: 0.47072, adv_train_accuracy: 81.25, clean_train_accuracy : 98.44\n",
      "[11,     6] loss: 0.59115, adv_train_accuracy: 76.56, clean_train_accuracy : 96.48\n",
      "[11,    11] loss: 0.46658, adv_train_accuracy: 80.47, clean_train_accuracy : 98.05\n",
      "[11,    16] loss: 0.50385, adv_train_accuracy: 78.91, clean_train_accuracy : 98.05\n",
      "0.689453125\n",
      "0.716796875\n",
      "duration: 26 s - train loss: 0.49348 - train accuracy: 80.31 - validation loss: 0.89154 - validation accuracy: 71.64 \n",
      "[12,     1] loss: 0.52736, adv_train_accuracy: 76.56, clean_train_accuracy : 98.44\n",
      "[12,     6] loss: 0.51706, adv_train_accuracy: 78.52, clean_train_accuracy : 97.27\n",
      "[12,    11] loss: 0.61270, adv_train_accuracy: 77.34, clean_train_accuracy : 97.66\n",
      "[12,    16] loss: 0.43072, adv_train_accuracy: 83.98, clean_train_accuracy : 98.05\n",
      "0.701171875\n",
      "0.759765625\n",
      "duration: 26 s - train loss: 0.51584 - train accuracy: 79.43 - validation loss: 0.88272 - validation accuracy: 71.28 \n",
      "[13,     1] loss: 0.45775, adv_train_accuracy: 82.81, clean_train_accuracy : 98.44\n",
      "[13,     6] loss: 0.41447, adv_train_accuracy: 82.42, clean_train_accuracy : 99.22\n",
      "[13,    11] loss: 0.47319, adv_train_accuracy: 79.69, clean_train_accuracy : 99.22\n",
      "[13,    16] loss: 0.39527, adv_train_accuracy: 85.55, clean_train_accuracy : 98.05\n",
      "0.66796875\n",
      "0.73828125\n",
      "duration: 25 s - train loss: 0.46673 - train accuracy: 82.01 - validation loss: 0.92360 - validation accuracy: 71.09 \n",
      "[14,     1] loss: 0.50028, adv_train_accuracy: 78.91, clean_train_accuracy : 97.66\n",
      "[14,     6] loss: 0.56539, adv_train_accuracy: 76.95, clean_train_accuracy : 98.44\n",
      "[14,    11] loss: 0.42139, adv_train_accuracy: 81.25, clean_train_accuracy : 98.83\n",
      "[14,    16] loss: 0.41595, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "0.73046875\n",
      "0.7578125\n",
      "duration: 25 s - train loss: 0.51851 - train accuracy: 79.08 - validation loss: 0.89881 - validation accuracy: 72.27 \n",
      "[15,     1] loss: 0.48007, adv_train_accuracy: 80.08, clean_train_accuracy : 98.05\n",
      "[15,     6] loss: 0.45097, adv_train_accuracy: 81.25, clean_train_accuracy : 98.44\n",
      "[15,    11] loss: 0.46931, adv_train_accuracy: 80.08, clean_train_accuracy : 99.22\n",
      "[15,    16] loss: 0.43406, adv_train_accuracy: 82.81, clean_train_accuracy : 98.05\n",
      "0.66796875\n",
      "0.7265625\n",
      "duration: 26 s - train loss: 0.47888 - train accuracy: 80.62 - validation loss: 0.91045 - validation accuracy: 71.16 \n",
      "[16,     1] loss: 0.48785, adv_train_accuracy: 82.81, clean_train_accuracy : 96.48\n",
      "[16,     6] loss: 0.50702, adv_train_accuracy: 76.95, clean_train_accuracy : 96.48\n",
      "[16,    11] loss: 0.46925, adv_train_accuracy: 80.08, clean_train_accuracy : 99.22\n",
      "[16,    16] loss: 0.55301, adv_train_accuracy: 79.30, clean_train_accuracy : 98.44\n",
      "0.673828125\n",
      "0.708984375\n",
      "duration: 25 s - train loss: 0.51322 - train accuracy: 79.82 - validation loss: 0.85047 - validation accuracy: 71.55 \n",
      "[17,     1] loss: 0.55931, adv_train_accuracy: 80.08, clean_train_accuracy : 96.48\n",
      "[17,     6] loss: 0.50836, adv_train_accuracy: 80.08, clean_train_accuracy : 97.27\n",
      "[17,    11] loss: 0.50242, adv_train_accuracy: 81.25, clean_train_accuracy : 99.22\n",
      "[17,    16] loss: 0.49533, adv_train_accuracy: 81.25, clean_train_accuracy : 98.83\n",
      "0.6328125\n",
      "0.724609375\n",
      "duration: 26 s - train loss: 0.52577 - train accuracy: 79.22 - validation loss: 0.84768 - validation accuracy: 72.10 \n",
      "[18,     1] loss: 0.49794, adv_train_accuracy: 80.86, clean_train_accuracy : 99.61\n",
      "[18,     6] loss: 0.43388, adv_train_accuracy: 81.64, clean_train_accuracy : 99.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 0.48419, adv_train_accuracy: 81.64, clean_train_accuracy : 98.83\n",
      "[18,    16] loss: 0.48882, adv_train_accuracy: 82.81, clean_train_accuracy : 98.05\n",
      "0.6328125\n",
      "0.7265625\n",
      "duration: 26 s - train loss: 0.48969 - train accuracy: 79.88 - validation loss: 0.90621 - validation accuracy: 71.20 \n",
      "[19,     1] loss: 0.44070, adv_train_accuracy: 85.16, clean_train_accuracy : 99.61\n",
      "[19,     6] loss: 0.54257, adv_train_accuracy: 78.12, clean_train_accuracy : 97.66\n",
      "[19,    11] loss: 0.50127, adv_train_accuracy: 81.64, clean_train_accuracy : 97.27\n",
      "[19,    16] loss: 0.42733, adv_train_accuracy: 82.81, clean_train_accuracy : 96.88\n",
      "0.677734375\n",
      "0.728515625\n",
      "duration: 26 s - train loss: 0.48138 - train accuracy: 80.86 - validation loss: 0.89846 - validation accuracy: 71.10 \n",
      "[20,     1] loss: 0.49397, adv_train_accuracy: 80.08, clean_train_accuracy : 96.88\n",
      "[20,     6] loss: 0.56685, adv_train_accuracy: 76.56, clean_train_accuracy : 97.66\n",
      "[20,    11] loss: 0.51940, adv_train_accuracy: 76.95, clean_train_accuracy : 96.09\n",
      "[20,    16] loss: 0.45634, adv_train_accuracy: 80.08, clean_train_accuracy : 98.44\n",
      "0.658203125\n",
      "0.740234375\n",
      "duration: 26 s - train loss: 0.48200 - train accuracy: 80.84 - validation loss: 0.87011 - validation accuracy: 72.24 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>16</td>\n",
       "      <td>0.513220</td>\n",
       "      <td>79.824219</td>\n",
       "      <td>0.850472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.55</td>\n",
       "      <td>415.981601</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>17</td>\n",
       "      <td>0.525769</td>\n",
       "      <td>79.218750</td>\n",
       "      <td>0.847683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.10</td>\n",
       "      <td>442.231275</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>18</td>\n",
       "      <td>0.489694</td>\n",
       "      <td>79.882812</td>\n",
       "      <td>0.906207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.20</td>\n",
       "      <td>468.529715</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>19</td>\n",
       "      <td>0.481381</td>\n",
       "      <td>80.859375</td>\n",
       "      <td>0.898460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.10</td>\n",
       "      <td>494.900061</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>20</td>\n",
       "      <td>0.482004</td>\n",
       "      <td>80.839844</td>\n",
       "      <td>0.870111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.24</td>\n",
       "      <td>521.359941</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "215    16    0.513220       79.824219         0.850472               NaN   \n",
       "216    17    0.525769       79.218750         0.847683               NaN   \n",
       "217    18    0.489694       79.882812         0.906207               NaN   \n",
       "218    19    0.481381       80.859375         0.898460               NaN   \n",
       "219    20    0.482004       80.839844         0.870111               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "215         NaN             NaN       NaN             NaN       NaN   \n",
       "216         NaN             NaN       NaN             NaN       NaN   \n",
       "217         NaN             NaN       NaN             NaN       NaN   \n",
       "218         NaN             NaN       NaN             NaN       NaN   \n",
       "219         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "215                71.55  415.981601  CrossEntropyLoss()   \n",
       "216                72.10  442.231275  CrossEntropyLoss()   \n",
       "217                71.20  468.529715  CrossEntropyLoss()   \n",
       "218                71.10  494.900061  CrossEntropyLoss()   \n",
       "219                72.24  521.359941  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "215  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "216  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "217  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "218  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "219  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "215            NaN       256  \n",
       "216            NaN       256  \n",
       "217            NaN       256  \n",
       "218            NaN       256  \n",
       "219            NaN       256  \n",
       "\n",
       "[220 rows x 17 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7109375"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.765625"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 0.49696, adv_train_accuracy: 78.12, clean_train_accuracy : 99.22\n",
      "[1,     6] loss: 0.40134, adv_train_accuracy: 83.98, clean_train_accuracy : 98.83\n",
      "[1,    11] loss: 0.52894, adv_train_accuracy: 79.30, clean_train_accuracy : 96.48\n",
      "[1,    16] loss: 0.42151, adv_train_accuracy: 83.59, clean_train_accuracy : 98.05\n",
      "0.64453125\n",
      "0.71484375\n",
      "duration: 26 s - train loss: 0.47769 - train accuracy: 81.23 - validation loss: 0.93654 - validation accuracy: 70.72 \n",
      "[2,     1] loss: 0.58664, adv_train_accuracy: 78.91, clean_train_accuracy : 97.27\n",
      "[2,     6] loss: 0.49328, adv_train_accuracy: 79.69, clean_train_accuracy : 98.83\n",
      "[2,    11] loss: 0.39800, adv_train_accuracy: 84.77, clean_train_accuracy : 96.88\n",
      "[2,    16] loss: 0.46152, adv_train_accuracy: 82.03, clean_train_accuracy : 98.44\n",
      "0.666015625\n",
      "0.7421875\n",
      "duration: 26 s - train loss: 0.48150 - train accuracy: 80.74 - validation loss: 0.86997 - validation accuracy: 72.44 \n",
      "[3,     1] loss: 0.39087, adv_train_accuracy: 79.69, clean_train_accuracy : 99.22\n",
      "[3,     6] loss: 0.59575, adv_train_accuracy: 76.17, clean_train_accuracy : 98.44\n",
      "[3,    11] loss: 0.44892, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[3,    16] loss: 0.45679, adv_train_accuracy: 79.69, clean_train_accuracy : 99.22\n",
      "0.640625\n",
      "0.744140625\n",
      "duration: 26 s - train loss: 0.47025 - train accuracy: 80.70 - validation loss: 0.89628 - validation accuracy: 71.90 \n",
      "[4,     1] loss: 0.42497, adv_train_accuracy: 81.25, clean_train_accuracy : 98.44\n",
      "[4,     6] loss: 0.47161, adv_train_accuracy: 80.08, clean_train_accuracy : 98.44\n",
      "[4,    11] loss: 0.46465, adv_train_accuracy: 81.64, clean_train_accuracy : 98.44\n",
      "[4,    16] loss: 0.40843, adv_train_accuracy: 82.03, clean_train_accuracy : 98.44\n",
      "0.671875\n",
      "0.708984375\n",
      "duration: 26 s - train loss: 0.44189 - train accuracy: 81.95 - validation loss: 0.85943 - validation accuracy: 72.39 \n",
      "[5,     1] loss: 0.43864, adv_train_accuracy: 82.81, clean_train_accuracy : 98.44\n",
      "[5,     6] loss: 0.41508, adv_train_accuracy: 83.98, clean_train_accuracy : 98.05\n",
      "[5,    11] loss: 0.48192, adv_train_accuracy: 80.86, clean_train_accuracy : 98.05\n",
      "[5,    16] loss: 0.49066, adv_train_accuracy: 81.64, clean_train_accuracy : 98.44\n",
      "0.6328125\n",
      "0.70703125\n",
      "duration: 26 s - train loss: 0.47128 - train accuracy: 81.07 - validation loss: 0.91612 - validation accuracy: 71.00 \n",
      "[6,     1] loss: 0.48066, adv_train_accuracy: 80.08, clean_train_accuracy : 97.66\n",
      "[6,     6] loss: 0.44234, adv_train_accuracy: 80.08, clean_train_accuracy : 98.83\n",
      "[6,    11] loss: 0.49068, adv_train_accuracy: 80.86, clean_train_accuracy : 99.22\n",
      "[6,    16] loss: 0.44869, adv_train_accuracy: 79.30, clean_train_accuracy : 98.83\n",
      "0.662109375\n",
      "0.6953125\n",
      "duration: 26 s - train loss: 0.41577 - train accuracy: 82.99 - validation loss: 0.94541 - validation accuracy: 71.59 \n",
      "[7,     1] loss: 0.44154, adv_train_accuracy: 82.03, clean_train_accuracy : 97.27\n",
      "[7,     6] loss: 0.43026, adv_train_accuracy: 80.47, clean_train_accuracy : 98.05\n",
      "[7,    11] loss: 0.43225, adv_train_accuracy: 82.81, clean_train_accuracy : 98.05\n",
      "[7,    16] loss: 0.42072, adv_train_accuracy: 82.03, clean_train_accuracy : 97.27\n",
      "0.658203125\n",
      "0.72265625\n",
      "duration: 26 s - train loss: 0.40709 - train accuracy: 84.04 - validation loss: 0.90522 - validation accuracy: 72.53 \n",
      "[8,     1] loss: 0.35108, adv_train_accuracy: 85.55, clean_train_accuracy : 99.22\n",
      "[8,     6] loss: 0.42417, adv_train_accuracy: 81.25, clean_train_accuracy : 98.83\n",
      "[8,    11] loss: 0.47478, adv_train_accuracy: 80.47, clean_train_accuracy : 98.44\n",
      "[8,    16] loss: 0.42283, adv_train_accuracy: 86.33, clean_train_accuracy : 97.66\n",
      "0.689453125\n",
      "0.744140625\n",
      "duration: 25 s - train loss: 0.41461 - train accuracy: 84.06 - validation loss: 0.83963 - validation accuracy: 72.28 \n",
      "[9,     1] loss: 0.37164, adv_train_accuracy: 88.67, clean_train_accuracy : 97.27\n",
      "[9,     6] loss: 0.40812, adv_train_accuracy: 82.03, clean_train_accuracy : 99.22\n",
      "[9,    11] loss: 0.44287, adv_train_accuracy: 82.03, clean_train_accuracy : 99.22\n",
      "[9,    16] loss: 0.43360, adv_train_accuracy: 81.64, clean_train_accuracy : 98.44\n",
      "0.638671875\n",
      "0.728515625\n",
      "duration: 25 s - train loss: 0.42970 - train accuracy: 83.36 - validation loss: 0.83947 - validation accuracy: 72.82 \n",
      "[10,     1] loss: 0.32083, adv_train_accuracy: 90.23, clean_train_accuracy : 98.83\n",
      "[10,     6] loss: 0.47045, adv_train_accuracy: 80.86, clean_train_accuracy : 97.66\n",
      "[10,    11] loss: 0.50449, adv_train_accuracy: 75.78, clean_train_accuracy : 98.05\n",
      "[10,    16] loss: 0.44523, adv_train_accuracy: 82.42, clean_train_accuracy : 98.83\n",
      "0.72265625\n",
      "0.71484375\n",
      "duration: 26 s - train loss: 0.43114 - train accuracy: 83.01 - validation loss: 0.89783 - validation accuracy: 71.97 \n",
      "[11,     1] loss: 0.41687, adv_train_accuracy: 85.16, clean_train_accuracy : 98.83\n",
      "[11,     6] loss: 0.39108, adv_train_accuracy: 85.16, clean_train_accuracy : 100.00\n",
      "[11,    11] loss: 0.43573, adv_train_accuracy: 83.20, clean_train_accuracy : 98.83\n",
      "[11,    16] loss: 0.45375, adv_train_accuracy: 82.03, clean_train_accuracy : 99.61\n",
      "0.689453125\n",
      "0.771484375\n",
      "duration: 26 s - train loss: 0.43094 - train accuracy: 83.54 - validation loss: 0.95932 - validation accuracy: 70.93 \n",
      "[12,     1] loss: 0.41332, adv_train_accuracy: 83.98, clean_train_accuracy : 98.44\n",
      "[12,     6] loss: 0.49275, adv_train_accuracy: 81.64, clean_train_accuracy : 97.66\n",
      "[12,    11] loss: 0.45169, adv_train_accuracy: 78.52, clean_train_accuracy : 98.44\n",
      "[12,    16] loss: 0.42490, adv_train_accuracy: 83.59, clean_train_accuracy : 98.44\n",
      "0.658203125\n",
      "0.744140625\n",
      "duration: 26 s - train loss: 0.43623 - train accuracy: 83.09 - validation loss: 0.85263 - validation accuracy: 72.31 \n",
      "[13,     1] loss: 0.44225, adv_train_accuracy: 83.59, clean_train_accuracy : 98.05\n",
      "[13,     6] loss: 0.39687, adv_train_accuracy: 84.77, clean_train_accuracy : 98.83\n",
      "[13,    11] loss: 0.39284, adv_train_accuracy: 82.03, clean_train_accuracy : 99.22\n",
      "[13,    16] loss: 0.46782, adv_train_accuracy: 82.81, clean_train_accuracy : 97.66\n",
      "0.65625\n",
      "0.771484375\n",
      "duration: 26 s - train loss: 0.40087 - train accuracy: 83.85 - validation loss: 0.89847 - validation accuracy: 71.63 \n",
      "[14,     1] loss: 0.38605, adv_train_accuracy: 82.81, clean_train_accuracy : 98.44\n",
      "[14,     6] loss: 0.38662, adv_train_accuracy: 83.98, clean_train_accuracy : 98.83\n",
      "[14,    11] loss: 0.49754, adv_train_accuracy: 79.69, clean_train_accuracy : 98.05\n",
      "[14,    16] loss: 0.42453, adv_train_accuracy: 81.64, clean_train_accuracy : 99.22\n",
      "0.650390625\n",
      "0.72265625\n",
      "duration: 26 s - train loss: 0.43049 - train accuracy: 82.68 - validation loss: 0.95239 - validation accuracy: 70.29 \n",
      "[15,     1] loss: 0.46464, adv_train_accuracy: 81.64, clean_train_accuracy : 98.05\n",
      "[15,     6] loss: 0.48530, adv_train_accuracy: 80.86, clean_train_accuracy : 98.44\n",
      "[15,    11] loss: 0.40254, adv_train_accuracy: 83.20, clean_train_accuracy : 99.22\n",
      "[15,    16] loss: 0.41596, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "0.67578125\n",
      "0.724609375\n",
      "duration: 26 s - train loss: 0.43701 - train accuracy: 82.87 - validation loss: 0.86114 - validation accuracy: 72.30 \n",
      "[16,     1] loss: 0.36725, adv_train_accuracy: 85.55, clean_train_accuracy : 98.44\n",
      "[16,     6] loss: 0.36989, adv_train_accuracy: 84.77, clean_train_accuracy : 98.83\n",
      "[16,    11] loss: 0.41757, adv_train_accuracy: 85.16, clean_train_accuracy : 98.44\n",
      "[16,    16] loss: 0.43290, adv_train_accuracy: 82.81, clean_train_accuracy : 98.83\n",
      "0.673828125\n",
      "0.736328125\n",
      "duration: 26 s - train loss: 0.38387 - train accuracy: 84.73 - validation loss: 0.93319 - validation accuracy: 71.95 \n",
      "[17,     1] loss: 0.34482, adv_train_accuracy: 87.11, clean_train_accuracy : 98.83\n",
      "[17,     6] loss: 0.37303, adv_train_accuracy: 86.72, clean_train_accuracy : 99.22\n",
      "[17,    11] loss: 0.44134, adv_train_accuracy: 79.69, clean_train_accuracy : 98.44\n",
      "[17,    16] loss: 0.45677, adv_train_accuracy: 80.08, clean_train_accuracy : 98.83\n",
      "0.693359375\n",
      "0.71875\n",
      "duration: 26 s - train loss: 0.38675 - train accuracy: 84.92 - validation loss: 0.92724 - validation accuracy: 71.48 \n",
      "[18,     1] loss: 0.42020, adv_train_accuracy: 86.33, clean_train_accuracy : 98.05\n",
      "[18,     6] loss: 0.43769, adv_train_accuracy: 82.03, clean_train_accuracy : 98.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 0.37667, adv_train_accuracy: 85.16, clean_train_accuracy : 99.61\n",
      "[18,    16] loss: 0.41865, adv_train_accuracy: 85.55, clean_train_accuracy : 98.83\n",
      "0.693359375\n",
      "0.736328125\n",
      "duration: 26 s - train loss: 0.42484 - train accuracy: 83.69 - validation loss: 0.96930 - validation accuracy: 71.53 \n",
      "[19,     1] loss: 0.40208, adv_train_accuracy: 84.38, clean_train_accuracy : 98.44\n",
      "[19,     6] loss: 0.35392, adv_train_accuracy: 85.16, clean_train_accuracy : 99.61\n",
      "[19,    11] loss: 0.43544, adv_train_accuracy: 84.38, clean_train_accuracy : 98.05\n",
      "[19,    16] loss: 0.43063, adv_train_accuracy: 84.77, clean_train_accuracy : 99.22\n",
      "0.662109375\n",
      "0.755859375\n",
      "duration: 26 s - train loss: 0.39468 - train accuracy: 84.26 - validation loss: 0.89694 - validation accuracy: 71.51 \n",
      "[20,     1] loss: 0.41201, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[20,     6] loss: 0.44030, adv_train_accuracy: 81.25, clean_train_accuracy : 99.61\n",
      "[20,    11] loss: 0.49435, adv_train_accuracy: 81.64, clean_train_accuracy : 98.44\n",
      "[20,    16] loss: 0.38733, adv_train_accuracy: 83.20, clean_train_accuracy : 98.83\n",
      "0.650390625\n",
      "0.716796875\n",
      "duration: 26 s - train loss: 0.40935 - train accuracy: 83.61 - validation loss: 0.94373 - validation accuracy: 71.60 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>16</td>\n",
       "      <td>0.383871</td>\n",
       "      <td>84.726562</td>\n",
       "      <td>0.933191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.95</td>\n",
       "      <td>418.488399</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>17</td>\n",
       "      <td>0.386753</td>\n",
       "      <td>84.921875</td>\n",
       "      <td>0.927244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.48</td>\n",
       "      <td>444.528893</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>18</td>\n",
       "      <td>0.424838</td>\n",
       "      <td>83.691406</td>\n",
       "      <td>0.969295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.53</td>\n",
       "      <td>470.638513</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>19</td>\n",
       "      <td>0.394678</td>\n",
       "      <td>84.257812</td>\n",
       "      <td>0.896936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.51</td>\n",
       "      <td>496.677764</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>20</td>\n",
       "      <td>0.409349</td>\n",
       "      <td>83.613281</td>\n",
       "      <td>0.943729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.60</td>\n",
       "      <td>522.735624</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "235    16    0.383871       84.726562         0.933191               NaN   \n",
       "236    17    0.386753       84.921875         0.927244               NaN   \n",
       "237    18    0.424838       83.691406         0.969295               NaN   \n",
       "238    19    0.394678       84.257812         0.896936               NaN   \n",
       "239    20    0.409349       83.613281         0.943729               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "235         NaN             NaN       NaN             NaN       NaN   \n",
       "236         NaN             NaN       NaN             NaN       NaN   \n",
       "237         NaN             NaN       NaN             NaN       NaN   \n",
       "238         NaN             NaN       NaN             NaN       NaN   \n",
       "239         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "235                71.95  418.488399  CrossEntropyLoss()   \n",
       "236                71.48  444.528893  CrossEntropyLoss()   \n",
       "237                71.53  470.638513  CrossEntropyLoss()   \n",
       "238                71.51  496.677764  CrossEntropyLoss()   \n",
       "239                71.60  522.735624  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "235  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "236  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "237  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "238  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "239  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "235            NaN       256  \n",
       "236            NaN       256  \n",
       "237            NaN       256  \n",
       "238            NaN       256  \n",
       "239            NaN       256  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7265625"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 0.36227, adv_train_accuracy: 84.38, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.29763, adv_train_accuracy: 89.06, clean_train_accuracy : 97.66\n",
      "[1,    11] loss: 0.34024, adv_train_accuracy: 85.55, clean_train_accuracy : 99.61\n",
      "[1,    16] loss: 0.31391, adv_train_accuracy: 89.45, clean_train_accuracy : 99.61\n",
      "0.669921875\n",
      "0.73828125\n",
      "duration: 26 s - train loss: 0.37298 - train accuracy: 85.18 - validation loss: 0.89034 - validation accuracy: 72.44 \n",
      "[2,     1] loss: 0.31012, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "[2,     6] loss: 0.38679, adv_train_accuracy: 83.20, clean_train_accuracy : 98.83\n",
      "[2,    11] loss: 0.34688, adv_train_accuracy: 86.72, clean_train_accuracy : 99.61\n",
      "[2,    16] loss: 0.40312, adv_train_accuracy: 80.86, clean_train_accuracy : 99.22\n",
      "0.708984375\n",
      "0.697265625\n",
      "duration: 26 s - train loss: 0.37116 - train accuracy: 84.71 - validation loss: 0.89954 - validation accuracy: 72.20 \n",
      "[3,     1] loss: 0.36011, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[3,     6] loss: 0.53708, adv_train_accuracy: 79.30, clean_train_accuracy : 98.83\n",
      "[3,    11] loss: 0.51903, adv_train_accuracy: 80.86, clean_train_accuracy : 98.44\n",
      "[3,    16] loss: 0.45106, adv_train_accuracy: 81.25, clean_train_accuracy : 100.00\n",
      "0.646484375\n",
      "0.712890625\n",
      "duration: 26 s - train loss: 0.46461 - train accuracy: 81.93 - validation loss: 0.88999 - validation accuracy: 72.21 \n",
      "[4,     1] loss: 0.35270, adv_train_accuracy: 85.16, clean_train_accuracy : 99.61\n",
      "[4,     6] loss: 0.32183, adv_train_accuracy: 86.33, clean_train_accuracy : 100.00\n",
      "[4,    11] loss: 0.50730, adv_train_accuracy: 79.69, clean_train_accuracy : 98.05\n",
      "[4,    16] loss: 0.42340, adv_train_accuracy: 85.55, clean_train_accuracy : 98.05\n",
      "0.671875\n",
      "0.712890625\n",
      "duration: 26 s - train loss: 0.39146 - train accuracy: 84.04 - validation loss: 0.91901 - validation accuracy: 71.48 \n",
      "[5,     1] loss: 0.43926, adv_train_accuracy: 81.64, clean_train_accuracy : 98.05\n",
      "[5,     6] loss: 0.36862, adv_train_accuracy: 83.98, clean_train_accuracy : 99.22\n",
      "[5,    11] loss: 0.43170, adv_train_accuracy: 83.98, clean_train_accuracy : 98.83\n",
      "[5,    16] loss: 0.32651, adv_train_accuracy: 87.89, clean_train_accuracy : 98.44\n",
      "0.66015625\n",
      "0.716796875\n",
      "duration: 26 s - train loss: 0.37477 - train accuracy: 84.79 - validation loss: 0.98661 - validation accuracy: 72.21 \n",
      "[6,     1] loss: 0.26923, adv_train_accuracy: 90.62, clean_train_accuracy : 99.61\n",
      "[6,     6] loss: 0.36564, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "[6,    11] loss: 0.36372, adv_train_accuracy: 85.55, clean_train_accuracy : 98.83\n",
      "[6,    16] loss: 0.39609, adv_train_accuracy: 82.81, clean_train_accuracy : 98.05\n",
      "0.65625\n",
      "0.73046875\n",
      "duration: 26 s - train loss: 0.35444 - train accuracy: 86.37 - validation loss: 0.92958 - validation accuracy: 71.59 \n",
      "[7,     1] loss: 0.32381, adv_train_accuracy: 85.16, clean_train_accuracy : 99.61\n",
      "[7,     6] loss: 0.30449, adv_train_accuracy: 87.50, clean_train_accuracy : 99.61\n",
      "[7,    11] loss: 0.38103, adv_train_accuracy: 85.55, clean_train_accuracy : 98.83\n",
      "[7,    16] loss: 0.31135, adv_train_accuracy: 89.06, clean_train_accuracy : 99.61\n",
      "0.697265625\n",
      "0.751953125\n",
      "duration: 26 s - train loss: 0.33452 - train accuracy: 86.29 - validation loss: 0.90107 - validation accuracy: 73.38 \n",
      "[8,     1] loss: 0.34716, adv_train_accuracy: 87.11, clean_train_accuracy : 98.44\n",
      "[8,     6] loss: 0.35525, adv_train_accuracy: 88.67, clean_train_accuracy : 100.00\n",
      "[8,    11] loss: 0.26917, adv_train_accuracy: 90.62, clean_train_accuracy : 99.61\n",
      "[8,    16] loss: 0.42018, adv_train_accuracy: 82.03, clean_train_accuracy : 98.83\n",
      "0.6875\n",
      "0.77734375\n",
      "duration: 26 s - train loss: 0.34059 - train accuracy: 86.72 - validation loss: 0.95685 - validation accuracy: 71.07 \n",
      "[9,     1] loss: 0.46485, adv_train_accuracy: 82.03, clean_train_accuracy : 100.00\n",
      "[9,     6] loss: 0.38726, adv_train_accuracy: 83.98, clean_train_accuracy : 99.22\n",
      "[9,    11] loss: 0.35221, adv_train_accuracy: 84.77, clean_train_accuracy : 99.22\n",
      "[9,    16] loss: 0.40296, adv_train_accuracy: 83.98, clean_train_accuracy : 99.22\n",
      "0.666015625\n",
      "0.744140625\n",
      "duration: 26 s - train loss: 0.35979 - train accuracy: 85.51 - validation loss: 0.87662 - validation accuracy: 73.23 \n",
      "[10,     1] loss: 0.34372, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "[10,     6] loss: 0.40563, adv_train_accuracy: 83.59, clean_train_accuracy : 98.83\n",
      "[10,    11] loss: 0.33924, adv_train_accuracy: 85.55, clean_train_accuracy : 98.44\n",
      "[10,    16] loss: 0.42856, adv_train_accuracy: 82.42, clean_train_accuracy : 99.22\n",
      "0.662109375\n",
      "0.740234375\n",
      "duration: 26 s - train loss: 0.37210 - train accuracy: 85.08 - validation loss: 0.93834 - validation accuracy: 71.09 \n",
      "[11,     1] loss: 0.44606, adv_train_accuracy: 83.20, clean_train_accuracy : 98.05\n",
      "[11,     6] loss: 0.38849, adv_train_accuracy: 83.20, clean_train_accuracy : 99.61\n",
      "[11,    11] loss: 0.44369, adv_train_accuracy: 82.42, clean_train_accuracy : 98.83\n",
      "[11,    16] loss: 0.35124, adv_train_accuracy: 87.89, clean_train_accuracy : 98.83\n",
      "0.673828125\n",
      "0.740234375\n",
      "duration: 26 s - train loss: 0.38098 - train accuracy: 84.79 - validation loss: 0.92861 - validation accuracy: 72.37 \n",
      "[12,     1] loss: 0.31609, adv_train_accuracy: 89.06, clean_train_accuracy : 99.22\n",
      "[12,     6] loss: 0.28001, adv_train_accuracy: 88.67, clean_train_accuracy : 99.61\n",
      "[12,    11] loss: 0.31025, adv_train_accuracy: 87.89, clean_train_accuracy : 97.66\n",
      "[12,    16] loss: 0.39136, adv_train_accuracy: 85.94, clean_train_accuracy : 99.22\n",
      "0.634765625\n",
      "0.708984375\n",
      "duration: 26 s - train loss: 0.35158 - train accuracy: 86.07 - validation loss: 0.88699 - validation accuracy: 71.73 \n",
      "[13,     1] loss: 0.31360, adv_train_accuracy: 88.28, clean_train_accuracy : 99.61\n",
      "[13,     6] loss: 0.27083, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[13,    11] loss: 0.26076, adv_train_accuracy: 91.02, clean_train_accuracy : 100.00\n",
      "[13,    16] loss: 0.31531, adv_train_accuracy: 84.77, clean_train_accuracy : 99.22\n",
      "0.6875\n",
      "0.744140625\n",
      "duration: 26 s - train loss: 0.31766 - train accuracy: 87.46 - validation loss: 0.90599 - validation accuracy: 72.84 \n",
      "[14,     1] loss: 0.28152, adv_train_accuracy: 89.45, clean_train_accuracy : 99.61\n",
      "[14,     6] loss: 0.26993, adv_train_accuracy: 90.62, clean_train_accuracy : 98.83\n",
      "[14,    11] loss: 0.24420, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[14,    16] loss: 0.36301, adv_train_accuracy: 86.33, clean_train_accuracy : 98.05\n",
      "0.681640625\n",
      "0.75\n",
      "duration: 26 s - train loss: 0.30365 - train accuracy: 88.18 - validation loss: 1.01207 - validation accuracy: 70.57 \n",
      "[15,     1] loss: 0.36614, adv_train_accuracy: 85.94, clean_train_accuracy : 98.44\n",
      "[15,     6] loss: 0.41937, adv_train_accuracy: 83.59, clean_train_accuracy : 98.83\n",
      "[15,    11] loss: 0.35592, adv_train_accuracy: 84.38, clean_train_accuracy : 99.61\n",
      "[15,    16] loss: 0.35368, adv_train_accuracy: 85.16, clean_train_accuracy : 99.61\n",
      "0.6875\n",
      "0.75390625\n",
      "duration: 25 s - train loss: 0.33795 - train accuracy: 86.33 - validation loss: 0.96267 - validation accuracy: 71.97 \n",
      "[16,     1] loss: 0.31555, adv_train_accuracy: 86.72, clean_train_accuracy : 99.61\n",
      "[16,     6] loss: 0.32991, adv_train_accuracy: 86.72, clean_train_accuracy : 99.61\n",
      "[16,    11] loss: 0.28768, adv_train_accuracy: 87.11, clean_train_accuracy : 100.00\n",
      "[16,    16] loss: 0.34557, adv_train_accuracy: 84.77, clean_train_accuracy : 99.61\n",
      "0.6875\n",
      "0.732421875\n",
      "duration: 26 s - train loss: 0.32096 - train accuracy: 86.84 - validation loss: 0.88869 - validation accuracy: 73.29 \n",
      "[17,     1] loss: 0.20521, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "[17,     6] loss: 0.32071, adv_train_accuracy: 87.50, clean_train_accuracy : 99.61\n",
      "[17,    11] loss: 0.32571, adv_train_accuracy: 86.33, clean_train_accuracy : 99.22\n",
      "[17,    16] loss: 0.27795, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "0.677734375\n",
      "0.7421875\n",
      "duration: 26 s - train loss: 0.29350 - train accuracy: 88.16 - validation loss: 0.93109 - validation accuracy: 72.73 \n",
      "[18,     1] loss: 0.32299, adv_train_accuracy: 87.89, clean_train_accuracy : 98.83\n",
      "[18,     6] loss: 0.40401, adv_train_accuracy: 85.94, clean_train_accuracy : 98.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 0.30849, adv_train_accuracy: 86.33, clean_train_accuracy : 99.22\n",
      "[18,    16] loss: 0.32062, adv_train_accuracy: 86.33, clean_train_accuracy : 99.22\n",
      "0.669921875\n",
      "0.720703125\n",
      "duration: 26 s - train loss: 0.31668 - train accuracy: 87.83 - validation loss: 0.90042 - validation accuracy: 72.60 \n",
      "[19,     1] loss: 0.37241, adv_train_accuracy: 84.77, clean_train_accuracy : 98.83\n",
      "[19,     6] loss: 0.33860, adv_train_accuracy: 87.89, clean_train_accuracy : 98.44\n",
      "[19,    11] loss: 0.24915, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[19,    16] loss: 0.28202, adv_train_accuracy: 87.89, clean_train_accuracy : 99.61\n",
      "0.67578125\n",
      "0.7578125\n",
      "duration: 26 s - train loss: 0.32703 - train accuracy: 87.05 - validation loss: 0.95727 - validation accuracy: 71.99 \n",
      "[20,     1] loss: 0.39689, adv_train_accuracy: 85.16, clean_train_accuracy : 98.83\n",
      "[20,     6] loss: 0.24378, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[20,    11] loss: 0.30404, adv_train_accuracy: 89.84, clean_train_accuracy : 99.61\n",
      "[20,    16] loss: 0.28388, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "0.677734375\n",
      "0.759765625\n",
      "duration: 26 s - train loss: 0.30842 - train accuracy: 88.26 - validation loss: 0.96027 - validation accuracy: 72.95 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>16</td>\n",
       "      <td>0.320956</td>\n",
       "      <td>86.835938</td>\n",
       "      <td>0.888691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.29</td>\n",
       "      <td>417.413660</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>17</td>\n",
       "      <td>0.293502</td>\n",
       "      <td>88.164062</td>\n",
       "      <td>0.931090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.73</td>\n",
       "      <td>443.453804</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>18</td>\n",
       "      <td>0.316678</td>\n",
       "      <td>87.832031</td>\n",
       "      <td>0.900421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.60</td>\n",
       "      <td>469.481604</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>19</td>\n",
       "      <td>0.327025</td>\n",
       "      <td>87.050781</td>\n",
       "      <td>0.957270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.99</td>\n",
       "      <td>495.534477</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>20</td>\n",
       "      <td>0.308423</td>\n",
       "      <td>88.261719</td>\n",
       "      <td>0.960266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.95</td>\n",
       "      <td>521.605616</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "255    16    0.320956       86.835938         0.888691               NaN   \n",
       "256    17    0.293502       88.164062         0.931090               NaN   \n",
       "257    18    0.316678       87.832031         0.900421               NaN   \n",
       "258    19    0.327025       87.050781         0.957270               NaN   \n",
       "259    20    0.308423       88.261719         0.960266               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "255         NaN             NaN       NaN             NaN       NaN   \n",
       "256         NaN             NaN       NaN             NaN       NaN   \n",
       "257         NaN             NaN       NaN             NaN       NaN   \n",
       "258         NaN             NaN       NaN             NaN       NaN   \n",
       "259         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "255                73.29  417.413660  CrossEntropyLoss()   \n",
       "256                72.73  443.453804  CrossEntropyLoss()   \n",
       "257                72.60  469.481604  CrossEntropyLoss()   \n",
       "258                71.99  495.534477  CrossEntropyLoss()   \n",
       "259                72.95  521.605616  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "255  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "256  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "257  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "258  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "259  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "255            NaN       256  \n",
       "256            NaN       256  \n",
       "257            NaN       256  \n",
       "258            NaN       256  \n",
       "259            NaN       256  \n",
       "\n",
       "[260 rows x 17 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66015625"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75390625"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 0.31123, adv_train_accuracy: 88.67, clean_train_accuracy : 99.61\n",
      "[1,     6] loss: 0.32791, adv_train_accuracy: 87.11, clean_train_accuracy : 98.44\n",
      "[1,    11] loss: 0.30133, adv_train_accuracy: 87.89, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.24426, adv_train_accuracy: 90.23, clean_train_accuracy : 99.61\n",
      "0.671875\n",
      "0.724609375\n",
      "duration: 25 s - train loss: 0.28096 - train accuracy: 89.06 - validation loss: 0.96146 - validation accuracy: 72.81 \n",
      "[2,     1] loss: 0.24819, adv_train_accuracy: 89.45, clean_train_accuracy : 98.83\n",
      "[2,     6] loss: 0.27491, adv_train_accuracy: 87.89, clean_train_accuracy : 98.44\n",
      "[2,    11] loss: 0.31867, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[2,    16] loss: 0.26691, adv_train_accuracy: 88.67, clean_train_accuracy : 98.44\n",
      "0.662109375\n",
      "0.728515625\n",
      "duration: 26 s - train loss: 0.29319 - train accuracy: 88.14 - validation loss: 0.94609 - validation accuracy: 72.26 \n",
      "[3,     1] loss: 0.29794, adv_train_accuracy: 90.62, clean_train_accuracy : 98.83\n",
      "[3,     6] loss: 0.24287, adv_train_accuracy: 90.23, clean_train_accuracy : 99.61\n",
      "[3,    11] loss: 0.25697, adv_train_accuracy: 87.11, clean_train_accuracy : 99.22\n",
      "[3,    16] loss: 0.29516, adv_train_accuracy: 88.67, clean_train_accuracy : 99.22\n",
      "0.68359375\n",
      "0.775390625\n",
      "duration: 26 s - train loss: 0.29742 - train accuracy: 87.97 - validation loss: 0.98465 - validation accuracy: 70.97 \n",
      "[4,     1] loss: 0.35292, adv_train_accuracy: 87.50, clean_train_accuracy : 98.83\n",
      "[4,     6] loss: 0.40045, adv_train_accuracy: 83.98, clean_train_accuracy : 98.83\n",
      "[4,    11] loss: 0.26532, adv_train_accuracy: 90.23, clean_train_accuracy : 98.83\n",
      "[4,    16] loss: 0.35217, adv_train_accuracy: 87.89, clean_train_accuracy : 98.83\n",
      "0.708984375\n",
      "0.734375\n",
      "duration: 26 s - train loss: 0.30526 - train accuracy: 88.18 - validation loss: 0.99224 - validation accuracy: 70.96 \n",
      "[5,     1] loss: 0.25376, adv_train_accuracy: 88.67, clean_train_accuracy : 99.61\n",
      "[5,     6] loss: 0.28272, adv_train_accuracy: 87.11, clean_train_accuracy : 100.00\n",
      "[5,    11] loss: 0.24356, adv_train_accuracy: 91.02, clean_train_accuracy : 99.61\n",
      "[5,    16] loss: 0.19535, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "0.671875\n",
      "0.771484375\n",
      "duration: 26 s - train loss: 0.27350 - train accuracy: 89.22 - validation loss: 0.91491 - validation accuracy: 72.14 \n",
      "[6,     1] loss: 0.24231, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[6,     6] loss: 0.32250, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "[6,    11] loss: 0.33249, adv_train_accuracy: 88.67, clean_train_accuracy : 99.61\n",
      "[6,    16] loss: 0.26639, adv_train_accuracy: 90.62, clean_train_accuracy : 99.61\n",
      "0.681640625\n",
      "0.751953125\n",
      "duration: 26 s - train loss: 0.29273 - train accuracy: 88.34 - validation loss: 0.96349 - validation accuracy: 71.38 \n",
      "[7,     1] loss: 0.31166, adv_train_accuracy: 87.11, clean_train_accuracy : 99.22\n",
      "[7,     6] loss: 0.23452, adv_train_accuracy: 91.02, clean_train_accuracy : 99.22\n",
      "[7,    11] loss: 0.23566, adv_train_accuracy: 90.62, clean_train_accuracy : 98.05\n",
      "[7,    16] loss: 0.31974, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "0.70703125\n",
      "0.7109375\n",
      "duration: 26 s - train loss: 0.28089 - train accuracy: 89.04 - validation loss: 1.03904 - validation accuracy: 71.69 \n",
      "[8,     1] loss: 0.37678, adv_train_accuracy: 86.33, clean_train_accuracy : 98.83\n",
      "[8,     6] loss: 0.27555, adv_train_accuracy: 86.33, clean_train_accuracy : 99.61\n",
      "[8,    11] loss: 0.26124, adv_train_accuracy: 91.02, clean_train_accuracy : 99.22\n",
      "[8,    16] loss: 0.26393, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "0.6796875\n",
      "0.736328125\n",
      "duration: 26 s - train loss: 0.29664 - train accuracy: 88.09 - validation loss: 1.00200 - validation accuracy: 71.64 \n",
      "[9,     1] loss: 0.32421, adv_train_accuracy: 87.89, clean_train_accuracy : 100.00\n",
      "[9,     6] loss: 0.23046, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[9,    11] loss: 0.27869, adv_train_accuracy: 89.06, clean_train_accuracy : 99.61\n",
      "[9,    16] loss: 0.31775, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n",
      "0.6796875\n",
      "0.76171875\n",
      "duration: 26 s - train loss: 0.29701 - train accuracy: 88.22 - validation loss: 1.00655 - validation accuracy: 71.04 \n",
      "[10,     1] loss: 0.28057, adv_train_accuracy: 89.45, clean_train_accuracy : 99.22\n",
      "[10,     6] loss: 0.27205, adv_train_accuracy: 89.45, clean_train_accuracy : 99.61\n",
      "[10,    11] loss: 0.38613, adv_train_accuracy: 85.55, clean_train_accuracy : 99.22\n",
      "[10,    16] loss: 0.31884, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "0.642578125\n",
      "0.74609375\n",
      "duration: 26 s - train loss: 0.31162 - train accuracy: 87.52 - validation loss: 0.91254 - validation accuracy: 72.15 \n",
      "[11,     1] loss: 0.25754, adv_train_accuracy: 87.89, clean_train_accuracy : 100.00\n",
      "[11,     6] loss: 0.26945, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[11,    11] loss: 0.32869, adv_train_accuracy: 85.55, clean_train_accuracy : 98.83\n",
      "[11,    16] loss: 0.36412, adv_train_accuracy: 85.16, clean_train_accuracy : 98.83\n",
      "0.708984375\n",
      "0.73828125\n",
      "duration: 26 s - train loss: 0.31722 - train accuracy: 87.23 - validation loss: 0.98097 - validation accuracy: 71.10 \n",
      "[12,     1] loss: 0.36640, adv_train_accuracy: 84.77, clean_train_accuracy : 98.83\n",
      "[12,     6] loss: 0.33203, adv_train_accuracy: 86.72, clean_train_accuracy : 99.61\n",
      "[12,    11] loss: 0.25373, adv_train_accuracy: 88.67, clean_train_accuracy : 99.22\n",
      "[12,    16] loss: 0.33502, adv_train_accuracy: 86.72, clean_train_accuracy : 98.44\n",
      "0.72265625\n",
      "0.751953125\n",
      "duration: 26 s - train loss: 0.31510 - train accuracy: 87.11 - validation loss: 0.91144 - validation accuracy: 72.71 \n",
      "[13,     1] loss: 0.28780, adv_train_accuracy: 89.45, clean_train_accuracy : 100.00\n",
      "[13,     6] loss: 0.26448, adv_train_accuracy: 89.45, clean_train_accuracy : 100.00\n",
      "[13,    11] loss: 0.28503, adv_train_accuracy: 89.84, clean_train_accuracy : 99.61\n",
      "[13,    16] loss: 0.30504, adv_train_accuracy: 88.67, clean_train_accuracy : 99.22\n",
      "0.69921875\n",
      "0.724609375\n",
      "duration: 26 s - train loss: 0.28431 - train accuracy: 89.06 - validation loss: 0.98011 - validation accuracy: 71.76 \n",
      "[14,     1] loss: 0.27521, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[14,     6] loss: 0.32930, adv_train_accuracy: 84.77, clean_train_accuracy : 100.00\n",
      "[14,    11] loss: 0.21728, adv_train_accuracy: 91.02, clean_train_accuracy : 100.00\n",
      "[14,    16] loss: 0.24195, adv_train_accuracy: 90.23, clean_train_accuracy : 100.00\n",
      "0.71484375\n",
      "0.7578125\n",
      "duration: 26 s - train loss: 0.28631 - train accuracy: 88.67 - validation loss: 0.98129 - validation accuracy: 71.67 \n",
      "[15,     1] loss: 0.22522, adv_train_accuracy: 92.97, clean_train_accuracy : 99.22\n",
      "[15,     6] loss: 0.65960, adv_train_accuracy: 78.12, clean_train_accuracy : 99.61\n",
      "[15,    11] loss: 0.51856, adv_train_accuracy: 81.25, clean_train_accuracy : 98.83\n",
      "[15,    16] loss: 0.38063, adv_train_accuracy: 84.77, clean_train_accuracy : 99.61\n",
      "0.701171875\n",
      "0.73046875\n",
      "duration: 26 s - train loss: 0.43901 - train accuracy: 83.28 - validation loss: 0.95103 - validation accuracy: 71.35 \n",
      "[16,     1] loss: 0.39436, adv_train_accuracy: 85.55, clean_train_accuracy : 98.05\n",
      "[16,     6] loss: 0.29078, adv_train_accuracy: 86.72, clean_train_accuracy : 99.61\n",
      "[16,    11] loss: 0.43915, adv_train_accuracy: 83.20, clean_train_accuracy : 99.22\n",
      "[16,    16] loss: 0.35984, adv_train_accuracy: 84.77, clean_train_accuracy : 99.22\n",
      "0.671875\n",
      "0.765625\n",
      "duration: 26 s - train loss: 0.35110 - train accuracy: 86.09 - validation loss: 0.93651 - validation accuracy: 72.31 \n",
      "[17,     1] loss: 0.37330, adv_train_accuracy: 86.72, clean_train_accuracy : 98.83\n",
      "[17,     6] loss: 0.29965, adv_train_accuracy: 88.67, clean_train_accuracy : 99.22\n",
      "[17,    11] loss: 0.36287, adv_train_accuracy: 88.28, clean_train_accuracy : 99.61\n",
      "[17,    16] loss: 0.33247, adv_train_accuracy: 88.28, clean_train_accuracy : 97.66\n",
      "0.708984375\n",
      "0.767578125\n",
      "duration: 26 s - train loss: 0.31627 - train accuracy: 87.79 - validation loss: 0.95489 - validation accuracy: 72.29 \n",
      "[18,     1] loss: 0.28151, adv_train_accuracy: 90.23, clean_train_accuracy : 100.00\n",
      "[18,     6] loss: 0.28289, adv_train_accuracy: 87.50, clean_train_accuracy : 99.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 0.26072, adv_train_accuracy: 88.67, clean_train_accuracy : 100.00\n",
      "[18,    16] loss: 0.39390, adv_train_accuracy: 82.81, clean_train_accuracy : 99.61\n",
      "0.70703125\n",
      "0.80859375\n",
      "duration: 26 s - train loss: 0.30046 - train accuracy: 88.16 - validation loss: 0.96238 - validation accuracy: 71.53 \n",
      "[19,     1] loss: 0.35224, adv_train_accuracy: 84.38, clean_train_accuracy : 99.61\n",
      "[19,     6] loss: 0.21526, adv_train_accuracy: 91.80, clean_train_accuracy : 99.22\n",
      "[19,    11] loss: 0.24114, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "[19,    16] loss: 0.30954, adv_train_accuracy: 84.77, clean_train_accuracy : 100.00\n",
      "0.6640625\n",
      "0.75390625\n",
      "duration: 26 s - train loss: 0.29808 - train accuracy: 88.18 - validation loss: 1.02996 - validation accuracy: 71.43 \n",
      "[20,     1] loss: 0.31439, adv_train_accuracy: 87.50, clean_train_accuracy : 99.61\n",
      "[20,     6] loss: 0.29577, adv_train_accuracy: 87.50, clean_train_accuracy : 99.61\n",
      "[20,    11] loss: 0.24912, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[20,    16] loss: 0.33042, adv_train_accuracy: 87.89, clean_train_accuracy : 99.22\n",
      "0.685546875\n",
      "0.74609375\n",
      "duration: 26 s - train loss: 0.31437 - train accuracy: 87.77 - validation loss: 0.90769 - validation accuracy: 73.23 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>16</td>\n",
       "      <td>0.351104</td>\n",
       "      <td>86.093750</td>\n",
       "      <td>0.936510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.31</td>\n",
       "      <td>421.187411</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>17</td>\n",
       "      <td>0.316270</td>\n",
       "      <td>87.792969</td>\n",
       "      <td>0.954886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.29</td>\n",
       "      <td>447.475544</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>18</td>\n",
       "      <td>0.300461</td>\n",
       "      <td>88.164062</td>\n",
       "      <td>0.962383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.53</td>\n",
       "      <td>473.745143</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>19</td>\n",
       "      <td>0.298084</td>\n",
       "      <td>88.183594</td>\n",
       "      <td>1.029958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.43</td>\n",
       "      <td>499.942343</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20</td>\n",
       "      <td>0.314374</td>\n",
       "      <td>87.773438</td>\n",
       "      <td>0.907691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.23</td>\n",
       "      <td>526.173222</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "275    16    0.351104       86.093750         0.936510               NaN   \n",
       "276    17    0.316270       87.792969         0.954886               NaN   \n",
       "277    18    0.300461       88.164062         0.962383               NaN   \n",
       "278    19    0.298084       88.183594         1.029958               NaN   \n",
       "279    20    0.314374       87.773438         0.907691               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "275         NaN             NaN       NaN             NaN       NaN   \n",
       "276         NaN             NaN       NaN             NaN       NaN   \n",
       "277         NaN             NaN       NaN             NaN       NaN   \n",
       "278         NaN             NaN       NaN             NaN       NaN   \n",
       "279         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "275                72.31  421.187411  CrossEntropyLoss()   \n",
       "276                72.29  447.475544  CrossEntropyLoss()   \n",
       "277                71.53  473.745143  CrossEntropyLoss()   \n",
       "278                71.43  499.942343  CrossEntropyLoss()   \n",
       "279                73.23  526.173222  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "275  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "276  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "277  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "278  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "279  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "275            NaN       256  \n",
       "276            NaN       256  \n",
       "277            NaN       256  \n",
       "278            NaN       256  \n",
       "279            NaN       256  \n",
       "\n",
       "[280 rows x 17 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66796875"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 0.29716, adv_train_accuracy: 89.45, clean_train_accuracy : 98.83\n",
      "[1,     6] loss: 0.30633, adv_train_accuracy: 88.67, clean_train_accuracy : 99.61\n",
      "[1,    11] loss: 0.28403, adv_train_accuracy: 87.89, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.26278, adv_train_accuracy: 91.41, clean_train_accuracy : 98.44\n",
      "0.6953125\n",
      "0.720703125\n",
      "duration: 26 s - train loss: 0.28021 - train accuracy: 89.63 - validation loss: 1.01731 - validation accuracy: 72.00 \n",
      "[2,     1] loss: 0.25274, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[2,     6] loss: 0.29647, adv_train_accuracy: 89.84, clean_train_accuracy : 99.61\n",
      "[2,    11] loss: 0.21771, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "[2,    16] loss: 0.28240, adv_train_accuracy: 90.23, clean_train_accuracy : 99.61\n",
      "0.728515625\n",
      "0.755859375\n",
      "duration: 26 s - train loss: 0.28321 - train accuracy: 88.69 - validation loss: 0.99070 - validation accuracy: 72.34 \n",
      "[3,     1] loss: 0.23745, adv_train_accuracy: 91.41, clean_train_accuracy : 98.44\n",
      "[3,     6] loss: 0.25980, adv_train_accuracy: 90.23, clean_train_accuracy : 98.44\n",
      "[3,    11] loss: 0.20086, adv_train_accuracy: 92.19, clean_train_accuracy : 99.61\n",
      "[3,    16] loss: 0.36876, adv_train_accuracy: 85.16, clean_train_accuracy : 99.22\n",
      "0.701171875\n",
      "0.73828125\n",
      "duration: 26 s - train loss: 0.28800 - train accuracy: 88.40 - validation loss: 1.00777 - validation accuracy: 71.13 \n",
      "[4,     1] loss: 0.37734, adv_train_accuracy: 84.38, clean_train_accuracy : 99.22\n",
      "[4,     6] loss: 0.32231, adv_train_accuracy: 86.33, clean_train_accuracy : 98.44\n",
      "[4,    11] loss: 0.27459, adv_train_accuracy: 88.67, clean_train_accuracy : 98.83\n",
      "[4,    16] loss: 0.41631, adv_train_accuracy: 83.59, clean_train_accuracy : 99.61\n",
      "0.705078125\n",
      "0.77734375\n",
      "duration: 26 s - train loss: 0.29128 - train accuracy: 88.55 - validation loss: 0.92540 - validation accuracy: 72.61 \n",
      "[5,     1] loss: 0.25729, adv_train_accuracy: 87.89, clean_train_accuracy : 100.00\n",
      "[5,     6] loss: 0.28210, adv_train_accuracy: 88.67, clean_train_accuracy : 99.22\n",
      "[5,    11] loss: 0.27203, adv_train_accuracy: 89.45, clean_train_accuracy : 100.00\n",
      "[5,    16] loss: 0.20000, adv_train_accuracy: 91.41, clean_train_accuracy : 99.22\n",
      "0.70703125\n",
      "0.771484375\n",
      "duration: 26 s - train loss: 0.25689 - train accuracy: 89.57 - validation loss: 1.00172 - validation accuracy: 71.83 \n",
      "[6,     1] loss: 0.21844, adv_train_accuracy: 92.58, clean_train_accuracy : 99.22\n",
      "[6,     6] loss: 0.22422, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[6,    11] loss: 0.22867, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[6,    16] loss: 0.26834, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "0.6953125\n",
      "0.76171875\n",
      "duration: 26 s - train loss: 0.25164 - train accuracy: 89.96 - validation loss: 0.97020 - validation accuracy: 72.42 \n",
      "[7,     1] loss: 0.22891, adv_train_accuracy: 91.80, clean_train_accuracy : 99.61\n",
      "[7,     6] loss: 0.35513, adv_train_accuracy: 84.77, clean_train_accuracy : 100.00\n",
      "[7,    11] loss: 0.31799, adv_train_accuracy: 85.94, clean_train_accuracy : 100.00\n",
      "[7,    16] loss: 0.25768, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "0.671875\n",
      "0.734375\n",
      "duration: 26 s - train loss: 0.27236 - train accuracy: 89.43 - validation loss: 1.00024 - validation accuracy: 71.60 \n",
      "[8,     1] loss: 0.32050, adv_train_accuracy: 85.55, clean_train_accuracy : 98.83\n",
      "[8,     6] loss: 0.28417, adv_train_accuracy: 89.06, clean_train_accuracy : 99.61\n",
      "[8,    11] loss: 0.32232, adv_train_accuracy: 86.33, clean_train_accuracy : 99.61\n",
      "[8,    16] loss: 0.23414, adv_train_accuracy: 89.84, clean_train_accuracy : 99.61\n",
      "0.685546875\n",
      "0.76171875\n",
      "duration: 26 s - train loss: 0.26593 - train accuracy: 89.45 - validation loss: 0.97660 - validation accuracy: 72.23 \n",
      "[9,     1] loss: 0.19574, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "[9,     6] loss: 0.30087, adv_train_accuracy: 88.67, clean_train_accuracy : 99.22\n",
      "[9,    11] loss: 0.24644, adv_train_accuracy: 90.23, clean_train_accuracy : 98.83\n",
      "[9,    16] loss: 0.27673, adv_train_accuracy: 88.28, clean_train_accuracy : 99.61\n",
      "0.697265625\n",
      "0.732421875\n",
      "duration: 26 s - train loss: 0.27468 - train accuracy: 89.53 - validation loss: 1.02359 - validation accuracy: 71.04 \n",
      "[10,     1] loss: 0.29388, adv_train_accuracy: 88.28, clean_train_accuracy : 99.61\n",
      "[10,     6] loss: 0.26088, adv_train_accuracy: 87.89, clean_train_accuracy : 99.22\n",
      "[10,    11] loss: 0.23981, adv_train_accuracy: 91.02, clean_train_accuracy : 99.22\n",
      "[10,    16] loss: 0.25212, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "0.6640625\n",
      "0.75\n",
      "duration: 26 s - train loss: 0.29283 - train accuracy: 88.61 - validation loss: 0.91948 - validation accuracy: 73.39 \n",
      "[11,     1] loss: 0.31911, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[11,     6] loss: 0.27424, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[11,    11] loss: 0.22562, adv_train_accuracy: 91.41, clean_train_accuracy : 98.83\n",
      "[11,    16] loss: 0.21109, adv_train_accuracy: 91.80, clean_train_accuracy : 99.22\n",
      "0.65625\n",
      "0.755859375\n",
      "duration: 26 s - train loss: 0.24348 - train accuracy: 90.82 - validation loss: 1.05721 - validation accuracy: 71.88 \n",
      "[12,     1] loss: 0.26316, adv_train_accuracy: 89.84, clean_train_accuracy : 99.22\n",
      "[12,     6] loss: 0.26630, adv_train_accuracy: 89.84, clean_train_accuracy : 99.61\n",
      "[12,    11] loss: 0.21959, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[12,    16] loss: 0.20521, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "0.685546875\n",
      "0.74609375\n",
      "duration: 26 s - train loss: 0.25410 - train accuracy: 89.67 - validation loss: 0.99231 - validation accuracy: 72.60 \n",
      "[13,     1] loss: 0.23279, adv_train_accuracy: 88.67, clean_train_accuracy : 100.00\n",
      "[13,     6] loss: 0.26555, adv_train_accuracy: 90.23, clean_train_accuracy : 99.22\n",
      "[13,    11] loss: 0.25502, adv_train_accuracy: 92.19, clean_train_accuracy : 99.61\n",
      "[13,    16] loss: 0.21937, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "0.654296875\n",
      "0.76953125\n",
      "duration: 26 s - train loss: 0.24554 - train accuracy: 90.59 - validation loss: 0.94992 - validation accuracy: 73.03 \n",
      "[14,     1] loss: 0.21198, adv_train_accuracy: 91.41, clean_train_accuracy : 99.61\n",
      "[14,     6] loss: 0.20652, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[14,    11] loss: 0.22460, adv_train_accuracy: 91.80, clean_train_accuracy : 99.61\n",
      "[14,    16] loss: 0.22511, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "0.724609375\n",
      "0.736328125\n",
      "duration: 26 s - train loss: 0.22830 - train accuracy: 90.88 - validation loss: 1.05108 - validation accuracy: 71.41 \n",
      "[15,     1] loss: 0.21265, adv_train_accuracy: 92.19, clean_train_accuracy : 99.61\n",
      "[15,     6] loss: 0.21854, adv_train_accuracy: 92.19, clean_train_accuracy : 99.61\n",
      "[15,    11] loss: 0.26537, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[15,    16] loss: 0.22479, adv_train_accuracy: 91.41, clean_train_accuracy : 99.61\n",
      "0.66015625\n",
      "0.74609375\n",
      "duration: 26 s - train loss: 0.22524 - train accuracy: 91.27 - validation loss: 1.02476 - validation accuracy: 71.93 \n",
      "[16,     1] loss: 0.23132, adv_train_accuracy: 91.02, clean_train_accuracy : 100.00\n",
      "[16,     6] loss: 0.19141, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[16,    11] loss: 0.25673, adv_train_accuracy: 89.45, clean_train_accuracy : 99.22\n",
      "[16,    16] loss: 0.35029, adv_train_accuracy: 84.77, clean_train_accuracy : 99.61\n",
      "0.69140625\n",
      "0.712890625\n",
      "duration: 26 s - train loss: 0.26743 - train accuracy: 89.59 - validation loss: 0.90294 - validation accuracy: 71.96 \n",
      "[17,     1] loss: 0.25635, adv_train_accuracy: 88.67, clean_train_accuracy : 98.83\n",
      "[17,     6] loss: 0.17504, adv_train_accuracy: 92.58, clean_train_accuracy : 99.61\n",
      "[17,    11] loss: 0.25745, adv_train_accuracy: 89.45, clean_train_accuracy : 100.00\n",
      "[17,    16] loss: 0.24658, adv_train_accuracy: 91.80, clean_train_accuracy : 99.61\n",
      "0.701171875\n",
      "0.751953125\n",
      "duration: 26 s - train loss: 0.23617 - train accuracy: 90.53 - validation loss: 0.97350 - validation accuracy: 72.25 \n",
      "[18,     1] loss: 0.21625, adv_train_accuracy: 93.36, clean_train_accuracy : 99.61\n",
      "[18,     6] loss: 0.26293, adv_train_accuracy: 89.45, clean_train_accuracy : 99.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 0.19101, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[18,    16] loss: 0.19373, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "0.69921875\n",
      "0.7421875\n",
      "duration: 26 s - train loss: 0.22796 - train accuracy: 90.78 - validation loss: 0.98945 - validation accuracy: 73.22 \n",
      "[19,     1] loss: 0.16857, adv_train_accuracy: 93.75, clean_train_accuracy : 99.61\n",
      "[19,     6] loss: 0.16132, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[19,    11] loss: 0.17184, adv_train_accuracy: 94.53, clean_train_accuracy : 99.61\n",
      "[19,    16] loss: 0.18077, adv_train_accuracy: 93.36, clean_train_accuracy : 100.00\n",
      "0.7109375\n",
      "0.716796875\n",
      "duration: 26 s - train loss: 0.20507 - train accuracy: 92.29 - validation loss: 0.96015 - validation accuracy: 72.85 \n",
      "[20,     1] loss: 0.19884, adv_train_accuracy: 91.02, clean_train_accuracy : 99.61\n",
      "[20,     6] loss: 0.18573, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[20,    11] loss: 0.19404, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[20,    16] loss: 0.19825, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "0.677734375\n",
      "0.75390625\n",
      "duration: 26 s - train loss: 0.19991 - train accuracy: 92.07 - validation loss: 1.02706 - validation accuracy: 72.22 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>16</td>\n",
       "      <td>0.267434</td>\n",
       "      <td>89.589844</td>\n",
       "      <td>0.902936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.96</td>\n",
       "      <td>419.792504</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>17</td>\n",
       "      <td>0.236173</td>\n",
       "      <td>90.527344</td>\n",
       "      <td>0.973497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.25</td>\n",
       "      <td>445.994847</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>18</td>\n",
       "      <td>0.227965</td>\n",
       "      <td>90.781250</td>\n",
       "      <td>0.989452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.22</td>\n",
       "      <td>472.196134</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>19</td>\n",
       "      <td>0.205065</td>\n",
       "      <td>92.285156</td>\n",
       "      <td>0.960155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.85</td>\n",
       "      <td>498.507426</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>20</td>\n",
       "      <td>0.199910</td>\n",
       "      <td>92.070312</td>\n",
       "      <td>1.027064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.22</td>\n",
       "      <td>524.801977</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "295    16    0.267434       89.589844         0.902936               NaN   \n",
       "296    17    0.236173       90.527344         0.973497               NaN   \n",
       "297    18    0.227965       90.781250         0.989452               NaN   \n",
       "298    19    0.205065       92.285156         0.960155               NaN   \n",
       "299    20    0.199910       92.070312         1.027064               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "295         NaN             NaN       NaN             NaN       NaN   \n",
       "296         NaN             NaN       NaN             NaN       NaN   \n",
       "297         NaN             NaN       NaN             NaN       NaN   \n",
       "298         NaN             NaN       NaN             NaN       NaN   \n",
       "299         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "295                71.96  419.792504  CrossEntropyLoss()   \n",
       "296                72.25  445.994847  CrossEntropyLoss()   \n",
       "297                73.22  472.196134  CrossEntropyLoss()   \n",
       "298                72.85  498.507426  CrossEntropyLoss()   \n",
       "299                72.22  524.801977  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "295  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "296  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "297  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "298  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "299  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "295            NaN       256  \n",
       "296            NaN       256  \n",
       "297            NaN       256  \n",
       "298            NaN       256  \n",
       "299            NaN       256  \n",
       "\n",
       "[300 rows x 17 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64453125"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.734375"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 0.16947, adv_train_accuracy: 94.14, clean_train_accuracy : 99.61\n",
      "[1,     6] loss: 0.18315, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.21003, adv_train_accuracy: 93.36, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.30578, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "0.65625\n",
      "0.73046875\n",
      "duration: 26 s - train loss: 0.20121 - train accuracy: 92.21 - validation loss: 1.00304 - validation accuracy: 72.85 \n",
      "[2,     1] loss: 0.19700, adv_train_accuracy: 91.80, clean_train_accuracy : 98.44\n",
      "[2,     6] loss: 0.26725, adv_train_accuracy: 91.02, clean_train_accuracy : 100.00\n",
      "[2,    11] loss: 0.23576, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[2,    16] loss: 0.31746, adv_train_accuracy: 89.84, clean_train_accuracy : 99.61\n",
      "0.66015625\n",
      "0.767578125\n",
      "duration: 26 s - train loss: 0.23749 - train accuracy: 91.00 - validation loss: 1.00129 - validation accuracy: 71.47 \n",
      "[3,     1] loss: 0.31358, adv_train_accuracy: 88.28, clean_train_accuracy : 98.83\n",
      "[3,     6] loss: 0.23603, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[3,    11] loss: 0.20703, adv_train_accuracy: 92.58, clean_train_accuracy : 99.61\n",
      "[3,    16] loss: 0.21736, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "0.697265625\n",
      "0.767578125\n",
      "duration: 26 s - train loss: 0.24451 - train accuracy: 90.21 - validation loss: 1.03325 - validation accuracy: 72.47 \n",
      "[4,     1] loss: 0.24029, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[4,     6] loss: 0.22675, adv_train_accuracy: 91.80, clean_train_accuracy : 99.61\n",
      "[4,    11] loss: 0.21176, adv_train_accuracy: 91.80, clean_train_accuracy : 99.61\n",
      "[4,    16] loss: 0.20390, adv_train_accuracy: 91.02, clean_train_accuracy : 100.00\n",
      "0.689453125\n",
      "0.751953125\n",
      "duration: 26 s - train loss: 0.21986 - train accuracy: 91.39 - validation loss: 1.02967 - validation accuracy: 72.96 \n",
      "[5,     1] loss: 0.26966, adv_train_accuracy: 91.41, clean_train_accuracy : 98.83\n",
      "[5,     6] loss: 0.15938, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[5,    11] loss: 0.21350, adv_train_accuracy: 91.80, clean_train_accuracy : 99.22\n",
      "[5,    16] loss: 0.26046, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "0.6953125\n",
      "0.73046875\n",
      "duration: 26 s - train loss: 0.22708 - train accuracy: 91.27 - validation loss: 0.98831 - validation accuracy: 72.13 \n",
      "[6,     1] loss: 0.22818, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[6,     6] loss: 0.20414, adv_train_accuracy: 92.58, clean_train_accuracy : 99.22\n",
      "[6,    11] loss: 0.28821, adv_train_accuracy: 87.89, clean_train_accuracy : 99.61\n",
      "[6,    16] loss: 0.28316, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "0.712890625\n",
      "0.7421875\n",
      "duration: 26 s - train loss: 0.21209 - train accuracy: 91.66 - validation loss: 0.95794 - validation accuracy: 72.86 \n",
      "[7,     1] loss: 0.25222, adv_train_accuracy: 89.45, clean_train_accuracy : 99.22\n",
      "[7,     6] loss: 0.24546, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[7,    11] loss: 0.23897, adv_train_accuracy: 91.02, clean_train_accuracy : 100.00\n",
      "[7,    16] loss: 0.23954, adv_train_accuracy: 92.19, clean_train_accuracy : 99.61\n",
      "0.671875\n",
      "0.76171875\n",
      "duration: 26 s - train loss: 0.26484 - train accuracy: 89.24 - validation loss: 0.98611 - validation accuracy: 71.80 \n",
      "[8,     1] loss: 0.19883, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[8,     6] loss: 0.20051, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[8,    11] loss: 0.33085, adv_train_accuracy: 87.11, clean_train_accuracy : 100.00\n",
      "[8,    16] loss: 0.24870, adv_train_accuracy: 91.80, clean_train_accuracy : 99.61\n",
      "0.697265625\n",
      "0.763671875\n",
      "duration: 26 s - train loss: 0.24456 - train accuracy: 90.49 - validation loss: 0.94387 - validation accuracy: 72.20 \n",
      "[9,     1] loss: 0.23575, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[9,     6] loss: 0.27226, adv_train_accuracy: 87.50, clean_train_accuracy : 100.00\n",
      "[9,    11] loss: 0.21113, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[9,    16] loss: 0.22028, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "0.646484375\n",
      "0.74609375\n",
      "duration: 26 s - train loss: 0.23006 - train accuracy: 90.70 - validation loss: 1.02476 - validation accuracy: 73.26 \n",
      "[10,     1] loss: 0.20064, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[10,     6] loss: 0.20352, adv_train_accuracy: 93.36, clean_train_accuracy : 99.61\n",
      "[10,    11] loss: 0.23570, adv_train_accuracy: 90.62, clean_train_accuracy : 99.22\n",
      "[10,    16] loss: 0.32179, adv_train_accuracy: 86.72, clean_train_accuracy : 99.61\n",
      "0.685546875\n",
      "0.728515625\n",
      "duration: 26 s - train loss: 0.24182 - train accuracy: 90.53 - validation loss: 0.95934 - validation accuracy: 73.32 \n",
      "[11,     1] loss: 0.15277, adv_train_accuracy: 97.27, clean_train_accuracy : 100.00\n",
      "[11,     6] loss: 0.23435, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[11,    11] loss: 0.23510, adv_train_accuracy: 89.45, clean_train_accuracy : 100.00\n",
      "[11,    16] loss: 0.25703, adv_train_accuracy: 89.45, clean_train_accuracy : 99.22\n",
      "0.65625\n",
      "0.73828125\n",
      "duration: 26 s - train loss: 0.24838 - train accuracy: 90.14 - validation loss: 1.00943 - validation accuracy: 72.24 \n",
      "[12,     1] loss: 0.25558, adv_train_accuracy: 90.23, clean_train_accuracy : 98.83\n",
      "[12,     6] loss: 0.27486, adv_train_accuracy: 87.50, clean_train_accuracy : 99.61\n",
      "[12,    11] loss: 0.22119, adv_train_accuracy: 90.23, clean_train_accuracy : 99.22\n",
      "[12,    16] loss: 0.19301, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "0.67578125\n",
      "0.740234375\n",
      "duration: 26 s - train loss: 0.21944 - train accuracy: 91.02 - validation loss: 1.05558 - validation accuracy: 71.90 \n",
      "[13,     1] loss: 0.23003, adv_train_accuracy: 90.62, clean_train_accuracy : 99.61\n",
      "[13,     6] loss: 0.22518, adv_train_accuracy: 88.28, clean_train_accuracy : 99.22\n",
      "[13,    11] loss: 0.20747, adv_train_accuracy: 92.19, clean_train_accuracy : 99.61\n",
      "[13,    16] loss: 0.16736, adv_train_accuracy: 93.36, clean_train_accuracy : 100.00\n",
      "0.67578125\n",
      "0.75\n",
      "duration: 26 s - train loss: 0.17680 - train accuracy: 92.89 - validation loss: 1.03987 - validation accuracy: 72.92 \n",
      "[14,     1] loss: 0.13187, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[14,     6] loss: 0.18288, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "[14,    11] loss: 0.21903, adv_train_accuracy: 91.02, clean_train_accuracy : 99.22\n",
      "[14,    16] loss: 0.24805, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "0.6796875\n",
      "0.75390625\n",
      "duration: 26 s - train loss: 0.20327 - train accuracy: 91.88 - validation loss: 0.98266 - validation accuracy: 71.81 \n",
      "[15,     1] loss: 0.24491, adv_train_accuracy: 89.84, clean_train_accuracy : 99.61\n",
      "[15,     6] loss: 0.15370, adv_train_accuracy: 95.70, clean_train_accuracy : 99.61\n",
      "[15,    11] loss: 0.21077, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[15,    16] loss: 0.16957, adv_train_accuracy: 94.14, clean_train_accuracy : 99.61\n",
      "0.716796875\n",
      "0.744140625\n",
      "duration: 26 s - train loss: 0.19055 - train accuracy: 92.70 - validation loss: 0.98285 - validation accuracy: 72.46 \n",
      "[16,     1] loss: 0.22291, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[16,     6] loss: 0.19103, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[16,    11] loss: 0.17335, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "[16,    16] loss: 0.22574, adv_train_accuracy: 91.02, clean_train_accuracy : 99.61\n",
      "0.66015625\n",
      "0.71484375\n",
      "duration: 26 s - train loss: 0.18203 - train accuracy: 93.18 - validation loss: 0.96143 - validation accuracy: 73.63 \n",
      "[17,     1] loss: 0.18309, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "[17,     6] loss: 0.17198, adv_train_accuracy: 94.53, clean_train_accuracy : 99.61\n",
      "[17,    11] loss: 0.17729, adv_train_accuracy: 93.36, clean_train_accuracy : 100.00\n",
      "[17,    16] loss: 0.16569, adv_train_accuracy: 93.36, clean_train_accuracy : 99.61\n",
      "0.66015625\n",
      "0.75390625\n",
      "duration: 26 s - train loss: 0.17925 - train accuracy: 93.32 - validation loss: 1.00944 - validation accuracy: 72.73 \n",
      "[18,     1] loss: 0.17717, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[18,     6] loss: 0.15610, adv_train_accuracy: 93.36, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 0.19858, adv_train_accuracy: 91.02, clean_train_accuracy : 99.61\n",
      "[18,    16] loss: 0.14276, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "0.68359375\n",
      "0.734375\n",
      "duration: 26 s - train loss: 0.18667 - train accuracy: 93.01 - validation loss: 1.01676 - validation accuracy: 73.27 \n",
      "[19,     1] loss: 0.12738, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[19,     6] loss: 0.16358, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[19,    11] loss: 0.26273, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "[19,    16] loss: 0.15289, adv_train_accuracy: 94.92, clean_train_accuracy : 99.22\n",
      "0.716796875\n",
      "0.748046875\n",
      "duration: 26 s - train loss: 0.19706 - train accuracy: 91.97 - validation loss: 1.06382 - validation accuracy: 72.01 \n",
      "[20,     1] loss: 0.23576, adv_train_accuracy: 92.19, clean_train_accuracy : 99.61\n",
      "[20,     6] loss: 0.15983, adv_train_accuracy: 92.19, clean_train_accuracy : 99.61\n",
      "[20,    11] loss: 0.17887, adv_train_accuracy: 92.58, clean_train_accuracy : 99.61\n",
      "[20,    16] loss: 0.16388, adv_train_accuracy: 94.53, clean_train_accuracy : 99.22\n",
      "0.6875\n",
      "0.7578125\n",
      "duration: 26 s - train loss: 0.19481 - train accuracy: 92.91 - validation loss: 1.07232 - validation accuracy: 72.80 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>16</td>\n",
       "      <td>0.182025</td>\n",
       "      <td>93.183594</td>\n",
       "      <td>0.961434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.63</td>\n",
       "      <td>419.073536</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>17</td>\n",
       "      <td>0.179248</td>\n",
       "      <td>93.320312</td>\n",
       "      <td>1.009441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.73</td>\n",
       "      <td>445.158308</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>18</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>93.007812</td>\n",
       "      <td>1.016756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.27</td>\n",
       "      <td>471.321837</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>19</td>\n",
       "      <td>0.197062</td>\n",
       "      <td>91.972656</td>\n",
       "      <td>1.063818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.01</td>\n",
       "      <td>497.441381</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>20</td>\n",
       "      <td>0.194806</td>\n",
       "      <td>92.910156</td>\n",
       "      <td>1.072323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.80</td>\n",
       "      <td>523.567498</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "315    16    0.182025       93.183594         0.961434               NaN   \n",
       "316    17    0.179248       93.320312         1.009441               NaN   \n",
       "317    18    0.186667       93.007812         1.016756               NaN   \n",
       "318    19    0.197062       91.972656         1.063818               NaN   \n",
       "319    20    0.194806       92.910156         1.072323               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "315         NaN             NaN       NaN             NaN       NaN   \n",
       "316         NaN             NaN       NaN             NaN       NaN   \n",
       "317         NaN             NaN       NaN             NaN       NaN   \n",
       "318         NaN             NaN       NaN             NaN       NaN   \n",
       "319         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "315                73.63  419.073536  CrossEntropyLoss()   \n",
       "316                72.73  445.158308  CrossEntropyLoss()   \n",
       "317                73.27  471.321837  CrossEntropyLoss()   \n",
       "318                72.01  497.441381  CrossEntropyLoss()   \n",
       "319                72.80  523.567498  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "315  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "316  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "317  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "318  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "319  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "315            NaN       256  \n",
       "316            NaN       256  \n",
       "317            NaN       256  \n",
       "318            NaN       256  \n",
       "319            NaN       256  \n",
       "\n",
       "[320 rows x 17 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.634765625"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7578125"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 0.18506, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "[1,     6] loss: 0.20237, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.21115, adv_train_accuracy: 91.80, clean_train_accuracy : 99.61\n",
      "[1,    16] loss: 0.20351, adv_train_accuracy: 92.58, clean_train_accuracy : 99.61\n",
      "0.640625\n",
      "0.76171875\n",
      "duration: 26 s - train loss: 0.20143 - train accuracy: 92.25 - validation loss: 0.97370 - validation accuracy: 73.48 \n",
      "[2,     1] loss: 0.19454, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[2,     6] loss: 0.16332, adv_train_accuracy: 93.36, clean_train_accuracy : 99.61\n",
      "[2,    11] loss: 0.15289, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "[2,    16] loss: 0.20829, adv_train_accuracy: 92.19, clean_train_accuracy : 99.61\n",
      "0.65625\n",
      "0.72265625\n",
      "duration: 26 s - train loss: 0.18416 - train accuracy: 93.01 - validation loss: 1.04101 - validation accuracy: 72.50 \n",
      "[3,     1] loss: 0.20737, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[3,     6] loss: 0.15158, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[3,    11] loss: 0.19210, adv_train_accuracy: 92.19, clean_train_accuracy : 99.61\n",
      "[3,    16] loss: 0.18529, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "0.685546875\n",
      "0.736328125\n",
      "duration: 25 s - train loss: 0.20655 - train accuracy: 92.46 - validation loss: 0.97103 - validation accuracy: 72.10 \n",
      "[4,     1] loss: 0.16284, adv_train_accuracy: 94.92, clean_train_accuracy : 100.00\n",
      "[4,     6] loss: 0.20537, adv_train_accuracy: 92.19, clean_train_accuracy : 99.61\n",
      "[4,    11] loss: 0.26696, adv_train_accuracy: 92.19, clean_train_accuracy : 99.22\n",
      "[4,    16] loss: 0.21306, adv_train_accuracy: 91.80, clean_train_accuracy : 99.61\n",
      "0.677734375\n",
      "0.75390625\n",
      "duration: 26 s - train loss: 0.21031 - train accuracy: 91.95 - validation loss: 1.06606 - validation accuracy: 71.48 \n",
      "[5,     1] loss: 0.24939, adv_train_accuracy: 87.11, clean_train_accuracy : 99.61\n",
      "[5,     6] loss: 0.29197, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[5,    11] loss: 0.20983, adv_train_accuracy: 91.41, clean_train_accuracy : 99.61\n",
      "[5,    16] loss: 0.26847, adv_train_accuracy: 89.45, clean_train_accuracy : 100.00\n",
      "0.716796875\n",
      "0.728515625\n",
      "duration: 26 s - train loss: 0.24338 - train accuracy: 90.55 - validation loss: 0.99643 - validation accuracy: 72.86 \n",
      "[6,     1] loss: 0.18586, adv_train_accuracy: 92.58, clean_train_accuracy : 99.61\n",
      "[6,     6] loss: 0.25259, adv_train_accuracy: 89.45, clean_train_accuracy : 100.00\n",
      "[6,    11] loss: 0.26954, adv_train_accuracy: 90.62, clean_train_accuracy : 99.61\n",
      "[6,    16] loss: 0.22672, adv_train_accuracy: 89.45, clean_train_accuracy : 100.00\n",
      "0.646484375\n",
      "0.740234375\n",
      "duration: 25 s - train loss: 0.21026 - train accuracy: 92.09 - validation loss: 1.02908 - validation accuracy: 72.68 \n",
      "[7,     1] loss: 0.20111, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[7,     6] loss: 0.23937, adv_train_accuracy: 89.45, clean_train_accuracy : 100.00\n",
      "[7,    11] loss: 0.23806, adv_train_accuracy: 89.45, clean_train_accuracy : 100.00\n",
      "[7,    16] loss: 0.21353, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "0.671875\n",
      "0.763671875\n",
      "duration: 26 s - train loss: 0.20315 - train accuracy: 91.84 - validation loss: 1.00588 - validation accuracy: 72.73 \n",
      "[8,     1] loss: 0.18779, adv_train_accuracy: 90.23, clean_train_accuracy : 100.00\n",
      "[8,     6] loss: 0.19433, adv_train_accuracy: 93.36, clean_train_accuracy : 99.61\n",
      "[8,    11] loss: 0.20204, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[8,    16] loss: 0.19924, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "0.6796875\n",
      "0.73828125\n",
      "duration: 26 s - train loss: 0.18912 - train accuracy: 92.34 - validation loss: 1.12881 - validation accuracy: 70.70 \n",
      "[9,     1] loss: 0.20779, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[9,     6] loss: 0.21708, adv_train_accuracy: 93.36, clean_train_accuracy : 99.61\n",
      "[9,    11] loss: 0.24928, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[9,    16] loss: 0.21143, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "0.697265625\n",
      "0.720703125\n",
      "duration: 25 s - train loss: 0.22043 - train accuracy: 91.68 - validation loss: 0.99488 - validation accuracy: 72.17 \n",
      "[10,     1] loss: 0.31454, adv_train_accuracy: 85.94, clean_train_accuracy : 98.83\n",
      "[10,     6] loss: 0.20899, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "[10,    11] loss: 0.24934, adv_train_accuracy: 91.02, clean_train_accuracy : 100.00\n",
      "[10,    16] loss: 0.21773, adv_train_accuracy: 90.23, clean_train_accuracy : 99.61\n",
      "0.693359375\n",
      "0.7734375\n",
      "duration: 26 s - train loss: 0.24653 - train accuracy: 89.77 - validation loss: 1.07268 - validation accuracy: 71.51 \n",
      "[11,     1] loss: 0.29784, adv_train_accuracy: 87.89, clean_train_accuracy : 100.00\n",
      "[11,     6] loss: 0.14339, adv_train_accuracy: 93.36, clean_train_accuracy : 100.00\n",
      "[11,    11] loss: 0.13022, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[11,    16] loss: 0.17666, adv_train_accuracy: 92.58, clean_train_accuracy : 99.61\n",
      "0.7109375\n",
      "0.787109375\n",
      "duration: 25 s - train loss: 0.19858 - train accuracy: 92.11 - validation loss: 1.02958 - validation accuracy: 72.87 \n",
      "[12,     1] loss: 0.20411, adv_train_accuracy: 90.62, clean_train_accuracy : 99.61\n",
      "[12,     6] loss: 0.17733, adv_train_accuracy: 90.23, clean_train_accuracy : 100.00\n",
      "[12,    11] loss: 0.16108, adv_train_accuracy: 94.14, clean_train_accuracy : 100.00\n",
      "[12,    16] loss: 0.18421, adv_train_accuracy: 93.75, clean_train_accuracy : 99.61\n",
      "0.701171875\n",
      "0.73828125\n",
      "duration: 26 s - train loss: 0.18120 - train accuracy: 92.34 - validation loss: 1.12057 - validation accuracy: 71.72 \n",
      "[13,     1] loss: 0.24667, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[13,     6] loss: 0.19255, adv_train_accuracy: 92.58, clean_train_accuracy : 99.61\n",
      "[13,    11] loss: 0.19666, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[13,    16] loss: 0.14072, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "0.69921875\n",
      "0.7734375\n",
      "duration: 26 s - train loss: 0.19381 - train accuracy: 92.42 - validation loss: 1.09973 - validation accuracy: 72.38 \n",
      "[14,     1] loss: 0.24632, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[14,     6] loss: 0.12887, adv_train_accuracy: 94.92, clean_train_accuracy : 99.61\n",
      "[14,    11] loss: 0.18277, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[14,    16] loss: 0.24649, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "0.708984375\n",
      "0.76171875\n",
      "duration: 26 s - train loss: 0.17824 - train accuracy: 93.20 - validation loss: 1.04372 - validation accuracy: 71.98 \n",
      "[15,     1] loss: 0.21006, adv_train_accuracy: 90.23, clean_train_accuracy : 100.00\n",
      "[15,     6] loss: 0.13115, adv_train_accuracy: 93.75, clean_train_accuracy : 99.61\n",
      "[15,    11] loss: 0.14267, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[15,    16] loss: 0.17952, adv_train_accuracy: 91.80, clean_train_accuracy : 99.22\n",
      "0.6875\n",
      "0.8125\n",
      "duration: 26 s - train loss: 0.16226 - train accuracy: 93.61 - validation loss: 1.05215 - validation accuracy: 72.84 \n",
      "[16,     1] loss: 0.18300, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[16,     6] loss: 0.19164, adv_train_accuracy: 93.36, clean_train_accuracy : 100.00\n",
      "[16,    11] loss: 0.28646, adv_train_accuracy: 88.28, clean_train_accuracy : 100.00\n",
      "[16,    16] loss: 0.20218, adv_train_accuracy: 91.41, clean_train_accuracy : 99.61\n",
      "0.697265625\n",
      "0.75\n",
      "duration: 26 s - train loss: 0.20777 - train accuracy: 92.21 - validation loss: 1.00310 - validation accuracy: 71.68 \n",
      "[17,     1] loss: 0.18851, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "[17,     6] loss: 0.13534, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[17,    11] loss: 0.16047, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[17,    16] loss: 0.22413, adv_train_accuracy: 91.02, clean_train_accuracy : 99.61\n",
      "0.67578125\n",
      "0.7421875\n",
      "duration: 26 s - train loss: 0.16589 - train accuracy: 93.71 - validation loss: 1.11481 - validation accuracy: 71.26 \n",
      "[18,     1] loss: 0.19846, adv_train_accuracy: 92.19, clean_train_accuracy : 99.61\n",
      "[18,     6] loss: 0.18953, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 0.18996, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "[18,    16] loss: 0.15984, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "0.6640625\n",
      "0.759765625\n",
      "duration: 26 s - train loss: 0.17657 - train accuracy: 92.95 - validation loss: 1.02389 - validation accuracy: 72.54 \n",
      "[19,     1] loss: 0.14040, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[19,     6] loss: 0.15084, adv_train_accuracy: 93.36, clean_train_accuracy : 100.00\n",
      "[19,    11] loss: 0.18563, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "[19,    16] loss: 0.28425, adv_train_accuracy: 89.06, clean_train_accuracy : 100.00\n",
      "0.701171875\n",
      "0.72265625\n",
      "duration: 26 s - train loss: 0.17438 - train accuracy: 93.46 - validation loss: 1.05285 - validation accuracy: 72.57 \n",
      "[20,     1] loss: 0.18076, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[20,     6] loss: 0.16069, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[20,    11] loss: 0.20244, adv_train_accuracy: 91.80, clean_train_accuracy : 99.61\n",
      "[20,    16] loss: 0.16593, adv_train_accuracy: 94.14, clean_train_accuracy : 100.00\n",
      "0.666015625\n",
      "0.705078125\n",
      "duration: 26 s - train loss: 0.19051 - train accuracy: 92.73 - validation loss: 1.08761 - validation accuracy: 70.86 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>16</td>\n",
       "      <td>0.207767</td>\n",
       "      <td>92.207031</td>\n",
       "      <td>1.003103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.68</td>\n",
       "      <td>416.562722</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>17</td>\n",
       "      <td>0.165894</td>\n",
       "      <td>93.710938</td>\n",
       "      <td>1.114807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.26</td>\n",
       "      <td>442.664834</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>18</td>\n",
       "      <td>0.176574</td>\n",
       "      <td>92.949219</td>\n",
       "      <td>1.023890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.54</td>\n",
       "      <td>468.665618</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>19</td>\n",
       "      <td>0.174385</td>\n",
       "      <td>93.457031</td>\n",
       "      <td>1.052848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.57</td>\n",
       "      <td>494.955294</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>20</td>\n",
       "      <td>0.190507</td>\n",
       "      <td>92.734375</td>\n",
       "      <td>1.087607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.86</td>\n",
       "      <td>521.285391</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "335    16    0.207767       92.207031         1.003103               NaN   \n",
       "336    17    0.165894       93.710938         1.114807               NaN   \n",
       "337    18    0.176574       92.949219         1.023890               NaN   \n",
       "338    19    0.174385       93.457031         1.052848               NaN   \n",
       "339    20    0.190507       92.734375         1.087607               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "335         NaN             NaN       NaN             NaN       NaN   \n",
       "336         NaN             NaN       NaN             NaN       NaN   \n",
       "337         NaN             NaN       NaN             NaN       NaN   \n",
       "338         NaN             NaN       NaN             NaN       NaN   \n",
       "339         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "335                71.68  416.562722  CrossEntropyLoss()   \n",
       "336                71.26  442.664834  CrossEntropyLoss()   \n",
       "337                72.54  468.665618  CrossEntropyLoss()   \n",
       "338                72.57  494.955294  CrossEntropyLoss()   \n",
       "339                70.86  521.285391  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "335  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "336  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "337  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "338  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "339  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "335            NaN       256  \n",
       "336            NaN       256  \n",
       "337            NaN       256  \n",
       "338            NaN       256  \n",
       "339            NaN       256  \n",
       "\n",
       "[340 rows x 17 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.693359375"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.767578125"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 0.16889, adv_train_accuracy: 94.53, clean_train_accuracy : 99.61\n",
      "[1,     6] loss: 0.16321, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.37779, adv_train_accuracy: 87.11, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.30959, adv_train_accuracy: 88.67, clean_train_accuracy : 99.22\n",
      "0.697265625\n",
      "0.71875\n",
      "duration: 26 s - train loss: 0.24782 - train accuracy: 90.94 - validation loss: 0.95020 - validation accuracy: 71.54 \n",
      "[2,     1] loss: 0.21022, adv_train_accuracy: 91.02, clean_train_accuracy : 99.22\n",
      "[2,     6] loss: 0.18885, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "[2,    11] loss: 0.15164, adv_train_accuracy: 94.14, clean_train_accuracy : 100.00\n",
      "[2,    16] loss: 0.19662, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "0.69140625\n",
      "0.734375\n",
      "duration: 26 s - train loss: 0.18458 - train accuracy: 92.83 - validation loss: 1.06309 - validation accuracy: 72.66 \n",
      "[3,     1] loss: 0.20287, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "[3,     6] loss: 0.19894, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[3,    11] loss: 0.23317, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[3,    16] loss: 0.12806, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "0.693359375\n",
      "0.767578125\n",
      "duration: 26 s - train loss: 0.18016 - train accuracy: 93.18 - validation loss: 1.03795 - validation accuracy: 71.90 \n",
      "[4,     1] loss: 0.13876, adv_train_accuracy: 94.92, clean_train_accuracy : 100.00\n",
      "[4,     6] loss: 0.19446, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[4,    11] loss: 0.17782, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[4,    16] loss: 0.19886, adv_train_accuracy: 94.14, clean_train_accuracy : 100.00\n",
      "0.6796875\n",
      "0.76171875\n",
      "duration: 26 s - train loss: 0.19647 - train accuracy: 92.19 - validation loss: 0.99421 - validation accuracy: 72.30 \n",
      "[5,     1] loss: 0.24374, adv_train_accuracy: 89.84, clean_train_accuracy : 100.00\n",
      "[5,     6] loss: 0.14625, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[5,    11] loss: 0.13059, adv_train_accuracy: 94.14, clean_train_accuracy : 100.00\n",
      "[5,    16] loss: 0.18515, adv_train_accuracy: 94.14, clean_train_accuracy : 99.61\n",
      "0.67578125\n",
      "0.7734375\n",
      "duration: 26 s - train loss: 0.17248 - train accuracy: 93.26 - validation loss: 1.05600 - validation accuracy: 73.00 \n",
      "[6,     1] loss: 0.16070, adv_train_accuracy: 93.36, clean_train_accuracy : 99.61\n",
      "[6,     6] loss: 0.17426, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[6,    11] loss: 0.27464, adv_train_accuracy: 91.80, clean_train_accuracy : 99.61\n",
      "[6,    16] loss: 0.16130, adv_train_accuracy: 95.70, clean_train_accuracy : 100.00\n",
      "0.673828125\n",
      "0.71875\n",
      "duration: 26 s - train loss: 0.16927 - train accuracy: 93.85 - validation loss: 1.00766 - validation accuracy: 72.40 \n",
      "[7,     1] loss: 0.17653, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[7,     6] loss: 0.23815, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[7,    11] loss: 0.13263, adv_train_accuracy: 95.70, clean_train_accuracy : 100.00\n",
      "[7,    16] loss: 0.20653, adv_train_accuracy: 91.41, clean_train_accuracy : 99.61\n",
      "0.681640625\n",
      "0.765625\n",
      "duration: 26 s - train loss: 0.18130 - train accuracy: 92.99 - validation loss: 1.03249 - validation accuracy: 72.66 \n",
      "[8,     1] loss: 0.19333, adv_train_accuracy: 93.75, clean_train_accuracy : 99.61\n",
      "[8,     6] loss: 0.18355, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[8,    11] loss: 0.15041, adv_train_accuracy: 94.92, clean_train_accuracy : 99.61\n",
      "[8,    16] loss: 0.17013, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n",
      "0.689453125\n",
      "0.76171875\n",
      "duration: 26 s - train loss: 0.17131 - train accuracy: 93.14 - validation loss: 1.11237 - validation accuracy: 73.12 \n",
      "[9,     1] loss: 0.12213, adv_train_accuracy: 95.70, clean_train_accuracy : 100.00\n",
      "[9,     6] loss: 0.16762, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[9,    11] loss: 0.15240, adv_train_accuracy: 94.53, clean_train_accuracy : 98.83\n",
      "[9,    16] loss: 0.23532, adv_train_accuracy: 90.23, clean_train_accuracy : 99.61\n",
      "0.712890625\n",
      "0.732421875\n",
      "duration: 26 s - train loss: 0.16943 - train accuracy: 93.61 - validation loss: 1.06024 - validation accuracy: 72.40 \n",
      "[10,     1] loss: 0.14274, adv_train_accuracy: 95.70, clean_train_accuracy : 100.00\n",
      "[10,     6] loss: 0.19295, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[10,    11] loss: 0.24595, adv_train_accuracy: 91.02, clean_train_accuracy : 99.22\n",
      "[10,    16] loss: 0.22642, adv_train_accuracy: 90.23, clean_train_accuracy : 99.61\n",
      "0.71484375\n",
      "0.7890625\n",
      "duration: 26 s - train loss: 0.18517 - train accuracy: 92.97 - validation loss: 0.99441 - validation accuracy: 72.31 \n",
      "[11,     1] loss: 0.24989, adv_train_accuracy: 88.67, clean_train_accuracy : 100.00\n",
      "[11,     6] loss: 0.15139, adv_train_accuracy: 93.36, clean_train_accuracy : 100.00\n",
      "[11,    11] loss: 0.14483, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[11,    16] loss: 0.18673, adv_train_accuracy: 94.92, clean_train_accuracy : 99.61\n",
      "0.66015625\n",
      "0.740234375\n",
      "duration: 26 s - train loss: 0.20122 - train accuracy: 91.95 - validation loss: 1.01543 - validation accuracy: 72.12 \n",
      "[12,     1] loss: 0.21399, adv_train_accuracy: 91.02, clean_train_accuracy : 100.00\n",
      "[12,     6] loss: 0.19156, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[12,    11] loss: 0.16180, adv_train_accuracy: 92.58, clean_train_accuracy : 99.61\n",
      "[12,    16] loss: 0.19517, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "0.701171875\n",
      "0.73828125\n",
      "duration: 26 s - train loss: 0.21338 - train accuracy: 91.58 - validation loss: 1.02839 - validation accuracy: 72.07 \n",
      "[13,     1] loss: 0.21259, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[13,     6] loss: 0.17919, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "[13,    11] loss: 0.15102, adv_train_accuracy: 93.75, clean_train_accuracy : 99.61\n",
      "[13,    16] loss: 0.17137, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "0.673828125\n",
      "0.76171875\n",
      "duration: 26 s - train loss: 0.17612 - train accuracy: 93.05 - validation loss: 1.05814 - validation accuracy: 72.22 \n",
      "[14,     1] loss: 0.13713, adv_train_accuracy: 93.36, clean_train_accuracy : 99.22\n",
      "[14,     6] loss: 0.13446, adv_train_accuracy: 96.09, clean_train_accuracy : 100.00\n",
      "[14,    11] loss: 0.16078, adv_train_accuracy: 94.14, clean_train_accuracy : 100.00\n",
      "[14,    16] loss: 0.16950, adv_train_accuracy: 94.14, clean_train_accuracy : 100.00\n",
      "0.685546875\n",
      "0.73828125\n",
      "duration: 26 s - train loss: 0.16037 - train accuracy: 94.02 - validation loss: 1.04603 - validation accuracy: 73.20 \n",
      "[15,     1] loss: 0.18624, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[15,     6] loss: 0.15650, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "[15,    11] loss: 0.12767, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[15,    16] loss: 0.17075, adv_train_accuracy: 94.14, clean_train_accuracy : 99.61\n",
      "0.697265625\n",
      "0.7421875\n",
      "duration: 26 s - train loss: 0.16374 - train accuracy: 93.54 - validation loss: 0.97734 - validation accuracy: 72.46 \n",
      "[16,     1] loss: 0.20465, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[16,     6] loss: 0.20050, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "[16,    11] loss: 0.15773, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[16,    16] loss: 0.17323, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "0.658203125\n",
      "0.748046875\n",
      "duration: 26 s - train loss: 0.16477 - train accuracy: 93.59 - validation loss: 1.08473 - validation accuracy: 72.28 \n",
      "[17,     1] loss: 0.10159, adv_train_accuracy: 96.09, clean_train_accuracy : 99.61\n",
      "[17,     6] loss: 0.17209, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[17,    11] loss: 0.18782, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[17,    16] loss: 0.29098, adv_train_accuracy: 86.72, clean_train_accuracy : 100.00\n",
      "0.716796875\n",
      "0.73828125\n",
      "duration: 26 s - train loss: 0.17890 - train accuracy: 92.44 - validation loss: 1.07389 - validation accuracy: 71.73 \n",
      "[18,     1] loss: 0.19219, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "[18,     6] loss: 0.13420, adv_train_accuracy: 96.48, clean_train_accuracy : 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    11] loss: 0.15879, adv_train_accuracy: 94.14, clean_train_accuracy : 100.00\n",
      "[18,    16] loss: 0.20898, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "0.681640625\n",
      "0.732421875\n",
      "duration: 26 s - train loss: 0.17810 - train accuracy: 93.30 - validation loss: 1.03942 - validation accuracy: 72.62 \n",
      "[19,     1] loss: 0.16492, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "[19,     6] loss: 0.14674, adv_train_accuracy: 95.70, clean_train_accuracy : 99.61\n",
      "[19,    11] loss: 0.20795, adv_train_accuracy: 93.36, clean_train_accuracy : 100.00\n",
      "[19,    16] loss: 0.17964, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "0.701171875\n",
      "0.775390625\n",
      "duration: 26 s - train loss: 0.17331 - train accuracy: 93.73 - validation loss: 0.98477 - validation accuracy: 73.39 \n",
      "[20,     1] loss: 0.14873, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "[20,     6] loss: 0.13645, adv_train_accuracy: 94.14, clean_train_accuracy : 100.00\n",
      "[20,    11] loss: 0.18422, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[20,    16] loss: 0.17974, adv_train_accuracy: 91.41, clean_train_accuracy : 100.00\n",
      "0.7109375\n",
      "0.732421875\n",
      "duration: 25 s - train loss: 0.16295 - train accuracy: 93.55 - validation loss: 1.03895 - validation accuracy: 72.56 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.069616</td>\n",
       "      <td>10.019531</td>\n",
       "      <td>3.418694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>27.299788</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.292510</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>2.192064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.43</td>\n",
       "      <td>53.504930</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.474881</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>2.233554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.19</td>\n",
       "      <td>79.630913</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.347974</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>2.084406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.54</td>\n",
       "      <td>106.239956</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.225618</td>\n",
       "      <td>17.734375</td>\n",
       "      <td>1.975296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.90</td>\n",
       "      <td>132.602924</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>16</td>\n",
       "      <td>0.164769</td>\n",
       "      <td>93.593750</td>\n",
       "      <td>1.084731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.28</td>\n",
       "      <td>420.345668</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>17</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>92.441406</td>\n",
       "      <td>1.073892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.73</td>\n",
       "      <td>446.568607</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>18</td>\n",
       "      <td>0.178096</td>\n",
       "      <td>93.300781</td>\n",
       "      <td>1.039423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.62</td>\n",
       "      <td>472.594736</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>19</td>\n",
       "      <td>0.173306</td>\n",
       "      <td>93.730469</td>\n",
       "      <td>0.984771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.39</td>\n",
       "      <td>498.670351</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>20</td>\n",
       "      <td>0.162949</td>\n",
       "      <td>93.554688</td>\n",
       "      <td>1.038948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.56</td>\n",
       "      <td>524.577562</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0       1   10.069616       10.019531         3.418694               NaN   \n",
       "1       2    3.292510        8.789062         2.192064               NaN   \n",
       "2       3    2.474881       13.281250         2.233554               NaN   \n",
       "3       4    2.347974       16.093750         2.084406               NaN   \n",
       "4       5    2.225618       17.734375         1.975296               NaN   \n",
       "..    ...         ...             ...              ...               ...   \n",
       "355    16    0.164769       93.593750         1.084731               NaN   \n",
       "356    17    0.178900       92.441406         1.073892               NaN   \n",
       "357    18    0.178096       93.300781         1.039423               NaN   \n",
       "358    19    0.173306       93.730469         0.984771               NaN   \n",
       "359    20    0.162949       93.554688         1.038948               NaN   \n",
       "\n",
       "     l_inf_loss  l_2_robustness  l_2_loss  l_0_robustness  l_0_loss  \\\n",
       "0           NaN             NaN       NaN             NaN       NaN   \n",
       "1           NaN             NaN       NaN             NaN       NaN   \n",
       "2           NaN             NaN       NaN             NaN       NaN   \n",
       "3           NaN             NaN       NaN             NaN       NaN   \n",
       "4           NaN             NaN       NaN             NaN       NaN   \n",
       "..          ...             ...       ...             ...       ...   \n",
       "355         NaN             NaN       NaN             NaN       NaN   \n",
       "356         NaN             NaN       NaN             NaN       NaN   \n",
       "357         NaN             NaN       NaN             NaN       NaN   \n",
       "358         NaN             NaN       NaN             NaN       NaN   \n",
       "359         NaN             NaN       NaN             NaN       NaN   \n",
       "\n",
       "     validation_accuracy    duration           criterion  \\\n",
       "0                  14.26   27.299788  CrossEntropyLoss()   \n",
       "1                  23.43   53.504930  CrossEntropyLoss()   \n",
       "2                  27.19   79.630913  CrossEntropyLoss()   \n",
       "3                  28.54  106.239956  CrossEntropyLoss()   \n",
       "4                  32.90  132.602924  CrossEntropyLoss()   \n",
       "..                   ...         ...                 ...   \n",
       "355                72.28  420.345668  CrossEntropyLoss()   \n",
       "356                71.73  446.568607  CrossEntropyLoss()   \n",
       "357                72.62  472.594736  CrossEntropyLoss()   \n",
       "358                73.39  498.670351  CrossEntropyLoss()   \n",
       "359                72.56  524.577562  CrossEntropyLoss()   \n",
       "\n",
       "                                             optimizer    method  \\\n",
       "0    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4    Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                 ...       ...   \n",
       "355  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "356  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "357  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "358  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "359  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "     learning_rate batchsize  \n",
       "0              NaN       256  \n",
       "1              NaN       256  \n",
       "2              NaN       256  \n",
       "3              NaN       256  \n",
       "4              NaN       256  \n",
       "..             ...       ...  \n",
       "355            NaN       256  \n",
       "356            NaN       256  \n",
       "357            NaN       256  \n",
       "358            NaN       256  \n",
       "359            NaN       256  \n",
       "\n",
       "[360 rows x 17 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.650390625"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73828125"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast adversarial training\n",
      "fast adv. train.\n",
      "[1,     1] loss: 0.15072, adv_train_accuracy: 94.92, clean_train_accuracy : 100.00\n",
      "[1,     6] loss: 0.13959, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "[1,    11] loss: 0.22094, adv_train_accuracy: 91.02, clean_train_accuracy : 100.00\n",
      "[1,    16] loss: 0.22141, adv_train_accuracy: 91.02, clean_train_accuracy : 100.00\n",
      "0.669921875\n",
      "0.732421875\n",
      "duration: 26 s - train loss: 0.17056 - train accuracy: 93.44 - validation loss: 1.04028 - validation accuracy: 72.40 \n",
      "[2,     1] loss: 0.18358, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[2,     6] loss: 0.17461, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[2,    11] loss: 0.27278, adv_train_accuracy: 91.02, clean_train_accuracy : 100.00\n",
      "[2,    16] loss: 0.15589, adv_train_accuracy: 94.14, clean_train_accuracy : 99.61\n",
      "0.697265625\n",
      "0.720703125\n",
      "duration: 26 s - train loss: 0.16689 - train accuracy: 93.79 - validation loss: 1.13343 - validation accuracy: 72.17 \n",
      "[3,     1] loss: 0.13846, adv_train_accuracy: 93.75, clean_train_accuracy : 99.61\n",
      "[3,     6] loss: 0.15679, adv_train_accuracy: 95.31, clean_train_accuracy : 99.61\n",
      "[3,    11] loss: 0.19715, adv_train_accuracy: 91.02, clean_train_accuracy : 99.61\n",
      "[3,    16] loss: 0.16472, adv_train_accuracy: 93.75, clean_train_accuracy : 99.61\n",
      "0.689453125\n",
      "0.716796875\n",
      "duration: 26 s - train loss: 0.16013 - train accuracy: 93.87 - validation loss: 1.16682 - validation accuracy: 71.28 \n",
      "[4,     1] loss: 0.25025, adv_train_accuracy: 90.62, clean_train_accuracy : 100.00\n",
      "[4,     6] loss: 0.15707, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[4,    11] loss: 0.21340, adv_train_accuracy: 90.23, clean_train_accuracy : 100.00\n",
      "[4,    16] loss: 0.12595, adv_train_accuracy: 95.70, clean_train_accuracy : 100.00\n",
      "0.69140625\n",
      "0.771484375\n",
      "duration: 26 s - train loss: 0.18855 - train accuracy: 92.54 - validation loss: 1.18062 - validation accuracy: 72.05 \n",
      "[5,     1] loss: 0.16290, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "[5,     6] loss: 0.18403, adv_train_accuracy: 92.97, clean_train_accuracy : 100.00\n",
      "[5,    11] loss: 0.13777, adv_train_accuracy: 94.14, clean_train_accuracy : 100.00\n",
      "[5,    16] loss: 0.23823, adv_train_accuracy: 93.36, clean_train_accuracy : 100.00\n",
      "0.693359375\n",
      "0.75390625\n",
      "duration: 25 s - train loss: 0.17212 - train accuracy: 93.48 - validation loss: 1.11487 - validation accuracy: 71.40 \n",
      "[6,     1] loss: 0.17821, adv_train_accuracy: 93.75, clean_train_accuracy : 100.00\n",
      "[6,     6] loss: 0.18008, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[6,    11] loss: 0.18238, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[6,    16] loss: 0.20529, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "0.69921875\n",
      "0.763671875\n",
      "duration: 26 s - train loss: 0.17300 - train accuracy: 92.95 - validation loss: 1.13011 - validation accuracy: 72.01 \n",
      "[7,     1] loss: 0.17342, adv_train_accuracy: 93.75, clean_train_accuracy : 99.61\n",
      "[7,     6] loss: 0.20566, adv_train_accuracy: 92.97, clean_train_accuracy : 99.61\n",
      "[7,    11] loss: 0.22651, adv_train_accuracy: 91.02, clean_train_accuracy : 100.00\n",
      "[7,    16] loss: 0.19378, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "0.681640625\n",
      "0.724609375\n",
      "duration: 26 s - train loss: 0.17305 - train accuracy: 93.57 - validation loss: 1.09866 - validation accuracy: 72.55 \n",
      "[8,     1] loss: 0.12710, adv_train_accuracy: 94.92, clean_train_accuracy : 100.00\n",
      "[8,     6] loss: 0.11864, adv_train_accuracy: 94.53, clean_train_accuracy : 100.00\n",
      "[8,    11] loss: 0.13634, adv_train_accuracy: 95.31, clean_train_accuracy : 99.61\n",
      "[8,    16] loss: 0.14676, adv_train_accuracy: 94.14, clean_train_accuracy : 100.00\n",
      "0.708984375\n",
      "0.73828125\n",
      "duration: 25 s - train loss: 0.14326 - train accuracy: 94.39 - validation loss: 1.11566 - validation accuracy: 72.47 \n",
      "[9,     1] loss: 0.11781, adv_train_accuracy: 95.31, clean_train_accuracy : 99.61\n",
      "[9,     6] loss: 0.21221, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[9,    11] loss: 0.15055, adv_train_accuracy: 94.92, clean_train_accuracy : 99.61\n",
      "[9,    16] loss: 0.11765, adv_train_accuracy: 97.27, clean_train_accuracy : 100.00\n",
      "0.68359375\n",
      "0.73046875\n",
      "duration: 26 s - train loss: 0.15962 - train accuracy: 94.26 - validation loss: 1.12130 - validation accuracy: 72.26 \n",
      "[10,     1] loss: 0.13059, adv_train_accuracy: 96.48, clean_train_accuracy : 99.61\n",
      "[10,     6] loss: 0.17972, adv_train_accuracy: 92.19, clean_train_accuracy : 100.00\n",
      "[10,    11] loss: 0.22181, adv_train_accuracy: 93.36, clean_train_accuracy : 100.00\n",
      "[10,    16] loss: 0.17193, adv_train_accuracy: 94.92, clean_train_accuracy : 100.00\n",
      "0.73828125\n",
      "0.78515625\n",
      "duration: 26 s - train loss: 0.16329 - train accuracy: 94.04 - validation loss: 1.09709 - validation accuracy: 72.41 \n",
      "[11,     1] loss: 0.19394, adv_train_accuracy: 91.80, clean_train_accuracy : 100.00\n",
      "[11,     6] loss: 0.29565, adv_train_accuracy: 92.19, clean_train_accuracy : 98.83\n",
      "[11,    11] loss: 0.18154, adv_train_accuracy: 92.58, clean_train_accuracy : 100.00\n",
      "[11,    16] loss: 0.18952, adv_train_accuracy: 95.31, clean_train_accuracy : 100.00\n",
      "0.701171875\n",
      "0.70703125\n",
      "duration: 26 s - train loss: 0.16790 - train accuracy: 93.71 - validation loss: 1.04433 - validation accuracy: 73.57 \n",
      "[12,     1] loss: 0.12879, adv_train_accuracy: 94.14, clean_train_accuracy : 100.00\n",
      "[12,     6] loss: 0.24258, adv_train_accuracy: 91.80, clean_train_accuracy : 99.61\n",
      "[12,    11] loss: 0.18633, adv_train_accuracy: 93.75, clean_train_accuracy : 99.22\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-92f1ccd60ab4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/pytorch-network-pruning/src/models.py\u001b[0m in \u001b[0;36mfit_fast\u001b[0;34m(self, train_loader, val_loader, epochs, device, eps, number_of_replays, patience, evaluate_robustness)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_replays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fast adversarial training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_fit_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_fast_with_double_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_replays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-network-pruning/src/training.py\u001b[0m in \u001b[0;36m_fit_fast\u001b[0;34m(model, train_loader, val_loader, epochs, device, eps, patience, evaluate_robustness)\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m                 \u001b[0mclean_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mclean_train_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit_fast(train_loader, test_loader , 20, device, patience=None, evaluate_robustness=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 8/255, device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, success = PGD(model, test_loader, torch.nn.CrossEntropyLoss(), device)\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD(model, data_loader, criterion, device, max_stepsize=1.25*8/255, eps=8/255, steps=7):\n",
    "    model.eval()\n",
    "    advs = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(data_loader):\n",
    "        if i < 2:\n",
    "            inputs, labels = data\n",
    "            inputs, labels =inputs.to(device), labels.to(device)\n",
    "\n",
    "            adv_examples = inputs\n",
    "            adv_examples.requires_grad = True\n",
    "            adv_examples.retain_grad()\n",
    "            for step in range(steps):\n",
    "                #print(torch.max(adv_examples[0]-inputs[0][0]))\n",
    "                adv_examples, pert = FGSM_step(model, adv_examples, labels, criterion, max_stepsize, device)\n",
    "                pert = adv_examples - inputs\n",
    "                pert.clamp_(-eps, eps)\n",
    "                adv_examples = inputs + pert\n",
    "                adv_examples.clamp_(0,1)\n",
    "            advs.append(adv_examples)\n",
    "            preds = model(adv_examples)\n",
    "            #pred_labels = \n",
    "            _, predicted = torch.max(preds.data, 1)\n",
    "            total += len(predicted)\n",
    "            #correct += (pred_labels == labels).sum().item()\n",
    "            correct += (predicted != labels).sum().item()\n",
    "    return advs, correct/total\n",
    "        \n",
    "\n",
    "def FGSM_step(model, inputs, labels, criterion, eps, device):\n",
    "\n",
    "    inputs.retain_grad()\n",
    "    perturbation = torch.zeros_like(inputs).to(device)\n",
    "    preds = model(inputs)\n",
    "    loss = criterion(preds, labels)\n",
    "    loss.backward(retain_graph=True)\n",
    "    perturbation = torch.sign(inputs.grad).clamp_(-eps, eps)\n",
    "    adv_examples = inputs + perturbation\n",
    "    adv_examples.clamp_(0,1)\n",
    "    return adv_examples, perturbation\n",
    "    \n",
    "\n",
    "def FGSM(model, data_loader, criterion, eps, device):\n",
    "    model.eval()\n",
    "    #mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "    #mean = torch.tensor(mean).view(3,1,1).expand(3,32,32).to(device)\n",
    "    #std = torch.tensor(std).view(3,1,1).expand(3,32,32).to(device)\n",
    "    advs = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i,data in enumerate(data_loader):\n",
    "        if i < 2:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs.requires_grad = True\n",
    "            adv_examples, perturbation = FGSM_step(model, inputs, labels, criterion, eps, device)\n",
    "\n",
    "            advs.append(adv_examples)\n",
    "            preds = model(adv_examples)\n",
    "            #pred_labels = \n",
    "            _, predicted = torch.max(preds.data, 1)\n",
    "            total += len(predicted)\n",
    "            #correct += (pred_labels == labels).sum().item()\n",
    "            correct += (predicted != labels).sum().item()\n",
    "\n",
    "    \n",
    "    return advs, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./saved-models/cifar-resnet-fast-10k-train-data.pth'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH='./saved-models/cifar-resnet-fast-10k-train-data.pth'\n",
    "safe_model(PATH, model, description='N/A', loss='N/A',epoch='N/A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
