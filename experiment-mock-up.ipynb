{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "from src.models import CifarResNet, MNIST_CNN, CIFAR_CNN\n",
    "from src.helpers import evaluate_rob_accuracy, evaluate_clean_accuracy, load_model, safe_model,_evaluate_model\n",
    "from src.data_loader import load_torchvision_dataset, load_imagenette\n",
    "import subprocess\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "identifying layers\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "10\n",
      "[False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False]\n",
      "start epoch: 0\n",
      "robustness:  0.2671875\n",
      "0 48.4098424911499 0.020000000000000018 2.5103499463272096 0.1633\n",
      "start epoch: 1\n",
      "robustness:  0.271875\n",
      "1 48.60154318809509 0.040000000000000036 2.0534860025787354 0.22814\n",
      "start epoch: 2\n",
      "robustness:  0.3015625\n",
      "2 48.70618224143982 0.05999999999999997 1.9963367218780517 0.24684\n",
      "start epoch: 3\n",
      "robustness:  0.3\n",
      "3 48.88509964942932 0.07999999999999999 1.9403338637924195 0.2685\n",
      "start epoch: 4\n",
      "robustness:  0.2984375\n",
      "4 48.91189622879028 0.1 1.8696382135391236 0.29176\n",
      "start epoch: 5\n",
      "robustness:  0.3015625\n",
      "5 48.94861888885498 0.12000000000000002 1.80864080783844 0.3149\n",
      "start epoch: 6\n",
      "robustness:  0.3421875\n",
      "6 49.00322437286377 0.14000000000000004 1.7462898318862916 0.33842\n",
      "start epoch: 7\n",
      "robustness:  0.3484375\n",
      "7 49.003798723220825 0.15999999999999998 1.6981734755706788 0.3523\n",
      "start epoch: 8\n",
      "robustness:  0.3578125\n",
      "8 49.61145210266113 0.18 1.655470539855957 0.36888\n",
      "start epoch: 9\n",
      "robustness:  0.3734375\n",
      "9 49.41596174240112 0.2 1.6189385181427003 0.384\n",
      "0.0\n",
      "start epoch: 10\n",
      "robustness:  0.3953125\n",
      "10 49.08839464187622 0.18 1.5825025534820556 0.3976\n",
      "start epoch: 11\n"
     ]
    }
   ],
   "source": [
    "#train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True, batchsize=128)\n",
    "train_loader, test_loader = get_loaders(128)\n",
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "#model.prune_magnitude_global_unstruct(.0, device)\n",
    "#hist = model.fit_fast_locuslab(train_loader, test_loader , 15, device, eps=8,patience=None, evaluate_robustness=False)\n",
    "masks = list(filter(lambda x: 'mask' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))\n",
    "train_locus(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.3138814685821534, 0.0798)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_standard(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.315561389923096, 0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pgd(test_loader, model, 30, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruned - 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "identifying layers\n",
      "tensor(0.9485)\n",
      "tensor(0.9218)\n",
      "tensor(0.9208)\n",
      "tensor(0.9196)\n",
      "tensor(0.9200)\n",
      "tensor(0.9032)\n",
      "tensor(0.8866)\n",
      "tensor(0.9709)\n",
      "tensor(0.8872)\n",
      "tensor(0.8875)\n",
      "tensor(0.8621)\n",
      "tensor(0.8396)\n",
      "tensor(0.9554)\n",
      "tensor(0.8410)\n",
      "tensor(0.8408)\n",
      "tensor(0.8040)\n",
      "tensor(0.7739)\n",
      "tensor(0.9346)\n",
      "tensor(0.7746)\n",
      "tensor(0.7740)\n",
      "tensor(1.)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "start epoch: 0\n",
      "0 46.646488428115845 0.02666666666666666 2.464958632659912 0.16658\n",
      "start epoch: 1\n",
      "1 46.77658295631409 0.05333333333333332 2.0598497940063476 0.22432\n",
      "start epoch: 2\n",
      "2 46.786173820495605 0.07999999999999999 2.0111606967163085 0.24568\n",
      "start epoch: 3\n",
      "3 46.850473403930664 0.10666666666666665 1.9462248986816406 0.26722\n",
      "start epoch: 4\n",
      "4 46.90013551712036 0.1333333333333333 1.8751359702301025 0.29162\n",
      "start epoch: 5\n",
      "5 46.91172814369202 0.15999999999999998 1.802174209022522 0.31808\n",
      "start epoch: 6\n",
      "6 46.90692734718323 0.18666666666666673 1.7420188931655884 0.33728\n",
      "start epoch: 7\n",
      "7 46.893341302871704 0.18666666666666673 1.6856929816436768 0.35886\n",
      "start epoch: 8\n",
      "8 46.90585970878601 0.15999999999999998 1.6302491360473632 0.37892\n",
      "start epoch: 9\n",
      "9 46.93929171562195 0.1333333333333334 1.5798748998641967 0.39826\n",
      "start epoch: 10\n",
      "10 46.90399432182312 0.10666666666666665 1.5309732667922973 0.4154\n",
      "start epoch: 11\n",
      "11 46.91444373130798 0.07999999999999999 1.4828530690383912 0.43348\n",
      "start epoch: 12\n",
      "12 46.892699003219604 0.05333333333333332 1.4287402411270143 0.4512\n",
      "start epoch: 13\n",
      "13 46.90722298622131 0.02666666666666666 1.354413597717285 0.4776\n",
      "start epoch: 14\n",
      "14 46.89475893974304 0.0 1.258878427696228 0.5107\n",
      "identifying layers\n",
      "tensor(0.9485)\n",
      "tensor(0.9218)\n",
      "tensor(0.9208)\n",
      "tensor(0.9196)\n",
      "tensor(0.9200)\n",
      "tensor(0.9032)\n",
      "tensor(0.8866)\n",
      "tensor(0.9709)\n",
      "tensor(0.8872)\n",
      "tensor(0.8875)\n",
      "tensor(0.8621)\n",
      "tensor(0.8396)\n",
      "tensor(0.9554)\n",
      "tensor(0.8410)\n",
      "tensor(0.8408)\n",
      "tensor(0.8040)\n",
      "tensor(0.7739)\n",
      "tensor(0.9346)\n",
      "tensor(0.7746)\n",
      "tensor(0.7740)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True, batchsize=128)\n",
    "train_loader, test_loader = get_loaders(128)\n",
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "model.prune_magnitude_global_unstruct(.2, device)\n",
    "masks = list(filter(lambda x: 'mask' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))\n",
    "#hist = model.fit_fast_locuslab(train_loader, test_loader , 15, device, eps=8,patience=None, evaluate_robustness=False)\n",
    "train_locus(model)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7692893251419067, 0.7588)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_standard(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.057338547706604, 0.471875)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pgd(test_loader, model, 30, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruned - 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "identifying layers\n",
      "tensor(0.8872)\n",
      "tensor(0.8416)\n",
      "tensor(0.8390)\n",
      "tensor(0.8389)\n",
      "tensor(0.8423)\n",
      "tensor(0.8045)\n",
      "tensor(0.7728)\n",
      "tensor(0.9365)\n",
      "tensor(0.7755)\n",
      "tensor(0.7748)\n",
      "tensor(0.7239)\n",
      "tensor(0.6803)\n",
      "tensor(0.9065)\n",
      "tensor(0.6803)\n",
      "tensor(0.6808)\n",
      "tensor(0.6084)\n",
      "tensor(0.5483)\n",
      "tensor(0.8677)\n",
      "tensor(0.5486)\n",
      "tensor(0.5484)\n",
      "tensor(1.)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "start epoch: 0\n",
      "0 46.66033315658569 0.02666666666666666 2.46786300491333 0.16342\n",
      "start epoch: 1\n",
      "1 46.724276065826416 0.05333333333333332 2.041916581726074 0.23036\n",
      "start epoch: 2\n",
      "2 46.7903048992157 0.07999999999999999 1.99392629611969 0.25078\n",
      "start epoch: 3\n",
      "3 46.76216268539429 0.10666666666666665 1.936928617324829 0.26988\n",
      "start epoch: 4\n",
      "4 46.76258730888367 0.1333333333333333 1.865154624595642 0.29436\n",
      "start epoch: 5\n",
      "5 46.787880659103394 0.15999999999999998 1.8027686996078491 0.31764\n",
      "start epoch: 6\n",
      "6 46.78488755226135 0.18666666666666673 1.742174242477417 0.34124\n",
      "start epoch: 7\n",
      "7 46.773000717163086 0.18666666666666673 1.6869291301727294 0.35782\n",
      "start epoch: 8\n",
      "8 46.76813268661499 0.15999999999999998 1.6279181065750121 0.38046\n",
      "start epoch: 9\n",
      "9 46.77965188026428 0.1333333333333334 1.5764760265731812 0.39802\n",
      "start epoch: 10\n",
      "10 46.80862522125244 0.10666666666666665 1.5313446154022217 0.4147\n",
      "start epoch: 11\n",
      "11 46.793559312820435 0.07999999999999999 1.4796614957427978 0.43354\n",
      "start epoch: 12\n",
      "12 46.794143199920654 0.05333333333333332 1.4282513393402099 0.45292\n",
      "start epoch: 13\n",
      "13 46.787050008773804 0.02666666666666666 1.3558718218994141 0.47874\n",
      "start epoch: 14\n",
      "14 46.78971266746521 0.0 1.2461230722808838 0.51702\n",
      "identifying layers\n",
      "tensor(0.8872)\n",
      "tensor(0.8416)\n",
      "tensor(0.8390)\n",
      "tensor(0.8389)\n",
      "tensor(0.8423)\n",
      "tensor(0.8045)\n",
      "tensor(0.7728)\n",
      "tensor(0.9365)\n",
      "tensor(0.7755)\n",
      "tensor(0.7748)\n",
      "tensor(0.7239)\n",
      "tensor(0.6803)\n",
      "tensor(0.9065)\n",
      "tensor(0.6803)\n",
      "tensor(0.6808)\n",
      "tensor(0.6084)\n",
      "tensor(0.5483)\n",
      "tensor(0.8677)\n",
      "tensor(0.5486)\n",
      "tensor(0.5484)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True, batchsize=128)\n",
    "train_loader, test_loader = get_loaders(128)\n",
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "model.prune_magnitude_global_unstruct(.4, device)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))\n",
    "#hist = model.fit_fast_locuslab(train_loader, test_loader , 15, device, eps=8,patience=None, evaluate_robustness=False)\n",
    "train_locus(model)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.736889973115921, 0.7662)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_standard(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0443589806556701, 0.4359375)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pgd(test_loader, model, 30, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruned - 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "identifying layers\n",
      "tensor(0.8212)\n",
      "tensor(0.7616)\n",
      "tensor(0.7677)\n",
      "tensor(0.7607)\n",
      "tensor(0.7609)\n",
      "tensor(0.7047)\n",
      "tensor(0.6590)\n",
      "tensor(0.9014)\n",
      "tensor(0.6613)\n",
      "tensor(0.6624)\n",
      "tensor(0.5834)\n",
      "tensor(0.5200)\n",
      "tensor(0.8625)\n",
      "tensor(0.5212)\n",
      "tensor(0.5210)\n",
      "tensor(0.4136)\n",
      "tensor(0.3229)\n",
      "tensor(0.8050)\n",
      "tensor(0.3224)\n",
      "tensor(0.3223)\n",
      "tensor(1.)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "start epoch: 0\n",
      "0 46.66895079612732 0.02666666666666666 2.4538612197875977 0.1585\n",
      "start epoch: 1\n",
      "1 46.73046875 0.05333333333333332 2.0430101528167723 0.2309\n",
      "start epoch: 2\n",
      "2 46.78710722923279 0.07999999999999999 1.981627148513794 0.25278\n",
      "start epoch: 3\n",
      "3 46.76747250556946 0.10666666666666665 1.923511754760742 0.2728\n",
      "start epoch: 4\n",
      "4 46.79446983337402 0.1333333333333333 1.8697924224090576 0.29212\n",
      "start epoch: 5\n",
      "5 46.78754258155823 0.15999999999999998 1.8093430243682862 0.31728\n",
      "start epoch: 6\n",
      "6 46.79087162017822 0.18666666666666673 1.7492355242538453 0.33448\n",
      "start epoch: 7\n",
      "7 46.78787922859192 0.18666666666666673 1.6909135737991332 0.35702\n",
      "start epoch: 8\n",
      "8 46.8248405456543 0.15999999999999998 1.6281058614730834 0.37998\n",
      "start epoch: 9\n",
      "9 46.79780316352844 0.1333333333333334 1.581285937271118 0.39764\n",
      "start epoch: 10\n",
      "10 46.81040835380554 0.10666666666666665 1.5411132595062256 0.41166\n",
      "start epoch: 11\n",
      "11 46.799283266067505 0.07999999999999999 1.4939703299713134 0.42798\n",
      "start epoch: 12\n",
      "12 46.79842019081116 0.05333333333333332 1.4412857237243653 0.44826\n",
      "start epoch: 13\n",
      "13 46.81511378288269 0.02666666666666666 1.3742566010665893 0.47114\n",
      "start epoch: 14\n",
      "14 46.810720920562744 0.0 1.2805424143600463 0.50246\n",
      "identifying layers\n",
      "tensor(0.8212)\n",
      "tensor(0.7616)\n",
      "tensor(0.7677)\n",
      "tensor(0.7607)\n",
      "tensor(0.7609)\n",
      "tensor(0.7047)\n",
      "tensor(0.6590)\n",
      "tensor(0.9014)\n",
      "tensor(0.6613)\n",
      "tensor(0.6624)\n",
      "tensor(0.5834)\n",
      "tensor(0.5200)\n",
      "tensor(0.8625)\n",
      "tensor(0.5212)\n",
      "tensor(0.5210)\n",
      "tensor(0.4136)\n",
      "tensor(0.3229)\n",
      "tensor(0.8050)\n",
      "tensor(0.3224)\n",
      "tensor(0.3223)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True, batchsize=128)\n",
    "train_loader, test_loader = get_loaders(128)\n",
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "\n",
    "model.prune_magnitude_global_unstruct(.6, device)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))\n",
    "#hist = model.fit_fast_locuslab(train_loader, test_loader , 15, device, eps=8,patience=None, evaluate_robustness=False)\n",
    "train_locus(model)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7783312847137451, 0.759)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_standard(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0655462503433228, 0.440625)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pgd(test_loader, model, 30, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruned - 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "identifying layers\n",
      "tensor(0.7749)\n",
      "tensor(0.6793)\n",
      "tensor(0.6782)\n",
      "tensor(0.6807)\n",
      "tensor(0.6803)\n",
      "tensor(0.6109)\n",
      "tensor(0.5499)\n",
      "tensor(0.8683)\n",
      "tensor(0.5489)\n",
      "tensor(0.5487)\n",
      "tensor(0.4453)\n",
      "tensor(0.3616)\n",
      "tensor(0.8151)\n",
      "tensor(0.3611)\n",
      "tensor(0.3612)\n",
      "tensor(0.2168)\n",
      "tensor(0.0969)\n",
      "tensor(0.7382)\n",
      "tensor(0.0968)\n",
      "tensor(0.0968)\n",
      "tensor(1.)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "start epoch: 0\n",
      "0 46.72706580162048 0.02666666666666666 2.412520524749756 0.15316\n",
      "start epoch: 1\n",
      "1 46.76249861717224 0.05333333333333332 2.0351523764419555 0.2332\n",
      "start epoch: 2\n",
      "2 46.781190395355225 0.07999999999999999 1.9721833965301514 0.25534\n",
      "start epoch: 3\n",
      "3 46.80348038673401 0.10666666666666665 1.9127853866958617 0.27476\n",
      "start epoch: 4\n",
      "4 46.87474608421326 0.1333333333333333 1.857335548439026 0.29498\n",
      "start epoch: 5\n",
      "5 46.844494581222534 0.15999999999999998 1.8025161251831054 0.31966\n",
      "start epoch: 6\n",
      "6 46.86362957954407 0.18666666666666673 1.7431475149154663 0.33768\n",
      "start epoch: 7\n",
      "7 46.86165976524353 0.18666666666666673 1.6922453290939332 0.35514\n",
      "start epoch: 8\n",
      "8 46.86807990074158 0.15999999999999998 1.632829021759033 0.3779\n",
      "start epoch: 9\n",
      "9 46.851250886917114 0.1333333333333334 1.5898043418884278 0.39394\n",
      "start epoch: 10\n",
      "10 46.853163719177246 0.10666666666666665 1.5448900606155396 0.4096\n",
      "start epoch: 11\n",
      "11 46.85634422302246 0.07999999999999999 1.5027073805999756 0.42588\n",
      "start epoch: 12\n",
      "12 46.874835729599 0.05333333333333332 1.451551324043274 0.4446\n",
      "start epoch: 13\n",
      "13 46.84680938720703 0.02666666666666666 1.393287171020508 0.46236\n",
      "start epoch: 14\n",
      "14 46.863720655441284 0.0 1.3023007406616212 0.4965\n",
      "identifying layers\n",
      "tensor(0.7749)\n",
      "tensor(0.6793)\n",
      "tensor(0.6782)\n",
      "tensor(0.6807)\n",
      "tensor(0.6803)\n",
      "tensor(0.6109)\n",
      "tensor(0.5499)\n",
      "tensor(0.8683)\n",
      "tensor(0.5489)\n",
      "tensor(0.5487)\n",
      "tensor(0.4453)\n",
      "tensor(0.3616)\n",
      "tensor(0.8151)\n",
      "tensor(0.3611)\n",
      "tensor(0.3612)\n",
      "tensor(0.2168)\n",
      "tensor(0.0969)\n",
      "tensor(0.7382)\n",
      "tensor(0.0968)\n",
      "tensor(0.0968)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True, batchsize=128)\n",
    "train_loader, test_loader = get_loaders(128)\n",
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "\n",
    "model.prune_magnitude_global_unstruct(.8, device)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))\n",
    "#hist = model.fit_fast_locuslab(train_loader, test_loader , 15, device, eps=8,patience=None, evaluate_robustness=False)\n",
    "train_locus(model)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7973790740013122, 0.7473)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_standard(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0835805892944337, 0.4421875)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pgd(test_loader, model, 30, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruned - 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "identifying layers\n",
      "tensor(0.7216)\n",
      "tensor(0.6332)\n",
      "tensor(0.6256)\n",
      "tensor(0.6289)\n",
      "tensor(0.6262)\n",
      "tensor(0.5423)\n",
      "tensor(0.4709)\n",
      "tensor(0.8381)\n",
      "tensor(0.4686)\n",
      "tensor(0.4694)\n",
      "tensor(0.3524)\n",
      "tensor(0.2520)\n",
      "tensor(0.7793)\n",
      "tensor(0.2538)\n",
      "tensor(0.2534)\n",
      "tensor(0.0841)\n",
      "tensor(0.)\n",
      "tensor(0.6943)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "start epoch: 0\n",
      "0 46.63044452667236 0.02666666666666666 2.3700496726989746 0.15332\n",
      "start epoch: 1\n",
      "1 46.6238853931427 0.05333333333333332 2.069132757797241 0.2208\n",
      "start epoch: 2\n",
      "2 46.66654968261719 0.07999999999999999 2.0044870193862914 0.24238\n",
      "start epoch: 3\n",
      "3 46.66773843765259 0.10666666666666665 1.9537378856658936 0.26204\n",
      "start epoch: 4\n",
      "4 46.690486669540405 0.1333333333333333 1.9020487480163575 0.27916\n",
      "start epoch: 5\n",
      "5 46.68206238746643 0.15999999999999998 1.8567330883407593 0.29528\n",
      "start epoch: 6\n",
      "6 46.73046088218689 0.18666666666666673 1.805345231590271 0.31812\n",
      "start epoch: 7\n",
      "7 46.70666790008545 0.18666666666666673 1.7531047599029541 0.33502\n",
      "start epoch: 8\n",
      "8 46.718589782714844 0.15999999999999998 1.7022117930984497 0.3536\n",
      "start epoch: 9\n",
      "9 46.73631525039673 0.1333333333333334 1.661003028717041 0.37144\n",
      "start epoch: 10\n",
      "10 46.712326765060425 0.10666666666666665 1.6197065964508057 0.38522\n",
      "start epoch: 11\n",
      "11 46.69460988044739 0.07999999999999999 1.578962589302063 0.40056\n",
      "start epoch: 12\n",
      "12 46.70713186264038 0.05333333333333332 1.5357463326263427 0.41476\n",
      "start epoch: 13\n",
      "13 46.75287413597107 0.02666666666666666 1.4770592724990845 0.43766\n",
      "start epoch: 14\n",
      "14 46.703407764434814 0.0 1.3978579515075684 0.46628\n",
      "identifying layers\n",
      "tensor(0.7216)\n",
      "tensor(0.6332)\n",
      "tensor(0.6256)\n",
      "tensor(0.6289)\n",
      "tensor(0.6262)\n",
      "tensor(0.5423)\n",
      "tensor(0.4709)\n",
      "tensor(0.8381)\n",
      "tensor(0.4686)\n",
      "tensor(0.4694)\n",
      "tensor(0.3524)\n",
      "tensor(0.2520)\n",
      "tensor(0.7793)\n",
      "tensor(0.2538)\n",
      "tensor(0.2534)\n",
      "tensor(0.0841)\n",
      "tensor(0.)\n",
      "tensor(0.6943)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True, batchsize=128)\n",
    "train_loader, test_loader = get_loaders(128)\n",
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "\n",
    "model.prune_magnitude_global_unstruct(.9, device)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))\n",
    "#hist = model.fit_fast_locuslab(train_loader, test_loader , 15, device, eps=8,patience=None, evaluate_robustness=False)\n",
    "train_locus(model)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8329505568504334, 0.7304)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_standard(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1110131740570068, 0.4109375)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pgd(test_loader, model, 30, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruned - 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "identifying layers\n",
      "tensor(0.6597)\n",
      "tensor(0.5386)\n",
      "tensor(0.5350)\n",
      "tensor(0.5373)\n",
      "tensor(0.5343)\n",
      "tensor(0.4290)\n",
      "tensor(0.3414)\n",
      "tensor(0.8129)\n",
      "tensor(0.3439)\n",
      "tensor(0.3438)\n",
      "tensor(0.1943)\n",
      "tensor(0.0709)\n",
      "tensor(0.7295)\n",
      "tensor(0.0705)\n",
      "tensor(0.0709)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.6202)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "start epoch: 0\n",
      "0 46.58905816078186 0.02666666666666666 2.357825498199463 0.14424\n",
      "start epoch: 1\n",
      "1 46.633423805236816 0.05333333333333332 2.064723356170654 0.2206\n",
      "start epoch: 2\n",
      "2 46.69510865211487 0.07999999999999999 2.003135856399536 0.24342\n",
      "start epoch: 3\n",
      "3 46.705808877944946 0.10666666666666665 1.943422922744751 0.26678\n",
      "start epoch: 4\n",
      "4 46.691819190979004 0.1333333333333333 1.8985942798233033 0.28282\n",
      "start epoch: 5\n",
      "5 46.72416591644287 0.15999999999999998 1.8512597156524657 0.29646\n",
      "start epoch: 6\n",
      "6 46.72291588783264 0.18666666666666673 1.808127463645935 0.31702\n",
      "start epoch: 7\n",
      "7 46.748902320861816 0.18666666666666673 1.7693107048797607 0.32762\n",
      "start epoch: 8\n",
      "8 46.735453367233276 0.15999999999999998 1.7250105334091186 0.34136\n",
      "start epoch: 9\n",
      "9 46.72959589958191 0.1333333333333334 1.683093815689087 0.36004\n",
      "start epoch: 10\n",
      "10 46.740508794784546 0.10666666666666665 1.6560946359634399 0.36976\n",
      "start epoch: 11\n",
      "11 46.738136768341064 0.07999999999999999 1.622798208618164 0.38108\n",
      "start epoch: 12\n",
      "12 46.717777967453 0.05333333333333332 1.583099665184021 0.39648\n",
      "start epoch: 13\n",
      "13 46.76828217506409 0.02666666666666666 1.5303719651031493 0.4154\n",
      "start epoch: 14\n",
      "14 46.72043490409851 0.0 1.462745987586975 0.4406\n",
      "identifying layers\n",
      "tensor(0.6597)\n",
      "tensor(0.5386)\n",
      "tensor(0.5350)\n",
      "tensor(0.5373)\n",
      "tensor(0.5343)\n",
      "tensor(0.4290)\n",
      "tensor(0.3414)\n",
      "tensor(0.8129)\n",
      "tensor(0.3439)\n",
      "tensor(0.3438)\n",
      "tensor(0.1943)\n",
      "tensor(0.0709)\n",
      "tensor(0.7295)\n",
      "tensor(0.0705)\n",
      "tensor(0.0709)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.6202)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True, batchsize=128)\n",
    "train_loader, test_loader = get_loaders(128)\n",
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "\n",
    "model.prune_magnitude_global_unstruct(.95, device)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))\n",
    "#hist = model.fit_fast_locuslab(train_loader, test_loader , 15, device, eps=8,patience=None, evaluate_robustness=False)\n",
    "train_locus(model)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9141734148979187, 0.6989)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_standard(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1695979833602905, 0.415625)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pgd(test_loader, model, 30, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruned - 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "identifying layers\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.0000)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.5405)\n",
      "tensor(0.3829)\n",
      "tensor(0.3856)\n",
      "tensor(0.3847)\n",
      "tensor(0.3782)\n",
      "tensor(0.2407)\n",
      "tensor(0.1261)\n",
      "tensor(0.7542)\n",
      "tensor(0.1256)\n",
      "tensor(0.1272)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.6463)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.4945)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "start epoch: 0\n",
      "0 46.52212190628052 0.02666666666666666 2.3199258992004395 0.13666\n",
      "start epoch: 1\n",
      "1 46.54180026054382 0.05333333333333332 2.0984325939178468 0.20376\n",
      "start epoch: 2\n",
      "2 46.58250951766968 0.07999999999999999 2.0426071308898925 0.22992\n",
      "start epoch: 3\n",
      "3 46.56392979621887 0.10666666666666665 2.005122496032715 0.24568\n",
      "start epoch: 4\n",
      "4 46.659802198410034 0.1333333333333333 1.9755203115463258 0.25392\n",
      "start epoch: 5\n",
      "5 46.620407581329346 0.15999999999999998 1.949036870956421 0.26408\n",
      "start epoch: 6\n",
      "6 46.62820792198181 0.18666666666666673 1.925837085494995 0.27456\n",
      "start epoch: 7\n",
      "7 46.63377809524536 0.18666666666666673 1.907254372329712 0.2801\n",
      "start epoch: 8\n",
      "8 46.61521601676941 0.15999999999999998 1.8829965490722655 0.28926\n",
      "start epoch: 9\n",
      "9 46.66476559638977 0.1333333333333334 1.8646351135253907 0.29206\n",
      "start epoch: 10\n",
      "10 46.62179088592529 0.10666666666666665 1.8431347406768799 0.30222\n",
      "start epoch: 11\n",
      "11 46.61635708808899 0.07999999999999999 1.8204039324569703 0.30834\n",
      "start epoch: 12\n",
      "12 46.62264966964722 0.05333333333333332 1.795473285293579 0.31638\n",
      "start epoch: 13\n",
      "13 46.64148187637329 0.02666666666666666 1.763083585281372 0.329\n",
      "start epoch: 14\n",
      "14 46.61892890930176 0.0 1.7184955727767945 0.34556\n",
      "identifying layers\n",
      "tensor(0.5405)\n",
      "tensor(0.3829)\n",
      "tensor(0.3856)\n",
      "tensor(0.3847)\n",
      "tensor(0.3782)\n",
      "tensor(0.2407)\n",
      "tensor(0.1261)\n",
      "tensor(0.7542)\n",
      "tensor(0.1256)\n",
      "tensor(0.1272)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.6463)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.4945)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True, batchsize=128)\n",
    "train_loader, test_loader = get_loaders(128)\n",
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))\n",
    "model.prune_magnitude_global_unstruct(.98, device)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))\n",
    "#hist = model.fit_fast_locuslab(train_loader, test_loader , 15, device, eps=8,patience=None, evaluate_robustness=False)\n",
    "train_locus(model)\n",
    "masks = list(filter(lambda x: 'weights' in x,list(model.state_dict().keys())))\n",
    "for mask in masks:\n",
    "    print(len(torch.nonzero(model.state_dict()[mask]))/torch.prod(torch.tensor(model.state_dict()[mask].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2244552396774293, 0.5862)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_standard(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4200933694839477, 0.3171875)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pgd(test_loader, model, 30, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "identifying layers\n",
      "1\n",
      "[False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "start epoch: 0\n",
      "robustness:  0.2414\n",
      "0 79.29987597465515 0.020000000000000018 2.5171619160461427 0.16298\n",
      "0.014285714285714287\n",
      "start epoch: 1\n",
      "robustness:  0.2395\n",
      "1 79.02739477157593 0.040000000000000036 2.077198622665405 0.21866\n",
      "0.028571428571428574\n",
      "start epoch: 2\n",
      "robustness:  0.2293\n",
      "2 79.10126638412476 0.05999999999999997 2.003020969924927 0.24856\n",
      "0.04285714285714286\n",
      "start epoch: 3\n",
      "robustness:  0.2987\n",
      "3 79.16091537475586 0.07999999999999999 1.9513498001098633 0.26572\n",
      "0.05714285714285715\n",
      "start epoch: 4\n",
      "robustness:  0.3003\n",
      "4 79.12271809577942 0.1 1.9209635214614869 0.2762\n",
      "0.07142857142857144\n",
      "start epoch: 5\n",
      "robustness:  0.3104\n",
      "5 79.18853211402893 0.12000000000000002 1.8866271829223633 0.28902\n",
      "0.08571428571428572\n",
      "start epoch: 6\n",
      "robustness:  0.3086\n",
      "6 79.11350584030151 0.14000000000000004 1.8749848574829102 0.29384\n",
      "0.1\n",
      "start epoch: 7\n",
      "robustness:  0.3004\n",
      "7 79.08687043190002 0.15999999999999998 1.857027857284546 0.30074\n",
      "0.1142857142857143\n",
      "start epoch: 8\n",
      "robustness:  0.2859\n",
      "8 79.10360836982727 0.18 1.851782120666504 0.3026\n",
      "0.1285714285714286\n",
      "start epoch: 9\n",
      "robustness:  0.2969\n",
      "9 79.14749884605408 0.2 1.839483830795288 0.30592\n",
      "0.14285714285714288\n",
      "start epoch: 10\n",
      "robustness:  0.3307\n",
      "10 79.1327383518219 0.18 1.8179924465942383 0.3137\n",
      "0.15714285714285717\n",
      "start epoch: 11\n",
      "robustness:  0.3192\n",
      "11 79.19349431991577 0.15999999999999998 1.8048201364517211 0.3182\n",
      "0.17142857142857143\n",
      "start epoch: 12\n",
      "robustness:  0.3354\n",
      "12 79.27000093460083 0.14000000000000004 1.7887549493026733 0.32272\n",
      "0.18571428571428572\n",
      "start epoch: 13\n",
      "robustness:  0.3269\n",
      "13 79.17913222312927 0.12000000000000002 1.7643311025619506 0.33276\n",
      "0.2\n",
      "start epoch: 14\n",
      "robustness:  0.3242\n",
      "14 79.12935853004456 0.1 1.747250131225586 0.33756\n",
      "0.2142857142857143\n",
      "start epoch: 15\n",
      "robustness:  0.3209\n",
      "15 79.12680387496948 0.07999999999999999 1.7212414642715455 0.34754\n",
      "0.2285714285714286\n",
      "start epoch: 16\n",
      "robustness:  0.3559\n",
      "16 79.15312480926514 0.05999999999999997 1.6957480661010742 0.36032\n",
      "0.24285714285714288\n",
      "start epoch: 17\n",
      "robustness:  0.3758\n",
      "17 79.20269131660461 0.040000000000000036 1.6648598358535767 0.36926\n",
      "0.2571428571428572\n",
      "start epoch: 18\n",
      "robustness:  0.3699\n",
      "18 79.12279343605042 0.020000000000000018 1.6286888071060182 0.38436\n",
      "0.27142857142857146\n",
      "start epoch: 19\n",
      "robustness:  0.3874\n",
      "19 79.15671682357788 0.0 1.584430822906494 0.39676\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CifarResNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d6f4b6c1afe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCifarResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_fast_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruning_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruning_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/pytorch-network-pruning/src/models.py\u001b[0m in \u001b[0;36mfit_fast_new\u001b[0;34m(self, train_data, val_data, device, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_fast_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_fit_fast_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_replays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/pytorch-network-pruning/src/training.py\u001b[0m in \u001b[0;36m_fit_fast_new\u001b[0;34m(model, train_loader, test_loader, device, pruning_ratio, pruning_steps, epochs, epsilon, alpha, pgd_alpha, lr_min, lr_max, momentum, weight_decay)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mmodel_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCifarResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_state_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CifarResNet' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_loaders(128)\n",
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "model.fit_fast_new(train_loader, test_loader,device, pruning_ratio=0.2, pruning_steps=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9284108551025391, 0.6874)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_standard(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1732340574264526, 0.409375)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pgd(test_loader, model,30, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 steps, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7567685401439667, 0.7647)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_standard(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0522079348564148, 0.465625)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pgd(test_loader, model, 30, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14 steps, 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7916890334129334, 0.7532)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_standard(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.076668906211853, 0.4421875)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pgd(test_loader, model, 30, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 steps, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49224170689582825, 0.8273)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_standard(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.4420580863952637, 0.0015625)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pgd(test_loader, model, 30, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre Start GPU MEMORY: 1625.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "identifying layers\n",
      "start epoch: 0\n",
      "0.234375 0.234375 False\n",
      "0 1e-05 2.354994194107056 0.21522\n",
      "start epoch: 1\n",
      "0.2578125 0.0234375 False\n",
      "1 1e-05 1.9713263381576538 0.26594\n",
      "start epoch: 2\n",
      "0.2421875 -0.015625 False\n",
      "2 1.0000000000000002e-06 1.9697702747344972 0.26606\n",
      "start epoch: 3\n",
      "0.21875 -0.0390625 False\n",
      "3 1.0000000000000002e-06 1.968983780555725 0.2659\n",
      "start epoch: 4\n",
      "0.265625 0.0078125 False\n",
      "4 1.0000000000000002e-07 1.968894191055298 0.266\n",
      "start epoch: 5\n",
      "0.296875 0.03125 False\n",
      "5 1.0000000000000002e-07 1.9688206040191651 0.2659\n",
      "start epoch: 6\n",
      "0.28125 -0.015625 False\n",
      "7 1.0000000000000002e-07 1.968812221221924 0.26594\n",
      "start epoch: 8\n",
      "0.203125 -0.09375 False\n",
      "8 1.0000000000000002e-07 1.9688087783050536 0.26592\n",
      "start epoch: 9\n",
      "0.2734375 -0.0234375 False\n",
      "9 1.0000000000000002e-07 1.968803286895752 0.26592\n",
      "start epoch: 10\n",
      "0.2265625 -0.0703125 False\n",
      "10 1.0000000000000002e-07 1.9687986569595337 0.26588\n",
      "start epoch: 11\n",
      "0.171875 -0.125 False\n",
      "11 1.0000000000000002e-07 1.9687954357910156 0.26584\n",
      "start epoch: 12\n",
      "0.2890625 -0.0078125 False\n",
      "12 1.0000000000000002e-07 1.9687914206314088 0.26586\n",
      "start epoch: 13\n",
      "0.2734375 -0.0234375 False\n",
      "13 1.0000000000000002e-07 1.9687857358169556 0.26588\n",
      "start epoch: 14\n",
      "0.25 -0.046875 False\n",
      "14 1.0000000000000004e-08 1.9687825829696655 0.26586\n",
      "training finished\n",
      "start epoch: 0\n",
      "0.28125 0.28125 False\n",
      "0 1e-05 1.966403349838257 0.2644\n",
      "start epoch: 1\n",
      "0.2734375 -0.0078125 False\n",
      "1 1e-05 1.9089905474472046 0.28462\n",
      "start epoch: 2\n",
      "0.328125 0.046875 False\n",
      "2 1.0000000000000002e-06 1.9077931962585448 0.28562\n",
      "start epoch: 3\n",
      "0.34375 0.015625 False\n",
      "3 1.0000000000000002e-06 1.907241986618042 0.28574\n",
      "start epoch: 4\n",
      "0.28125 -0.0625 False\n",
      "4 1.0000000000000002e-07 1.9071716677856445 0.286\n",
      "start epoch: 5\n",
      "0.3125 -0.03125 False\n",
      "5 1.0000000000000002e-07 1.907119236831665 0.28614\n",
      "start epoch: 6\n",
      "0.25 -0.09375 False\n",
      "6 1.0000000000000002e-07 1.9071155563735962 0.28632\n",
      "start epoch: 7\n",
      "0.375 0.03125 False\n",
      "7 1.0000000000000002e-07 1.9071117355728149 0.2863\n",
      "start epoch: 8\n",
      "0.28125 -0.09375 False\n",
      "8 1.0000000000000002e-07 1.9071080587387086 0.28628\n",
      "start epoch: 9\n",
      "0.2890625 -0.0859375 False\n",
      "9 1.0000000000000002e-07 1.9071058013153077 0.28628\n",
      "start epoch: 10\n",
      "0.2890625 -0.0859375 False\n",
      "10 1.0000000000000002e-07 1.9071029312896728 0.2863\n",
      "start epoch: 11\n",
      "0.265625 -0.109375 False\n",
      "11 1.0000000000000002e-07 1.9070996075820923 0.28632\n",
      "start epoch: 12\n",
      "0.34375 -0.03125 False\n",
      "12 1.0000000000000002e-07 1.9070961910629272 0.2863\n",
      "start epoch: 13\n",
      "0.3359375 -0.0390625 False\n",
      "13 1.0000000000000002e-07 1.9070935268783569 0.28634\n",
      "start epoch: 14\n",
      "0.3046875 -0.0703125 False\n",
      "14 1.0000000000000004e-08 1.907087767982483 0.2864\n",
      "training finished\n",
      "start epoch: 0\n",
      "0.3515625 0.3515625 False\n",
      "0 1e-05 1.909902275352478 0.27966\n",
      "start epoch: 1\n",
      "0.2734375 -0.078125 False\n",
      "1 1e-05 1.8694890319824218 0.29738\n",
      "start epoch: 2\n",
      "0.2578125 -0.09375 False\n",
      "2 1.0000000000000002e-06 1.8681840636825562 0.2974\n",
      "start epoch: 3\n",
      "0.3671875 0.015625 False\n",
      "3 1.0000000000000002e-06 1.8677781987762452 0.29776\n",
      "start epoch: 4\n",
      "0.3203125 -0.046875 False\n",
      "4 1.0000000000000002e-07 1.8676640185928344 0.29748\n",
      "start epoch: 5\n",
      "0.2734375 -0.09375 False\n",
      "5 1.0000000000000002e-07 1.8675980633926392 0.2975\n",
      "start epoch: 6\n",
      "0.3125 -0.0546875 False\n",
      "6 1.0000000000000002e-07 1.867596086769104 0.2975\n",
      "start epoch: 7\n",
      "0.296875 -0.0703125 False\n",
      "7 1.0000000000000002e-07 1.8675914456176759 0.29746\n",
      "start epoch: 8\n",
      "0.265625 -0.1015625 False\n",
      "8 1.0000000000000002e-07 1.8675888324737548 0.29746\n",
      "start epoch: 9\n",
      "0.328125 -0.0390625 False\n",
      "9 1.0000000000000002e-07 1.8675859629058837 0.29758\n",
      "start epoch: 10\n",
      "0.21875 -0.1484375 False\n",
      "10 1.0000000000000002e-07 1.8675839250183106 0.29752\n",
      "start epoch: 11\n",
      "0.2734375 -0.09375 False\n",
      "11 1.0000000000000002e-07 1.8675818081283568 0.2974\n",
      "start epoch: 12\n",
      "0.296875 -0.0703125 False\n",
      "12 1.0000000000000002e-07 1.8675779496002198 0.29742\n",
      "start epoch: 13\n",
      "0.296875 -0.0703125 False\n",
      "13 1.0000000000000002e-07 1.8675756511688233 0.29738\n",
      "start epoch: 14\n",
      "0.21875 -0.1484375 False\n",
      "14 1.0000000000000004e-08 1.867568642578125 0.2975\n",
      "training finished\n",
      "start epoch: 0\n",
      "0.3203125 0.3203125 False\n",
      "0 1e-05 1.8987587796401977 0.28766\n",
      "start epoch: 1\n",
      "0.265625 -0.0546875 False\n",
      "1 1e-05 1.8549604095458985 0.30068\n",
      "start epoch: 2\n",
      "0.2890625 -0.03125 False\n",
      "2 1.0000000000000002e-06 1.8536729695892333 0.30178\n",
      "start epoch: 3\n",
      "0.40625 0.0859375 False\n",
      "3 1.0000000000000002e-06 1.853194119949341 0.30262\n",
      "start epoch: 4\n",
      "0.265625 -0.140625 False\n",
      "4 1.0000000000000002e-07 1.8531208757781983 0.3025\n",
      "start epoch: 5\n",
      "0.3125 -0.09375 False\n",
      "5 1.0000000000000002e-07 1.8530648540878296 0.30264\n",
      "start epoch: 6\n",
      "0.265625 -0.140625 False\n",
      "6 1.0000000000000002e-07 1.8530617538452148 0.3026\n",
      "start epoch: 7\n",
      "0.34375 -0.0625 False\n",
      "7 1.0000000000000002e-07 1.8530600491714477 0.3026\n",
      "start epoch: 8\n",
      "0.3671875 -0.0390625 False\n",
      "8 1.0000000000000002e-07 1.8530564254760742 0.30252\n",
      "start epoch: 9\n",
      "0.265625 -0.140625 False\n",
      "9 1.0000000000000002e-07 1.8530542783355712 0.30258\n",
      "start epoch: 10\n",
      "0.3359375 -0.0703125 False\n",
      "10 1.0000000000000002e-07 1.853050999107361 0.30262\n",
      "start epoch: 11\n",
      "0.3515625 -0.0546875 False\n",
      "11 1.0000000000000002e-07 1.8530471337890626 0.3026\n",
      "start epoch: 12\n",
      "0.28125 -0.125 False\n",
      "12 1.0000000000000002e-07 1.8530454680633546 0.3025\n",
      "start epoch: 13\n",
      "0.3359375 -0.0703125 False\n",
      "13 1.0000000000000002e-07 1.8530413735961915 0.3026\n",
      "start epoch: 14\n",
      "0.3125 -0.09375 False\n",
      "14 1.0000000000000004e-08 1.853038974685669 0.30254\n",
      "training finished\n"
     ]
    }
   ],
   "source": [
    "print (\"Pre Start GPU MEMORY: %s\" % get_gpu_memory_map())\n",
    "ARCHITECTURE = 'PreActResNet18'\n",
    "TRAINING_METHOD = 'fast'\n",
    "PRUNING_METHOD = 'unstructured_global_magnitude'\n",
    "ratios = [1,2,4,8,16,32,64]\n",
    "train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=False, batchsize=128)\n",
    "EPOCHS = 50\n",
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "stats = []\n",
    "#PATH = './experiment-models/unstructured_global_magnitude-fast-1-99.pt'\n",
    "#checkpoint = torch.load(PATH)\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "for ratio in ratios:\n",
    "    torch.cuda.empty_cache()\n",
    "    rate = 1-1/ratio\n",
    "    model.prune_magnitude_global_unstruct(rate, device)\n",
    "    model.train()\n",
    "    hist = model.fit_fast_locuslab(train_loader, test_loader , 15, device, eps=8,patience=None, evaluate_robustness=False)\n",
    "    model.eval()\n",
    "    clean_acc = evaluate_standard(test_loader, model)[1]\n",
    "    rob_acc = evaluate_pgd(test_loader, model, 30, 3)[1]\n",
    "    state_dict = model.state_dict()\n",
    "    stats.append(\n",
    "        {\n",
    "            'ratio': ratio,\n",
    "            'clean accuracy': clean_acc,\n",
    "            'robust accuracy':rob_acc,\n",
    "            'history': hist,\n",
    "        }\n",
    "        \n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-095f0147d00e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ratio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'robust accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "for i,stat in enumerate(stats):\n",
    "    print(i, stat['ratio'], stat['clean accuracy'], stat['robust accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, stat in enumerate(stats):\n",
    "    print(stat['ratio'], stat['clean accuracy'], stat['robust accuracy'])\n",
    "    for i,epoch_stats in enumerate(stat['history']):\n",
    "        #print(epoch_stats)\n",
    "        print(i, epoch_stats['robust accuracy'], epoch_stats['clean accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, stat in enumerate(stats):\n",
    "    print(stat['ratio'], stat['clean accuracy'], stat['robust accuracy'])\n",
    "    for i,epoch_stats in enumerate(stat['history']):\n",
    "        model.load_state_dict(epoch_stats['state dict'])\n",
    "        print(i, evaluate_standard(test_loader, model))\n",
    "        print(i, evaluate_pgd(test_loader, model,20,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f081bdc955a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#print(evaluate_pgd(test_loader, model, 10,2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "for i, hist in enumerate(stats[0]['history']):\n",
    "    print(i, hist['clean accuracy'])\n",
    "    model.load_state_dict(hist['state dict'])\n",
    "    #print(evaluate_pgd(test_loader, model, 10,2))\n",
    "    print(evaluate_standard(test_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "epochs = 15\n",
    "\n",
    "epsilon = 8\n",
    "alpha = 10\n",
    "std = torch.tensor((1,1,1)).view(3,1,1).cuda()\n",
    "pgd_alpha = (2 / 255.) / std\n",
    "lr_min = 0.\n",
    "lr_max = 0.2\n",
    "momentum = .9\n",
    "weight_decay = 5e-4\n",
    "lower_limit = torch.tensor((0,0,0)).view(3,1,1).cuda()\n",
    "upper_limit = torch.tensor((1,1,1)).view(3,1,1).cuda()\n",
    "\n",
    "def train_locus(model, train_loader, test_loader, pruning_ratio=0, pruning_steps=1, epochs = 20, epsilon = 8, alpha = 10, pgd_alpha = 2, lr_min = 0.,lr_max = 0.2, momentum = .9, weight_decay = 5e-4):\n",
    "    std = torch.tensor((1,1,1)).view(3,1,1).cuda()\n",
    "    pgd_alpha = (pgd_alpha / 255.) / std\n",
    "    lower_limit = torch.tensor((0,0,0)).view(3,1,1).cuda()\n",
    "    upper_limit = torch.tensor((1,1,1)).view(3,1,1).cuda()\n",
    "    epsilon = (epsilon / 255.) / std\n",
    "    alpha = (alpha / 255.) / std\n",
    "    pgd_alpha = (2 / 255.) / std\n",
    "\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=lr_max, momentum=momentum, weight_decay=weight_decay)\n",
    "    #amp_args = dict(opt_level=args.opt_level, loss_scale=args.loss_scale, verbosity=False)\n",
    "    #if args.opt_level == 'O2':\n",
    "    #    amp_args['master_weights'] = args.master_weights\n",
    "    #model, opt = amp.initialize(model, opt, **amp_args)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    lr_steps = epochs * len(train_loader)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(opt, base_lr=lr_min, max_lr=lr_max, step_size_up=lr_steps / 2, step_size_down=lr_steps / 2)\n",
    "    \n",
    "    pruning_intervals = round(epochs/(pruning_steps + 1))\n",
    "    print(pruning_intervals)\n",
    "    pruning_schedule = [ epoch % pruning_intervals == 0 and epoch / pruning_intervals != 0 for epoch in list(range(epochs))]\n",
    "    print(pruning_schedule)\n",
    "    pruning_step = 1\n",
    "    # Training\n",
    "    prev_robust_acc = 0.\n",
    "    start_train_time = time.time()\n",
    "    #logger.info('Epoch \\t Seconds \\t LR \\t \\t Train Loss \\t Train Acc')\n",
    "    for epoch in range(epochs):\n",
    "        if pruning_schedule[epoch] == True:\n",
    "            pruning_step_ratio = pruning_ratio/pruning_steps*pruning_step\n",
    "            print(pruning_step_ratio)\n",
    "            model.prune_magnitude_global_unstruct(pruning_step_ratio, device)\n",
    "            pruning_step+=1\n",
    "            \n",
    "        print('start epoch:', epoch)\n",
    "        \n",
    "        start_epoch_time = time.time()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_n = 0\n",
    "        for i, (X, y) in enumerate(train_loader):\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            if i == 0:\n",
    "                first_batch = (X, y)\n",
    "            delta = torch.zeros_like(X).cuda()\n",
    "            delta.requires_grad = True\n",
    "            output = model(X + delta[:X.size(0)])\n",
    "            loss = F.cross_entropy(output, y)\n",
    "            #with amp.scale_loss(loss, opt) as scaled_loss:\n",
    "            #    scaled_loss.backward()\n",
    "            loss.backward()\n",
    "            grad = delta.grad.detach()\n",
    "            delta.data = clamp(delta + alpha * torch.sign(grad), -epsilon, epsilon)\n",
    "            #print(type(lower_limit))\n",
    "            #print(type(X))\n",
    "            delta.data[:X.size(0)] = clamp(delta[:X.size(0)], lower_limit - X, upper_limit - X)\n",
    "            delta = delta.detach()\n",
    "            output = model(X + delta[:X.size(0)])\n",
    "            loss = criterion(output, y)\n",
    "            opt.zero_grad()\n",
    "            #with amp.scale_loss(loss, opt) as scaled_loss:\n",
    "            #    scaled_loss.backward()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss += loss.item() * y.size(0)\n",
    "            train_acc += (output.max(1)[1] == y).sum().item()\n",
    "            train_n += y.size(0)\n",
    "            scheduler.step()\n",
    "        \n",
    "            # Check current PGD robustness of model using random minibatch\n",
    "        X, y = first_batch\n",
    "        pgd_delta = attack_pgd(model, X, y, epsilon, pgd_alpha, 7, 1, opt)\n",
    "        with torch.no_grad():\n",
    "            output = model(clamp(X + pgd_delta[:X.size(0)], lower_limit, upper_limit))\n",
    "        robust_acc = evaluate_pgd(test_loader, model, 7, 1)[1]\n",
    "        print('robustness: ',robust_acc, )\n",
    "        if robust_acc - prev_robust_acc < -0.2:\n",
    "            break\n",
    "        if robust_acc > prev_robust_acc:\n",
    "            prev_robust_acc = robust_acc\n",
    "            best_state_dict = copy.deepcopy(model.state_dict())\n",
    "        epoch_time = time.time()\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        #logger.info('%d \\t %.1f \\t \\t %.4f \\t %.4f \\t %.4f', epoch, epoch_time - start_epoch_time, lr, train_loss/train_n, train_acc/train_n)\n",
    "        print(epoch, epoch_time - start_epoch_time, lr, train_loss/train_n, train_acc/train_n)\n",
    "    train_time = time.time()\n",
    "    \n",
    "    #best_state_dict = model.state_dict()\n",
    "    #torch.save(best_state_dict, os.path.join(args.out_dir, 'model.pth'))\n",
    "    #logger.info('Total train time: %.4f minutes', (train_time - start_train_time)/60)\n",
    "\n",
    "    # Evaluation\n",
    "    model_test = CifarResNet().cuda()\n",
    "    model.load_state_dict(best_state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    pgd_loss, pgd_acc = evaluate_pgd(test_loader, model, 30, 3)\n",
    "    test_loss, test_acc = evaluate_standard(test_loader, model)\n",
    "\n",
    "    #logger.info('Test Loss \\t Test Acc \\t PGD Loss \\t PGD Acc')\n",
    "    #logger.info('%.4f \\t \\t %.4f \\t %.4f \\t %.4f', test_loss, test_acc, pgd_loss, pgd_acc)\n",
    "\n",
    "def get_loaders(batch_size):\n",
    "    dir_ = '/home/florian/dev/pytorch-network-pruning/data'\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(cifar10_mean, cifar10_std),\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(cifar10_mean, cifar10_std),\n",
    "    ])\n",
    "    num_workers = 2\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        dir_, train=True, transform=train_transform, download=True)\n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        dir_, train=False, transform=test_transform, download=True)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=2,\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
