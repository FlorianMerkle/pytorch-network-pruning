{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.models import CifarResNet, MNIST_CNN, CIFAR_CNN\n",
    "from src.helpers import evaluate_rob_accuracy, evaluate_clean_accuracy, load_model, safe_model,_evaluate_model\n",
    "from src.data_loader import load_torchvision_dataset, load_imagenette\n",
    "#from src.pruning import identify_layers, _evaluate_sparsity\n",
    "\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 43.28379, train_accuracy: 12.30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-6d1634c3175d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_fast_with_double_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/pytorch-network-pruning/src/models.py\u001b[0m in \u001b[0;36mfit_fast_with_double_update\u001b[0;34m(self, train_loader, val_loader, epochs, device, eps, number_of_replays, patience, evaluate_robustness)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_fast_with_double_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_replays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_fit_fast_with_double_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_robustness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0midentify_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-network-pruning/src/training.py\u001b[0m in \u001b[0;36m_fit_fast_with_double_update\u001b[0;34m(model, train_loader, val_loader, epochs, device, eps, patience, evaluate_robustness)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;31m# second backwards pass to update weights on adv.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-network-pruning/src/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-network-pruning/src/custom_modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m#print('inputs',shortcut.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;31m#print('after conv 1',x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_stats = model.fit_fast_with_double_update(train_loader, test_loader, 200, device, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9947862945d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l_inf_robustness'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l_2_robustness'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    947\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/pandas/plotting/_matplotlib/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ax\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_ax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# no non-numeric frames or series allowed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no numeric data to plot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;31m# GH25587: cast ExtensionArray of pandas (IntegerArray, etc.) to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "train_stats.plot(x='epoch', y=['l_inf_robustness', 'l_2_robustness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./saved-models/fast-double-vs-standard-experiment-double-update-fast-training.pt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PATH='./saved-models/fast-double-vs-standard-experiment-double-update-fast-training.pt'\n",
    "#optimizer = train_stats['optimizer'][0]\n",
    "#safe_model(PATH, model, optimizer, description='Comparing fast adversarial training with single and double updates', loss='N/A',epoch='92')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n"
     ]
    }
   ],
   "source": [
    "PATH='./saved-models/fast-double-vs-standard-experiment-double-update-fast-training.pt'\n",
    "model = CifarResNet().to(device)\n",
    "model = load_model(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM(model, data_loader, criterion, eps, device):\n",
    "    #mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "    #mean = torch.tensor(mean).view(3,1,1).expand(3,32,32).to(device)\n",
    "    #std = torch.tensor(std).view(3,1,1).expand(3,32,32).to(device)\n",
    "    advs = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in data_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels =inputs.to(device), labels.to(device)\n",
    "        inputs.requires_grad = True\n",
    "        perturbation = torch.zeros_like(inputs, requires_grad=True).to(device)\n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        perturbation = torch.sign(inputs.grad).clamp_(-eps, eps)\n",
    "        adv_examples = inputs + perturbation\n",
    "        advs.append(adv_examples)\n",
    "        preds = model(adv_examples)\n",
    "        #pred_labels = \n",
    "        _, predicted = torch.max(preds.data, 1)\n",
    "        total += len(predicted)\n",
    "        #correct += (pred_labels == labels).sum().item()\n",
    "        correct += (predicted != labels).sum().item()\n",
    "\n",
    "    \n",
    "    return advs, correct/total\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "advs, success = FGSM(model, test_loader, torch.nn.CrossEntropyLoss(), 16/255, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4104"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4669"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86.72, 0.0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_clean_accuracy(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(iter(test_loader))[0][1]\n",
    "label = next(iter(test_loader))[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f54d3e86e20>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.permute(1, 2, 0)  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_torchvision_dataset(dataset, batchsize=512, data_augmentation=False):\n",
    "    if data_augmentation == True:\n",
    "        train_transforms = torchvision.transforms.Compose([\n",
    "            #torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.RandomRotation(20),\n",
    "            torchvision.transforms.Resize(40),\n",
    "            torchvision.transforms.RandomResizedCrop(32),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),        \n",
    "        ])\n",
    "    if data_augmentation == False:\n",
    "        train_transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),        \n",
    "        ])\n",
    "    val_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    if dataset == 'MNIST':\n",
    "        train = torchvision.datasets.MNIST('./data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "        test = torchvision.datasets.MNIST('./data', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    if dataset == 'CIFAR10':\n",
    "        train = torchvision.datasets.CIFAR10('./data', train=True, transform=train_transforms, download=True)\n",
    "        test = torchvision.datasets.CIFAR10('./data', train=False, transform=val_transforms, download=True)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train,\n",
    "        batch_size=batchsize,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test,\n",
    "        batch_size=batchsize,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = invTrans(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
