{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.models import CifarResNet, MNIST_CNN, CIFAR_CNN\n",
    "from src.helpers import evaluate_rob_accuracy, evaluate_clean_accuracy, load_model, safe_model,_evaluate_model\n",
    "from src.data_loader import load_torchvision_dataset, load_imagenette\n",
    "#from src.pruning import identify_layers, _evaluate_sparsity\n",
    "\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CifarResNet(\n",
       "  (c1): MaskedConvLayer()\n",
       "  (r1): ResBlock(\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c1): MaskedConvLayer()\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c2): MaskedConvLayer()\n",
       "  )\n",
       "  (r2): ResBlock(\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c1): MaskedConvLayer()\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c2): MaskedConvLayer()\n",
       "  )\n",
       "  (r3): ResBlock(\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c1): MaskedConvLayer()\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c2): MaskedConvLayer()\n",
       "    (c3): MaskedConvLayer()\n",
       "  )\n",
       "  (r4): ResBlock(\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c1): MaskedConvLayer()\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c2): MaskedConvLayer()\n",
       "  )\n",
       "  (r5): ResBlock(\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c1): MaskedConvLayer()\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c2): MaskedConvLayer()\n",
       "    (c3): MaskedConvLayer()\n",
       "  )\n",
       "  (r6): ResBlock(\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c1): MaskedConvLayer()\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c2): MaskedConvLayer()\n",
       "  )\n",
       "  (r7): ResBlock(\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c1): MaskedConvLayer()\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c2): MaskedConvLayer()\n",
       "    (c3): MaskedConvLayer()\n",
       "  )\n",
       "  (r8): ResBlock(\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c1): MaskedConvLayer()\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (c2): MaskedConvLayer()\n",
       "  )\n",
       "  (p2): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "  (d1): MaskedLinearLayer()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CifarResNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 1.96118, train_accuracy: 29.88\n",
      "[1,     2] loss: 5.29874, train_accuracy: 19.73\n",
      "[1,     3] loss: 5.81986, train_accuracy: 9.96\n",
      "[1,     4] loss: 3.74798, train_accuracy: 10.94\n",
      "[1,     5] loss: 3.13215, train_accuracy: 19.34\n",
      "[1,     6] loss: 3.23406, train_accuracy: 16.21\n",
      "[1,     7] loss: 2.71220, train_accuracy: 14.06\n",
      "[1,     8] loss: 2.70970, train_accuracy: 12.50\n",
      "[1,     9] loss: 2.92613, train_accuracy: 16.21\n",
      "[1,    10] loss: 3.54328, train_accuracy: 20.70\n",
      "[1,    11] loss: 2.51670, train_accuracy: 19.73\n",
      "[1,    12] loss: 3.60842, train_accuracy: 18.36\n",
      "[1,    13] loss: 2.74857, train_accuracy: 21.48\n",
      "[1,    14] loss: 3.33330, train_accuracy: 19.34\n",
      "[1,    15] loss: 2.32501, train_accuracy: 17.97\n",
      "[1,    16] loss: 2.24358, train_accuracy: 22.27\n",
      "[1,    17] loss: 2.64021, train_accuracy: 19.73\n",
      "[1,    18] loss: 2.76872, train_accuracy: 21.48\n",
      "[1,    19] loss: 2.12910, train_accuracy: 23.63\n",
      "[1,    20] loss: 2.65200, train_accuracy: 22.07\n",
      "[1,    21] loss: 2.74562, train_accuracy: 19.92\n",
      "[1,    22] loss: 2.16225, train_accuracy: 19.34\n",
      "[1,    23] loss: 2.27643, train_accuracy: 20.51\n",
      "[1,    24] loss: 2.08289, train_accuracy: 23.24\n",
      "[1,    25] loss: 2.62969, train_accuracy: 23.05\n",
      "[1,    26] loss: 2.03913, train_accuracy: 27.73\n",
      "[1,    27] loss: 2.55019, train_accuracy: 24.80\n",
      "[1,    28] loss: 2.31672, train_accuracy: 24.41\n",
      "[1,    29] loss: 1.93811, train_accuracy: 25.20\n",
      "[1,    30] loss: 2.79507, train_accuracy: 21.68\n",
      "[1,    31] loss: 2.59042, train_accuracy: 21.48\n",
      "[1,    32] loss: 2.30391, train_accuracy: 21.88\n",
      "[1,    33] loss: 2.27049, train_accuracy: 23.44\n",
      "[1,    34] loss: 2.29560, train_accuracy: 22.85\n",
      "[1,    35] loss: 2.41500, train_accuracy: 26.17\n",
      "[1,    36] loss: 2.38045, train_accuracy: 24.41\n",
      "[1,    37] loss: 2.06585, train_accuracy: 23.24\n",
      "[1,    38] loss: 2.30997, train_accuracy: 25.39\n",
      "[1,    39] loss: 2.27247, train_accuracy: 19.34\n",
      "[1,    40] loss: 2.06438, train_accuracy: 23.83\n",
      "[1,    41] loss: 2.53409, train_accuracy: 23.83\n",
      "[1,    42] loss: 2.09260, train_accuracy: 27.15\n",
      "[1,    43] loss: 2.44138, train_accuracy: 25.98\n",
      "[1,    44] loss: 2.01403, train_accuracy: 16.99\n",
      "[1,    45] loss: 2.13854, train_accuracy: 21.68\n",
      "[1,    46] loss: 2.42418, train_accuracy: 21.09\n",
      "[1,    47] loss: 2.16198, train_accuracy: 28.52\n",
      "[1,    48] loss: 2.20434, train_accuracy: 22.85\n",
      "[1,    49] loss: 2.33032, train_accuracy: 24.22\n",
      "[1,    50] loss: 2.20892, train_accuracy: 22.85\n",
      "[1,    51] loss: 2.38625, train_accuracy: 24.61\n",
      "[1,    52] loss: 2.04137, train_accuracy: 26.37\n",
      "[1,    53] loss: 2.27016, train_accuracy: 22.85\n",
      "[1,    54] loss: 2.05912, train_accuracy: 24.80\n",
      "[1,    55] loss: 2.03874, train_accuracy: 24.41\n",
      "[1,    56] loss: 2.07695, train_accuracy: 26.17\n",
      "[1,    57] loss: 2.14962, train_accuracy: 27.15\n",
      "[1,    58] loss: 1.94958, train_accuracy: 28.12\n",
      "[1,    59] loss: 1.97083, train_accuracy: 26.56\n",
      "[1,    60] loss: 2.11187, train_accuracy: 28.71\n",
      "[1,    61] loss: 2.17822, train_accuracy: 23.63\n",
      "[1,    62] loss: 1.95796, train_accuracy: 29.10\n",
      "[1,    63] loss: 2.00656, train_accuracy: 28.12\n",
      "[1,    64] loss: 2.18801, train_accuracy: 27.15\n",
      "[1,    65] loss: 2.07276, train_accuracy: 26.95\n",
      "[1,    66] loss: 1.97245, train_accuracy: 30.47\n",
      "[1,    67] loss: 2.00991, train_accuracy: 26.37\n",
      "[1,    68] loss: 1.94494, train_accuracy: 28.71\n",
      "[1,    69] loss: 1.88458, train_accuracy: 26.37\n",
      "[1,    70] loss: 1.95229, train_accuracy: 28.52\n",
      "[1,    71] loss: 2.06723, train_accuracy: 24.61\n",
      "[1,    72] loss: 1.92163, train_accuracy: 26.76\n",
      "[1,    73] loss: 2.25108, train_accuracy: 28.12\n",
      "[1,    74] loss: 2.05343, train_accuracy: 29.10\n",
      "[1,    75] loss: 1.97100, train_accuracy: 27.15\n",
      "[1,    76] loss: 1.93518, train_accuracy: 28.52\n",
      "[1,    77] loss: 2.13650, train_accuracy: 26.17\n",
      "[1,    78] loss: 1.94618, train_accuracy: 27.54\n",
      "[1,    79] loss: 2.10553, train_accuracy: 26.76\n",
      "[1,    80] loss: 1.94324, train_accuracy: 24.61\n",
      "[1,    81] loss: 1.91386, train_accuracy: 28.12\n",
      "[1,    82] loss: 1.92361, train_accuracy: 27.15\n",
      "[1,    83] loss: 1.86681, train_accuracy: 31.84\n",
      "[1,    84] loss: 2.04579, train_accuracy: 25.20\n",
      "[1,    85] loss: 1.84578, train_accuracy: 32.23\n",
      "[1,    86] loss: 1.83027, train_accuracy: 32.81\n",
      "[1,    87] loss: 1.92711, train_accuracy: 24.41\n",
      "[1,    88] loss: 1.90451, train_accuracy: 29.88\n",
      "[1,    89] loss: 1.95114, train_accuracy: 28.32\n",
      "[1,    90] loss: 1.94785, train_accuracy: 28.12\n",
      "[1,    91] loss: 1.86278, train_accuracy: 31.25\n",
      "[1,    92] loss: 2.00004, train_accuracy: 25.98\n",
      "[1,    93] loss: 1.90095, train_accuracy: 27.54\n",
      "[1,    94] loss: 1.87727, train_accuracy: 30.86\n",
      "[1,    95] loss: 1.85113, train_accuracy: 29.69\n",
      "[1,    96] loss: 1.97814, train_accuracy: 26.76\n",
      "[1,    97] loss: 1.90124, train_accuracy: 29.69\n",
      "[1,    98] loss: 1.84053, train_accuracy: 32.14\n",
      "duration: 111 s - train loss: 2.31661 - train accuracy: 24.48 - validation loss: 1.76 - validation accuracy: 35.15 \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_stats = model.fit(train_loader, test_loader, 1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_stats['l_inf_robustness'] = model.train_stats['l_inf_robustness'].map(lambda x: x.item())\n",
    "model.train_stats['l_2_robustness'] = model.train_stats['l_2_robustness'].map(lambda x: x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.493002</td>\n",
       "      <td>20.343534</td>\n",
       "      <td>2.253086</td>\n",
       "      <td>0.279297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.59</td>\n",
       "      <td>112.124355</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336</td>\n",
       "      <td>0.279297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.304893</td>\n",
       "      <td>25.700202</td>\n",
       "      <td>1.882308</td>\n",
       "      <td>0.279297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.85</td>\n",
       "      <td>225.014890</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336</td>\n",
       "      <td>0.279297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.316611</td>\n",
       "      <td>24.480970</td>\n",
       "      <td>1.760163</td>\n",
       "      <td>0.337891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.15</td>\n",
       "      <td>111.586921</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336</td>\n",
       "      <td>0.337891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch  train_loss  train_accuracy  validation_loss  l_inf_robustness  \\\n",
       "0     1    4.493002       20.343534         2.253086          0.279297   \n",
       "1     2    2.304893       25.700202         1.882308          0.279297   \n",
       "2     1    2.316611       24.480970         1.760163          0.337891   \n",
       "\n",
       "   l_inf_loss  l_2_robustness  l_2_loss l_0_robustness  l_0_loss  \\\n",
       "0         NaN        0.289062       NaN              0       NaN   \n",
       "1         NaN        0.289062       NaN              0       NaN   \n",
       "2         NaN        0.355469       NaN              0       NaN   \n",
       "\n",
       "   validation_accuracy    duration           criterion  \\\n",
       "0                28.59  112.124355  CrossEntropyLoss()   \n",
       "1                33.85  225.014890  CrossEntropyLoss()   \n",
       "2                35.15  111.586921  CrossEntropyLoss()   \n",
       "\n",
       "                                           optimizer    method  learning_rate  \\\n",
       "0  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard            NaN   \n",
       "1  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard            NaN   \n",
       "2  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard            NaN   \n",
       "\n",
       "  batchsize      test  \n",
       "0       336  0.279297  \n",
       "1       336  0.279297  \n",
       "2       336  0.337891  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './saved-models/cifar-resnet-100e-data_aug'\n",
    "safe_model(PATH, model, optimizer_state_dict, description='w/ full data auggmentation pipeline', loss='N/A',epoch='100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './saved-models/cifar-resnet-100e-data_aug'\n",
    "model = load_model(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_stats.plot(x='epoch', y=['validation_loss','validation_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_stats.plot(x='epoch', y=['train_loss','train_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
