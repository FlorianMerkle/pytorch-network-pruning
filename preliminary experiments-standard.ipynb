{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.models import CifarResNet, MNIST_CNN, CIFAR_CNN\n",
    "from src.helpers import evaluate_rob_accuracy, evaluate_clean_accuracy, load_model, safe_model,_evaluate_model\n",
    "from src.data_loader import load_torchvision_dataset, load_imagenette\n",
    "#from src.pruning import identify_layers, _evaluate_sparsity\n",
    "\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l2_robustness</th>\n",
       "      <th>linf_robustness</th>\n",
       "      <th>clean_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.117186</td>\n",
       "      <td>67.382809</td>\n",
       "      <td>67.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.945312</td>\n",
       "      <td>66.015623</td>\n",
       "      <td>69.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.554687</td>\n",
       "      <td>64.062499</td>\n",
       "      <td>68.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65.820310</td>\n",
       "      <td>62.499996</td>\n",
       "      <td>65.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>57.226559</td>\n",
       "      <td>52.343747</td>\n",
       "      <td>55.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    l2_robustness  linf_robustness  clean_accuracy\n",
       "1       70.117186        67.382809           67.90\n",
       "2       68.945312        66.015623           69.22\n",
       "4       68.554687        64.062499           68.67\n",
       "8       65.820310        62.499996           65.39\n",
       "16      57.226559        52.343747           55.59"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('./results/preliminary-double.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.76, 0.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evaluate_clean_accuracy(model.to(device), test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "from foolbox.attacks import LinfPGD, FGSM, L0BrendelBethgeAttack, L2CarliniWagnerAttack\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "\n",
    "def run(training_method):\n",
    "    model = CIFAR_CNN().to(device)\n",
    "    #print(model.device)\n",
    "    compression_rates = [1,2,4,8,16]\n",
    "    stats = {}\n",
    "    for ratio in compression_rates:\n",
    "        print('compression rate: ', 1-1/ratio)\n",
    "        fit = get_train_method(model, training_method)\n",
    "        model.prune_magnitude_global_unstruct(1-1/ratio, device)\n",
    "        #print(fit)\n",
    "        train_data = fit(train_loader, test_loader, epochs, device, eps=8/255, patience=5)\n",
    "        images, labels = next(iter(test_loader))\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        #stats[f'ratio']['l0_robustness'] = bb_attack(model, images, labels).item()\n",
    "        #print('bb done')\n",
    "        stats[f'{ratio}'] = {}\n",
    "        stats[f'{ratio}']['l2_robustness'] = cw_attack(model, images, labels).item()\n",
    "        print('cw done')\n",
    "        stats[f'{ratio}']['linf_robustness'] = pgd_attack(model, images, labels).item()\n",
    "        print('pgd done')\n",
    "        stats[f'{ratio}']['clean_accuracy'] = train_data['val_accuracy']\n",
    "        \n",
    "    return(stats)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "def get_train_method(model, method):\n",
    "    if method=='standard':\n",
    "        return model.fit\n",
    "    if method=='free':\n",
    "        return model.fit_free\n",
    "    if method=='fast':\n",
    "        return model.fit_fast\n",
    "    if method=='fast_double':\n",
    "        return model.fit_fast_with_double_update\n",
    "\n",
    "def bb_attack(model, images, labels, eps=8/255):\n",
    "    model.eval()\n",
    "    fmodel = PyTorchModel(model, bounds=(0, 1))\n",
    "    attack = L0BrendelBethgeAttack()\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=eps)\n",
    "    model.train()\n",
    "\n",
    "    return (1 - torch.sum(success)/len(success)) / 100\n",
    "\n",
    "def cw_attack(model, images, labels, eps=8/255):\n",
    "    model.eval()\n",
    "    fmodel = PyTorchModel(model, bounds=(0, 1))\n",
    "    attack = L2CarliniWagnerAttack()\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=eps)\n",
    "    model.train()\n",
    "\n",
    "    return (1 - torch.sum(success)/len(success)) / 100\n",
    "\n",
    "def pgd_attack(model, images, labels, eps=8/255):\n",
    "    model.eval()\n",
    "    fmodel = PyTorchModel(model, bounds=(0, 1))\n",
    "    attack = LinfPGD()\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=eps)\n",
    "    model.train()\n",
    "\n",
    "    return (1 - torch.sum(success)/len(success)) / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Update vs. Single Update Fast Adversarial Training\n",
    "Specs:\n",
    "\n",
    "CIFAR CNN: 4 Conv (16,16,32,32) with batchnorm, 2 FC (128,10)\n",
    "\n",
    "Data: Cifar (32,32,3)\n",
    "\n",
    "30 Epochs with eps=8/255\n",
    "\n",
    "\n",
    "\n",
    "Standard Fast Adv. Training:\n",
    "Clean: 63.05%\n",
    "Robust: 59.34%\n",
    "\n",
    "Fast Adv. Training w Double Update:\n",
    "Clean: 63.99%\n",
    "Robust: 61.35%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n"
     ]
    }
   ],
   "source": [
    "#model = ResNet()\n",
    "#model = MNIST_CNN()\n",
    "model = CIFAR_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = load_torchvision_dataset('CIFAR10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './saved-models/CIFAR-baseline-150-epochs.pth'\n",
    "model = load_model(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "\n",
    "1. Prune\n",
    "2. Train\n",
    "3. measure robust accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "compression rate:  0.0\n",
      "[1,     1] loss: 3.07543, train_accuracy: 8.59\n",
      "[1,     2] loss: 2.74960, train_accuracy: 11.13\n",
      "[1,     3] loss: 2.46489, train_accuracy: 17.19\n",
      "[1,     4] loss: 2.45922, train_accuracy: 21.09\n",
      "[1,     5] loss: 2.41755, train_accuracy: 20.90\n",
      "[1,     6] loss: 2.31154, train_accuracy: 22.66\n",
      "[1,     7] loss: 2.24753, train_accuracy: 22.66\n",
      "[1,     8] loss: 2.26820, train_accuracy: 20.70\n",
      "[1,     9] loss: 2.13691, train_accuracy: 26.95\n",
      "[1,    10] loss: 2.09834, train_accuracy: 24.80\n",
      "[1,    11] loss: 2.12638, train_accuracy: 28.32\n",
      "[1,    12] loss: 2.06679, train_accuracy: 31.25\n",
      "[1,    13] loss: 2.05545, train_accuracy: 27.34\n",
      "[1,    14] loss: 1.94770, train_accuracy: 33.20\n",
      "[1,    15] loss: 1.88556, train_accuracy: 34.38\n",
      "[1,    16] loss: 1.91349, train_accuracy: 31.64\n",
      "[1,    17] loss: 1.89596, train_accuracy: 32.62\n",
      "[1,    18] loss: 1.91558, train_accuracy: 31.45\n",
      "[1,    19] loss: 1.85688, train_accuracy: 34.96\n",
      "[1,    20] loss: 1.89446, train_accuracy: 38.09\n",
      "[1,    21] loss: 1.83907, train_accuracy: 34.57\n",
      "[1,    22] loss: 1.85212, train_accuracy: 32.62\n",
      "[1,    23] loss: 1.73340, train_accuracy: 37.11\n",
      "[1,    24] loss: 1.81675, train_accuracy: 35.55\n",
      "[1,    25] loss: 1.77203, train_accuracy: 33.98\n",
      "[1,    26] loss: 1.77021, train_accuracy: 39.06\n",
      "[1,    27] loss: 1.73994, train_accuracy: 36.13\n",
      "[1,    28] loss: 1.73911, train_accuracy: 41.60\n",
      "[1,    29] loss: 1.71595, train_accuracy: 38.67\n",
      "[1,    30] loss: 1.74815, train_accuracy: 38.09\n",
      "[1,    31] loss: 1.67154, train_accuracy: 41.21\n",
      "[1,    32] loss: 1.74494, train_accuracy: 37.89\n",
      "[1,    33] loss: 1.78208, train_accuracy: 37.50\n",
      "[1,    34] loss: 1.65397, train_accuracy: 42.58\n",
      "[1,    35] loss: 1.70256, train_accuracy: 37.50\n",
      "[1,    36] loss: 1.68610, train_accuracy: 41.41\n",
      "[1,    37] loss: 1.65428, train_accuracy: 43.16\n",
      "[1,    38] loss: 1.68002, train_accuracy: 34.96\n",
      "[1,    39] loss: 1.75997, train_accuracy: 39.65\n",
      "[1,    40] loss: 1.67531, train_accuracy: 39.26\n",
      "[1,    41] loss: 1.61218, train_accuracy: 40.82\n",
      "[1,    42] loss: 1.63052, train_accuracy: 40.23\n",
      "[1,    43] loss: 1.56449, train_accuracy: 43.16\n",
      "[1,    44] loss: 1.58898, train_accuracy: 41.41\n",
      "[1,    45] loss: 1.66715, train_accuracy: 40.43\n",
      "[1,    46] loss: 1.62402, train_accuracy: 40.82\n",
      "[1,    47] loss: 1.60892, train_accuracy: 42.77\n",
      "[1,    48] loss: 1.59034, train_accuracy: 43.36\n",
      "[1,    49] loss: 1.57828, train_accuracy: 43.55\n",
      "[1,    50] loss: 1.61376, train_accuracy: 41.80\n",
      "[1,    51] loss: 1.57939, train_accuracy: 45.51\n",
      "[1,    52] loss: 1.62088, train_accuracy: 46.09\n",
      "[1,    53] loss: 1.64620, train_accuracy: 42.58\n",
      "[1,    54] loss: 1.59718, train_accuracy: 42.19\n",
      "[1,    55] loss: 1.56495, train_accuracy: 45.70\n",
      "[1,    56] loss: 1.50187, train_accuracy: 44.14\n",
      "[1,    57] loss: 1.65728, train_accuracy: 40.23\n",
      "[1,    58] loss: 1.54960, train_accuracy: 43.16\n",
      "[1,    59] loss: 1.58672, train_accuracy: 43.55\n",
      "[1,    60] loss: 1.56906, train_accuracy: 42.19\n",
      "[1,    61] loss: 1.55430, train_accuracy: 41.60\n",
      "[1,    62] loss: 1.54587, train_accuracy: 46.09\n",
      "[1,    63] loss: 1.55676, train_accuracy: 44.53\n",
      "[1,    64] loss: 1.59658, train_accuracy: 43.75\n",
      "[1,    65] loss: 1.59092, train_accuracy: 43.95\n",
      "[1,    66] loss: 1.48699, train_accuracy: 44.92\n",
      "[1,    67] loss: 1.56505, train_accuracy: 41.02\n",
      "[1,    68] loss: 1.56307, train_accuracy: 43.16\n",
      "[1,    69] loss: 1.44678, train_accuracy: 46.29\n",
      "[1,    70] loss: 1.53889, train_accuracy: 44.92\n",
      "[1,    71] loss: 1.55126, train_accuracy: 43.75\n",
      "[1,    72] loss: 1.54904, train_accuracy: 44.92\n",
      "[1,    73] loss: 1.40546, train_accuracy: 47.27\n",
      "[1,    74] loss: 1.51794, train_accuracy: 45.51\n",
      "[1,    75] loss: 1.54821, train_accuracy: 47.07\n",
      "[1,    76] loss: 1.52377, train_accuracy: 45.51\n",
      "[1,    77] loss: 1.52253, train_accuracy: 45.31\n",
      "[1,    78] loss: 1.61618, train_accuracy: 43.16\n",
      "[1,    79] loss: 1.48574, train_accuracy: 44.53\n",
      "[1,    80] loss: 1.41220, train_accuracy: 48.63\n",
      "[1,    81] loss: 1.53161, train_accuracy: 45.31\n",
      "[1,    82] loss: 1.51062, train_accuracy: 44.14\n",
      "[1,    83] loss: 1.42260, train_accuracy: 48.05\n",
      "[1,    84] loss: 1.44765, train_accuracy: 47.46\n",
      "[1,    85] loss: 1.41238, train_accuracy: 46.68\n",
      "[1,    86] loss: 1.49803, train_accuracy: 45.51\n",
      "[1,    87] loss: 1.31852, train_accuracy: 54.69\n",
      "[1,    88] loss: 1.45026, train_accuracy: 47.85\n",
      "[1,    89] loss: 1.43839, train_accuracy: 50.59\n",
      "[1,    90] loss: 1.46772, train_accuracy: 49.02\n",
      "[1,    91] loss: 1.35656, train_accuracy: 50.59\n",
      "[1,    92] loss: 1.44463, train_accuracy: 47.07\n",
      "[1,    93] loss: 1.44756, train_accuracy: 48.05\n",
      "[1,    94] loss: 1.42504, train_accuracy: 46.68\n",
      "[1,    95] loss: 1.40756, train_accuracy: 47.66\n",
      "[1,    96] loss: 1.41025, train_accuracy: 51.17\n",
      "[1,    97] loss: 1.44642, train_accuracy: 46.88\n",
      "[1,    98] loss: 1.41367, train_accuracy: 46.73\n",
      "duration: 11 s - train loss: 1.70310 - train accuracy: 39.76 - validation loss: 1.41 - validation accuracy: 49.60 \n",
      "[2,     1] loss: 1.38381, train_accuracy: 51.17\n",
      "[2,     2] loss: 1.38028, train_accuracy: 51.56\n",
      "[2,     3] loss: 1.38534, train_accuracy: 53.32\n",
      "[2,     4] loss: 1.32504, train_accuracy: 53.91\n",
      "[2,     5] loss: 1.29421, train_accuracy: 55.47\n",
      "[2,     6] loss: 1.45569, train_accuracy: 48.05\n",
      "[2,     7] loss: 1.36604, train_accuracy: 52.15\n",
      "[2,     8] loss: 1.24720, train_accuracy: 55.86\n",
      "[2,     9] loss: 1.29213, train_accuracy: 53.12\n",
      "[2,    10] loss: 1.35304, train_accuracy: 50.78\n",
      "[2,    11] loss: 1.32219, train_accuracy: 49.61\n",
      "[2,    12] loss: 1.22530, train_accuracy: 55.86\n",
      "[2,    13] loss: 1.30179, train_accuracy: 51.95\n",
      "[2,    14] loss: 1.29599, train_accuracy: 54.69\n",
      "[2,    15] loss: 1.30373, train_accuracy: 54.30\n",
      "[2,    16] loss: 1.34335, train_accuracy: 49.80\n",
      "[2,    17] loss: 1.32015, train_accuracy: 54.30\n",
      "[2,    18] loss: 1.39548, train_accuracy: 49.22\n",
      "[2,    19] loss: 1.26130, train_accuracy: 55.08\n",
      "[2,    20] loss: 1.34489, train_accuracy: 54.10\n",
      "[2,    21] loss: 1.38734, train_accuracy: 51.76\n",
      "[2,    22] loss: 1.34379, train_accuracy: 53.12\n",
      "[2,    23] loss: 1.28478, train_accuracy: 54.30\n",
      "[2,    24] loss: 1.36761, train_accuracy: 49.80\n",
      "[2,    25] loss: 1.34498, train_accuracy: 49.02\n",
      "[2,    26] loss: 1.36669, train_accuracy: 51.56\n",
      "[2,    27] loss: 1.33982, train_accuracy: 51.76\n",
      "[2,    28] loss: 1.27884, train_accuracy: 53.32\n",
      "[2,    29] loss: 1.37933, train_accuracy: 49.02\n",
      "[2,    30] loss: 1.33689, train_accuracy: 54.49\n",
      "[2,    31] loss: 1.36119, train_accuracy: 52.15\n",
      "[2,    32] loss: 1.28626, train_accuracy: 54.49\n",
      "[2,    33] loss: 1.25774, train_accuracy: 55.27\n",
      "[2,    34] loss: 1.27712, train_accuracy: 54.49\n",
      "[2,    35] loss: 1.30791, train_accuracy: 54.69\n",
      "[2,    36] loss: 1.23946, train_accuracy: 53.71\n",
      "[2,    37] loss: 1.36169, train_accuracy: 50.39\n",
      "[2,    38] loss: 1.28092, train_accuracy: 56.25\n",
      "[2,    39] loss: 1.24234, train_accuracy: 53.12\n",
      "[2,    40] loss: 1.29483, train_accuracy: 53.32\n",
      "[2,    41] loss: 1.27655, train_accuracy: 54.30\n",
      "[2,    42] loss: 1.33484, train_accuracy: 52.73\n",
      "[2,    43] loss: 1.35348, train_accuracy: 49.61\n",
      "[2,    44] loss: 1.34311, train_accuracy: 51.17\n",
      "[2,    45] loss: 1.27345, train_accuracy: 54.10\n",
      "[2,    46] loss: 1.28449, train_accuracy: 51.95\n",
      "[2,    47] loss: 1.24123, train_accuracy: 53.12\n",
      "[2,    48] loss: 1.29166, train_accuracy: 53.91\n",
      "[2,    49] loss: 1.21943, train_accuracy: 56.64\n",
      "[2,    50] loss: 1.32054, train_accuracy: 53.52\n",
      "[2,    51] loss: 1.32067, train_accuracy: 52.54\n",
      "[2,    52] loss: 1.40213, train_accuracy: 52.73\n",
      "[2,    53] loss: 1.33416, train_accuracy: 52.54\n",
      "[2,    54] loss: 1.28982, train_accuracy: 53.71\n",
      "[2,    55] loss: 1.28714, train_accuracy: 56.25\n",
      "[2,    56] loss: 1.22092, train_accuracy: 57.23\n",
      "[2,    57] loss: 1.25248, train_accuracy: 53.91\n",
      "[2,    58] loss: 1.30387, train_accuracy: 54.49\n",
      "[2,    59] loss: 1.23046, train_accuracy: 56.25\n",
      "[2,    60] loss: 1.29678, train_accuracy: 52.15\n",
      "[2,    61] loss: 1.17472, train_accuracy: 56.05\n",
      "[2,    62] loss: 1.25044, train_accuracy: 55.86\n",
      "[2,    63] loss: 1.25928, train_accuracy: 55.08\n",
      "[2,    64] loss: 1.29738, train_accuracy: 53.12\n",
      "[2,    65] loss: 1.26531, train_accuracy: 56.05\n",
      "[2,    66] loss: 1.27024, train_accuracy: 54.69\n",
      "[2,    67] loss: 1.32520, train_accuracy: 55.08\n",
      "[2,    68] loss: 1.24688, train_accuracy: 55.66\n",
      "[2,    69] loss: 1.30019, train_accuracy: 52.73\n",
      "[2,    70] loss: 1.25735, train_accuracy: 53.91\n",
      "[2,    71] loss: 1.28878, train_accuracy: 53.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    72] loss: 1.25887, train_accuracy: 53.71\n",
      "[2,    73] loss: 1.26233, train_accuracy: 55.66\n",
      "[2,    74] loss: 1.21899, train_accuracy: 56.45\n",
      "[2,    75] loss: 1.30196, train_accuracy: 54.69\n",
      "[2,    76] loss: 1.26409, train_accuracy: 56.45\n",
      "[2,    77] loss: 1.27879, train_accuracy: 53.32\n",
      "[2,    78] loss: 1.30535, train_accuracy: 53.71\n",
      "[2,    79] loss: 1.21662, train_accuracy: 53.32\n",
      "[2,    80] loss: 1.31086, train_accuracy: 55.66\n",
      "[2,    81] loss: 1.26724, train_accuracy: 54.10\n",
      "[2,    82] loss: 1.20118, train_accuracy: 57.23\n",
      "[2,    83] loss: 1.19477, train_accuracy: 58.40\n",
      "[2,    84] loss: 1.27326, train_accuracy: 52.93\n",
      "[2,    85] loss: 1.33639, train_accuracy: 53.71\n",
      "[2,    86] loss: 1.32417, train_accuracy: 52.15\n",
      "[2,    87] loss: 1.21581, train_accuracy: 53.52\n",
      "[2,    88] loss: 1.30643, train_accuracy: 53.12\n",
      "[2,    89] loss: 1.37992, train_accuracy: 52.15\n",
      "[2,    90] loss: 1.22989, train_accuracy: 55.27\n",
      "[2,    91] loss: 1.25408, train_accuracy: 55.08\n",
      "[2,    92] loss: 1.20920, train_accuracy: 57.23\n",
      "[2,    93] loss: 1.21077, train_accuracy: 55.86\n",
      "[2,    94] loss: 1.20724, train_accuracy: 56.45\n",
      "[2,    95] loss: 1.28959, train_accuracy: 50.20\n",
      "[2,    96] loss: 1.30522, train_accuracy: 51.56\n",
      "[2,    97] loss: 1.25465, train_accuracy: 53.91\n",
      "[2,    98] loss: 1.21490, train_accuracy: 56.55\n",
      "duration: 11 s - train loss: 1.29431 - train accuracy: 53.65 - validation loss: 1.28 - validation accuracy: 54.27 \n",
      "[3,     1] loss: 1.21668, train_accuracy: 56.05\n",
      "[3,     2] loss: 1.11547, train_accuracy: 60.94\n",
      "[3,     3] loss: 1.16005, train_accuracy: 60.35\n",
      "[3,     4] loss: 1.15423, train_accuracy: 58.98\n",
      "[3,     5] loss: 1.16847, train_accuracy: 58.79\n",
      "[3,     6] loss: 1.12262, train_accuracy: 60.35\n",
      "[3,     7] loss: 1.18238, train_accuracy: 59.18\n",
      "[3,     8] loss: 1.13186, train_accuracy: 60.55\n",
      "[3,     9] loss: 1.22406, train_accuracy: 55.47\n",
      "[3,    10] loss: 1.09288, train_accuracy: 61.33\n",
      "[3,    11] loss: 1.13734, train_accuracy: 59.18\n",
      "[3,    12] loss: 1.14312, train_accuracy: 59.57\n",
      "[3,    13] loss: 1.22117, train_accuracy: 57.62\n",
      "[3,    14] loss: 1.20045, train_accuracy: 57.23\n",
      "[3,    15] loss: 1.12056, train_accuracy: 59.18\n",
      "[3,    16] loss: 1.26395, train_accuracy: 55.66\n",
      "[3,    17] loss: 1.14746, train_accuracy: 60.74\n",
      "[3,    18] loss: 1.15706, train_accuracy: 58.98\n",
      "[3,    19] loss: 1.20144, train_accuracy: 59.18\n",
      "[3,    20] loss: 1.10927, train_accuracy: 60.55\n",
      "[3,    21] loss: 1.22666, train_accuracy: 57.62\n",
      "[3,    22] loss: 1.19548, train_accuracy: 57.81\n",
      "[3,    23] loss: 1.13097, train_accuracy: 58.20\n",
      "[3,    24] loss: 1.08321, train_accuracy: 62.70\n",
      "[3,    25] loss: 1.16759, train_accuracy: 56.84\n",
      "[3,    26] loss: 1.20629, train_accuracy: 57.23\n",
      "[3,    27] loss: 1.10854, train_accuracy: 61.33\n",
      "[3,    28] loss: 1.10349, train_accuracy: 60.35\n",
      "[3,    29] loss: 1.10569, train_accuracy: 60.74\n",
      "[3,    30] loss: 1.03847, train_accuracy: 64.06\n",
      "[3,    31] loss: 1.12915, train_accuracy: 61.33\n",
      "[3,    32] loss: 1.23748, train_accuracy: 54.49\n",
      "[3,    33] loss: 1.17450, train_accuracy: 58.98\n",
      "[3,    34] loss: 1.17915, train_accuracy: 57.23\n",
      "[3,    35] loss: 1.15967, train_accuracy: 59.96\n",
      "[3,    36] loss: 1.18458, train_accuracy: 58.59\n",
      "[3,    37] loss: 1.09184, train_accuracy: 61.91\n",
      "[3,    38] loss: 1.13406, train_accuracy: 61.91\n",
      "[3,    39] loss: 1.14557, train_accuracy: 59.77\n",
      "[3,    40] loss: 1.12274, train_accuracy: 60.55\n",
      "[3,    41] loss: 1.16716, train_accuracy: 59.57\n",
      "[3,    42] loss: 1.13453, train_accuracy: 59.77\n",
      "[3,    43] loss: 1.16577, train_accuracy: 58.01\n",
      "[3,    44] loss: 1.09552, train_accuracy: 64.26\n",
      "[3,    45] loss: 1.15607, train_accuracy: 62.11\n",
      "[3,    46] loss: 1.10326, train_accuracy: 59.38\n",
      "[3,    47] loss: 1.17808, train_accuracy: 58.59\n",
      "[3,    48] loss: 1.14819, train_accuracy: 57.03\n",
      "[3,    49] loss: 1.08723, train_accuracy: 60.74\n",
      "[3,    50] loss: 1.06494, train_accuracy: 61.13\n",
      "[3,    51] loss: 1.11160, train_accuracy: 61.72\n",
      "[3,    52] loss: 1.09600, train_accuracy: 59.96\n",
      "[3,    53] loss: 1.19335, train_accuracy: 58.20\n",
      "[3,    54] loss: 1.13188, train_accuracy: 58.98\n",
      "[3,    55] loss: 1.16166, train_accuracy: 57.42\n",
      "[3,    56] loss: 1.25061, train_accuracy: 56.05\n",
      "[3,    57] loss: 1.08794, train_accuracy: 60.35\n",
      "[3,    58] loss: 1.08552, train_accuracy: 60.55\n",
      "[3,    59] loss: 1.22748, train_accuracy: 56.64\n",
      "[3,    60] loss: 1.24113, train_accuracy: 57.23\n",
      "[3,    61] loss: 1.11405, train_accuracy: 62.11\n",
      "[3,    62] loss: 1.15949, train_accuracy: 59.38\n",
      "[3,    63] loss: 1.08267, train_accuracy: 63.09\n",
      "[3,    64] loss: 1.10126, train_accuracy: 61.13\n",
      "[3,    65] loss: 1.06701, train_accuracy: 61.52\n",
      "[3,    66] loss: 1.23370, train_accuracy: 57.42\n",
      "[3,    67] loss: 1.10319, train_accuracy: 61.33\n",
      "[3,    68] loss: 1.05918, train_accuracy: 59.38\n",
      "[3,    69] loss: 1.22820, train_accuracy: 56.05\n",
      "[3,    70] loss: 1.18530, train_accuracy: 57.23\n",
      "[3,    71] loss: 1.18782, train_accuracy: 56.84\n",
      "[3,    72] loss: 1.18288, train_accuracy: 58.40\n",
      "[3,    73] loss: 1.07128, train_accuracy: 61.52\n",
      "[3,    74] loss: 1.13870, train_accuracy: 60.35\n",
      "[3,    75] loss: 1.13622, train_accuracy: 59.18\n",
      "[3,    76] loss: 1.17015, train_accuracy: 54.88\n",
      "[3,    77] loss: 1.11444, train_accuracy: 59.96\n",
      "[3,    78] loss: 1.02667, train_accuracy: 64.45\n",
      "[3,    79] loss: 1.12643, train_accuracy: 62.50\n",
      "[3,    80] loss: 1.11979, train_accuracy: 60.94\n",
      "[3,    81] loss: 1.09356, train_accuracy: 60.94\n",
      "[3,    82] loss: 1.04487, train_accuracy: 62.30\n",
      "[3,    83] loss: 1.14614, train_accuracy: 60.16\n",
      "[3,    84] loss: 1.07928, train_accuracy: 62.50\n",
      "[3,    85] loss: 1.15774, train_accuracy: 56.84\n",
      "[3,    86] loss: 1.18338, train_accuracy: 58.40\n",
      "[3,    87] loss: 1.11032, train_accuracy: 60.16\n",
      "[3,    88] loss: 1.11203, train_accuracy: 58.79\n",
      "[3,    89] loss: 1.14801, train_accuracy: 60.55\n",
      "[3,    90] loss: 1.20295, train_accuracy: 57.03\n",
      "[3,    91] loss: 1.17194, train_accuracy: 57.42\n",
      "[3,    92] loss: 1.15230, train_accuracy: 58.20\n",
      "[3,    93] loss: 1.11719, train_accuracy: 59.18\n",
      "[3,    94] loss: 1.08858, train_accuracy: 62.89\n",
      "[3,    95] loss: 1.13206, train_accuracy: 58.59\n",
      "[3,    96] loss: 1.15685, train_accuracy: 58.79\n",
      "[3,    97] loss: 1.09060, train_accuracy: 61.72\n",
      "[3,    98] loss: 1.11508, train_accuracy: 57.14\n",
      "duration: 11 s - train loss: 1.14281 - train accuracy: 59.47 - validation loss: 1.20 - validation accuracy: 57.22 \n",
      "[4,     1] loss: 1.05720, train_accuracy: 63.48\n",
      "[4,     2] loss: 0.97537, train_accuracy: 66.02\n",
      "[4,     3] loss: 1.00697, train_accuracy: 66.02\n",
      "[4,     4] loss: 1.07213, train_accuracy: 62.11\n",
      "[4,     5] loss: 1.08565, train_accuracy: 64.06\n",
      "[4,     6] loss: 1.06477, train_accuracy: 63.28\n",
      "[4,     7] loss: 1.07162, train_accuracy: 61.13\n",
      "[4,     8] loss: 1.01598, train_accuracy: 66.60\n",
      "[4,     9] loss: 1.05448, train_accuracy: 61.72\n",
      "[4,    10] loss: 0.96359, train_accuracy: 64.06\n",
      "[4,    11] loss: 1.05656, train_accuracy: 62.11\n",
      "[4,    12] loss: 0.95787, train_accuracy: 68.36\n",
      "[4,    13] loss: 1.11165, train_accuracy: 60.74\n",
      "[4,    14] loss: 1.07114, train_accuracy: 63.67\n",
      "[4,    15] loss: 1.03845, train_accuracy: 59.38\n",
      "[4,    16] loss: 1.12210, train_accuracy: 61.13\n",
      "[4,    17] loss: 1.01553, train_accuracy: 65.62\n",
      "[4,    18] loss: 1.01028, train_accuracy: 63.67\n",
      "[4,    19] loss: 1.05880, train_accuracy: 63.67\n",
      "[4,    20] loss: 1.01195, train_accuracy: 66.21\n",
      "[4,    21] loss: 1.05662, train_accuracy: 61.91\n",
      "[4,    22] loss: 1.04822, train_accuracy: 64.06\n",
      "[4,    23] loss: 1.08428, train_accuracy: 62.11\n",
      "[4,    24] loss: 1.04667, train_accuracy: 63.28\n",
      "[4,    25] loss: 1.02214, train_accuracy: 64.84\n",
      "[4,    26] loss: 1.00628, train_accuracy: 64.26\n",
      "[4,    27] loss: 1.13466, train_accuracy: 59.38\n",
      "[4,    28] loss: 0.98332, train_accuracy: 66.02\n",
      "[4,    29] loss: 1.08536, train_accuracy: 60.74\n",
      "[4,    30] loss: 1.00314, train_accuracy: 64.45\n",
      "[4,    31] loss: 1.02371, train_accuracy: 64.26\n",
      "[4,    32] loss: 1.00093, train_accuracy: 67.19\n",
      "[4,    33] loss: 1.01007, train_accuracy: 66.02\n",
      "[4,    34] loss: 1.04153, train_accuracy: 61.13\n",
      "[4,    35] loss: 0.95029, train_accuracy: 65.04\n",
      "[4,    36] loss: 0.99421, train_accuracy: 63.28\n",
      "[4,    37] loss: 0.95682, train_accuracy: 65.23\n",
      "[4,    38] loss: 1.06182, train_accuracy: 64.06\n",
      "[4,    39] loss: 1.06623, train_accuracy: 64.26\n",
      "[4,    40] loss: 1.03040, train_accuracy: 61.72\n",
      "[4,    41] loss: 1.06740, train_accuracy: 61.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,    42] loss: 1.03705, train_accuracy: 62.89\n",
      "[4,    43] loss: 1.07753, train_accuracy: 63.28\n",
      "[4,    44] loss: 1.02250, train_accuracy: 63.87\n",
      "[4,    45] loss: 0.98614, train_accuracy: 65.43\n",
      "[4,    46] loss: 0.99279, train_accuracy: 66.60\n",
      "[4,    47] loss: 0.95851, train_accuracy: 65.23\n",
      "[4,    48] loss: 1.06056, train_accuracy: 64.84\n",
      "[4,    49] loss: 1.00350, train_accuracy: 64.26\n",
      "[4,    50] loss: 0.94727, train_accuracy: 65.62\n",
      "[4,    51] loss: 1.05110, train_accuracy: 64.45\n",
      "[4,    52] loss: 0.99912, train_accuracy: 63.09\n",
      "[4,    53] loss: 1.02604, train_accuracy: 63.67\n",
      "[4,    54] loss: 1.04325, train_accuracy: 61.13\n",
      "[4,    55] loss: 1.05767, train_accuracy: 61.52\n",
      "[4,    56] loss: 1.04199, train_accuracy: 61.72\n",
      "[4,    57] loss: 1.01788, train_accuracy: 62.30\n",
      "[4,    58] loss: 1.06780, train_accuracy: 62.89\n",
      "[4,    59] loss: 1.04485, train_accuracy: 64.26\n",
      "[4,    60] loss: 1.05533, train_accuracy: 62.30\n",
      "[4,    61] loss: 0.97149, train_accuracy: 66.80\n",
      "[4,    62] loss: 0.99877, train_accuracy: 65.04\n",
      "[4,    63] loss: 1.09851, train_accuracy: 63.28\n",
      "[4,    64] loss: 0.99116, train_accuracy: 65.43\n",
      "[4,    65] loss: 1.07268, train_accuracy: 63.09\n",
      "[4,    66] loss: 0.99211, train_accuracy: 68.36\n",
      "[4,    67] loss: 1.05369, train_accuracy: 65.23\n",
      "[4,    68] loss: 1.05069, train_accuracy: 64.26\n",
      "[4,    69] loss: 1.00801, train_accuracy: 61.72\n",
      "[4,    70] loss: 1.13582, train_accuracy: 58.20\n",
      "[4,    71] loss: 1.07496, train_accuracy: 60.55\n",
      "[4,    72] loss: 0.98579, train_accuracy: 65.23\n",
      "[4,    73] loss: 0.98989, train_accuracy: 65.82\n",
      "[4,    74] loss: 1.07774, train_accuracy: 61.33\n",
      "[4,    75] loss: 1.02118, train_accuracy: 61.91\n",
      "[4,    76] loss: 0.98885, train_accuracy: 65.04\n",
      "[4,    77] loss: 1.04825, train_accuracy: 64.84\n",
      "[4,    78] loss: 1.09883, train_accuracy: 60.35\n",
      "[4,    79] loss: 1.09104, train_accuracy: 62.50\n",
      "[4,    80] loss: 0.95757, train_accuracy: 66.60\n",
      "[4,    81] loss: 1.00770, train_accuracy: 66.41\n",
      "[4,    82] loss: 1.06310, train_accuracy: 64.06\n",
      "[4,    83] loss: 0.89691, train_accuracy: 66.80\n",
      "[4,    84] loss: 1.02688, train_accuracy: 62.89\n",
      "[4,    85] loss: 1.09366, train_accuracy: 62.70\n",
      "[4,    86] loss: 1.02961, train_accuracy: 65.62\n",
      "[4,    87] loss: 1.02132, train_accuracy: 61.91\n",
      "[4,    88] loss: 1.08475, train_accuracy: 59.57\n",
      "[4,    89] loss: 1.00746, train_accuracy: 64.45\n",
      "[4,    90] loss: 0.99834, train_accuracy: 62.30\n",
      "[4,    91] loss: 1.01997, train_accuracy: 63.67\n",
      "[4,    92] loss: 1.11115, train_accuracy: 60.74\n",
      "[4,    93] loss: 1.07301, train_accuracy: 60.16\n",
      "[4,    94] loss: 1.06214, train_accuracy: 63.67\n",
      "[4,    95] loss: 1.07112, train_accuracy: 62.11\n",
      "[4,    96] loss: 0.98270, train_accuracy: 64.65\n",
      "[4,    97] loss: 1.06664, train_accuracy: 63.48\n",
      "[4,    98] loss: 1.01027, train_accuracy: 62.50\n",
      "duration: 11 s - train loss: 1.03389 - train accuracy: 63.58 - validation loss: 1.15 - validation accuracy: 59.11 \n",
      "[5,     1] loss: 0.90583, train_accuracy: 68.95\n",
      "[5,     2] loss: 0.94585, train_accuracy: 65.62\n",
      "[5,     3] loss: 0.92633, train_accuracy: 68.16\n",
      "[5,     4] loss: 0.95790, train_accuracy: 66.80\n",
      "[5,     5] loss: 0.91005, train_accuracy: 68.75\n",
      "[5,     6] loss: 0.93842, train_accuracy: 67.77\n",
      "[5,     7] loss: 0.96214, train_accuracy: 66.41\n",
      "[5,     8] loss: 0.90371, train_accuracy: 67.77\n",
      "[5,     9] loss: 0.97968, train_accuracy: 65.23\n",
      "[5,    10] loss: 0.92719, train_accuracy: 64.65\n",
      "[5,    11] loss: 0.92820, train_accuracy: 69.14\n",
      "[5,    12] loss: 0.89626, train_accuracy: 70.70\n",
      "[5,    13] loss: 0.95544, train_accuracy: 67.97\n",
      "[5,    14] loss: 0.97329, train_accuracy: 64.65\n",
      "[5,    15] loss: 0.94289, train_accuracy: 67.19\n",
      "[5,    16] loss: 0.94562, train_accuracy: 66.41\n",
      "[5,    17] loss: 0.95641, train_accuracy: 66.99\n",
      "[5,    18] loss: 1.02872, train_accuracy: 66.21\n",
      "[5,    19] loss: 0.99423, train_accuracy: 62.70\n",
      "[5,    20] loss: 0.98928, train_accuracy: 63.87\n",
      "[5,    21] loss: 0.92717, train_accuracy: 68.16\n",
      "[5,    22] loss: 0.90076, train_accuracy: 68.36\n",
      "[5,    23] loss: 0.94375, train_accuracy: 67.19\n",
      "[5,    24] loss: 0.90719, train_accuracy: 67.58\n",
      "[5,    25] loss: 0.92312, train_accuracy: 67.38\n",
      "[5,    26] loss: 0.88703, train_accuracy: 67.77\n",
      "[5,    27] loss: 0.85310, train_accuracy: 70.12\n",
      "[5,    28] loss: 0.97711, train_accuracy: 65.62\n",
      "[5,    29] loss: 0.95383, train_accuracy: 66.21\n",
      "[5,    30] loss: 0.94370, train_accuracy: 67.97\n",
      "[5,    31] loss: 0.98871, train_accuracy: 66.60\n",
      "[5,    32] loss: 0.92744, train_accuracy: 66.21\n",
      "[5,    33] loss: 1.08100, train_accuracy: 62.70\n",
      "[5,    34] loss: 0.93610, train_accuracy: 69.92\n",
      "[5,    35] loss: 0.90376, train_accuracy: 68.75\n",
      "[5,    36] loss: 0.99718, train_accuracy: 65.62\n",
      "[5,    37] loss: 0.95565, train_accuracy: 64.26\n",
      "[5,    38] loss: 0.91601, train_accuracy: 68.36\n",
      "[5,    39] loss: 0.86065, train_accuracy: 68.95\n",
      "[5,    40] loss: 0.98888, train_accuracy: 64.84\n",
      "[5,    41] loss: 0.97626, train_accuracy: 69.14\n",
      "[5,    42] loss: 0.81978, train_accuracy: 71.68\n",
      "[5,    43] loss: 0.89148, train_accuracy: 68.95\n",
      "[5,    44] loss: 0.93068, train_accuracy: 65.43\n",
      "[5,    45] loss: 0.86781, train_accuracy: 67.19\n",
      "[5,    46] loss: 0.95288, train_accuracy: 67.77\n",
      "[5,    47] loss: 1.00026, train_accuracy: 65.04\n",
      "[5,    48] loss: 0.96822, train_accuracy: 67.38\n",
      "[5,    49] loss: 1.03051, train_accuracy: 64.26\n",
      "[5,    50] loss: 0.93561, train_accuracy: 68.95\n",
      "[5,    51] loss: 0.90866, train_accuracy: 68.36\n",
      "[5,    52] loss: 1.00197, train_accuracy: 66.02\n",
      "[5,    53] loss: 0.93853, train_accuracy: 67.38\n",
      "[5,    54] loss: 0.91690, train_accuracy: 68.75\n",
      "[5,    55] loss: 0.96368, train_accuracy: 64.84\n",
      "[5,    56] loss: 0.92061, train_accuracy: 66.99\n",
      "[5,    57] loss: 0.90113, train_accuracy: 68.55\n",
      "[5,    58] loss: 0.87737, train_accuracy: 69.53\n",
      "[5,    59] loss: 0.92306, train_accuracy: 67.58\n",
      "[5,    60] loss: 0.90390, train_accuracy: 70.51\n",
      "[5,    61] loss: 0.97429, train_accuracy: 63.48\n",
      "[5,    62] loss: 0.95161, train_accuracy: 68.75\n",
      "[5,    63] loss: 0.89175, train_accuracy: 70.70\n",
      "[5,    64] loss: 0.90649, train_accuracy: 67.19\n",
      "[5,    65] loss: 0.94803, train_accuracy: 67.38\n",
      "[5,    66] loss: 0.98182, train_accuracy: 63.67\n",
      "[5,    67] loss: 1.00346, train_accuracy: 65.23\n",
      "[5,    68] loss: 0.94615, train_accuracy: 67.77\n",
      "[5,    69] loss: 0.93867, train_accuracy: 64.45\n",
      "[5,    70] loss: 0.96431, train_accuracy: 67.38\n",
      "[5,    71] loss: 0.97137, train_accuracy: 66.41\n",
      "[5,    72] loss: 0.97554, train_accuracy: 67.38\n",
      "[5,    73] loss: 0.87614, train_accuracy: 70.90\n",
      "[5,    74] loss: 0.94520, train_accuracy: 69.73\n",
      "[5,    75] loss: 1.01256, train_accuracy: 66.41\n",
      "[5,    76] loss: 0.94604, train_accuracy: 66.99\n",
      "[5,    77] loss: 0.90083, train_accuracy: 67.38\n",
      "[5,    78] loss: 0.94644, train_accuracy: 65.04\n",
      "[5,    79] loss: 0.90465, train_accuracy: 65.23\n",
      "[5,    80] loss: 0.89913, train_accuracy: 69.53\n",
      "[5,    81] loss: 1.02750, train_accuracy: 63.48\n",
      "[5,    82] loss: 0.89860, train_accuracy: 68.36\n",
      "[5,    83] loss: 0.97841, train_accuracy: 65.04\n",
      "[5,    84] loss: 0.96175, train_accuracy: 67.19\n",
      "[5,    85] loss: 0.95168, train_accuracy: 66.41\n",
      "[5,    86] loss: 0.95025, train_accuracy: 66.21\n",
      "[5,    87] loss: 0.99331, train_accuracy: 63.48\n",
      "[5,    88] loss: 0.98341, train_accuracy: 63.28\n",
      "[5,    89] loss: 1.01289, train_accuracy: 64.45\n",
      "[5,    90] loss: 0.85727, train_accuracy: 69.53\n",
      "[5,    91] loss: 0.99501, train_accuracy: 65.82\n",
      "[5,    92] loss: 0.85232, train_accuracy: 68.95\n",
      "[5,    93] loss: 0.94634, train_accuracy: 65.23\n",
      "[5,    94] loss: 0.94277, train_accuracy: 68.16\n",
      "[5,    95] loss: 0.89436, train_accuracy: 69.53\n",
      "[5,    96] loss: 0.92261, train_accuracy: 67.19\n",
      "[5,    97] loss: 0.96711, train_accuracy: 68.55\n",
      "[5,    98] loss: 1.00336, train_accuracy: 63.69\n",
      "duration: 11 s - train loss: 0.94278 - train accuracy: 67.02 - validation loss: 1.13 - validation accuracy: 60.53 \n",
      "[6,     1] loss: 0.83875, train_accuracy: 71.68\n",
      "[6,     2] loss: 0.86823, train_accuracy: 69.73\n",
      "[6,     3] loss: 0.75830, train_accuracy: 74.02\n",
      "[6,     4] loss: 0.86179, train_accuracy: 72.27\n",
      "[6,     5] loss: 0.81990, train_accuracy: 68.95\n",
      "[6,     6] loss: 0.79455, train_accuracy: 73.24\n",
      "[6,     7] loss: 0.88060, train_accuracy: 67.97\n",
      "[6,     8] loss: 0.78174, train_accuracy: 74.41\n",
      "[6,     9] loss: 0.79890, train_accuracy: 71.48\n",
      "[6,    10] loss: 0.78995, train_accuracy: 72.46\n",
      "[6,    11] loss: 0.89155, train_accuracy: 68.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    12] loss: 0.87107, train_accuracy: 70.51\n",
      "[6,    13] loss: 0.89852, train_accuracy: 67.19\n",
      "[6,    14] loss: 0.86627, train_accuracy: 70.90\n",
      "[6,    15] loss: 0.84164, train_accuracy: 70.70\n",
      "[6,    16] loss: 0.79746, train_accuracy: 71.09\n",
      "[6,    17] loss: 0.83180, train_accuracy: 68.55\n",
      "[6,    18] loss: 0.80388, train_accuracy: 71.29\n",
      "[6,    19] loss: 0.92591, train_accuracy: 66.80\n",
      "[6,    20] loss: 0.86026, train_accuracy: 68.36\n",
      "[6,    21] loss: 0.85710, train_accuracy: 70.12\n",
      "[6,    22] loss: 0.77981, train_accuracy: 71.68\n",
      "[6,    23] loss: 0.96540, train_accuracy: 66.60\n",
      "[6,    24] loss: 0.88558, train_accuracy: 68.55\n",
      "[6,    25] loss: 0.86126, train_accuracy: 70.51\n",
      "[6,    26] loss: 0.81775, train_accuracy: 73.24\n",
      "[6,    27] loss: 0.80494, train_accuracy: 70.51\n",
      "[6,    28] loss: 0.90528, train_accuracy: 69.34\n",
      "[6,    29] loss: 0.90150, train_accuracy: 68.36\n",
      "[6,    30] loss: 0.85550, train_accuracy: 70.31\n",
      "[6,    31] loss: 0.83009, train_accuracy: 73.05\n",
      "[6,    32] loss: 0.88334, train_accuracy: 68.95\n",
      "[6,    33] loss: 0.80941, train_accuracy: 73.63\n",
      "[6,    34] loss: 0.88123, train_accuracy: 69.34\n",
      "[6,    35] loss: 0.83143, train_accuracy: 71.48\n",
      "[6,    36] loss: 0.90004, train_accuracy: 69.73\n",
      "[6,    37] loss: 0.84829, train_accuracy: 70.12\n",
      "[6,    38] loss: 0.92512, train_accuracy: 67.38\n",
      "[6,    39] loss: 0.77029, train_accuracy: 72.66\n",
      "[6,    40] loss: 0.90699, train_accuracy: 69.14\n",
      "[6,    41] loss: 0.88862, train_accuracy: 68.95\n",
      "[6,    42] loss: 0.79697, train_accuracy: 72.46\n",
      "[6,    43] loss: 0.91887, train_accuracy: 68.55\n",
      "[6,    44] loss: 0.84560, train_accuracy: 67.97\n",
      "[6,    45] loss: 0.88309, train_accuracy: 69.14\n",
      "[6,    46] loss: 0.84286, train_accuracy: 68.55\n",
      "[6,    47] loss: 0.89873, train_accuracy: 66.99\n",
      "[6,    48] loss: 0.86063, train_accuracy: 70.12\n",
      "[6,    49] loss: 0.82278, train_accuracy: 73.63\n",
      "[6,    50] loss: 0.77399, train_accuracy: 74.22\n",
      "[6,    51] loss: 0.88415, train_accuracy: 67.97\n",
      "[6,    52] loss: 0.89778, train_accuracy: 69.34\n",
      "[6,    53] loss: 0.90452, train_accuracy: 69.92\n",
      "[6,    54] loss: 0.76280, train_accuracy: 72.66\n",
      "[6,    55] loss: 0.99298, train_accuracy: 65.82\n",
      "[6,    56] loss: 0.89358, train_accuracy: 68.16\n",
      "[6,    57] loss: 0.79943, train_accuracy: 72.07\n",
      "[6,    58] loss: 0.82264, train_accuracy: 72.27\n",
      "[6,    59] loss: 0.82375, train_accuracy: 72.66\n",
      "[6,    60] loss: 0.85470, train_accuracy: 69.73\n",
      "[6,    61] loss: 0.79761, train_accuracy: 71.88\n",
      "[6,    62] loss: 0.87426, train_accuracy: 69.73\n",
      "[6,    63] loss: 0.85613, train_accuracy: 70.90\n",
      "[6,    64] loss: 0.94949, train_accuracy: 66.99\n",
      "[6,    65] loss: 0.86426, train_accuracy: 68.75\n",
      "[6,    66] loss: 0.91603, train_accuracy: 68.16\n",
      "[6,    67] loss: 0.83409, train_accuracy: 70.90\n",
      "[6,    68] loss: 0.87615, train_accuracy: 69.14\n",
      "[6,    69] loss: 0.97217, train_accuracy: 67.38\n",
      "[6,    70] loss: 0.84469, train_accuracy: 71.68\n",
      "[6,    71] loss: 0.84658, train_accuracy: 68.75\n",
      "[6,    72] loss: 0.91015, train_accuracy: 66.60\n",
      "[6,    73] loss: 0.92242, train_accuracy: 67.77\n",
      "[6,    74] loss: 0.85432, train_accuracy: 72.66\n",
      "[6,    75] loss: 0.89711, train_accuracy: 69.14\n",
      "[6,    76] loss: 0.85260, train_accuracy: 66.80\n",
      "[6,    77] loss: 0.80122, train_accuracy: 71.68\n",
      "[6,    78] loss: 0.89105, train_accuracy: 66.99\n",
      "[6,    79] loss: 0.98498, train_accuracy: 66.60\n",
      "[6,    80] loss: 0.91436, train_accuracy: 69.34\n",
      "[6,    81] loss: 0.81963, train_accuracy: 72.07\n",
      "[6,    82] loss: 0.86192, train_accuracy: 70.51\n",
      "[6,    83] loss: 0.86744, train_accuracy: 70.90\n",
      "[6,    84] loss: 1.01605, train_accuracy: 63.28\n",
      "[6,    85] loss: 0.84426, train_accuracy: 70.12\n",
      "[6,    86] loss: 0.89420, train_accuracy: 65.04\n",
      "[6,    87] loss: 0.89301, train_accuracy: 69.92\n",
      "[6,    88] loss: 0.89472, train_accuracy: 67.77\n",
      "[6,    89] loss: 0.82077, train_accuracy: 71.29\n",
      "[6,    90] loss: 0.87073, train_accuracy: 71.29\n",
      "[6,    91] loss: 0.96426, train_accuracy: 65.62\n",
      "[6,    92] loss: 0.86692, train_accuracy: 70.51\n",
      "[6,    93] loss: 0.94413, train_accuracy: 67.38\n",
      "[6,    94] loss: 0.85251, train_accuracy: 68.36\n",
      "[6,    95] loss: 0.87398, train_accuracy: 70.31\n",
      "[6,    96] loss: 0.90097, train_accuracy: 66.60\n",
      "[6,    97] loss: 0.87456, train_accuracy: 69.73\n",
      "[6,    98] loss: 0.85400, train_accuracy: 69.94\n",
      "duration: 12 s - train loss: 0.86473 - train accuracy: 69.78 - validation loss: 1.10 - validation accuracy: 61.91 \n",
      "[7,     1] loss: 0.70418, train_accuracy: 75.59\n",
      "[7,     2] loss: 0.79213, train_accuracy: 70.51\n",
      "[7,     3] loss: 0.81721, train_accuracy: 74.80\n",
      "[7,     4] loss: 0.70862, train_accuracy: 76.37\n",
      "[7,     5] loss: 0.80574, train_accuracy: 72.85\n",
      "[7,     6] loss: 0.78683, train_accuracy: 72.66\n",
      "[7,     7] loss: 0.79164, train_accuracy: 71.09\n",
      "[7,     8] loss: 0.72689, train_accuracy: 74.22\n",
      "[7,     9] loss: 0.72078, train_accuracy: 76.76\n",
      "[7,    10] loss: 0.84426, train_accuracy: 72.07\n",
      "[7,    11] loss: 0.76034, train_accuracy: 75.39\n",
      "[7,    12] loss: 0.74970, train_accuracy: 73.44\n",
      "[7,    13] loss: 0.77377, train_accuracy: 73.05\n",
      "[7,    14] loss: 0.65263, train_accuracy: 78.12\n",
      "[7,    15] loss: 0.75326, train_accuracy: 72.85\n",
      "[7,    16] loss: 0.85555, train_accuracy: 70.90\n",
      "[7,    17] loss: 0.81484, train_accuracy: 70.51\n",
      "[7,    18] loss: 0.78592, train_accuracy: 71.68\n",
      "[7,    19] loss: 0.71733, train_accuracy: 76.76\n",
      "[7,    20] loss: 0.82392, train_accuracy: 72.46\n",
      "[7,    21] loss: 0.77507, train_accuracy: 71.29\n",
      "[7,    22] loss: 0.80621, train_accuracy: 72.07\n",
      "[7,    23] loss: 0.85759, train_accuracy: 69.34\n",
      "[7,    24] loss: 0.77324, train_accuracy: 73.83\n",
      "[7,    25] loss: 0.82941, train_accuracy: 70.70\n",
      "[7,    26] loss: 0.78723, train_accuracy: 72.07\n",
      "[7,    27] loss: 0.79267, train_accuracy: 73.24\n",
      "[7,    28] loss: 0.84347, train_accuracy: 70.51\n",
      "[7,    29] loss: 0.78175, train_accuracy: 74.80\n",
      "[7,    30] loss: 0.77546, train_accuracy: 73.24\n",
      "[7,    31] loss: 0.80039, train_accuracy: 72.85\n",
      "[7,    32] loss: 0.81237, train_accuracy: 73.24\n",
      "[7,    33] loss: 0.79269, train_accuracy: 73.24\n",
      "[7,    34] loss: 0.75645, train_accuracy: 72.27\n",
      "[7,    35] loss: 0.80445, train_accuracy: 72.07\n",
      "[7,    36] loss: 0.80906, train_accuracy: 69.92\n",
      "[7,    37] loss: 0.74986, train_accuracy: 73.63\n",
      "[7,    38] loss: 0.75662, train_accuracy: 76.56\n",
      "[7,    39] loss: 0.84859, train_accuracy: 69.92\n",
      "[7,    40] loss: 0.74133, train_accuracy: 75.98\n",
      "[7,    41] loss: 0.81441, train_accuracy: 72.85\n",
      "[7,    42] loss: 0.88967, train_accuracy: 69.92\n",
      "[7,    43] loss: 0.79201, train_accuracy: 71.88\n",
      "[7,    44] loss: 0.79393, train_accuracy: 72.66\n",
      "[7,    45] loss: 0.79383, train_accuracy: 73.44\n",
      "[7,    46] loss: 0.82132, train_accuracy: 70.12\n",
      "[7,    47] loss: 0.81054, train_accuracy: 69.34\n",
      "[7,    48] loss: 0.81510, train_accuracy: 70.31\n",
      "[7,    49] loss: 0.77701, train_accuracy: 74.02\n",
      "[7,    50] loss: 0.77359, train_accuracy: 74.02\n",
      "[7,    51] loss: 0.81609, train_accuracy: 69.92\n",
      "[7,    52] loss: 0.73927, train_accuracy: 74.02\n",
      "[7,    53] loss: 0.81676, train_accuracy: 70.90\n",
      "[7,    54] loss: 0.79088, train_accuracy: 71.48\n",
      "[7,    55] loss: 0.80112, train_accuracy: 72.07\n",
      "[7,    56] loss: 0.75064, train_accuracy: 74.02\n",
      "[7,    57] loss: 0.74330, train_accuracy: 72.85\n",
      "[7,    58] loss: 0.87583, train_accuracy: 68.95\n",
      "[7,    59] loss: 0.83281, train_accuracy: 71.68\n",
      "[7,    60] loss: 0.86608, train_accuracy: 70.90\n",
      "[7,    61] loss: 0.78831, train_accuracy: 72.66\n",
      "[7,    62] loss: 0.76014, train_accuracy: 72.85\n",
      "[7,    63] loss: 0.81038, train_accuracy: 72.27\n",
      "[7,    64] loss: 0.84259, train_accuracy: 70.90\n",
      "[7,    65] loss: 0.80161, train_accuracy: 71.09\n",
      "[7,    66] loss: 0.71482, train_accuracy: 74.41\n",
      "[7,    67] loss: 0.84300, train_accuracy: 71.48\n",
      "[7,    68] loss: 0.88053, train_accuracy: 69.53\n",
      "[7,    69] loss: 0.76959, train_accuracy: 73.24\n",
      "[7,    70] loss: 0.88224, train_accuracy: 66.80\n",
      "[7,    71] loss: 0.84281, train_accuracy: 71.88\n",
      "[7,    72] loss: 0.79794, train_accuracy: 71.29\n",
      "[7,    73] loss: 0.75275, train_accuracy: 73.24\n",
      "[7,    74] loss: 0.73642, train_accuracy: 75.39\n",
      "[7,    75] loss: 0.86304, train_accuracy: 70.12\n",
      "[7,    76] loss: 0.80666, train_accuracy: 72.66\n",
      "[7,    77] loss: 0.77459, train_accuracy: 71.29\n",
      "[7,    78] loss: 0.80652, train_accuracy: 71.29\n",
      "[7,    79] loss: 0.78560, train_accuracy: 71.29\n",
      "[7,    80] loss: 0.84601, train_accuracy: 69.92\n",
      "[7,    81] loss: 0.75658, train_accuracy: 73.63\n",
      "[7,    82] loss: 0.83913, train_accuracy: 70.70\n",
      "[7,    83] loss: 0.78485, train_accuracy: 72.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,    84] loss: 0.80167, train_accuracy: 72.07\n",
      "[7,    85] loss: 0.89240, train_accuracy: 67.97\n",
      "[7,    86] loss: 0.87248, train_accuracy: 70.12\n",
      "[7,    87] loss: 0.78617, train_accuracy: 73.83\n",
      "[7,    88] loss: 0.77728, train_accuracy: 74.02\n",
      "[7,    89] loss: 0.78611, train_accuracy: 70.12\n",
      "[7,    90] loss: 0.77112, train_accuracy: 73.44\n",
      "[7,    91] loss: 0.73884, train_accuracy: 72.66\n",
      "[7,    92] loss: 0.80555, train_accuracy: 68.55\n",
      "[7,    93] loss: 0.89909, train_accuracy: 66.99\n",
      "[7,    94] loss: 0.80103, train_accuracy: 73.63\n",
      "[7,    95] loss: 0.81962, train_accuracy: 71.68\n",
      "[7,    96] loss: 0.84272, train_accuracy: 68.55\n",
      "[7,    97] loss: 0.85348, train_accuracy: 71.09\n",
      "[7,    98] loss: 0.89267, train_accuracy: 69.94\n",
      "duration: 11 s - train loss: 0.79816 - train accuracy: 72.18 - validation loss: 1.09 - validation accuracy: 62.13 \n",
      "[8,     1] loss: 0.73178, train_accuracy: 76.37\n",
      "[8,     2] loss: 0.75952, train_accuracy: 72.85\n",
      "[8,     3] loss: 0.70229, train_accuracy: 75.59\n",
      "[8,     4] loss: 0.75414, train_accuracy: 76.37\n",
      "[8,     5] loss: 0.70443, train_accuracy: 75.59\n",
      "[8,     6] loss: 0.62055, train_accuracy: 80.08\n",
      "[8,     7] loss: 0.69760, train_accuracy: 76.76\n",
      "[8,     8] loss: 0.75506, train_accuracy: 73.24\n",
      "[8,     9] loss: 0.64892, train_accuracy: 79.49\n",
      "[8,    10] loss: 0.66950, train_accuracy: 76.17\n",
      "[8,    11] loss: 0.67463, train_accuracy: 76.37\n",
      "[8,    12] loss: 0.67981, train_accuracy: 75.78\n",
      "[8,    13] loss: 0.69780, train_accuracy: 74.80\n",
      "[8,    14] loss: 0.65311, train_accuracy: 76.37\n",
      "[8,    15] loss: 0.69492, train_accuracy: 75.59\n",
      "[8,    16] loss: 0.73778, train_accuracy: 73.63\n",
      "[8,    17] loss: 0.67093, train_accuracy: 74.80\n",
      "[8,    18] loss: 0.69298, train_accuracy: 76.17\n",
      "[8,    19] loss: 0.69349, train_accuracy: 76.17\n",
      "[8,    20] loss: 0.63833, train_accuracy: 77.34\n",
      "[8,    21] loss: 0.66963, train_accuracy: 78.12\n",
      "[8,    22] loss: 0.70787, train_accuracy: 76.17\n",
      "[8,    23] loss: 0.73930, train_accuracy: 73.24\n",
      "[8,    24] loss: 0.69143, train_accuracy: 76.76\n",
      "[8,    25] loss: 0.71496, train_accuracy: 77.34\n",
      "[8,    26] loss: 0.67401, train_accuracy: 77.15\n",
      "[8,    27] loss: 0.75480, train_accuracy: 74.22\n",
      "[8,    28] loss: 0.70299, train_accuracy: 76.37\n",
      "[8,    29] loss: 0.74722, train_accuracy: 72.27\n",
      "[8,    30] loss: 0.65602, train_accuracy: 77.15\n",
      "[8,    31] loss: 0.68922, train_accuracy: 77.54\n",
      "[8,    32] loss: 0.70466, train_accuracy: 74.41\n",
      "[8,    33] loss: 0.70228, train_accuracy: 76.17\n",
      "[8,    34] loss: 0.77737, train_accuracy: 75.78\n",
      "[8,    35] loss: 0.74357, train_accuracy: 74.80\n",
      "[8,    36] loss: 0.70370, train_accuracy: 75.98\n",
      "[8,    37] loss: 0.71338, train_accuracy: 75.59\n",
      "[8,    38] loss: 0.71071, train_accuracy: 76.37\n",
      "[8,    39] loss: 0.72885, train_accuracy: 73.24\n",
      "[8,    40] loss: 0.66957, train_accuracy: 76.76\n",
      "[8,    41] loss: 0.75855, train_accuracy: 73.24\n",
      "[8,    42] loss: 0.67935, train_accuracy: 76.56\n",
      "[8,    43] loss: 0.73306, train_accuracy: 74.02\n",
      "[8,    44] loss: 0.72807, train_accuracy: 74.80\n",
      "[8,    45] loss: 0.74954, train_accuracy: 72.66\n",
      "[8,    46] loss: 0.73141, train_accuracy: 74.22\n",
      "[8,    47] loss: 0.75809, train_accuracy: 73.44\n",
      "[8,    48] loss: 0.77659, train_accuracy: 71.48\n",
      "[8,    49] loss: 0.77242, train_accuracy: 72.27\n",
      "[8,    50] loss: 0.72860, train_accuracy: 73.83\n",
      "[8,    51] loss: 0.76730, train_accuracy: 73.05\n",
      "[8,    52] loss: 0.70384, train_accuracy: 76.56\n",
      "[8,    53] loss: 0.79350, train_accuracy: 72.27\n",
      "[8,    54] loss: 0.74286, train_accuracy: 76.37\n",
      "[8,    55] loss: 0.72031, train_accuracy: 75.78\n",
      "[8,    56] loss: 0.68831, train_accuracy: 76.76\n",
      "[8,    57] loss: 0.77244, train_accuracy: 72.85\n",
      "[8,    58] loss: 0.81439, train_accuracy: 72.27\n",
      "[8,    59] loss: 0.76214, train_accuracy: 72.27\n",
      "[8,    60] loss: 0.76254, train_accuracy: 74.22\n",
      "[8,    61] loss: 0.71048, train_accuracy: 76.37\n",
      "[8,    62] loss: 0.79691, train_accuracy: 71.29\n",
      "[8,    63] loss: 0.75183, train_accuracy: 74.22\n",
      "[8,    64] loss: 0.77611, train_accuracy: 72.07\n",
      "[8,    65] loss: 0.77959, train_accuracy: 72.07\n",
      "[8,    66] loss: 0.70190, train_accuracy: 76.95\n",
      "[8,    67] loss: 0.70037, train_accuracy: 77.73\n",
      "[8,    68] loss: 0.82318, train_accuracy: 69.73\n",
      "[8,    69] loss: 0.72325, train_accuracy: 73.63\n",
      "[8,    70] loss: 0.75441, train_accuracy: 74.61\n",
      "[8,    71] loss: 0.81876, train_accuracy: 71.68\n",
      "[8,    72] loss: 0.76560, train_accuracy: 72.66\n",
      "[8,    73] loss: 0.73455, train_accuracy: 73.44\n",
      "[8,    74] loss: 0.77070, train_accuracy: 70.51\n",
      "[8,    75] loss: 0.74680, train_accuracy: 74.02\n",
      "[8,    76] loss: 0.66406, train_accuracy: 76.76\n",
      "[8,    77] loss: 0.74990, train_accuracy: 74.80\n",
      "[8,    78] loss: 0.81542, train_accuracy: 70.90\n",
      "[8,    79] loss: 0.75348, train_accuracy: 73.05\n",
      "[8,    80] loss: 0.85457, train_accuracy: 68.95\n",
      "[8,    81] loss: 0.76259, train_accuracy: 72.27\n",
      "[8,    82] loss: 0.73032, train_accuracy: 74.61\n",
      "[8,    83] loss: 0.72087, train_accuracy: 73.24\n",
      "[8,    84] loss: 0.72337, train_accuracy: 74.80\n",
      "[8,    85] loss: 0.71678, train_accuracy: 74.22\n",
      "[8,    86] loss: 0.76342, train_accuracy: 73.63\n",
      "[8,    87] loss: 0.71259, train_accuracy: 76.95\n",
      "[8,    88] loss: 0.76365, train_accuracy: 75.59\n",
      "[8,    89] loss: 0.82861, train_accuracy: 71.88\n",
      "[8,    90] loss: 0.75428, train_accuracy: 74.41\n",
      "[8,    91] loss: 0.70401, train_accuracy: 75.39\n",
      "[8,    92] loss: 0.83476, train_accuracy: 69.73\n",
      "[8,    93] loss: 0.71926, train_accuracy: 76.37\n",
      "[8,    94] loss: 0.76453, train_accuracy: 71.29\n",
      "[8,    95] loss: 0.79979, train_accuracy: 74.41\n",
      "[8,    96] loss: 0.74908, train_accuracy: 73.63\n",
      "[8,    97] loss: 0.81573, train_accuracy: 71.68\n",
      "[8,    98] loss: 0.74629, train_accuracy: 69.94\n",
      "duration: 11 s - train loss: 0.73290 - train accuracy: 74.52 - validation loss: 1.09 - validation accuracy: 62.63 \n",
      "[9,     1] loss: 0.70132, train_accuracy: 75.98\n",
      "[9,     2] loss: 0.60081, train_accuracy: 80.27\n",
      "[9,     3] loss: 0.64498, train_accuracy: 78.52\n",
      "[9,     4] loss: 0.64198, train_accuracy: 77.54\n",
      "[9,     5] loss: 0.61206, train_accuracy: 80.47\n",
      "[9,     6] loss: 0.55034, train_accuracy: 82.03\n",
      "[9,     7] loss: 0.64923, train_accuracy: 78.71\n",
      "[9,     8] loss: 0.66010, train_accuracy: 77.54\n",
      "[9,     9] loss: 0.65156, train_accuracy: 76.37\n",
      "[9,    10] loss: 0.64449, train_accuracy: 78.71\n",
      "[9,    11] loss: 0.61626, train_accuracy: 77.73\n",
      "[9,    12] loss: 0.65359, train_accuracy: 77.15\n",
      "[9,    13] loss: 0.59787, train_accuracy: 78.52\n",
      "[9,    14] loss: 0.61795, train_accuracy: 80.08\n",
      "[9,    15] loss: 0.59543, train_accuracy: 79.30\n",
      "[9,    16] loss: 0.58959, train_accuracy: 80.47\n",
      "[9,    17] loss: 0.60384, train_accuracy: 79.88\n",
      "[9,    18] loss: 0.58671, train_accuracy: 81.05\n",
      "[9,    19] loss: 0.60830, train_accuracy: 79.30\n",
      "[9,    20] loss: 0.68689, train_accuracy: 77.54\n",
      "[9,    21] loss: 0.58329, train_accuracy: 79.49\n",
      "[9,    22] loss: 0.64076, train_accuracy: 77.15\n",
      "[9,    23] loss: 0.58600, train_accuracy: 81.84\n",
      "[9,    24] loss: 0.64581, train_accuracy: 79.30\n",
      "[9,    25] loss: 0.70148, train_accuracy: 74.80\n",
      "[9,    26] loss: 0.70180, train_accuracy: 76.37\n",
      "[9,    27] loss: 0.65392, train_accuracy: 77.93\n",
      "[9,    28] loss: 0.61659, train_accuracy: 78.12\n",
      "[9,    29] loss: 0.72337, train_accuracy: 75.00\n",
      "[9,    30] loss: 0.68622, train_accuracy: 75.98\n",
      "[9,    31] loss: 0.72082, train_accuracy: 74.41\n",
      "[9,    32] loss: 0.62326, train_accuracy: 78.32\n",
      "[9,    33] loss: 0.68696, train_accuracy: 78.71\n",
      "[9,    34] loss: 0.72187, train_accuracy: 73.83\n",
      "[9,    35] loss: 0.69785, train_accuracy: 75.39\n",
      "[9,    36] loss: 0.65485, train_accuracy: 77.34\n",
      "[9,    37] loss: 0.61294, train_accuracy: 78.71\n",
      "[9,    38] loss: 0.61494, train_accuracy: 77.73\n",
      "[9,    39] loss: 0.67015, train_accuracy: 77.54\n",
      "[9,    40] loss: 0.70816, train_accuracy: 75.59\n",
      "[9,    41] loss: 0.61235, train_accuracy: 77.73\n",
      "[9,    42] loss: 0.70403, train_accuracy: 76.37\n",
      "[9,    43] loss: 0.72464, train_accuracy: 76.56\n",
      "[9,    44] loss: 0.65558, train_accuracy: 78.91\n",
      "[9,    45] loss: 0.64575, train_accuracy: 77.54\n",
      "[9,    46] loss: 0.69097, train_accuracy: 76.76\n",
      "[9,    47] loss: 0.64982, train_accuracy: 76.76\n",
      "[9,    48] loss: 0.62068, train_accuracy: 78.52\n",
      "[9,    49] loss: 0.71764, train_accuracy: 75.78\n",
      "[9,    50] loss: 0.72107, train_accuracy: 76.95\n",
      "[9,    51] loss: 0.64409, train_accuracy: 78.12\n",
      "[9,    52] loss: 0.68863, train_accuracy: 76.76\n",
      "[9,    53] loss: 0.72757, train_accuracy: 72.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,    54] loss: 0.71505, train_accuracy: 75.20\n",
      "[9,    55] loss: 0.71357, train_accuracy: 74.61\n",
      "[9,    56] loss: 0.66897, train_accuracy: 75.39\n",
      "[9,    57] loss: 0.72289, train_accuracy: 76.37\n",
      "[9,    58] loss: 0.71005, train_accuracy: 74.61\n",
      "[9,    59] loss: 0.59077, train_accuracy: 81.45\n",
      "[9,    60] loss: 0.69094, train_accuracy: 74.61\n",
      "[9,    61] loss: 0.71042, train_accuracy: 74.41\n",
      "[9,    62] loss: 0.74615, train_accuracy: 73.63\n",
      "[9,    63] loss: 0.64629, train_accuracy: 76.95\n",
      "[9,    64] loss: 0.64369, train_accuracy: 79.10\n",
      "[9,    65] loss: 0.69775, train_accuracy: 76.17\n",
      "[9,    66] loss: 0.69385, train_accuracy: 78.71\n",
      "[9,    67] loss: 0.63370, train_accuracy: 77.54\n",
      "[9,    68] loss: 0.67440, train_accuracy: 75.20\n",
      "[9,    69] loss: 0.69004, train_accuracy: 76.95\n",
      "[9,    70] loss: 0.81231, train_accuracy: 73.83\n",
      "[9,    71] loss: 0.74517, train_accuracy: 75.00\n",
      "[9,    72] loss: 0.71794, train_accuracy: 74.80\n",
      "[9,    73] loss: 0.75695, train_accuracy: 75.59\n",
      "[9,    74] loss: 0.64292, train_accuracy: 76.56\n",
      "[9,    75] loss: 0.72407, train_accuracy: 76.76\n",
      "[9,    76] loss: 0.70120, train_accuracy: 76.76\n",
      "[9,    77] loss: 0.76133, train_accuracy: 71.68\n",
      "[9,    78] loss: 0.68846, train_accuracy: 75.39\n",
      "[9,    79] loss: 0.73763, train_accuracy: 73.83\n",
      "[9,    80] loss: 0.68866, train_accuracy: 74.80\n",
      "[9,    81] loss: 0.63838, train_accuracy: 78.52\n",
      "[9,    82] loss: 0.71667, train_accuracy: 75.59\n",
      "[9,    83] loss: 0.70543, train_accuracy: 74.02\n",
      "[9,    84] loss: 0.68421, train_accuracy: 74.22\n",
      "[9,    85] loss: 0.63505, train_accuracy: 75.78\n",
      "[9,    86] loss: 0.77032, train_accuracy: 73.24\n",
      "[9,    87] loss: 0.66151, train_accuracy: 73.83\n",
      "[9,    88] loss: 0.73078, train_accuracy: 74.80\n",
      "[9,    89] loss: 0.71685, train_accuracy: 75.98\n",
      "[9,    90] loss: 0.64943, train_accuracy: 78.12\n",
      "[9,    91] loss: 0.73322, train_accuracy: 73.63\n",
      "[9,    92] loss: 0.70836, train_accuracy: 75.39\n",
      "[9,    93] loss: 0.67816, train_accuracy: 75.78\n",
      "[9,    94] loss: 0.70415, train_accuracy: 78.12\n",
      "[9,    95] loss: 0.72196, train_accuracy: 72.07\n",
      "[9,    96] loss: 0.67054, train_accuracy: 75.98\n",
      "[9,    97] loss: 0.73801, train_accuracy: 74.22\n",
      "[9,    98] loss: 0.67728, train_accuracy: 75.89\n",
      "duration: 11 s - train loss: 0.67380 - train accuracy: 76.75 - validation loss: 1.11 - validation accuracy: 62.15 \n",
      "[10,     1] loss: 0.57087, train_accuracy: 80.27\n",
      "[10,     2] loss: 0.53070, train_accuracy: 80.66\n",
      "[10,     3] loss: 0.63645, train_accuracy: 78.52\n",
      "[10,     4] loss: 0.58948, train_accuracy: 81.05\n",
      "[10,     5] loss: 0.59286, train_accuracy: 82.23\n",
      "[10,     6] loss: 0.62255, train_accuracy: 78.91\n",
      "[10,     7] loss: 0.60598, train_accuracy: 79.69\n",
      "[10,     8] loss: 0.60567, train_accuracy: 80.08\n",
      "[10,     9] loss: 0.60345, train_accuracy: 80.47\n",
      "[10,    10] loss: 0.65291, train_accuracy: 77.73\n",
      "[10,    11] loss: 0.54019, train_accuracy: 83.01\n",
      "[10,    12] loss: 0.63363, train_accuracy: 79.49\n",
      "[10,    13] loss: 0.59125, train_accuracy: 79.88\n",
      "[10,    14] loss: 0.56611, train_accuracy: 81.45\n",
      "[10,    15] loss: 0.56037, train_accuracy: 81.64\n",
      "[10,    16] loss: 0.63127, train_accuracy: 78.32\n",
      "[10,    17] loss: 0.55565, train_accuracy: 82.62\n",
      "[10,    18] loss: 0.56577, train_accuracy: 80.08\n",
      "[10,    19] loss: 0.57711, train_accuracy: 80.27\n",
      "[10,    20] loss: 0.59470, train_accuracy: 79.88\n",
      "[10,    21] loss: 0.59607, train_accuracy: 79.88\n",
      "[10,    22] loss: 0.55958, train_accuracy: 80.86\n",
      "[10,    23] loss: 0.63816, train_accuracy: 76.17\n",
      "[10,    24] loss: 0.63224, train_accuracy: 79.88\n",
      "[10,    25] loss: 0.52993, train_accuracy: 80.86\n",
      "[10,    26] loss: 0.55671, train_accuracy: 80.86\n",
      "[10,    27] loss: 0.61693, train_accuracy: 78.91\n",
      "[10,    28] loss: 0.66879, train_accuracy: 76.95\n",
      "[10,    29] loss: 0.68234, train_accuracy: 75.78\n",
      "[10,    30] loss: 0.60405, train_accuracy: 76.76\n",
      "[10,    31] loss: 0.62400, train_accuracy: 77.54\n",
      "[10,    32] loss: 0.60008, train_accuracy: 80.27\n",
      "[10,    33] loss: 0.60076, train_accuracy: 80.47\n",
      "[10,    34] loss: 0.63045, train_accuracy: 78.32\n",
      "[10,    35] loss: 0.59169, train_accuracy: 79.69\n",
      "[10,    36] loss: 0.67424, train_accuracy: 78.32\n",
      "[10,    37] loss: 0.61246, train_accuracy: 78.71\n",
      "[10,    38] loss: 0.61249, train_accuracy: 78.71\n",
      "[10,    39] loss: 0.65456, train_accuracy: 75.59\n",
      "[10,    40] loss: 0.59784, train_accuracy: 78.71\n",
      "[10,    41] loss: 0.59686, train_accuracy: 79.69\n",
      "[10,    42] loss: 0.61372, train_accuracy: 78.71\n",
      "[10,    43] loss: 0.58940, train_accuracy: 79.49\n",
      "[10,    44] loss: 0.60176, train_accuracy: 78.71\n",
      "[10,    45] loss: 0.63184, train_accuracy: 77.73\n",
      "[10,    46] loss: 0.61693, train_accuracy: 78.32\n",
      "[10,    47] loss: 0.63943, train_accuracy: 77.54\n",
      "[10,    48] loss: 0.58160, train_accuracy: 79.49\n",
      "[10,    49] loss: 0.54368, train_accuracy: 81.45\n",
      "[10,    50] loss: 0.62536, train_accuracy: 78.91\n",
      "[10,    51] loss: 0.67875, train_accuracy: 75.59\n",
      "[10,    52] loss: 0.60489, train_accuracy: 81.05\n",
      "[10,    53] loss: 0.64350, train_accuracy: 76.56\n",
      "[10,    54] loss: 0.59384, train_accuracy: 80.27\n",
      "[10,    55] loss: 0.60645, train_accuracy: 77.73\n",
      "[10,    56] loss: 0.55705, train_accuracy: 81.64\n",
      "[10,    57] loss: 0.60721, train_accuracy: 77.93\n",
      "[10,    58] loss: 0.70074, train_accuracy: 77.15\n",
      "[10,    59] loss: 0.59640, train_accuracy: 78.91\n",
      "[10,    60] loss: 0.62744, train_accuracy: 78.71\n",
      "[10,    61] loss: 0.61546, train_accuracy: 78.91\n",
      "[10,    62] loss: 0.58404, train_accuracy: 78.91\n",
      "[10,    63] loss: 0.57012, train_accuracy: 79.88\n",
      "[10,    64] loss: 0.64342, train_accuracy: 77.34\n",
      "[10,    65] loss: 0.58091, train_accuracy: 79.69\n",
      "[10,    66] loss: 0.60660, train_accuracy: 78.32\n",
      "[10,    67] loss: 0.64397, train_accuracy: 75.98\n",
      "[10,    68] loss: 0.66493, train_accuracy: 76.56\n",
      "[10,    69] loss: 0.69841, train_accuracy: 74.80\n",
      "[10,    70] loss: 0.64232, train_accuracy: 77.15\n",
      "[10,    71] loss: 0.64475, train_accuracy: 76.56\n",
      "[10,    72] loss: 0.65533, train_accuracy: 75.59\n",
      "[10,    73] loss: 0.69795, train_accuracy: 74.22\n",
      "[10,    74] loss: 0.66581, train_accuracy: 75.98\n",
      "[10,    75] loss: 0.61641, train_accuracy: 79.10\n",
      "[10,    76] loss: 0.63865, train_accuracy: 78.32\n",
      "[10,    77] loss: 0.61042, train_accuracy: 77.34\n",
      "[10,    78] loss: 0.65550, train_accuracy: 77.15\n",
      "[10,    79] loss: 0.62508, train_accuracy: 78.71\n",
      "[10,    80] loss: 0.68488, train_accuracy: 76.17\n",
      "[10,    81] loss: 0.64631, train_accuracy: 78.32\n",
      "[10,    82] loss: 0.64169, train_accuracy: 79.88\n",
      "[10,    83] loss: 0.67767, train_accuracy: 74.80\n",
      "[10,    84] loss: 0.66701, train_accuracy: 75.59\n",
      "[10,    85] loss: 0.62271, train_accuracy: 79.30\n",
      "[10,    86] loss: 0.60824, train_accuracy: 77.93\n",
      "[10,    87] loss: 0.66244, train_accuracy: 76.56\n",
      "[10,    88] loss: 0.63734, train_accuracy: 79.49\n",
      "[10,    89] loss: 0.64677, train_accuracy: 77.54\n",
      "[10,    90] loss: 0.62294, train_accuracy: 77.93\n",
      "[10,    91] loss: 0.66963, train_accuracy: 75.59\n",
      "[10,    92] loss: 0.62822, train_accuracy: 77.34\n",
      "[10,    93] loss: 0.61883, train_accuracy: 78.32\n",
      "[10,    94] loss: 0.69985, train_accuracy: 77.93\n",
      "[10,    95] loss: 0.65276, train_accuracy: 79.10\n",
      "[10,    96] loss: 0.68184, train_accuracy: 76.76\n",
      "[10,    97] loss: 0.60872, train_accuracy: 77.54\n",
      "[10,    98] loss: 0.59060, train_accuracy: 76.79\n",
      "duration: 11 s - train loss: 0.61934 - train accuracy: 78.56 - validation loss: 1.12 - validation accuracy: 63.15 \n",
      "[11,     1] loss: 0.50954, train_accuracy: 84.77\n",
      "[11,     2] loss: 0.51467, train_accuracy: 84.96\n",
      "[11,     3] loss: 0.48824, train_accuracy: 83.20\n",
      "[11,     4] loss: 0.48978, train_accuracy: 81.25\n",
      "[11,     5] loss: 0.56651, train_accuracy: 80.47\n",
      "[11,     6] loss: 0.47922, train_accuracy: 83.40\n",
      "[11,     7] loss: 0.50574, train_accuracy: 82.81\n",
      "[11,     8] loss: 0.53158, train_accuracy: 82.62\n",
      "[11,     9] loss: 0.55364, train_accuracy: 81.25\n",
      "[11,    10] loss: 0.51064, train_accuracy: 82.42\n",
      "[11,    11] loss: 0.48361, train_accuracy: 83.98\n",
      "[11,    12] loss: 0.51690, train_accuracy: 82.81\n",
      "[11,    13] loss: 0.55980, train_accuracy: 81.45\n",
      "[11,    14] loss: 0.54695, train_accuracy: 81.25\n",
      "[11,    15] loss: 0.60629, train_accuracy: 77.73\n",
      "[11,    16] loss: 0.48333, train_accuracy: 84.38\n",
      "[11,    17] loss: 0.58863, train_accuracy: 80.08\n",
      "[11,    18] loss: 0.55739, train_accuracy: 82.23\n",
      "[11,    19] loss: 0.50789, train_accuracy: 82.62\n",
      "[11,    20] loss: 0.53296, train_accuracy: 81.84\n",
      "[11,    21] loss: 0.53192, train_accuracy: 83.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,    22] loss: 0.52438, train_accuracy: 83.20\n",
      "[11,    23] loss: 0.61501, train_accuracy: 80.08\n",
      "[11,    24] loss: 0.51271, train_accuracy: 81.64\n",
      "[11,    25] loss: 0.58019, train_accuracy: 80.47\n",
      "[11,    26] loss: 0.49126, train_accuracy: 83.20\n",
      "[11,    27] loss: 0.50594, train_accuracy: 83.01\n",
      "[11,    28] loss: 0.54975, train_accuracy: 82.81\n",
      "[11,    29] loss: 0.55544, train_accuracy: 82.81\n",
      "[11,    30] loss: 0.58013, train_accuracy: 80.47\n",
      "[11,    31] loss: 0.53824, train_accuracy: 82.62\n",
      "[11,    32] loss: 0.54523, train_accuracy: 81.45\n",
      "[11,    33] loss: 0.55015, train_accuracy: 81.84\n",
      "[11,    34] loss: 0.53555, train_accuracy: 83.01\n",
      "[11,    35] loss: 0.57592, train_accuracy: 79.88\n",
      "[11,    36] loss: 0.55251, train_accuracy: 82.42\n",
      "[11,    37] loss: 0.54338, train_accuracy: 80.27\n",
      "[11,    38] loss: 0.56183, train_accuracy: 82.62\n",
      "[11,    39] loss: 0.54718, train_accuracy: 80.66\n",
      "[11,    40] loss: 0.53383, train_accuracy: 80.47\n",
      "[11,    41] loss: 0.52785, train_accuracy: 80.86\n",
      "[11,    42] loss: 0.57798, train_accuracy: 80.47\n",
      "[11,    43] loss: 0.58112, train_accuracy: 79.10\n",
      "[11,    44] loss: 0.53366, train_accuracy: 82.03\n",
      "[11,    45] loss: 0.65605, train_accuracy: 77.54\n",
      "[11,    46] loss: 0.55007, train_accuracy: 81.64\n",
      "[11,    47] loss: 0.51640, train_accuracy: 82.42\n",
      "[11,    48] loss: 0.52407, train_accuracy: 80.66\n",
      "[11,    49] loss: 0.60185, train_accuracy: 78.52\n",
      "[11,    50] loss: 0.60135, train_accuracy: 80.47\n",
      "[11,    51] loss: 0.48440, train_accuracy: 82.42\n",
      "[11,    52] loss: 0.53541, train_accuracy: 81.45\n",
      "[11,    53] loss: 0.51780, train_accuracy: 82.81\n",
      "[11,    54] loss: 0.56803, train_accuracy: 79.49\n",
      "[11,    55] loss: 0.58751, train_accuracy: 81.45\n",
      "[11,    56] loss: 0.57572, train_accuracy: 80.66\n",
      "[11,    57] loss: 0.55058, train_accuracy: 82.03\n",
      "[11,    58] loss: 0.51241, train_accuracy: 82.42\n",
      "[11,    59] loss: 0.56710, train_accuracy: 81.45\n",
      "[11,    60] loss: 0.56691, train_accuracy: 81.25\n",
      "[11,    61] loss: 0.60590, train_accuracy: 82.03\n",
      "[11,    62] loss: 0.59907, train_accuracy: 79.69\n",
      "[11,    63] loss: 0.61636, train_accuracy: 79.10\n",
      "[11,    64] loss: 0.61854, train_accuracy: 77.34\n",
      "[11,    65] loss: 0.61388, train_accuracy: 78.12\n",
      "[11,    66] loss: 0.60373, train_accuracy: 79.69\n",
      "[11,    67] loss: 0.49995, train_accuracy: 82.81\n",
      "[11,    68] loss: 0.56794, train_accuracy: 81.05\n",
      "[11,    69] loss: 0.63340, train_accuracy: 74.61\n",
      "[11,    70] loss: 0.57883, train_accuracy: 79.88\n",
      "[11,    71] loss: 0.60400, train_accuracy: 79.88\n",
      "[11,    72] loss: 0.64373, train_accuracy: 77.93\n",
      "[11,    73] loss: 0.58333, train_accuracy: 79.88\n",
      "[11,    74] loss: 0.58018, train_accuracy: 79.10\n",
      "[11,    75] loss: 0.50928, train_accuracy: 83.40\n",
      "[11,    76] loss: 0.54636, train_accuracy: 80.47\n",
      "[11,    77] loss: 0.61470, train_accuracy: 78.32\n",
      "[11,    78] loss: 0.47913, train_accuracy: 85.94\n",
      "[11,    79] loss: 0.61812, train_accuracy: 79.88\n",
      "[11,    80] loss: 0.62101, train_accuracy: 77.73\n",
      "[11,    81] loss: 0.57682, train_accuracy: 81.45\n",
      "[11,    82] loss: 0.63657, train_accuracy: 80.86\n",
      "[11,    83] loss: 0.65742, train_accuracy: 75.78\n",
      "[11,    84] loss: 0.53884, train_accuracy: 81.05\n",
      "[11,    85] loss: 0.64559, train_accuracy: 75.20\n",
      "[11,    86] loss: 0.59879, train_accuracy: 80.86\n",
      "[11,    87] loss: 0.59568, train_accuracy: 79.10\n",
      "[11,    88] loss: 0.56250, train_accuracy: 80.08\n",
      "[11,    89] loss: 0.61005, train_accuracy: 80.08\n",
      "[11,    90] loss: 0.61785, train_accuracy: 80.86\n",
      "[11,    91] loss: 0.55277, train_accuracy: 80.66\n",
      "[11,    92] loss: 0.59792, train_accuracy: 79.49\n",
      "[11,    93] loss: 0.61703, train_accuracy: 78.91\n",
      "[11,    94] loss: 0.66638, train_accuracy: 77.15\n",
      "[11,    95] loss: 0.59082, train_accuracy: 77.93\n",
      "[11,    96] loss: 0.60241, train_accuracy: 77.15\n",
      "[11,    97] loss: 0.61544, train_accuracy: 78.12\n",
      "[11,    98] loss: 0.60201, train_accuracy: 77.68\n",
      "duration: 11 s - train loss: 0.56349 - train accuracy: 80.82 - validation loss: 1.15 - validation accuracy: 62.38 \n",
      "[12,     1] loss: 0.43687, train_accuracy: 83.79\n",
      "[12,     2] loss: 0.50132, train_accuracy: 82.62\n",
      "[12,     3] loss: 0.50580, train_accuracy: 82.81\n",
      "[12,     4] loss: 0.50252, train_accuracy: 81.84\n",
      "[12,     5] loss: 0.47667, train_accuracy: 84.18\n",
      "[12,     6] loss: 0.44299, train_accuracy: 84.96\n",
      "[12,     7] loss: 0.50498, train_accuracy: 83.20\n",
      "[12,     8] loss: 0.42541, train_accuracy: 86.72\n",
      "[12,     9] loss: 0.45235, train_accuracy: 84.96\n",
      "[12,    10] loss: 0.53818, train_accuracy: 82.42\n",
      "[12,    11] loss: 0.44615, train_accuracy: 86.33\n",
      "[12,    12] loss: 0.47333, train_accuracy: 83.20\n",
      "[12,    13] loss: 0.47416, train_accuracy: 82.42\n",
      "[12,    14] loss: 0.59195, train_accuracy: 79.69\n",
      "[12,    15] loss: 0.45398, train_accuracy: 85.16\n",
      "[12,    16] loss: 0.48633, train_accuracy: 83.20\n",
      "[12,    17] loss: 0.53703, train_accuracy: 83.40\n",
      "[12,    18] loss: 0.42924, train_accuracy: 87.50\n",
      "[12,    19] loss: 0.49116, train_accuracy: 83.20\n",
      "[12,    20] loss: 0.46343, train_accuracy: 84.57\n",
      "[12,    21] loss: 0.46722, train_accuracy: 83.98\n",
      "[12,    22] loss: 0.47706, train_accuracy: 83.98\n",
      "[12,    23] loss: 0.52273, train_accuracy: 83.20\n",
      "[12,    24] loss: 0.50233, train_accuracy: 82.81\n",
      "[12,    25] loss: 0.40091, train_accuracy: 87.70\n",
      "[12,    26] loss: 0.48380, train_accuracy: 84.38\n",
      "[12,    27] loss: 0.52721, train_accuracy: 80.66\n",
      "[12,    28] loss: 0.50918, train_accuracy: 82.03\n",
      "[12,    29] loss: 0.48419, train_accuracy: 83.40\n",
      "[12,    30] loss: 0.44772, train_accuracy: 83.59\n",
      "[12,    31] loss: 0.46019, train_accuracy: 83.79\n",
      "[12,    32] loss: 0.50172, train_accuracy: 83.40\n",
      "[12,    33] loss: 0.51334, train_accuracy: 82.81\n",
      "[12,    34] loss: 0.48296, train_accuracy: 83.59\n",
      "[12,    35] loss: 0.58486, train_accuracy: 80.66\n",
      "[12,    36] loss: 0.51206, train_accuracy: 82.81\n",
      "[12,    37] loss: 0.43269, train_accuracy: 86.33\n",
      "[12,    38] loss: 0.46273, train_accuracy: 84.38\n",
      "[12,    39] loss: 0.45082, train_accuracy: 85.55\n",
      "[12,    40] loss: 0.51809, train_accuracy: 82.23\n",
      "[12,    41] loss: 0.46718, train_accuracy: 83.40\n",
      "[12,    42] loss: 0.49191, train_accuracy: 83.98\n",
      "[12,    43] loss: 0.49435, train_accuracy: 84.18\n",
      "[12,    44] loss: 0.56126, train_accuracy: 80.08\n",
      "[12,    45] loss: 0.54915, train_accuracy: 83.20\n",
      "[12,    46] loss: 0.50535, train_accuracy: 82.42\n",
      "[12,    47] loss: 0.55718, train_accuracy: 81.05\n",
      "[12,    48] loss: 0.47398, train_accuracy: 83.98\n",
      "[12,    49] loss: 0.48677, train_accuracy: 84.57\n",
      "[12,    50] loss: 0.53573, train_accuracy: 81.05\n",
      "[12,    51] loss: 0.50193, train_accuracy: 83.98\n",
      "[12,    52] loss: 0.53725, train_accuracy: 83.40\n",
      "[12,    53] loss: 0.49395, train_accuracy: 83.20\n",
      "[12,    54] loss: 0.53740, train_accuracy: 79.30\n",
      "[12,    55] loss: 0.53317, train_accuracy: 81.84\n",
      "[12,    56] loss: 0.52037, train_accuracy: 81.05\n",
      "[12,    57] loss: 0.47719, train_accuracy: 83.59\n",
      "[12,    58] loss: 0.52181, train_accuracy: 82.81\n",
      "[12,    59] loss: 0.47159, train_accuracy: 82.81\n",
      "[12,    60] loss: 0.60266, train_accuracy: 79.30\n",
      "[12,    61] loss: 0.55562, train_accuracy: 79.49\n",
      "[12,    62] loss: 0.52382, train_accuracy: 81.05\n",
      "[12,    63] loss: 0.54381, train_accuracy: 79.10\n",
      "[12,    64] loss: 0.54487, train_accuracy: 81.45\n",
      "[12,    65] loss: 0.46864, train_accuracy: 86.52\n",
      "[12,    66] loss: 0.54654, train_accuracy: 81.25\n",
      "[12,    67] loss: 0.52836, train_accuracy: 82.23\n",
      "[12,    68] loss: 0.60675, train_accuracy: 80.66\n",
      "[12,    69] loss: 0.44010, train_accuracy: 83.79\n",
      "[12,    70] loss: 0.55053, train_accuracy: 81.45\n",
      "[12,    71] loss: 0.57497, train_accuracy: 80.27\n",
      "[12,    72] loss: 0.54809, train_accuracy: 79.69\n",
      "[12,    73] loss: 0.51014, train_accuracy: 83.01\n",
      "[12,    74] loss: 0.53755, train_accuracy: 82.03\n",
      "[12,    75] loss: 0.48289, train_accuracy: 84.96\n",
      "[12,    76] loss: 0.51510, train_accuracy: 81.25\n",
      "[12,    77] loss: 0.48733, train_accuracy: 83.01\n",
      "[12,    78] loss: 0.50870, train_accuracy: 80.47\n",
      "[12,    79] loss: 0.54634, train_accuracy: 79.88\n",
      "[12,    80] loss: 0.52510, train_accuracy: 78.52\n",
      "[12,    81] loss: 0.56046, train_accuracy: 81.84\n",
      "[12,    82] loss: 0.53335, train_accuracy: 81.05\n",
      "[12,    83] loss: 0.53515, train_accuracy: 83.79\n",
      "[12,    84] loss: 0.57346, train_accuracy: 81.05\n",
      "[12,    85] loss: 0.55385, train_accuracy: 79.69\n",
      "[12,    86] loss: 0.57360, train_accuracy: 79.10\n",
      "[12,    87] loss: 0.53980, train_accuracy: 81.45\n",
      "[12,    88] loss: 0.51974, train_accuracy: 82.03\n",
      "[12,    89] loss: 0.54548, train_accuracy: 81.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,    90] loss: 0.57979, train_accuracy: 80.66\n",
      "[12,    91] loss: 0.54003, train_accuracy: 81.84\n",
      "[12,    92] loss: 0.55166, train_accuracy: 81.05\n",
      "[12,    93] loss: 0.57747, train_accuracy: 79.49\n",
      "[12,    94] loss: 0.58432, train_accuracy: 80.08\n",
      "[12,    95] loss: 0.56046, train_accuracy: 79.88\n",
      "[12,    96] loss: 0.56537, train_accuracy: 78.32\n",
      "[12,    97] loss: 0.52539, train_accuracy: 82.42\n",
      "[12,    98] loss: 0.59180, train_accuracy: 77.68\n",
      "duration: 11 s - train loss: 0.51278 - train accuracy: 82.45 - validation loss: 1.17 - validation accuracy: 62.48 \n",
      "[13,     1] loss: 0.47505, train_accuracy: 84.18\n",
      "[13,     2] loss: 0.45384, train_accuracy: 87.30\n",
      "[13,     3] loss: 0.43835, train_accuracy: 87.11\n",
      "[13,     4] loss: 0.48637, train_accuracy: 83.79\n",
      "[13,     5] loss: 0.43700, train_accuracy: 85.74\n",
      "[13,     6] loss: 0.42396, train_accuracy: 86.52\n",
      "[13,     7] loss: 0.45408, train_accuracy: 85.94\n",
      "[13,     8] loss: 0.41696, train_accuracy: 85.94\n",
      "[13,     9] loss: 0.44039, train_accuracy: 86.72\n",
      "[13,    10] loss: 0.47607, train_accuracy: 83.40\n",
      "[13,    11] loss: 0.45379, train_accuracy: 86.72\n",
      "[13,    12] loss: 0.39547, train_accuracy: 88.09\n",
      "[13,    13] loss: 0.41180, train_accuracy: 87.30\n",
      "[13,    14] loss: 0.49140, train_accuracy: 85.74\n",
      "[13,    15] loss: 0.39703, train_accuracy: 85.55\n",
      "[13,    16] loss: 0.43143, train_accuracy: 86.13\n",
      "[13,    17] loss: 0.40800, train_accuracy: 88.48\n",
      "[13,    18] loss: 0.46522, train_accuracy: 85.74\n",
      "[13,    19] loss: 0.43093, train_accuracy: 86.52\n",
      "[13,    20] loss: 0.47771, train_accuracy: 85.35\n",
      "[13,    21] loss: 0.42994, train_accuracy: 84.38\n",
      "[13,    22] loss: 0.41796, train_accuracy: 85.35\n",
      "[13,    23] loss: 0.39880, train_accuracy: 87.50\n",
      "[13,    24] loss: 0.45906, train_accuracy: 86.52\n",
      "[13,    25] loss: 0.47720, train_accuracy: 85.35\n",
      "[13,    26] loss: 0.39810, train_accuracy: 86.72\n",
      "[13,    27] loss: 0.43366, train_accuracy: 85.74\n",
      "[13,    28] loss: 0.43004, train_accuracy: 86.91\n",
      "[13,    29] loss: 0.43240, train_accuracy: 84.96\n",
      "[13,    30] loss: 0.41961, train_accuracy: 84.38\n",
      "[13,    31] loss: 0.44662, train_accuracy: 84.96\n",
      "[13,    32] loss: 0.43815, train_accuracy: 85.94\n",
      "[13,    33] loss: 0.41667, train_accuracy: 85.35\n",
      "[13,    34] loss: 0.43640, train_accuracy: 85.94\n",
      "[13,    35] loss: 0.44911, train_accuracy: 86.91\n",
      "[13,    36] loss: 0.42541, train_accuracy: 85.35\n",
      "[13,    37] loss: 0.43894, train_accuracy: 86.13\n",
      "[13,    38] loss: 0.44578, train_accuracy: 84.96\n",
      "[13,    39] loss: 0.43947, train_accuracy: 85.74\n",
      "[13,    40] loss: 0.47715, train_accuracy: 84.38\n",
      "[13,    41] loss: 0.44085, train_accuracy: 82.81\n",
      "[13,    42] loss: 0.44244, train_accuracy: 84.96\n",
      "[13,    43] loss: 0.46836, train_accuracy: 86.33\n",
      "[13,    44] loss: 0.46195, train_accuracy: 85.16\n",
      "[13,    45] loss: 0.50952, train_accuracy: 82.42\n",
      "[13,    46] loss: 0.46659, train_accuracy: 82.81\n",
      "[13,    47] loss: 0.44950, train_accuracy: 84.57\n",
      "[13,    48] loss: 0.46878, train_accuracy: 84.96\n",
      "[13,    49] loss: 0.45578, train_accuracy: 86.13\n",
      "[13,    50] loss: 0.48565, train_accuracy: 83.59\n",
      "[13,    51] loss: 0.48891, train_accuracy: 83.20\n",
      "[13,    52] loss: 0.47880, train_accuracy: 83.79\n",
      "[13,    53] loss: 0.50803, train_accuracy: 80.86\n",
      "[13,    54] loss: 0.45624, train_accuracy: 84.38\n",
      "[13,    55] loss: 0.50040, train_accuracy: 83.20\n",
      "[13,    56] loss: 0.52810, train_accuracy: 81.64\n",
      "[13,    57] loss: 0.54565, train_accuracy: 78.91\n",
      "[13,    58] loss: 0.45639, train_accuracy: 84.96\n",
      "[13,    59] loss: 0.49169, train_accuracy: 84.18\n",
      "[13,    60] loss: 0.47108, train_accuracy: 83.79\n",
      "[13,    61] loss: 0.43975, train_accuracy: 85.16\n",
      "[13,    62] loss: 0.53035, train_accuracy: 81.64\n",
      "[13,    63] loss: 0.54883, train_accuracy: 80.66\n",
      "[13,    64] loss: 0.47195, train_accuracy: 84.57\n",
      "[13,    65] loss: 0.49167, train_accuracy: 82.42\n",
      "[13,    66] loss: 0.45152, train_accuracy: 84.18\n",
      "[13,    67] loss: 0.48802, train_accuracy: 81.64\n",
      "[13,    68] loss: 0.44949, train_accuracy: 86.33\n",
      "[13,    69] loss: 0.48799, train_accuracy: 82.42\n",
      "[13,    70] loss: 0.43270, train_accuracy: 84.18\n",
      "[13,    71] loss: 0.47006, train_accuracy: 83.98\n",
      "[13,    72] loss: 0.46447, train_accuracy: 83.98\n",
      "[13,    73] loss: 0.46600, train_accuracy: 83.79\n",
      "[13,    74] loss: 0.52107, train_accuracy: 81.25\n",
      "[13,    75] loss: 0.59829, train_accuracy: 78.12\n",
      "[13,    76] loss: 0.43618, train_accuracy: 85.55\n",
      "[13,    77] loss: 0.46093, train_accuracy: 83.79\n",
      "[13,    78] loss: 0.49511, train_accuracy: 84.96\n",
      "[13,    79] loss: 0.47177, train_accuracy: 84.38\n",
      "[13,    80] loss: 0.52877, train_accuracy: 80.08\n",
      "[13,    81] loss: 0.48120, train_accuracy: 84.18\n",
      "[13,    82] loss: 0.49880, train_accuracy: 82.23\n",
      "[13,    83] loss: 0.50124, train_accuracy: 82.81\n",
      "[13,    84] loss: 0.51122, train_accuracy: 82.42\n",
      "[13,    85] loss: 0.51171, train_accuracy: 81.64\n",
      "[13,    86] loss: 0.49992, train_accuracy: 82.42\n",
      "[13,    87] loss: 0.56377, train_accuracy: 82.62\n",
      "[13,    88] loss: 0.52169, train_accuracy: 81.84\n",
      "[13,    89] loss: 0.49859, train_accuracy: 82.03\n",
      "[13,    90] loss: 0.49520, train_accuracy: 83.59\n",
      "[13,    91] loss: 0.50949, train_accuracy: 83.40\n",
      "[13,    92] loss: 0.49707, train_accuracy: 82.81\n",
      "[13,    93] loss: 0.51461, train_accuracy: 82.62\n",
      "[13,    94] loss: 0.55354, train_accuracy: 83.01\n",
      "[13,    95] loss: 0.48536, train_accuracy: 82.81\n",
      "[13,    96] loss: 0.55817, train_accuracy: 81.64\n",
      "[13,    97] loss: 0.53187, train_accuracy: 80.47\n",
      "[13,    98] loss: 0.40709, train_accuracy: 86.31\n",
      "duration: 11 s - train loss: 0.46934 - train accuracy: 84.29 - validation loss: 1.22 - validation accuracy: 62.07 \n",
      "stopped early after 5 epochs without decrease of validation loss\n",
      "Finished Training\n",
      "cw done\n",
      "pgd done\n",
      "compression rate:  0.5\n",
      "[1,     1] loss: 0.76125, train_accuracy: 71.48\n",
      "[1,     2] loss: 0.63092, train_accuracy: 77.54\n",
      "[1,     3] loss: 0.70399, train_accuracy: 73.63\n",
      "[1,     4] loss: 0.56093, train_accuracy: 78.52\n",
      "[1,     5] loss: 0.57904, train_accuracy: 79.30\n",
      "[1,     6] loss: 0.59340, train_accuracy: 78.71\n",
      "[1,     7] loss: 0.64252, train_accuracy: 76.76\n",
      "[1,     8] loss: 0.60378, train_accuracy: 78.12\n",
      "[1,     9] loss: 0.55950, train_accuracy: 79.69\n",
      "[1,    10] loss: 0.59581, train_accuracy: 79.69\n",
      "[1,    11] loss: 0.61550, train_accuracy: 76.95\n",
      "[1,    12] loss: 0.61827, train_accuracy: 77.73\n",
      "[1,    13] loss: 0.55577, train_accuracy: 79.69\n",
      "[1,    14] loss: 0.60993, train_accuracy: 79.10\n",
      "[1,    15] loss: 0.56513, train_accuracy: 79.30\n",
      "[1,    16] loss: 0.56127, train_accuracy: 82.23\n",
      "[1,    17] loss: 0.56349, train_accuracy: 79.88\n",
      "[1,    18] loss: 0.53224, train_accuracy: 81.45\n",
      "[1,    19] loss: 0.57729, train_accuracy: 81.64\n",
      "[1,    20] loss: 0.53806, train_accuracy: 83.01\n",
      "[1,    21] loss: 0.53306, train_accuracy: 79.69\n",
      "[1,    22] loss: 0.58592, train_accuracy: 81.05\n",
      "[1,    23] loss: 0.51679, train_accuracy: 81.05\n",
      "[1,    24] loss: 0.49509, train_accuracy: 81.64\n",
      "[1,    25] loss: 0.58282, train_accuracy: 77.93\n",
      "[1,    26] loss: 0.54618, train_accuracy: 80.08\n",
      "[1,    27] loss: 0.56259, train_accuracy: 80.47\n",
      "[1,    28] loss: 0.54586, train_accuracy: 78.71\n",
      "[1,    29] loss: 0.57789, train_accuracy: 79.69\n",
      "[1,    30] loss: 0.54096, train_accuracy: 80.86\n",
      "[1,    31] loss: 0.53101, train_accuracy: 81.25\n",
      "[1,    32] loss: 0.51192, train_accuracy: 83.79\n",
      "[1,    33] loss: 0.54710, train_accuracy: 80.66\n",
      "[1,    34] loss: 0.55245, train_accuracy: 80.08\n",
      "[1,    35] loss: 0.56774, train_accuracy: 79.88\n",
      "[1,    36] loss: 0.52531, train_accuracy: 80.66\n",
      "[1,    37] loss: 0.52456, train_accuracy: 82.62\n",
      "[1,    38] loss: 0.54975, train_accuracy: 80.47\n",
      "[1,    39] loss: 0.50600, train_accuracy: 84.38\n",
      "[1,    40] loss: 0.57747, train_accuracy: 79.30\n",
      "[1,    41] loss: 0.52252, train_accuracy: 80.66\n",
      "[1,    42] loss: 0.52926, train_accuracy: 80.47\n",
      "[1,    43] loss: 0.51311, train_accuracy: 80.86\n",
      "[1,    44] loss: 0.45747, train_accuracy: 83.79\n",
      "[1,    45] loss: 0.46906, train_accuracy: 84.38\n",
      "[1,    46] loss: 0.45719, train_accuracy: 84.18\n",
      "[1,    47] loss: 0.54627, train_accuracy: 79.49\n",
      "[1,    48] loss: 0.51412, train_accuracy: 82.81\n",
      "[1,    49] loss: 0.47058, train_accuracy: 81.84\n",
      "[1,    50] loss: 0.54136, train_accuracy: 80.47\n",
      "[1,    51] loss: 0.56431, train_accuracy: 77.93\n",
      "[1,    52] loss: 0.56014, train_accuracy: 81.64\n",
      "[1,    53] loss: 0.50527, train_accuracy: 82.23\n",
      "[1,    54] loss: 0.53745, train_accuracy: 82.62\n",
      "[1,    55] loss: 0.49614, train_accuracy: 83.01\n",
      "[1,    56] loss: 0.49234, train_accuracy: 84.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    57] loss: 0.54244, train_accuracy: 81.64\n",
      "[1,    58] loss: 0.52838, train_accuracy: 81.84\n",
      "[1,    59] loss: 0.51767, train_accuracy: 81.25\n",
      "[1,    60] loss: 0.44967, train_accuracy: 86.72\n",
      "[1,    61] loss: 0.59022, train_accuracy: 78.91\n",
      "[1,    62] loss: 0.52758, train_accuracy: 81.25\n",
      "[1,    63] loss: 0.50904, train_accuracy: 82.42\n",
      "[1,    64] loss: 0.50788, train_accuracy: 82.42\n",
      "[1,    65] loss: 0.45437, train_accuracy: 84.18\n",
      "[1,    66] loss: 0.57891, train_accuracy: 78.91\n",
      "[1,    67] loss: 0.49972, train_accuracy: 82.03\n",
      "[1,    68] loss: 0.51997, train_accuracy: 81.45\n",
      "[1,    69] loss: 0.51355, train_accuracy: 83.01\n",
      "[1,    70] loss: 0.48535, train_accuracy: 81.45\n",
      "[1,    71] loss: 0.47978, train_accuracy: 83.59\n",
      "[1,    72] loss: 0.48323, train_accuracy: 83.59\n",
      "[1,    73] loss: 0.50755, train_accuracy: 82.81\n",
      "[1,    74] loss: 0.52626, train_accuracy: 81.84\n",
      "[1,    75] loss: 0.54141, train_accuracy: 80.47\n",
      "[1,    76] loss: 0.47733, train_accuracy: 83.40\n",
      "[1,    77] loss: 0.51649, train_accuracy: 81.64\n",
      "[1,    78] loss: 0.55798, train_accuracy: 81.05\n",
      "[1,    79] loss: 0.51631, train_accuracy: 81.45\n",
      "[1,    80] loss: 0.53985, train_accuracy: 82.03\n",
      "[1,    81] loss: 0.43967, train_accuracy: 85.74\n",
      "[1,    82] loss: 0.50877, train_accuracy: 80.86\n",
      "[1,    83] loss: 0.49347, train_accuracy: 81.25\n",
      "[1,    84] loss: 0.42130, train_accuracy: 86.72\n",
      "[1,    85] loss: 0.44944, train_accuracy: 84.18\n",
      "[1,    86] loss: 0.54946, train_accuracy: 79.69\n",
      "[1,    87] loss: 0.46914, train_accuracy: 83.01\n",
      "[1,    88] loss: 0.53809, train_accuracy: 82.81\n",
      "[1,    89] loss: 0.51127, train_accuracy: 82.03\n",
      "[1,    90] loss: 0.50711, train_accuracy: 82.23\n",
      "[1,    91] loss: 0.53078, train_accuracy: 80.47\n",
      "[1,    92] loss: 0.46792, train_accuracy: 83.40\n",
      "[1,    93] loss: 0.53058, train_accuracy: 82.42\n",
      "[1,    94] loss: 0.50565, train_accuracy: 81.64\n",
      "[1,    95] loss: 0.48226, train_accuracy: 82.03\n",
      "[1,    96] loss: 0.46596, train_accuracy: 83.79\n",
      "[1,    97] loss: 0.54270, train_accuracy: 79.69\n",
      "[1,    98] loss: 0.51670, train_accuracy: 82.14\n",
      "duration: 11 s - train loss: 0.53394 - train accuracy: 81.15 - validation loss: 1.19 - validation accuracy: 62.65 \n",
      "[2,     1] loss: 0.45192, train_accuracy: 83.59\n",
      "[2,     2] loss: 0.45427, train_accuracy: 84.96\n",
      "[2,     3] loss: 0.43094, train_accuracy: 86.13\n",
      "[2,     4] loss: 0.45570, train_accuracy: 84.96\n",
      "[2,     5] loss: 0.39978, train_accuracy: 86.91\n",
      "[2,     6] loss: 0.40871, train_accuracy: 88.28\n",
      "[2,     7] loss: 0.42157, train_accuracy: 85.74\n",
      "[2,     8] loss: 0.43498, train_accuracy: 85.94\n",
      "[2,     9] loss: 0.43167, train_accuracy: 84.96\n",
      "[2,    10] loss: 0.40304, train_accuracy: 85.55\n",
      "[2,    11] loss: 0.42083, train_accuracy: 85.55\n",
      "[2,    12] loss: 0.44718, train_accuracy: 84.57\n",
      "[2,    13] loss: 0.37341, train_accuracy: 86.52\n",
      "[2,    14] loss: 0.46333, train_accuracy: 84.18\n",
      "[2,    15] loss: 0.42639, train_accuracy: 85.74\n",
      "[2,    16] loss: 0.38609, train_accuracy: 87.89\n",
      "[2,    17] loss: 0.44010, train_accuracy: 85.55\n",
      "[2,    18] loss: 0.38418, train_accuracy: 87.30\n",
      "[2,    19] loss: 0.46653, train_accuracy: 82.23\n",
      "[2,    20] loss: 0.42663, train_accuracy: 85.94\n",
      "[2,    21] loss: 0.47447, train_accuracy: 83.98\n",
      "[2,    22] loss: 0.41215, train_accuracy: 87.30\n",
      "[2,    23] loss: 0.42125, train_accuracy: 84.96\n",
      "[2,    24] loss: 0.44224, train_accuracy: 85.74\n",
      "[2,    25] loss: 0.40875, train_accuracy: 87.11\n",
      "[2,    26] loss: 0.45328, train_accuracy: 84.96\n",
      "[2,    27] loss: 0.44082, train_accuracy: 85.55\n",
      "[2,    28] loss: 0.42970, train_accuracy: 85.35\n",
      "[2,    29] loss: 0.47689, train_accuracy: 83.98\n",
      "[2,    30] loss: 0.39156, train_accuracy: 85.35\n",
      "[2,    31] loss: 0.45248, train_accuracy: 83.40\n",
      "[2,    32] loss: 0.49681, train_accuracy: 84.96\n",
      "[2,    33] loss: 0.39986, train_accuracy: 85.35\n",
      "[2,    34] loss: 0.44920, train_accuracy: 86.33\n",
      "[2,    35] loss: 0.45778, train_accuracy: 84.57\n",
      "[2,    36] loss: 0.48799, train_accuracy: 83.79\n",
      "[2,    37] loss: 0.48135, train_accuracy: 84.57\n",
      "[2,    38] loss: 0.40334, train_accuracy: 87.70\n",
      "[2,    39] loss: 0.41960, train_accuracy: 86.33\n",
      "[2,    40] loss: 0.41170, train_accuracy: 86.91\n",
      "[2,    41] loss: 0.45161, train_accuracy: 85.94\n",
      "[2,    42] loss: 0.49227, train_accuracy: 83.59\n",
      "[2,    43] loss: 0.45475, train_accuracy: 84.57\n",
      "[2,    44] loss: 0.42194, train_accuracy: 85.94\n",
      "[2,    45] loss: 0.45777, train_accuracy: 83.98\n",
      "[2,    46] loss: 0.43783, train_accuracy: 85.55\n",
      "[2,    47] loss: 0.46441, train_accuracy: 85.74\n",
      "[2,    48] loss: 0.46660, train_accuracy: 82.23\n",
      "[2,    49] loss: 0.46137, train_accuracy: 87.30\n",
      "[2,    50] loss: 0.41496, train_accuracy: 87.30\n",
      "[2,    51] loss: 0.45265, train_accuracy: 85.16\n",
      "[2,    52] loss: 0.43631, train_accuracy: 84.38\n",
      "[2,    53] loss: 0.43274, train_accuracy: 85.74\n",
      "[2,    54] loss: 0.41723, train_accuracy: 86.52\n",
      "[2,    55] loss: 0.43365, train_accuracy: 85.35\n",
      "[2,    56] loss: 0.38412, train_accuracy: 88.09\n",
      "[2,    57] loss: 0.49636, train_accuracy: 83.01\n",
      "[2,    58] loss: 0.40181, train_accuracy: 84.57\n",
      "[2,    59] loss: 0.47752, train_accuracy: 82.23\n",
      "[2,    60] loss: 0.44670, train_accuracy: 85.16\n",
      "[2,    61] loss: 0.43269, train_accuracy: 88.09\n",
      "[2,    62] loss: 0.43517, train_accuracy: 84.77\n",
      "[2,    63] loss: 0.44139, train_accuracy: 85.35\n",
      "[2,    64] loss: 0.43180, train_accuracy: 84.96\n",
      "[2,    65] loss: 0.50115, train_accuracy: 82.23\n",
      "[2,    66] loss: 0.46165, train_accuracy: 82.81\n",
      "[2,    67] loss: 0.39295, train_accuracy: 87.30\n",
      "[2,    68] loss: 0.42855, train_accuracy: 86.72\n",
      "[2,    69] loss: 0.43307, train_accuracy: 85.16\n",
      "[2,    70] loss: 0.49018, train_accuracy: 83.20\n",
      "[2,    71] loss: 0.37721, train_accuracy: 85.94\n",
      "[2,    72] loss: 0.50837, train_accuracy: 80.27\n",
      "[2,    73] loss: 0.49859, train_accuracy: 84.38\n",
      "[2,    74] loss: 0.48340, train_accuracy: 83.79\n",
      "[2,    75] loss: 0.40600, train_accuracy: 85.74\n",
      "[2,    76] loss: 0.42117, train_accuracy: 85.74\n",
      "[2,    77] loss: 0.48919, train_accuracy: 84.18\n",
      "[2,    78] loss: 0.43967, train_accuracy: 86.33\n",
      "[2,    79] loss: 0.46230, train_accuracy: 82.62\n",
      "[2,    80] loss: 0.47393, train_accuracy: 84.57\n",
      "[2,    81] loss: 0.46851, train_accuracy: 83.20\n",
      "[2,    82] loss: 0.44847, train_accuracy: 83.59\n",
      "[2,    83] loss: 0.45747, train_accuracy: 85.94\n",
      "[2,    84] loss: 0.48263, train_accuracy: 82.62\n",
      "[2,    85] loss: 0.42326, train_accuracy: 86.72\n",
      "[2,    86] loss: 0.44397, train_accuracy: 85.55\n",
      "[2,    87] loss: 0.46651, train_accuracy: 84.38\n",
      "[2,    88] loss: 0.43733, train_accuracy: 83.79\n",
      "[2,    89] loss: 0.45424, train_accuracy: 83.20\n",
      "[2,    90] loss: 0.41300, train_accuracy: 83.98\n",
      "[2,    91] loss: 0.46019, train_accuracy: 83.20\n",
      "[2,    92] loss: 0.44273, train_accuracy: 83.79\n",
      "[2,    93] loss: 0.44895, train_accuracy: 83.40\n",
      "[2,    94] loss: 0.51770, train_accuracy: 82.23\n",
      "[2,    95] loss: 0.43675, train_accuracy: 84.57\n",
      "[2,    96] loss: 0.45022, train_accuracy: 85.74\n",
      "[2,    97] loss: 0.41506, train_accuracy: 85.35\n",
      "[2,    98] loss: 0.39845, train_accuracy: 87.80\n",
      "duration: 11 s - train loss: 0.44199 - train accuracy: 85.06 - validation loss: 1.23 - validation accuracy: 62.73 \n",
      "[3,     1] loss: 0.34310, train_accuracy: 90.04\n",
      "[3,     2] loss: 0.35269, train_accuracy: 88.87\n",
      "[3,     3] loss: 0.33441, train_accuracy: 89.65\n",
      "[3,     4] loss: 0.35712, train_accuracy: 88.67\n",
      "[3,     5] loss: 0.40516, train_accuracy: 87.11\n",
      "[3,     6] loss: 0.36638, train_accuracy: 88.09\n",
      "[3,     7] loss: 0.37857, train_accuracy: 86.52\n",
      "[3,     8] loss: 0.41761, train_accuracy: 87.70\n",
      "[3,     9] loss: 0.38651, train_accuracy: 86.91\n",
      "[3,    10] loss: 0.43525, train_accuracy: 85.55\n",
      "[3,    11] loss: 0.38439, train_accuracy: 89.45\n",
      "[3,    12] loss: 0.38638, train_accuracy: 87.70\n",
      "[3,    13] loss: 0.33882, train_accuracy: 88.28\n",
      "[3,    14] loss: 0.38073, train_accuracy: 88.09\n",
      "[3,    15] loss: 0.38813, train_accuracy: 88.09\n",
      "[3,    16] loss: 0.35855, train_accuracy: 89.45\n",
      "[3,    17] loss: 0.39147, train_accuracy: 87.70\n",
      "[3,    18] loss: 0.38858, train_accuracy: 87.11\n",
      "[3,    19] loss: 0.41451, train_accuracy: 85.74\n",
      "[3,    20] loss: 0.34966, train_accuracy: 87.70\n",
      "[3,    21] loss: 0.42689, train_accuracy: 85.35\n",
      "[3,    22] loss: 0.37485, train_accuracy: 87.50\n",
      "[3,    23] loss: 0.36122, train_accuracy: 88.28\n",
      "[3,    24] loss: 0.41975, train_accuracy: 85.16\n",
      "[3,    25] loss: 0.37721, train_accuracy: 88.48\n",
      "[3,    26] loss: 0.38084, train_accuracy: 88.87\n",
      "[3,    27] loss: 0.40341, train_accuracy: 85.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    28] loss: 0.34844, train_accuracy: 88.28\n",
      "[3,    29] loss: 0.41091, train_accuracy: 86.72\n",
      "[3,    30] loss: 0.39005, train_accuracy: 86.91\n",
      "[3,    31] loss: 0.41851, train_accuracy: 86.13\n",
      "[3,    32] loss: 0.36841, train_accuracy: 88.67\n",
      "[3,    33] loss: 0.43696, train_accuracy: 86.72\n",
      "[3,    34] loss: 0.43369, train_accuracy: 85.74\n",
      "[3,    35] loss: 0.38775, train_accuracy: 87.89\n",
      "[3,    36] loss: 0.42316, train_accuracy: 86.13\n",
      "[3,    37] loss: 0.38287, train_accuracy: 87.89\n",
      "[3,    38] loss: 0.34788, train_accuracy: 90.04\n",
      "[3,    39] loss: 0.45893, train_accuracy: 85.16\n",
      "[3,    40] loss: 0.39328, train_accuracy: 88.09\n",
      "[3,    41] loss: 0.43631, train_accuracy: 85.35\n",
      "[3,    42] loss: 0.42141, train_accuracy: 85.35\n",
      "[3,    43] loss: 0.44272, train_accuracy: 84.77\n",
      "[3,    44] loss: 0.45220, train_accuracy: 85.74\n",
      "[3,    45] loss: 0.39355, train_accuracy: 86.52\n",
      "[3,    46] loss: 0.49033, train_accuracy: 84.18\n",
      "[3,    47] loss: 0.39726, train_accuracy: 85.94\n",
      "[3,    48] loss: 0.42591, train_accuracy: 87.89\n",
      "[3,    49] loss: 0.44591, train_accuracy: 84.77\n",
      "[3,    50] loss: 0.37266, train_accuracy: 88.28\n",
      "[3,    51] loss: 0.37938, train_accuracy: 87.11\n",
      "[3,    52] loss: 0.41023, train_accuracy: 85.94\n",
      "[3,    53] loss: 0.38910, train_accuracy: 87.11\n",
      "[3,    54] loss: 0.42923, train_accuracy: 85.35\n",
      "[3,    55] loss: 0.41102, train_accuracy: 85.74\n",
      "[3,    56] loss: 0.40599, train_accuracy: 85.74\n",
      "[3,    57] loss: 0.36833, train_accuracy: 87.89\n",
      "[3,    58] loss: 0.36741, train_accuracy: 86.91\n",
      "[3,    59] loss: 0.45099, train_accuracy: 83.59\n",
      "[3,    60] loss: 0.39247, train_accuracy: 86.33\n",
      "[3,    61] loss: 0.39148, train_accuracy: 86.13\n",
      "[3,    62] loss: 0.40056, train_accuracy: 87.70\n",
      "[3,    63] loss: 0.42946, train_accuracy: 84.38\n",
      "[3,    64] loss: 0.38985, train_accuracy: 86.33\n",
      "[3,    65] loss: 0.39299, train_accuracy: 86.91\n",
      "[3,    66] loss: 0.42783, train_accuracy: 84.18\n",
      "[3,    67] loss: 0.41404, train_accuracy: 86.33\n",
      "[3,    68] loss: 0.39180, train_accuracy: 87.30\n",
      "[3,    69] loss: 0.36725, train_accuracy: 87.89\n",
      "[3,    70] loss: 0.42700, train_accuracy: 86.13\n",
      "[3,    71] loss: 0.45621, train_accuracy: 83.98\n",
      "[3,    72] loss: 0.38345, train_accuracy: 88.09\n",
      "[3,    73] loss: 0.43814, train_accuracy: 84.77\n",
      "[3,    74] loss: 0.41124, train_accuracy: 86.91\n",
      "[3,    75] loss: 0.44686, train_accuracy: 84.77\n",
      "[3,    76] loss: 0.39977, train_accuracy: 87.30\n",
      "[3,    77] loss: 0.41932, train_accuracy: 86.52\n",
      "[3,    78] loss: 0.42716, train_accuracy: 84.96\n",
      "[3,    79] loss: 0.41706, train_accuracy: 86.52\n",
      "[3,    80] loss: 0.42815, train_accuracy: 84.18\n",
      "[3,    81] loss: 0.41268, train_accuracy: 86.13\n",
      "[3,    82] loss: 0.39677, train_accuracy: 86.33\n",
      "[3,    83] loss: 0.41139, train_accuracy: 85.94\n",
      "[3,    84] loss: 0.49760, train_accuracy: 84.38\n",
      "[3,    85] loss: 0.39619, train_accuracy: 88.28\n",
      "[3,    86] loss: 0.40321, train_accuracy: 86.72\n",
      "[3,    87] loss: 0.46296, train_accuracy: 83.98\n",
      "[3,    88] loss: 0.44623, train_accuracy: 84.57\n",
      "[3,    89] loss: 0.41298, train_accuracy: 86.33\n",
      "[3,    90] loss: 0.41422, train_accuracy: 87.30\n",
      "[3,    91] loss: 0.42249, train_accuracy: 86.72\n",
      "[3,    92] loss: 0.38348, train_accuracy: 87.30\n",
      "[3,    93] loss: 0.46044, train_accuracy: 83.59\n",
      "[3,    94] loss: 0.37059, train_accuracy: 88.67\n",
      "[3,    95] loss: 0.45796, train_accuracy: 84.57\n",
      "[3,    96] loss: 0.42538, train_accuracy: 86.52\n",
      "[3,    97] loss: 0.38144, train_accuracy: 87.30\n",
      "[3,    98] loss: 0.35843, train_accuracy: 86.90\n",
      "duration: 10 s - train loss: 0.40367 - train accuracy: 86.69 - validation loss: 1.27 - validation accuracy: 62.87 \n",
      "[4,     1] loss: 0.34010, train_accuracy: 89.06\n",
      "[4,     2] loss: 0.31597, train_accuracy: 90.43\n",
      "[4,     3] loss: 0.36018, train_accuracy: 89.06\n",
      "[4,     4] loss: 0.32302, train_accuracy: 88.09\n",
      "[4,     5] loss: 0.36636, train_accuracy: 88.48\n",
      "[4,     6] loss: 0.32476, train_accuracy: 90.04\n",
      "[4,     7] loss: 0.31819, train_accuracy: 89.45\n",
      "[4,     8] loss: 0.36565, train_accuracy: 88.67\n",
      "[4,     9] loss: 0.36975, train_accuracy: 89.45\n",
      "[4,    10] loss: 0.34064, train_accuracy: 88.67\n",
      "[4,    11] loss: 0.33482, train_accuracy: 90.04\n",
      "[4,    12] loss: 0.31288, train_accuracy: 91.60\n",
      "[4,    13] loss: 0.33149, train_accuracy: 90.62\n",
      "[4,    14] loss: 0.34640, train_accuracy: 87.89\n",
      "[4,    15] loss: 0.32646, train_accuracy: 89.84\n",
      "[4,    16] loss: 0.37685, train_accuracy: 90.43\n",
      "[4,    17] loss: 0.33509, train_accuracy: 89.84\n",
      "[4,    18] loss: 0.35682, train_accuracy: 87.89\n",
      "[4,    19] loss: 0.38145, train_accuracy: 87.30\n",
      "[4,    20] loss: 0.34475, train_accuracy: 89.45\n",
      "[4,    21] loss: 0.34158, train_accuracy: 89.06\n",
      "[4,    22] loss: 0.31673, train_accuracy: 90.04\n",
      "[4,    23] loss: 0.31944, train_accuracy: 89.65\n",
      "[4,    24] loss: 0.34857, train_accuracy: 90.82\n",
      "[4,    25] loss: 0.33662, train_accuracy: 89.26\n",
      "[4,    26] loss: 0.37982, train_accuracy: 87.70\n",
      "[4,    27] loss: 0.39173, train_accuracy: 87.30\n",
      "[4,    28] loss: 0.34378, train_accuracy: 89.45\n",
      "[4,    29] loss: 0.37732, train_accuracy: 87.30\n",
      "[4,    30] loss: 0.32761, train_accuracy: 90.04\n",
      "[4,    31] loss: 0.37553, train_accuracy: 88.28\n",
      "[4,    32] loss: 0.33883, train_accuracy: 89.84\n",
      "[4,    33] loss: 0.35215, train_accuracy: 88.09\n",
      "[4,    34] loss: 0.35487, train_accuracy: 89.65\n",
      "[4,    35] loss: 0.37353, train_accuracy: 86.52\n",
      "[4,    36] loss: 0.35404, train_accuracy: 88.87\n",
      "[4,    37] loss: 0.37601, train_accuracy: 86.91\n",
      "[4,    38] loss: 0.33212, train_accuracy: 89.84\n",
      "[4,    39] loss: 0.36219, train_accuracy: 88.48\n",
      "[4,    40] loss: 0.40329, train_accuracy: 85.35\n",
      "[4,    41] loss: 0.38427, train_accuracy: 88.28\n",
      "[4,    42] loss: 0.37156, train_accuracy: 87.50\n",
      "[4,    43] loss: 0.39129, train_accuracy: 88.67\n",
      "[4,    44] loss: 0.39348, train_accuracy: 86.72\n",
      "[4,    45] loss: 0.36531, train_accuracy: 87.50\n",
      "[4,    46] loss: 0.42520, train_accuracy: 85.94\n",
      "[4,    47] loss: 0.39384, train_accuracy: 87.30\n",
      "[4,    48] loss: 0.40414, train_accuracy: 87.50\n",
      "[4,    49] loss: 0.35326, train_accuracy: 88.67\n",
      "[4,    50] loss: 0.37476, train_accuracy: 87.11\n",
      "[4,    51] loss: 0.34759, train_accuracy: 90.04\n",
      "[4,    52] loss: 0.37772, train_accuracy: 87.11\n",
      "[4,    53] loss: 0.39163, train_accuracy: 87.11\n",
      "[4,    54] loss: 0.39204, train_accuracy: 86.91\n",
      "[4,    55] loss: 0.38067, train_accuracy: 86.13\n",
      "[4,    56] loss: 0.36435, train_accuracy: 87.50\n",
      "[4,    57] loss: 0.39246, train_accuracy: 86.72\n",
      "[4,    58] loss: 0.39615, train_accuracy: 87.50\n",
      "[4,    59] loss: 0.34255, train_accuracy: 89.06\n",
      "[4,    60] loss: 0.36778, train_accuracy: 88.67\n",
      "[4,    61] loss: 0.40016, train_accuracy: 85.35\n",
      "[4,    62] loss: 0.37017, train_accuracy: 86.52\n",
      "[4,    63] loss: 0.36102, train_accuracy: 86.33\n",
      "[4,    64] loss: 0.41022, train_accuracy: 87.70\n",
      "[4,    65] loss: 0.41827, train_accuracy: 84.96\n",
      "[4,    66] loss: 0.42351, train_accuracy: 85.16\n",
      "[4,    67] loss: 0.39175, train_accuracy: 87.70\n",
      "[4,    68] loss: 0.40259, train_accuracy: 86.52\n",
      "[4,    69] loss: 0.40775, train_accuracy: 86.91\n",
      "[4,    70] loss: 0.32981, train_accuracy: 89.26\n",
      "[4,    71] loss: 0.42379, train_accuracy: 83.59\n",
      "[4,    72] loss: 0.42898, train_accuracy: 85.35\n",
      "[4,    73] loss: 0.35648, train_accuracy: 88.67\n",
      "[4,    74] loss: 0.37542, train_accuracy: 86.52\n",
      "[4,    75] loss: 0.45079, train_accuracy: 84.77\n",
      "[4,    76] loss: 0.40332, train_accuracy: 86.33\n",
      "[4,    77] loss: 0.37882, train_accuracy: 86.33\n",
      "[4,    78] loss: 0.38626, train_accuracy: 87.89\n",
      "[4,    79] loss: 0.47305, train_accuracy: 82.03\n",
      "[4,    80] loss: 0.42536, train_accuracy: 84.38\n",
      "[4,    81] loss: 0.42900, train_accuracy: 85.74\n",
      "[4,    82] loss: 0.39582, train_accuracy: 86.13\n",
      "[4,    83] loss: 0.40969, train_accuracy: 85.16\n",
      "[4,    84] loss: 0.39068, train_accuracy: 87.30\n",
      "[4,    85] loss: 0.37012, train_accuracy: 87.50\n",
      "[4,    86] loss: 0.39569, train_accuracy: 86.13\n",
      "[4,    87] loss: 0.38145, train_accuracy: 88.48\n",
      "[4,    88] loss: 0.44527, train_accuracy: 85.94\n",
      "[4,    89] loss: 0.42290, train_accuracy: 86.52\n",
      "[4,    90] loss: 0.34879, train_accuracy: 88.28\n",
      "[4,    91] loss: 0.34316, train_accuracy: 87.70\n",
      "[4,    92] loss: 0.41349, train_accuracy: 85.74\n",
      "[4,    93] loss: 0.41951, train_accuracy: 85.94\n",
      "[4,    94] loss: 0.41294, train_accuracy: 84.38\n",
      "[4,    95] loss: 0.35730, train_accuracy: 86.72\n",
      "[4,    96] loss: 0.36549, train_accuracy: 87.11\n",
      "[4,    97] loss: 0.36017, train_accuracy: 89.65\n",
      "[4,    98] loss: 0.39998, train_accuracy: 87.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 10 s - train loss: 0.37415 - train accuracy: 87.70 - validation loss: 1.31 - validation accuracy: 62.45 \n",
      "[5,     1] loss: 0.29866, train_accuracy: 91.60\n",
      "[5,     2] loss: 0.30170, train_accuracy: 91.02\n",
      "[5,     3] loss: 0.32866, train_accuracy: 89.65\n",
      "[5,     4] loss: 0.33305, train_accuracy: 90.62\n",
      "[5,     5] loss: 0.32744, train_accuracy: 89.65\n",
      "[5,     6] loss: 0.34357, train_accuracy: 89.65\n",
      "[5,     7] loss: 0.32735, train_accuracy: 88.48\n",
      "[5,     8] loss: 0.36896, train_accuracy: 88.67\n",
      "[5,     9] loss: 0.36271, train_accuracy: 89.45\n",
      "[5,    10] loss: 0.31707, train_accuracy: 90.04\n",
      "[5,    11] loss: 0.28586, train_accuracy: 92.77\n",
      "[5,    12] loss: 0.34526, train_accuracy: 86.52\n",
      "[5,    13] loss: 0.29254, train_accuracy: 90.23\n",
      "[5,    14] loss: 0.33232, train_accuracy: 89.06\n",
      "[5,    15] loss: 0.30549, train_accuracy: 91.02\n",
      "[5,    16] loss: 0.30786, train_accuracy: 90.82\n",
      "[5,    17] loss: 0.29184, train_accuracy: 90.62\n",
      "[5,    18] loss: 0.37565, train_accuracy: 87.70\n",
      "[5,    19] loss: 0.37137, train_accuracy: 88.28\n",
      "[5,    20] loss: 0.34055, train_accuracy: 89.65\n",
      "[5,    21] loss: 0.32564, train_accuracy: 88.09\n",
      "[5,    22] loss: 0.35651, train_accuracy: 87.70\n",
      "[5,    23] loss: 0.38590, train_accuracy: 86.72\n",
      "[5,    24] loss: 0.32978, train_accuracy: 88.87\n",
      "[5,    25] loss: 0.34968, train_accuracy: 89.45\n",
      "[5,    26] loss: 0.31876, train_accuracy: 89.65\n",
      "[5,    27] loss: 0.33096, train_accuracy: 92.19\n",
      "[5,    28] loss: 0.29493, train_accuracy: 91.41\n",
      "[5,    29] loss: 0.33118, train_accuracy: 88.28\n",
      "[5,    30] loss: 0.32437, train_accuracy: 89.84\n",
      "[5,    31] loss: 0.28982, train_accuracy: 91.80\n",
      "[5,    32] loss: 0.31007, train_accuracy: 89.84\n",
      "[5,    33] loss: 0.32687, train_accuracy: 88.28\n",
      "[5,    34] loss: 0.28450, train_accuracy: 91.60\n",
      "[5,    35] loss: 0.38898, train_accuracy: 86.52\n",
      "[5,    36] loss: 0.28352, train_accuracy: 91.41\n",
      "[5,    37] loss: 0.32952, train_accuracy: 90.04\n",
      "[5,    38] loss: 0.34485, train_accuracy: 89.65\n",
      "[5,    39] loss: 0.30801, train_accuracy: 90.43\n",
      "[5,    40] loss: 0.28640, train_accuracy: 91.80\n",
      "[5,    41] loss: 0.33033, train_accuracy: 87.70\n",
      "[5,    42] loss: 0.36933, train_accuracy: 88.09\n",
      "[5,    43] loss: 0.30860, train_accuracy: 89.65\n",
      "[5,    44] loss: 0.35298, train_accuracy: 89.06\n",
      "[5,    45] loss: 0.36469, train_accuracy: 87.89\n",
      "[5,    46] loss: 0.31197, train_accuracy: 91.02\n",
      "[5,    47] loss: 0.39245, train_accuracy: 88.28\n",
      "[5,    48] loss: 0.34920, train_accuracy: 88.87\n",
      "[5,    49] loss: 0.33993, train_accuracy: 87.89\n",
      "[5,    50] loss: 0.32194, train_accuracy: 90.82\n",
      "[5,    51] loss: 0.39882, train_accuracy: 88.48\n",
      "[5,    52] loss: 0.35242, train_accuracy: 89.06\n",
      "[5,    53] loss: 0.35074, train_accuracy: 86.72\n",
      "[5,    54] loss: 0.31387, train_accuracy: 89.84\n",
      "[5,    55] loss: 0.38400, train_accuracy: 87.70\n",
      "[5,    56] loss: 0.35560, train_accuracy: 87.70\n",
      "[5,    57] loss: 0.39416, train_accuracy: 87.50\n",
      "[5,    58] loss: 0.35661, train_accuracy: 85.74\n",
      "[5,    59] loss: 0.34961, train_accuracy: 89.06\n",
      "[5,    60] loss: 0.36649, train_accuracy: 87.89\n",
      "[5,    61] loss: 0.37791, train_accuracy: 86.52\n",
      "[5,    62] loss: 0.37607, train_accuracy: 87.11\n",
      "[5,    63] loss: 0.32312, train_accuracy: 89.45\n",
      "[5,    64] loss: 0.34639, train_accuracy: 88.09\n",
      "[5,    65] loss: 0.39016, train_accuracy: 87.50\n",
      "[5,    66] loss: 0.41797, train_accuracy: 87.11\n",
      "[5,    67] loss: 0.36696, train_accuracy: 88.67\n",
      "[5,    68] loss: 0.33939, train_accuracy: 90.04\n",
      "[5,    69] loss: 0.35794, train_accuracy: 87.30\n",
      "[5,    70] loss: 0.34092, train_accuracy: 88.28\n",
      "[5,    71] loss: 0.37364, train_accuracy: 87.50\n",
      "[5,    72] loss: 0.34261, train_accuracy: 87.50\n",
      "[5,    73] loss: 0.37286, train_accuracy: 88.09\n",
      "[5,    74] loss: 0.37750, train_accuracy: 87.30\n",
      "[5,    75] loss: 0.36531, train_accuracy: 88.09\n",
      "[5,    76] loss: 0.34725, train_accuracy: 88.67\n",
      "[5,    77] loss: 0.40329, train_accuracy: 85.94\n",
      "[5,    78] loss: 0.44965, train_accuracy: 84.77\n",
      "[5,    79] loss: 0.36058, train_accuracy: 88.28\n",
      "[5,    80] loss: 0.33664, train_accuracy: 89.84\n",
      "[5,    81] loss: 0.39780, train_accuracy: 86.33\n",
      "[5,    82] loss: 0.33367, train_accuracy: 90.04\n",
      "[5,    83] loss: 0.40124, train_accuracy: 85.16\n",
      "[5,    84] loss: 0.36415, train_accuracy: 87.70\n",
      "[5,    85] loss: 0.39229, train_accuracy: 86.72\n",
      "[5,    86] loss: 0.33987, train_accuracy: 89.84\n",
      "[5,    87] loss: 0.38468, train_accuracy: 88.09\n",
      "[5,    88] loss: 0.37993, train_accuracy: 86.33\n",
      "[5,    89] loss: 0.37124, train_accuracy: 87.70\n",
      "[5,    90] loss: 0.31354, train_accuracy: 89.84\n",
      "[5,    91] loss: 0.35249, train_accuracy: 88.67\n",
      "[5,    92] loss: 0.42754, train_accuracy: 87.11\n",
      "[5,    93] loss: 0.36446, train_accuracy: 87.70\n",
      "[5,    94] loss: 0.38880, train_accuracy: 87.50\n",
      "[5,    95] loss: 0.38256, train_accuracy: 88.28\n",
      "[5,    96] loss: 0.39338, train_accuracy: 86.72\n",
      "[5,    97] loss: 0.36304, train_accuracy: 88.09\n",
      "[5,    98] loss: 0.36235, train_accuracy: 88.10\n",
      "duration: 11 s - train loss: 0.34899 - train accuracy: 88.71 - validation loss: 1.35 - validation accuracy: 62.21 \n",
      "[6,     1] loss: 0.30853, train_accuracy: 91.60\n",
      "[6,     2] loss: 0.29323, train_accuracy: 91.80\n",
      "[6,     3] loss: 0.29287, train_accuracy: 90.43\n",
      "[6,     4] loss: 0.29189, train_accuracy: 91.99\n",
      "[6,     5] loss: 0.33111, train_accuracy: 89.65\n",
      "[6,     6] loss: 0.28114, train_accuracy: 91.80\n",
      "[6,     7] loss: 0.22643, train_accuracy: 94.53\n",
      "[6,     8] loss: 0.25742, train_accuracy: 91.60\n",
      "[6,     9] loss: 0.31261, train_accuracy: 89.65\n",
      "[6,    10] loss: 0.28859, train_accuracy: 91.60\n",
      "[6,    11] loss: 0.34291, train_accuracy: 89.84\n",
      "[6,    12] loss: 0.33406, train_accuracy: 90.04\n",
      "[6,    13] loss: 0.30484, train_accuracy: 91.41\n",
      "[6,    14] loss: 0.26509, train_accuracy: 91.60\n",
      "[6,    15] loss: 0.32738, train_accuracy: 89.84\n",
      "[6,    16] loss: 0.29895, train_accuracy: 91.60\n",
      "[6,    17] loss: 0.27253, train_accuracy: 92.77\n",
      "[6,    18] loss: 0.30367, train_accuracy: 87.89\n",
      "[6,    19] loss: 0.32680, train_accuracy: 89.84\n",
      "[6,    20] loss: 0.31998, train_accuracy: 89.84\n",
      "[6,    21] loss: 0.29890, train_accuracy: 92.38\n",
      "[6,    22] loss: 0.28378, train_accuracy: 91.60\n",
      "[6,    23] loss: 0.33085, train_accuracy: 89.65\n",
      "[6,    24] loss: 0.28474, train_accuracy: 90.43\n",
      "[6,    25] loss: 0.29510, train_accuracy: 90.23\n",
      "[6,    26] loss: 0.29661, train_accuracy: 91.21\n",
      "[6,    27] loss: 0.31298, train_accuracy: 90.82\n",
      "[6,    28] loss: 0.33648, train_accuracy: 88.67\n",
      "[6,    29] loss: 0.33900, train_accuracy: 90.62\n",
      "[6,    30] loss: 0.33799, train_accuracy: 88.48\n",
      "[6,    31] loss: 0.29987, train_accuracy: 90.04\n",
      "[6,    32] loss: 0.32114, train_accuracy: 90.62\n",
      "[6,    33] loss: 0.27553, train_accuracy: 92.38\n",
      "[6,    34] loss: 0.36117, train_accuracy: 87.70\n",
      "[6,    35] loss: 0.36829, train_accuracy: 86.52\n",
      "[6,    36] loss: 0.26864, train_accuracy: 90.43\n",
      "[6,    37] loss: 0.38678, train_accuracy: 86.52\n",
      "[6,    38] loss: 0.35032, train_accuracy: 89.06\n",
      "[6,    39] loss: 0.34091, train_accuracy: 89.84\n",
      "[6,    40] loss: 0.36202, train_accuracy: 87.50\n",
      "[6,    41] loss: 0.30435, train_accuracy: 89.45\n",
      "[6,    42] loss: 0.28197, train_accuracy: 90.82\n",
      "[6,    43] loss: 0.32074, train_accuracy: 88.67\n",
      "[6,    44] loss: 0.33047, train_accuracy: 90.82\n",
      "[6,    45] loss: 0.39508, train_accuracy: 86.52\n",
      "[6,    46] loss: 0.27714, train_accuracy: 90.43\n",
      "[6,    47] loss: 0.36747, train_accuracy: 88.28\n",
      "[6,    48] loss: 0.38403, train_accuracy: 86.72\n",
      "[6,    49] loss: 0.30299, train_accuracy: 90.43\n",
      "[6,    50] loss: 0.29287, train_accuracy: 90.62\n",
      "[6,    51] loss: 0.33297, train_accuracy: 88.09\n",
      "[6,    52] loss: 0.31087, train_accuracy: 90.82\n",
      "[6,    53] loss: 0.26473, train_accuracy: 91.60\n",
      "[6,    54] loss: 0.32384, train_accuracy: 90.43\n",
      "[6,    55] loss: 0.31444, train_accuracy: 90.82\n",
      "[6,    56] loss: 0.31402, train_accuracy: 90.62\n",
      "[6,    57] loss: 0.30992, train_accuracy: 88.28\n",
      "[6,    58] loss: 0.32595, train_accuracy: 90.04\n",
      "[6,    59] loss: 0.34318, train_accuracy: 89.65\n",
      "[6,    60] loss: 0.35277, train_accuracy: 87.89\n",
      "[6,    61] loss: 0.35866, train_accuracy: 89.65\n",
      "[6,    62] loss: 0.33345, train_accuracy: 88.09\n",
      "[6,    63] loss: 0.36408, train_accuracy: 87.89\n",
      "[6,    64] loss: 0.33144, train_accuracy: 90.82\n",
      "[6,    65] loss: 0.34020, train_accuracy: 88.09\n",
      "[6,    66] loss: 0.31628, train_accuracy: 89.45\n",
      "[6,    67] loss: 0.33953, train_accuracy: 88.28\n",
      "[6,    68] loss: 0.31768, train_accuracy: 89.06\n",
      "[6,    69] loss: 0.32076, train_accuracy: 89.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    70] loss: 0.33129, train_accuracy: 88.28\n",
      "[6,    71] loss: 0.33192, train_accuracy: 88.48\n",
      "[6,    72] loss: 0.34187, train_accuracy: 88.28\n",
      "[6,    73] loss: 0.33501, train_accuracy: 90.62\n",
      "[6,    74] loss: 0.31488, train_accuracy: 89.65\n",
      "[6,    75] loss: 0.31172, train_accuracy: 88.87\n",
      "[6,    76] loss: 0.30086, train_accuracy: 89.84\n",
      "[6,    77] loss: 0.34784, train_accuracy: 88.48\n",
      "[6,    78] loss: 0.34502, train_accuracy: 89.06\n",
      "[6,    79] loss: 0.27983, train_accuracy: 92.58\n",
      "[6,    80] loss: 0.36256, train_accuracy: 86.91\n",
      "[6,    81] loss: 0.35338, train_accuracy: 88.87\n",
      "[6,    82] loss: 0.34955, train_accuracy: 88.87\n",
      "[6,    83] loss: 0.32041, train_accuracy: 87.89\n",
      "[6,    84] loss: 0.37495, train_accuracy: 88.09\n",
      "[6,    85] loss: 0.30066, train_accuracy: 90.04\n",
      "[6,    86] loss: 0.34351, train_accuracy: 86.72\n",
      "[6,    87] loss: 0.43028, train_accuracy: 86.13\n",
      "[6,    88] loss: 0.28815, train_accuracy: 90.43\n",
      "[6,    89] loss: 0.38065, train_accuracy: 87.11\n",
      "[6,    90] loss: 0.33570, train_accuracy: 89.84\n",
      "[6,    91] loss: 0.34766, train_accuracy: 88.67\n",
      "[6,    92] loss: 0.37303, train_accuracy: 87.89\n",
      "[6,    93] loss: 0.32596, train_accuracy: 88.87\n",
      "[6,    94] loss: 0.38972, train_accuracy: 87.50\n",
      "[6,    95] loss: 0.28850, train_accuracy: 91.21\n",
      "[6,    96] loss: 0.35686, train_accuracy: 87.89\n",
      "[6,    97] loss: 0.33652, train_accuracy: 87.89\n",
      "[6,    98] loss: 0.35866, train_accuracy: 87.80\n",
      "duration: 11 s - train loss: 0.32408 - train accuracy: 89.58 - validation loss: 1.39 - validation accuracy: 62.55 \n",
      "[7,     1] loss: 0.27764, train_accuracy: 92.77\n",
      "[7,     2] loss: 0.25130, train_accuracy: 89.45\n",
      "[7,     3] loss: 0.26986, train_accuracy: 93.75\n",
      "[7,     4] loss: 0.27814, train_accuracy: 92.19\n",
      "[7,     5] loss: 0.25253, train_accuracy: 92.97\n",
      "[7,     6] loss: 0.26862, train_accuracy: 92.38\n",
      "[7,     7] loss: 0.32170, train_accuracy: 90.04\n",
      "[7,     8] loss: 0.30601, train_accuracy: 89.65\n",
      "[7,     9] loss: 0.26962, train_accuracy: 91.60\n",
      "[7,    10] loss: 0.27302, train_accuracy: 91.21\n",
      "[7,    11] loss: 0.25282, train_accuracy: 93.36\n",
      "[7,    12] loss: 0.26764, train_accuracy: 90.62\n",
      "[7,    13] loss: 0.27078, train_accuracy: 91.60\n",
      "[7,    14] loss: 0.24950, train_accuracy: 93.55\n",
      "[7,    15] loss: 0.34007, train_accuracy: 90.82\n",
      "[7,    16] loss: 0.25461, train_accuracy: 92.19\n",
      "[7,    17] loss: 0.27378, train_accuracy: 92.38\n",
      "[7,    18] loss: 0.27581, train_accuracy: 90.62\n",
      "[7,    19] loss: 0.28157, train_accuracy: 91.80\n",
      "[7,    20] loss: 0.27160, train_accuracy: 92.58\n",
      "[7,    21] loss: 0.23000, train_accuracy: 92.97\n",
      "[7,    22] loss: 0.25810, train_accuracy: 91.99\n",
      "[7,    23] loss: 0.31623, train_accuracy: 91.21\n",
      "[7,    24] loss: 0.26135, train_accuracy: 91.41\n",
      "[7,    25] loss: 0.25828, train_accuracy: 93.36\n",
      "[7,    26] loss: 0.26633, train_accuracy: 91.41\n",
      "[7,    27] loss: 0.30153, train_accuracy: 89.26\n",
      "[7,    28] loss: 0.30147, train_accuracy: 90.23\n",
      "[7,    29] loss: 0.25576, train_accuracy: 91.60\n",
      "[7,    30] loss: 0.25512, train_accuracy: 92.19\n",
      "[7,    31] loss: 0.26839, train_accuracy: 91.60\n",
      "[7,    32] loss: 0.25649, train_accuracy: 91.60\n",
      "[7,    33] loss: 0.32382, train_accuracy: 90.04\n",
      "[7,    34] loss: 0.29080, train_accuracy: 89.84\n",
      "[7,    35] loss: 0.31227, train_accuracy: 91.02\n",
      "[7,    36] loss: 0.29527, train_accuracy: 91.41\n",
      "[7,    37] loss: 0.28863, train_accuracy: 90.23\n",
      "[7,    38] loss: 0.34431, train_accuracy: 90.43\n",
      "[7,    39] loss: 0.33477, train_accuracy: 88.87\n",
      "[7,    40] loss: 0.25971, train_accuracy: 91.80\n",
      "[7,    41] loss: 0.30837, train_accuracy: 90.82\n",
      "[7,    42] loss: 0.27972, train_accuracy: 92.38\n",
      "[7,    43] loss: 0.35861, train_accuracy: 88.48\n",
      "[7,    44] loss: 0.32766, train_accuracy: 89.45\n",
      "[7,    45] loss: 0.31712, train_accuracy: 89.26\n",
      "[7,    46] loss: 0.32039, train_accuracy: 90.82\n",
      "[7,    47] loss: 0.30496, train_accuracy: 89.84\n",
      "[7,    48] loss: 0.25694, train_accuracy: 91.41\n",
      "[7,    49] loss: 0.29855, train_accuracy: 90.23\n",
      "[7,    50] loss: 0.29154, train_accuracy: 90.43\n",
      "[7,    51] loss: 0.33833, train_accuracy: 89.26\n",
      "[7,    52] loss: 0.28159, train_accuracy: 92.19\n",
      "[7,    53] loss: 0.32412, train_accuracy: 90.62\n",
      "[7,    54] loss: 0.32821, train_accuracy: 88.87\n",
      "[7,    55] loss: 0.30362, train_accuracy: 90.43\n",
      "[7,    56] loss: 0.30269, train_accuracy: 89.84\n",
      "[7,    57] loss: 0.27570, train_accuracy: 91.02\n",
      "[7,    58] loss: 0.36385, train_accuracy: 87.70\n",
      "[7,    59] loss: 0.29076, train_accuracy: 90.04\n",
      "[7,    60] loss: 0.33480, train_accuracy: 88.48\n",
      "[7,    61] loss: 0.28537, train_accuracy: 89.84\n",
      "[7,    62] loss: 0.31026, train_accuracy: 89.84\n",
      "[7,    63] loss: 0.29891, train_accuracy: 90.43\n",
      "[7,    64] loss: 0.33938, train_accuracy: 89.06\n",
      "[7,    65] loss: 0.30016, train_accuracy: 91.80\n",
      "[7,    66] loss: 0.31115, train_accuracy: 90.23\n",
      "[7,    67] loss: 0.33082, train_accuracy: 90.23\n",
      "[7,    68] loss: 0.32647, train_accuracy: 88.87\n",
      "[7,    69] loss: 0.31826, train_accuracy: 89.26\n",
      "[7,    70] loss: 0.29315, train_accuracy: 91.02\n",
      "[7,    71] loss: 0.31742, train_accuracy: 89.06\n",
      "[7,    72] loss: 0.32621, train_accuracy: 89.26\n",
      "[7,    73] loss: 0.29408, train_accuracy: 91.41\n",
      "[7,    74] loss: 0.32661, train_accuracy: 88.09\n",
      "[7,    75] loss: 0.34789, train_accuracy: 89.84\n",
      "[7,    76] loss: 0.25013, train_accuracy: 91.41\n",
      "[7,    77] loss: 0.33845, train_accuracy: 87.89\n",
      "[7,    78] loss: 0.34489, train_accuracy: 88.48\n",
      "[7,    79] loss: 0.33539, train_accuracy: 88.28\n",
      "[7,    80] loss: 0.27952, train_accuracy: 90.23\n",
      "[7,    81] loss: 0.28704, train_accuracy: 91.02\n",
      "[7,    82] loss: 0.39520, train_accuracy: 86.52\n",
      "[7,    83] loss: 0.35314, train_accuracy: 87.30\n",
      "[7,    84] loss: 0.29422, train_accuracy: 91.41\n",
      "[7,    85] loss: 0.30383, train_accuracy: 90.62\n",
      "[7,    86] loss: 0.32650, train_accuracy: 88.48\n",
      "[7,    87] loss: 0.35224, train_accuracy: 85.35\n",
      "[7,    88] loss: 0.31693, train_accuracy: 89.26\n",
      "[7,    89] loss: 0.35700, train_accuracy: 87.50\n",
      "[7,    90] loss: 0.30587, train_accuracy: 89.06\n",
      "[7,    91] loss: 0.32763, train_accuracy: 89.26\n",
      "[7,    92] loss: 0.35744, train_accuracy: 87.11\n",
      "[7,    93] loss: 0.31132, train_accuracy: 90.04\n",
      "[7,    94] loss: 0.38133, train_accuracy: 87.11\n",
      "[7,    95] loss: 0.29729, train_accuracy: 89.65\n",
      "[7,    96] loss: 0.34155, train_accuracy: 87.89\n",
      "[7,    97] loss: 0.32249, train_accuracy: 90.62\n",
      "[7,    98] loss: 0.31935, train_accuracy: 89.88\n",
      "duration: 10 s - train loss: 0.30222 - train accuracy: 90.33 - validation loss: 1.47 - validation accuracy: 62.11 \n",
      "stopped early after 5 epochs without decrease of validation loss\n",
      "Finished Training\n",
      "cw done\n",
      "pgd done\n",
      "compression rate:  0.75\n",
      "[1,     1] loss: 2.27544, train_accuracy: 41.60\n",
      "[1,     2] loss: 1.81786, train_accuracy: 50.39\n",
      "[1,     3] loss: 1.69456, train_accuracy: 53.12\n",
      "[1,     4] loss: 1.70329, train_accuracy: 49.02\n",
      "[1,     5] loss: 1.50067, train_accuracy: 53.12\n",
      "[1,     6] loss: 1.40210, train_accuracy: 52.54\n",
      "[1,     7] loss: 1.23811, train_accuracy: 57.62\n",
      "[1,     8] loss: 1.38095, train_accuracy: 57.62\n",
      "[1,     9] loss: 1.38021, train_accuracy: 58.20\n",
      "[1,    10] loss: 1.41756, train_accuracy: 56.84\n",
      "[1,    11] loss: 1.39066, train_accuracy: 57.03\n",
      "[1,    12] loss: 1.21536, train_accuracy: 61.52\n",
      "[1,    13] loss: 1.08161, train_accuracy: 63.87\n",
      "[1,    14] loss: 1.24482, train_accuracy: 57.42\n",
      "[1,    15] loss: 1.25826, train_accuracy: 59.96\n",
      "[1,    16] loss: 1.06858, train_accuracy: 66.02\n",
      "[1,    17] loss: 1.17560, train_accuracy: 60.55\n",
      "[1,    18] loss: 1.13226, train_accuracy: 60.94\n",
      "[1,    19] loss: 1.06415, train_accuracy: 62.89\n",
      "[1,    20] loss: 1.05154, train_accuracy: 66.21\n",
      "[1,    21] loss: 1.00740, train_accuracy: 63.67\n",
      "[1,    22] loss: 1.08630, train_accuracy: 62.30\n",
      "[1,    23] loss: 1.14683, train_accuracy: 62.70\n",
      "[1,    24] loss: 1.09661, train_accuracy: 65.62\n",
      "[1,    25] loss: 1.04877, train_accuracy: 65.82\n",
      "[1,    26] loss: 1.05023, train_accuracy: 65.23\n",
      "[1,    27] loss: 0.99510, train_accuracy: 67.19\n",
      "[1,    28] loss: 0.98511, train_accuracy: 67.77\n",
      "[1,    29] loss: 0.93599, train_accuracy: 67.58\n",
      "[1,    30] loss: 0.96511, train_accuracy: 67.97\n",
      "[1,    31] loss: 0.92613, train_accuracy: 67.77\n",
      "[1,    32] loss: 0.99970, train_accuracy: 66.60\n",
      "[1,    33] loss: 0.92561, train_accuracy: 68.55\n",
      "[1,    34] loss: 0.96866, train_accuracy: 69.53\n",
      "[1,    35] loss: 1.02088, train_accuracy: 66.21\n",
      "[1,    36] loss: 0.86397, train_accuracy: 69.14\n",
      "[1,    37] loss: 0.87483, train_accuracy: 69.92\n",
      "[1,    38] loss: 0.91979, train_accuracy: 69.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    39] loss: 0.83889, train_accuracy: 69.14\n",
      "[1,    40] loss: 0.91889, train_accuracy: 70.70\n",
      "[1,    41] loss: 0.86782, train_accuracy: 69.53\n",
      "[1,    42] loss: 0.91700, train_accuracy: 66.80\n",
      "[1,    43] loss: 0.87240, train_accuracy: 67.97\n",
      "[1,    44] loss: 0.85234, train_accuracy: 69.73\n",
      "[1,    45] loss: 0.88553, train_accuracy: 68.16\n",
      "[1,    46] loss: 0.91718, train_accuracy: 68.95\n",
      "[1,    47] loss: 0.97437, train_accuracy: 65.82\n",
      "[1,    48] loss: 0.89719, train_accuracy: 67.97\n",
      "[1,    49] loss: 0.91656, train_accuracy: 67.77\n",
      "[1,    50] loss: 0.74511, train_accuracy: 74.41\n",
      "[1,    51] loss: 0.91893, train_accuracy: 67.38\n",
      "[1,    52] loss: 0.93508, train_accuracy: 67.97\n",
      "[1,    53] loss: 0.77706, train_accuracy: 70.90\n",
      "[1,    54] loss: 0.82157, train_accuracy: 71.09\n",
      "[1,    55] loss: 0.87828, train_accuracy: 71.29\n",
      "[1,    56] loss: 0.88995, train_accuracy: 68.36\n",
      "[1,    57] loss: 0.77035, train_accuracy: 71.68\n",
      "[1,    58] loss: 0.86377, train_accuracy: 69.92\n",
      "[1,    59] loss: 0.81747, train_accuracy: 69.53\n",
      "[1,    60] loss: 0.90215, train_accuracy: 66.80\n",
      "[1,    61] loss: 0.82432, train_accuracy: 71.09\n",
      "[1,    62] loss: 0.93036, train_accuracy: 67.58\n",
      "[1,    63] loss: 0.90194, train_accuracy: 68.16\n",
      "[1,    64] loss: 0.73083, train_accuracy: 72.66\n",
      "[1,    65] loss: 0.78289, train_accuracy: 73.05\n",
      "[1,    66] loss: 0.78723, train_accuracy: 70.90\n",
      "[1,    67] loss: 0.83411, train_accuracy: 70.51\n",
      "[1,    68] loss: 0.85897, train_accuracy: 68.36\n",
      "[1,    69] loss: 0.85487, train_accuracy: 69.14\n",
      "[1,    70] loss: 0.84409, train_accuracy: 69.92\n",
      "[1,    71] loss: 0.81296, train_accuracy: 71.48\n",
      "[1,    72] loss: 0.82465, train_accuracy: 72.27\n",
      "[1,    73] loss: 0.84076, train_accuracy: 73.05\n",
      "[1,    74] loss: 0.68800, train_accuracy: 74.61\n",
      "[1,    75] loss: 0.83384, train_accuracy: 71.09\n",
      "[1,    76] loss: 0.84956, train_accuracy: 67.97\n",
      "[1,    77] loss: 0.79466, train_accuracy: 69.53\n",
      "[1,    78] loss: 0.79995, train_accuracy: 69.73\n",
      "[1,    79] loss: 0.88666, train_accuracy: 67.77\n",
      "[1,    80] loss: 0.80164, train_accuracy: 70.31\n",
      "[1,    81] loss: 0.70796, train_accuracy: 73.05\n",
      "[1,    82] loss: 0.76255, train_accuracy: 70.12\n",
      "[1,    83] loss: 0.79117, train_accuracy: 69.53\n",
      "[1,    84] loss: 0.88417, train_accuracy: 67.19\n",
      "[1,    85] loss: 0.82035, train_accuracy: 70.51\n",
      "[1,    86] loss: 0.87312, train_accuracy: 70.90\n",
      "[1,    87] loss: 0.80825, train_accuracy: 71.48\n",
      "[1,    88] loss: 0.70007, train_accuracy: 74.02\n",
      "[1,    89] loss: 0.68707, train_accuracy: 75.20\n",
      "[1,    90] loss: 0.81274, train_accuracy: 70.70\n",
      "[1,    91] loss: 0.70870, train_accuracy: 73.63\n",
      "[1,    92] loss: 0.76006, train_accuracy: 73.24\n",
      "[1,    93] loss: 0.81524, train_accuracy: 73.24\n",
      "[1,    94] loss: 0.75370, train_accuracy: 71.09\n",
      "[1,    95] loss: 0.73527, train_accuracy: 74.61\n",
      "[1,    96] loss: 0.81354, train_accuracy: 71.09\n",
      "[1,    97] loss: 0.72758, train_accuracy: 74.22\n",
      "[1,    98] loss: 0.88798, train_accuracy: 67.26\n",
      "duration: 12 s - train loss: 0.96959 - train accuracy: 67.06 - validation loss: 1.32 - validation accuracy: 59.81 \n",
      "[2,     1] loss: 0.57829, train_accuracy: 77.54\n",
      "[2,     2] loss: 0.69750, train_accuracy: 74.80\n",
      "[2,     3] loss: 0.63717, train_accuracy: 76.76\n",
      "[2,     4] loss: 0.75014, train_accuracy: 73.24\n",
      "[2,     5] loss: 0.64272, train_accuracy: 75.39\n",
      "[2,     6] loss: 0.65125, train_accuracy: 75.20\n",
      "[2,     7] loss: 0.68370, train_accuracy: 76.95\n",
      "[2,     8] loss: 0.61650, train_accuracy: 76.76\n",
      "[2,     9] loss: 0.72591, train_accuracy: 72.46\n",
      "[2,    10] loss: 0.64577, train_accuracy: 76.56\n",
      "[2,    11] loss: 0.62181, train_accuracy: 76.56\n",
      "[2,    12] loss: 0.71079, train_accuracy: 74.61\n",
      "[2,    13] loss: 0.71101, train_accuracy: 75.00\n",
      "[2,    14] loss: 0.64902, train_accuracy: 77.34\n",
      "[2,    15] loss: 0.64224, train_accuracy: 77.73\n",
      "[2,    16] loss: 0.69089, train_accuracy: 76.76\n",
      "[2,    17] loss: 0.71784, train_accuracy: 73.63\n",
      "[2,    18] loss: 0.73501, train_accuracy: 73.44\n",
      "[2,    19] loss: 0.62122, train_accuracy: 75.59\n",
      "[2,    20] loss: 0.64318, train_accuracy: 75.20\n",
      "[2,    21] loss: 0.79146, train_accuracy: 71.48\n",
      "[2,    22] loss: 0.69667, train_accuracy: 73.63\n",
      "[2,    23] loss: 0.65749, train_accuracy: 77.73\n",
      "[2,    24] loss: 0.66296, train_accuracy: 76.56\n",
      "[2,    25] loss: 0.63543, train_accuracy: 76.56\n",
      "[2,    26] loss: 0.63058, train_accuracy: 77.15\n",
      "[2,    27] loss: 0.70822, train_accuracy: 74.61\n",
      "[2,    28] loss: 0.69284, train_accuracy: 73.05\n",
      "[2,    29] loss: 0.67120, train_accuracy: 74.80\n",
      "[2,    30] loss: 0.75918, train_accuracy: 75.00\n",
      "[2,    31] loss: 0.61867, train_accuracy: 75.98\n",
      "[2,    32] loss: 0.67120, train_accuracy: 75.78\n",
      "[2,    33] loss: 0.80898, train_accuracy: 71.48\n",
      "[2,    34] loss: 0.76887, train_accuracy: 71.48\n",
      "[2,    35] loss: 0.57450, train_accuracy: 78.91\n",
      "[2,    36] loss: 0.75861, train_accuracy: 73.24\n",
      "[2,    37] loss: 0.63642, train_accuracy: 75.78\n",
      "[2,    38] loss: 0.67105, train_accuracy: 76.17\n",
      "[2,    39] loss: 0.66951, train_accuracy: 76.56\n",
      "[2,    40] loss: 0.68828, train_accuracy: 77.15\n",
      "[2,    41] loss: 0.78360, train_accuracy: 72.27\n",
      "[2,    42] loss: 0.67196, train_accuracy: 75.39\n",
      "[2,    43] loss: 0.63686, train_accuracy: 77.15\n",
      "[2,    44] loss: 0.71872, train_accuracy: 75.00\n",
      "[2,    45] loss: 0.70769, train_accuracy: 73.24\n",
      "[2,    46] loss: 0.64836, train_accuracy: 76.37\n",
      "[2,    47] loss: 0.72918, train_accuracy: 71.09\n",
      "[2,    48] loss: 0.67119, train_accuracy: 75.59\n",
      "[2,    49] loss: 0.69436, train_accuracy: 75.78\n",
      "[2,    50] loss: 0.66195, train_accuracy: 74.41\n",
      "[2,    51] loss: 0.66245, train_accuracy: 77.34\n",
      "[2,    52] loss: 0.59606, train_accuracy: 79.49\n",
      "[2,    53] loss: 0.78839, train_accuracy: 71.68\n",
      "[2,    54] loss: 0.59191, train_accuracy: 76.56\n",
      "[2,    55] loss: 0.62505, train_accuracy: 74.61\n",
      "[2,    56] loss: 0.61816, train_accuracy: 77.73\n",
      "[2,    57] loss: 0.63268, train_accuracy: 76.17\n",
      "[2,    58] loss: 0.64096, train_accuracy: 77.15\n",
      "[2,    59] loss: 0.62144, train_accuracy: 76.37\n",
      "[2,    60] loss: 0.59865, train_accuracy: 78.71\n",
      "[2,    61] loss: 0.72114, train_accuracy: 73.44\n",
      "[2,    62] loss: 0.70872, train_accuracy: 74.61\n",
      "[2,    63] loss: 0.67112, train_accuracy: 73.63\n",
      "[2,    64] loss: 0.60025, train_accuracy: 77.73\n",
      "[2,    65] loss: 0.69817, train_accuracy: 74.80\n",
      "[2,    66] loss: 0.75896, train_accuracy: 70.90\n",
      "[2,    67] loss: 0.68685, train_accuracy: 74.80\n",
      "[2,    68] loss: 0.67440, train_accuracy: 75.00\n",
      "[2,    69] loss: 0.69494, train_accuracy: 72.66\n",
      "[2,    70] loss: 0.73422, train_accuracy: 75.00\n",
      "[2,    71] loss: 0.73658, train_accuracy: 72.07\n",
      "[2,    72] loss: 0.61351, train_accuracy: 79.88\n",
      "[2,    73] loss: 0.63926, train_accuracy: 74.02\n",
      "[2,    74] loss: 0.60149, train_accuracy: 77.93\n",
      "[2,    75] loss: 0.67797, train_accuracy: 75.59\n",
      "[2,    76] loss: 0.62602, train_accuracy: 76.95\n",
      "[2,    77] loss: 0.57897, train_accuracy: 79.49\n",
      "[2,    78] loss: 0.67496, train_accuracy: 75.98\n",
      "[2,    79] loss: 0.67579, train_accuracy: 74.41\n",
      "[2,    80] loss: 0.68753, train_accuracy: 75.78\n",
      "[2,    81] loss: 0.66222, train_accuracy: 75.20\n",
      "[2,    82] loss: 0.60019, train_accuracy: 77.54\n",
      "[2,    83] loss: 0.70192, train_accuracy: 75.59\n",
      "[2,    84] loss: 0.68525, train_accuracy: 77.15\n",
      "[2,    85] loss: 0.64980, train_accuracy: 75.39\n",
      "[2,    86] loss: 0.61937, train_accuracy: 78.91\n",
      "[2,    87] loss: 0.67534, train_accuracy: 75.39\n",
      "[2,    88] loss: 0.71714, train_accuracy: 75.59\n",
      "[2,    89] loss: 0.74233, train_accuracy: 73.05\n",
      "[2,    90] loss: 0.70619, train_accuracy: 74.80\n",
      "[2,    91] loss: 0.72847, train_accuracy: 71.68\n",
      "[2,    92] loss: 0.62915, train_accuracy: 77.73\n",
      "[2,    93] loss: 0.64911, train_accuracy: 76.76\n",
      "[2,    94] loss: 0.66876, train_accuracy: 73.83\n",
      "[2,    95] loss: 0.68540, train_accuracy: 74.02\n",
      "[2,    96] loss: 0.60919, train_accuracy: 77.15\n",
      "[2,    97] loss: 0.65907, train_accuracy: 75.39\n",
      "[2,    98] loss: 0.64815, train_accuracy: 75.60\n",
      "duration: 12 s - train loss: 0.67287 - train accuracy: 75.43 - validation loss: 1.25 - validation accuracy: 60.99 \n",
      "[3,     1] loss: 0.54262, train_accuracy: 81.64\n",
      "[3,     2] loss: 0.60171, train_accuracy: 78.52\n",
      "[3,     3] loss: 0.60032, train_accuracy: 77.34\n",
      "[3,     4] loss: 0.59980, train_accuracy: 77.93\n",
      "[3,     5] loss: 0.63175, train_accuracy: 75.39\n",
      "[3,     6] loss: 0.66607, train_accuracy: 76.56\n",
      "[3,     7] loss: 0.55428, train_accuracy: 79.69\n",
      "[3,     8] loss: 0.63001, train_accuracy: 77.73\n",
      "[3,     9] loss: 0.58095, train_accuracy: 79.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    10] loss: 0.61302, train_accuracy: 77.15\n",
      "[3,    11] loss: 0.59912, train_accuracy: 79.30\n",
      "[3,    12] loss: 0.57429, train_accuracy: 80.08\n",
      "[3,    13] loss: 0.64461, train_accuracy: 76.95\n",
      "[3,    14] loss: 0.54358, train_accuracy: 80.86\n",
      "[3,    15] loss: 0.57310, train_accuracy: 79.30\n",
      "[3,    16] loss: 0.59006, train_accuracy: 78.71\n",
      "[3,    17] loss: 0.64195, train_accuracy: 75.59\n",
      "[3,    18] loss: 0.54751, train_accuracy: 83.20\n",
      "[3,    19] loss: 0.56973, train_accuracy: 79.88\n",
      "[3,    20] loss: 0.55320, train_accuracy: 78.52\n",
      "[3,    21] loss: 0.57215, train_accuracy: 79.49\n",
      "[3,    22] loss: 0.70220, train_accuracy: 75.39\n",
      "[3,    23] loss: 0.61950, train_accuracy: 75.98\n",
      "[3,    24] loss: 0.67682, train_accuracy: 75.00\n",
      "[3,    25] loss: 0.61033, train_accuracy: 78.52\n",
      "[3,    26] loss: 0.62644, train_accuracy: 77.34\n",
      "[3,    27] loss: 0.62422, train_accuracy: 78.32\n",
      "[3,    28] loss: 0.49646, train_accuracy: 82.23\n",
      "[3,    29] loss: 0.56745, train_accuracy: 78.52\n",
      "[3,    30] loss: 0.58011, train_accuracy: 78.32\n",
      "[3,    31] loss: 0.61602, train_accuracy: 79.49\n",
      "[3,    32] loss: 0.64183, train_accuracy: 79.10\n",
      "[3,    33] loss: 0.60812, train_accuracy: 78.12\n",
      "[3,    34] loss: 0.61325, train_accuracy: 78.91\n",
      "[3,    35] loss: 0.56845, train_accuracy: 76.76\n",
      "[3,    36] loss: 0.60405, train_accuracy: 78.12\n",
      "[3,    37] loss: 0.62167, train_accuracy: 77.54\n",
      "[3,    38] loss: 0.61285, train_accuracy: 77.54\n",
      "[3,    39] loss: 0.54742, train_accuracy: 79.10\n",
      "[3,    40] loss: 0.64167, train_accuracy: 75.78\n",
      "[3,    41] loss: 0.59186, train_accuracy: 77.73\n",
      "[3,    42] loss: 0.54222, train_accuracy: 81.84\n",
      "[3,    43] loss: 0.58897, train_accuracy: 79.10\n",
      "[3,    44] loss: 0.58778, train_accuracy: 77.15\n",
      "[3,    45] loss: 0.54214, train_accuracy: 82.23\n",
      "[3,    46] loss: 0.58485, train_accuracy: 79.69\n",
      "[3,    47] loss: 0.55271, train_accuracy: 79.49\n",
      "[3,    48] loss: 0.56535, train_accuracy: 77.93\n",
      "[3,    49] loss: 0.61885, train_accuracy: 77.93\n",
      "[3,    50] loss: 0.56527, train_accuracy: 80.47\n",
      "[3,    51] loss: 0.61983, train_accuracy: 78.12\n",
      "[3,    52] loss: 0.61016, train_accuracy: 76.95\n",
      "[3,    53] loss: 0.66496, train_accuracy: 75.59\n",
      "[3,    54] loss: 0.61070, train_accuracy: 77.54\n",
      "[3,    55] loss: 0.60762, train_accuracy: 77.34\n",
      "[3,    56] loss: 0.59623, train_accuracy: 77.54\n",
      "[3,    57] loss: 0.62223, train_accuracy: 76.95\n",
      "[3,    58] loss: 0.68274, train_accuracy: 75.98\n",
      "[3,    59] loss: 0.59540, train_accuracy: 78.71\n",
      "[3,    60] loss: 0.58770, train_accuracy: 78.71\n",
      "[3,    61] loss: 0.54482, train_accuracy: 79.49\n",
      "[3,    62] loss: 0.54050, train_accuracy: 81.64\n",
      "[3,    63] loss: 0.65568, train_accuracy: 76.76\n",
      "[3,    64] loss: 0.58908, train_accuracy: 79.10\n",
      "[3,    65] loss: 0.58601, train_accuracy: 78.71\n",
      "[3,    66] loss: 0.59652, train_accuracy: 77.73\n",
      "[3,    67] loss: 0.60414, train_accuracy: 79.10\n",
      "[3,    68] loss: 0.57640, train_accuracy: 80.08\n",
      "[3,    69] loss: 0.61137, train_accuracy: 78.91\n",
      "[3,    70] loss: 0.61655, train_accuracy: 77.93\n",
      "[3,    71] loss: 0.59209, train_accuracy: 75.59\n",
      "[3,    72] loss: 0.64952, train_accuracy: 77.54\n",
      "[3,    73] loss: 0.56553, train_accuracy: 79.69\n",
      "[3,    74] loss: 0.66415, train_accuracy: 74.22\n",
      "[3,    75] loss: 0.63430, train_accuracy: 77.73\n",
      "[3,    76] loss: 0.60540, train_accuracy: 78.12\n",
      "[3,    77] loss: 0.56732, train_accuracy: 79.30\n",
      "[3,    78] loss: 0.58257, train_accuracy: 79.49\n",
      "[3,    79] loss: 0.58112, train_accuracy: 79.10\n",
      "[3,    80] loss: 0.57658, train_accuracy: 78.91\n",
      "[3,    81] loss: 0.58131, train_accuracy: 77.54\n",
      "[3,    82] loss: 0.54919, train_accuracy: 80.66\n",
      "[3,    83] loss: 0.62279, train_accuracy: 75.59\n",
      "[3,    84] loss: 0.61454, train_accuracy: 76.95\n",
      "[3,    85] loss: 0.65805, train_accuracy: 75.39\n",
      "[3,    86] loss: 0.59674, train_accuracy: 79.49\n",
      "[3,    87] loss: 0.63152, train_accuracy: 77.54\n",
      "[3,    88] loss: 0.63870, train_accuracy: 75.98\n",
      "[3,    89] loss: 0.61066, train_accuracy: 78.32\n",
      "[3,    90] loss: 0.61391, train_accuracy: 78.32\n",
      "[3,    91] loss: 0.63368, train_accuracy: 76.76\n",
      "[3,    92] loss: 0.57763, train_accuracy: 78.91\n",
      "[3,    93] loss: 0.62346, train_accuracy: 76.56\n",
      "[3,    94] loss: 0.60567, train_accuracy: 77.54\n",
      "[3,    95] loss: 0.56977, train_accuracy: 79.49\n",
      "[3,    96] loss: 0.55569, train_accuracy: 79.49\n",
      "[3,    97] loss: 0.57412, train_accuracy: 79.10\n",
      "[3,    98] loss: 0.61217, train_accuracy: 75.60\n",
      "duration: 16 s - train loss: 0.59955 - train accuracy: 78.25 - validation loss: 1.23 - validation accuracy: 62.22 \n",
      "[4,     1] loss: 0.55725, train_accuracy: 80.86\n",
      "[4,     2] loss: 0.52722, train_accuracy: 82.03\n",
      "[4,     3] loss: 0.53870, train_accuracy: 80.27\n",
      "[4,     4] loss: 0.56994, train_accuracy: 80.08\n",
      "[4,     5] loss: 0.56425, train_accuracy: 79.30\n",
      "[4,     6] loss: 0.50144, train_accuracy: 81.05\n",
      "[4,     7] loss: 0.51328, train_accuracy: 81.64\n",
      "[4,     8] loss: 0.51028, train_accuracy: 81.45\n",
      "[4,     9] loss: 0.51931, train_accuracy: 80.27\n",
      "[4,    10] loss: 0.53610, train_accuracy: 82.23\n",
      "[4,    11] loss: 0.53188, train_accuracy: 78.71\n",
      "[4,    12] loss: 0.50234, train_accuracy: 82.81\n",
      "[4,    13] loss: 0.53661, train_accuracy: 80.86\n",
      "[4,    14] loss: 0.51173, train_accuracy: 80.47\n",
      "[4,    15] loss: 0.48205, train_accuracy: 83.98\n",
      "[4,    16] loss: 0.54897, train_accuracy: 78.91\n",
      "[4,    17] loss: 0.54367, train_accuracy: 79.88\n",
      "[4,    18] loss: 0.56853, train_accuracy: 79.49\n",
      "[4,    19] loss: 0.52262, train_accuracy: 81.45\n",
      "[4,    20] loss: 0.53825, train_accuracy: 82.03\n",
      "[4,    21] loss: 0.53470, train_accuracy: 81.05\n",
      "[4,    22] loss: 0.49202, train_accuracy: 81.84\n",
      "[4,    23] loss: 0.56236, train_accuracy: 79.10\n",
      "[4,    24] loss: 0.57470, train_accuracy: 78.52\n",
      "[4,    25] loss: 0.59185, train_accuracy: 79.69\n",
      "[4,    26] loss: 0.55859, train_accuracy: 78.52\n",
      "[4,    27] loss: 0.54506, train_accuracy: 81.05\n",
      "[4,    28] loss: 0.54605, train_accuracy: 82.03\n",
      "[4,    29] loss: 0.58751, train_accuracy: 78.32\n",
      "[4,    30] loss: 0.56686, train_accuracy: 78.71\n",
      "[4,    31] loss: 0.58942, train_accuracy: 79.30\n",
      "[4,    32] loss: 0.62645, train_accuracy: 75.78\n",
      "[4,    33] loss: 0.64791, train_accuracy: 77.34\n",
      "[4,    34] loss: 0.65663, train_accuracy: 77.73\n",
      "[4,    35] loss: 0.51343, train_accuracy: 82.03\n",
      "[4,    36] loss: 0.58070, train_accuracy: 78.52\n",
      "[4,    37] loss: 0.50640, train_accuracy: 82.42\n",
      "[4,    38] loss: 0.50353, train_accuracy: 83.20\n",
      "[4,    39] loss: 0.64856, train_accuracy: 74.80\n",
      "[4,    40] loss: 0.50802, train_accuracy: 80.86\n",
      "[4,    41] loss: 0.53675, train_accuracy: 80.86\n",
      "[4,    42] loss: 0.52352, train_accuracy: 79.49\n",
      "[4,    43] loss: 0.54974, train_accuracy: 80.27\n",
      "[4,    44] loss: 0.58252, train_accuracy: 78.91\n",
      "[4,    45] loss: 0.58321, train_accuracy: 78.12\n",
      "[4,    46] loss: 0.50074, train_accuracy: 80.27\n",
      "[4,    47] loss: 0.51926, train_accuracy: 80.86\n",
      "[4,    48] loss: 0.54394, train_accuracy: 81.05\n",
      "[4,    49] loss: 0.56382, train_accuracy: 79.88\n",
      "[4,    50] loss: 0.53417, train_accuracy: 81.45\n",
      "[4,    51] loss: 0.53904, train_accuracy: 79.30\n",
      "[4,    52] loss: 0.65091, train_accuracy: 77.34\n",
      "[4,    53] loss: 0.55953, train_accuracy: 77.34\n",
      "[4,    54] loss: 0.61709, train_accuracy: 80.27\n",
      "[4,    55] loss: 0.55648, train_accuracy: 78.71\n",
      "[4,    56] loss: 0.50960, train_accuracy: 82.42\n",
      "[4,    57] loss: 0.56893, train_accuracy: 79.69\n",
      "[4,    58] loss: 0.51659, train_accuracy: 77.73\n",
      "[4,    59] loss: 0.55524, train_accuracy: 80.86\n",
      "[4,    60] loss: 0.59558, train_accuracy: 79.30\n",
      "[4,    61] loss: 0.61405, train_accuracy: 78.71\n",
      "[4,    62] loss: 0.55938, train_accuracy: 79.69\n",
      "[4,    63] loss: 0.63846, train_accuracy: 77.54\n",
      "[4,    64] loss: 0.56348, train_accuracy: 80.08\n",
      "[4,    65] loss: 0.62080, train_accuracy: 77.15\n",
      "[4,    66] loss: 0.53660, train_accuracy: 79.69\n",
      "[4,    67] loss: 0.56552, train_accuracy: 82.23\n",
      "[4,    68] loss: 0.59553, train_accuracy: 77.93\n",
      "[4,    69] loss: 0.57061, train_accuracy: 79.30\n",
      "[4,    70] loss: 0.60535, train_accuracy: 78.32\n",
      "[4,    71] loss: 0.58677, train_accuracy: 79.88\n",
      "[4,    72] loss: 0.51827, train_accuracy: 80.66\n",
      "[4,    73] loss: 0.54282, train_accuracy: 81.25\n",
      "[4,    74] loss: 0.60861, train_accuracy: 78.52\n",
      "[4,    75] loss: 0.60523, train_accuracy: 77.54\n",
      "[4,    76] loss: 0.58434, train_accuracy: 81.25\n",
      "[4,    77] loss: 0.55830, train_accuracy: 80.86\n",
      "[4,    78] loss: 0.58256, train_accuracy: 79.69\n",
      "[4,    79] loss: 0.50210, train_accuracy: 80.86\n",
      "[4,    80] loss: 0.54983, train_accuracy: 79.69\n",
      "[4,    81] loss: 0.56088, train_accuracy: 80.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,    82] loss: 0.57556, train_accuracy: 82.42\n",
      "[4,    83] loss: 0.62533, train_accuracy: 78.52\n",
      "[4,    84] loss: 0.56377, train_accuracy: 78.71\n",
      "[4,    85] loss: 0.59354, train_accuracy: 77.93\n",
      "[4,    86] loss: 0.55756, train_accuracy: 79.69\n",
      "[4,    87] loss: 0.49982, train_accuracy: 80.66\n",
      "[4,    88] loss: 0.56076, train_accuracy: 80.08\n",
      "[4,    89] loss: 0.55987, train_accuracy: 80.08\n",
      "[4,    90] loss: 0.63704, train_accuracy: 76.95\n",
      "[4,    91] loss: 0.52661, train_accuracy: 79.88\n",
      "[4,    92] loss: 0.54289, train_accuracy: 79.88\n",
      "[4,    93] loss: 0.53883, train_accuracy: 81.25\n",
      "[4,    94] loss: 0.55844, train_accuracy: 77.93\n",
      "[4,    95] loss: 0.55982, train_accuracy: 80.08\n",
      "[4,    96] loss: 0.68819, train_accuracy: 75.98\n",
      "[4,    97] loss: 0.51579, train_accuracy: 79.88\n",
      "[4,    98] loss: 0.59802, train_accuracy: 79.46\n",
      "duration: 18 s - train loss: 0.55962 - train accuracy: 79.83 - validation loss: 1.24 - validation accuracy: 61.89 \n",
      "[5,     1] loss: 0.49228, train_accuracy: 81.84\n",
      "[5,     2] loss: 0.48200, train_accuracy: 82.42\n",
      "[5,     3] loss: 0.51434, train_accuracy: 81.84\n",
      "[5,     4] loss: 0.48902, train_accuracy: 81.84\n",
      "[5,     5] loss: 0.51943, train_accuracy: 81.05\n",
      "[5,     6] loss: 0.51754, train_accuracy: 82.03\n",
      "[5,     7] loss: 0.48767, train_accuracy: 82.23\n",
      "[5,     8] loss: 0.51852, train_accuracy: 82.42\n",
      "[5,     9] loss: 0.49274, train_accuracy: 82.03\n",
      "[5,    10] loss: 0.54926, train_accuracy: 78.32\n",
      "[5,    11] loss: 0.53039, train_accuracy: 82.23\n",
      "[5,    12] loss: 0.46513, train_accuracy: 84.77\n",
      "[5,    13] loss: 0.50387, train_accuracy: 83.01\n",
      "[5,    14] loss: 0.52166, train_accuracy: 80.08\n",
      "[5,    15] loss: 0.55883, train_accuracy: 80.08\n",
      "[5,    16] loss: 0.50516, train_accuracy: 81.84\n",
      "[5,    17] loss: 0.46486, train_accuracy: 83.59\n",
      "[5,    18] loss: 0.57048, train_accuracy: 77.34\n",
      "[5,    19] loss: 0.52813, train_accuracy: 81.05\n",
      "[5,    20] loss: 0.46472, train_accuracy: 85.55\n",
      "[5,    21] loss: 0.46325, train_accuracy: 84.57\n",
      "[5,    22] loss: 0.49717, train_accuracy: 81.84\n",
      "[5,    23] loss: 0.52400, train_accuracy: 79.88\n",
      "[5,    24] loss: 0.56863, train_accuracy: 80.27\n",
      "[5,    25] loss: 0.51332, train_accuracy: 80.66\n",
      "[5,    26] loss: 0.55325, train_accuracy: 82.42\n",
      "[5,    27] loss: 0.46400, train_accuracy: 83.40\n",
      "[5,    28] loss: 0.52240, train_accuracy: 82.62\n",
      "[5,    29] loss: 0.51765, train_accuracy: 82.62\n",
      "[5,    30] loss: 0.43309, train_accuracy: 84.18\n",
      "[5,    31] loss: 0.49288, train_accuracy: 83.79\n",
      "[5,    32] loss: 0.53654, train_accuracy: 81.64\n",
      "[5,    33] loss: 0.56258, train_accuracy: 79.49\n",
      "[5,    34] loss: 0.57256, train_accuracy: 79.30\n",
      "[5,    35] loss: 0.53036, train_accuracy: 79.69\n",
      "[5,    36] loss: 0.57398, train_accuracy: 78.12\n",
      "[5,    37] loss: 0.46783, train_accuracy: 82.62\n",
      "[5,    38] loss: 0.55334, train_accuracy: 80.08\n",
      "[5,    39] loss: 0.51149, train_accuracy: 82.42\n",
      "[5,    40] loss: 0.49255, train_accuracy: 83.01\n",
      "[5,    41] loss: 0.51673, train_accuracy: 82.42\n",
      "[5,    42] loss: 0.54406, train_accuracy: 80.27\n",
      "[5,    43] loss: 0.52137, train_accuracy: 80.08\n",
      "[5,    44] loss: 0.51491, train_accuracy: 81.25\n",
      "[5,    45] loss: 0.42644, train_accuracy: 84.57\n",
      "[5,    46] loss: 0.53258, train_accuracy: 81.05\n",
      "[5,    47] loss: 0.50283, train_accuracy: 83.59\n",
      "[5,    48] loss: 0.55741, train_accuracy: 78.52\n",
      "[5,    49] loss: 0.53412, train_accuracy: 82.03\n",
      "[5,    50] loss: 0.50101, train_accuracy: 82.81\n",
      "[5,    51] loss: 0.50292, train_accuracy: 81.45\n",
      "[5,    52] loss: 0.58808, train_accuracy: 78.12\n",
      "[5,    53] loss: 0.53160, train_accuracy: 80.86\n",
      "[5,    54] loss: 0.50814, train_accuracy: 82.42\n",
      "[5,    55] loss: 0.53952, train_accuracy: 79.88\n",
      "[5,    56] loss: 0.59459, train_accuracy: 78.71\n",
      "[5,    57] loss: 0.48093, train_accuracy: 82.81\n",
      "[5,    58] loss: 0.52949, train_accuracy: 80.86\n",
      "[5,    59] loss: 0.56480, train_accuracy: 80.66\n",
      "[5,    60] loss: 0.47959, train_accuracy: 83.79\n",
      "[5,    61] loss: 0.51669, train_accuracy: 80.66\n",
      "[5,    62] loss: 0.55937, train_accuracy: 78.52\n",
      "[5,    63] loss: 0.61172, train_accuracy: 78.52\n",
      "[5,    64] loss: 0.60147, train_accuracy: 78.71\n",
      "[5,    65] loss: 0.47591, train_accuracy: 83.98\n",
      "[5,    66] loss: 0.57252, train_accuracy: 76.95\n",
      "[5,    67] loss: 0.52792, train_accuracy: 80.47\n",
      "[5,    68] loss: 0.57151, train_accuracy: 78.91\n",
      "[5,    69] loss: 0.53147, train_accuracy: 82.42\n",
      "[5,    70] loss: 0.51691, train_accuracy: 83.98\n",
      "[5,    71] loss: 0.53583, train_accuracy: 80.66\n",
      "[5,    72] loss: 0.57132, train_accuracy: 79.30\n",
      "[5,    73] loss: 0.56499, train_accuracy: 82.03\n",
      "[5,    74] loss: 0.51067, train_accuracy: 81.05\n",
      "[5,    75] loss: 0.59270, train_accuracy: 79.88\n",
      "[5,    76] loss: 0.54346, train_accuracy: 80.66\n",
      "[5,    77] loss: 0.56124, train_accuracy: 79.10\n",
      "[5,    78] loss: 0.55555, train_accuracy: 78.71\n",
      "[5,    79] loss: 0.57417, train_accuracy: 79.30\n",
      "[5,    80] loss: 0.54228, train_accuracy: 81.25\n",
      "[5,    81] loss: 0.55840, train_accuracy: 80.66\n",
      "[5,    82] loss: 0.48085, train_accuracy: 82.42\n",
      "[5,    83] loss: 0.51904, train_accuracy: 81.25\n",
      "[5,    84] loss: 0.52374, train_accuracy: 81.25\n",
      "[5,    85] loss: 0.53684, train_accuracy: 80.66\n",
      "[5,    86] loss: 0.52908, train_accuracy: 79.88\n",
      "[5,    87] loss: 0.56456, train_accuracy: 78.71\n",
      "[5,    88] loss: 0.55768, train_accuracy: 77.93\n",
      "[5,    89] loss: 0.51392, train_accuracy: 81.45\n",
      "[5,    90] loss: 0.56280, train_accuracy: 79.69\n",
      "[5,    91] loss: 0.55049, train_accuracy: 78.71\n",
      "[5,    92] loss: 0.52198, train_accuracy: 81.25\n",
      "[5,    93] loss: 0.63627, train_accuracy: 79.69\n",
      "[5,    94] loss: 0.57052, train_accuracy: 80.27\n",
      "[5,    95] loss: 0.54639, train_accuracy: 79.69\n",
      "[5,    96] loss: 0.54290, train_accuracy: 81.05\n",
      "[5,    97] loss: 0.50894, train_accuracy: 80.47\n",
      "[5,    98] loss: 0.55411, train_accuracy: 77.68\n",
      "duration: 22 s - train loss: 0.52872 - train accuracy: 81.04 - validation loss: 1.24 - validation accuracy: 62.66 \n",
      "[6,     1] loss: 0.44114, train_accuracy: 84.96\n",
      "[6,     2] loss: 0.49892, train_accuracy: 82.03\n",
      "[6,     3] loss: 0.52319, train_accuracy: 81.05\n",
      "[6,     4] loss: 0.49446, train_accuracy: 82.42\n",
      "[6,     5] loss: 0.53012, train_accuracy: 80.86\n",
      "[6,     6] loss: 0.49523, train_accuracy: 82.03\n",
      "[6,     7] loss: 0.44400, train_accuracy: 84.77\n",
      "[6,     8] loss: 0.48553, train_accuracy: 84.57\n",
      "[6,     9] loss: 0.53616, train_accuracy: 83.01\n",
      "[6,    10] loss: 0.52604, train_accuracy: 80.86\n",
      "[6,    11] loss: 0.45649, train_accuracy: 85.35\n",
      "[6,    12] loss: 0.52709, train_accuracy: 81.05\n",
      "[6,    13] loss: 0.46279, train_accuracy: 85.35\n",
      "[6,    14] loss: 0.49710, train_accuracy: 80.86\n",
      "[6,    15] loss: 0.44624, train_accuracy: 84.77\n",
      "[6,    16] loss: 0.49784, train_accuracy: 82.42\n",
      "[6,    17] loss: 0.44579, train_accuracy: 84.18\n",
      "[6,    18] loss: 0.47521, train_accuracy: 84.18\n",
      "[6,    19] loss: 0.42708, train_accuracy: 84.18\n",
      "[6,    20] loss: 0.54507, train_accuracy: 79.69\n",
      "[6,    21] loss: 0.49539, train_accuracy: 81.64\n",
      "[6,    22] loss: 0.54160, train_accuracy: 79.88\n",
      "[6,    23] loss: 0.45907, train_accuracy: 82.42\n",
      "[6,    24] loss: 0.49396, train_accuracy: 82.62\n",
      "[6,    25] loss: 0.46772, train_accuracy: 83.20\n",
      "[6,    26] loss: 0.46898, train_accuracy: 83.79\n",
      "[6,    27] loss: 0.45875, train_accuracy: 83.59\n",
      "[6,    28] loss: 0.53440, train_accuracy: 82.42\n",
      "[6,    29] loss: 0.55136, train_accuracy: 81.45\n",
      "[6,    30] loss: 0.52278, train_accuracy: 81.05\n",
      "[6,    31] loss: 0.55713, train_accuracy: 80.27\n",
      "[6,    32] loss: 0.46719, train_accuracy: 84.96\n",
      "[6,    33] loss: 0.51242, train_accuracy: 82.03\n",
      "[6,    34] loss: 0.45864, train_accuracy: 84.18\n",
      "[6,    35] loss: 0.47706, train_accuracy: 82.23\n",
      "[6,    36] loss: 0.47116, train_accuracy: 82.23\n",
      "[6,    37] loss: 0.43152, train_accuracy: 83.01\n",
      "[6,    38] loss: 0.53117, train_accuracy: 81.05\n",
      "[6,    39] loss: 0.54971, train_accuracy: 78.12\n",
      "[6,    40] loss: 0.46211, train_accuracy: 83.40\n",
      "[6,    41] loss: 0.58348, train_accuracy: 77.93\n",
      "[6,    42] loss: 0.55189, train_accuracy: 79.10\n",
      "[6,    43] loss: 0.47988, train_accuracy: 83.01\n",
      "[6,    44] loss: 0.53758, train_accuracy: 80.47\n",
      "[6,    45] loss: 0.51271, train_accuracy: 83.01\n",
      "[6,    46] loss: 0.52223, train_accuracy: 81.64\n",
      "[6,    47] loss: 0.48456, train_accuracy: 81.84\n",
      "[6,    48] loss: 0.50722, train_accuracy: 82.62\n",
      "[6,    49] loss: 0.52969, train_accuracy: 82.03\n",
      "[6,    50] loss: 0.53180, train_accuracy: 82.23\n",
      "[6,    51] loss: 0.47393, train_accuracy: 82.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    52] loss: 0.51771, train_accuracy: 80.47\n",
      "[6,    53] loss: 0.52832, train_accuracy: 81.45\n",
      "[6,    54] loss: 0.51090, train_accuracy: 82.03\n",
      "[6,    55] loss: 0.51566, train_accuracy: 80.66\n",
      "[6,    56] loss: 0.48118, train_accuracy: 82.81\n",
      "[6,    57] loss: 0.41287, train_accuracy: 85.35\n",
      "[6,    58] loss: 0.48945, train_accuracy: 83.79\n",
      "[6,    59] loss: 0.50180, train_accuracy: 81.25\n",
      "[6,    60] loss: 0.53243, train_accuracy: 80.86\n",
      "[6,    61] loss: 0.43496, train_accuracy: 85.94\n",
      "[6,    62] loss: 0.51493, train_accuracy: 82.03\n",
      "[6,    63] loss: 0.52344, train_accuracy: 80.86\n",
      "[6,    64] loss: 0.50902, train_accuracy: 80.27\n",
      "[6,    65] loss: 0.58173, train_accuracy: 78.32\n",
      "[6,    66] loss: 0.51042, train_accuracy: 81.45\n",
      "[6,    67] loss: 0.50134, train_accuracy: 84.57\n",
      "[6,    68] loss: 0.47506, train_accuracy: 83.79\n",
      "[6,    69] loss: 0.55803, train_accuracy: 79.10\n",
      "[6,    70] loss: 0.44004, train_accuracy: 86.72\n",
      "[6,    71] loss: 0.50914, train_accuracy: 83.59\n",
      "[6,    72] loss: 0.49863, train_accuracy: 83.59\n",
      "[6,    73] loss: 0.49784, train_accuracy: 82.03\n",
      "[6,    74] loss: 0.47731, train_accuracy: 82.23\n",
      "[6,    75] loss: 0.45928, train_accuracy: 83.59\n",
      "[6,    76] loss: 0.51369, train_accuracy: 80.08\n",
      "[6,    77] loss: 0.49102, train_accuracy: 84.57\n",
      "[6,    78] loss: 0.53292, train_accuracy: 81.25\n",
      "[6,    79] loss: 0.51719, train_accuracy: 81.05\n",
      "[6,    80] loss: 0.53571, train_accuracy: 79.49\n",
      "[6,    81] loss: 0.51183, train_accuracy: 80.27\n",
      "[6,    82] loss: 0.62486, train_accuracy: 76.76\n",
      "[6,    83] loss: 0.55030, train_accuracy: 79.30\n",
      "[6,    84] loss: 0.49035, train_accuracy: 83.01\n",
      "[6,    85] loss: 0.50387, train_accuracy: 82.23\n",
      "[6,    86] loss: 0.53171, train_accuracy: 81.45\n",
      "[6,    87] loss: 0.48792, train_accuracy: 83.59\n",
      "[6,    88] loss: 0.49750, train_accuracy: 82.62\n",
      "[6,    89] loss: 0.54136, train_accuracy: 78.91\n",
      "[6,    90] loss: 0.47458, train_accuracy: 81.84\n",
      "[6,    91] loss: 0.51291, train_accuracy: 83.20\n",
      "[6,    92] loss: 0.47790, train_accuracy: 81.25\n",
      "[6,    93] loss: 0.48037, train_accuracy: 81.05\n",
      "[6,    94] loss: 0.51841, train_accuracy: 82.23\n",
      "[6,    95] loss: 0.59179, train_accuracy: 78.12\n",
      "[6,    96] loss: 0.49487, train_accuracy: 81.25\n",
      "[6,    97] loss: 0.53777, train_accuracy: 80.47\n",
      "[6,    98] loss: 0.55767, train_accuracy: 77.98\n",
      "duration: 25 s - train loss: 0.50348 - train accuracy: 82.02 - validation loss: 1.25 - validation accuracy: 62.55 \n",
      "[7,     1] loss: 0.41156, train_accuracy: 86.52\n",
      "[7,     2] loss: 0.48231, train_accuracy: 82.42\n",
      "[7,     3] loss: 0.45357, train_accuracy: 83.98\n",
      "[7,     4] loss: 0.49103, train_accuracy: 83.01\n",
      "[7,     5] loss: 0.42886, train_accuracy: 84.77\n",
      "[7,     6] loss: 0.53851, train_accuracy: 81.25\n",
      "[7,     7] loss: 0.43944, train_accuracy: 85.35\n",
      "[7,     8] loss: 0.39457, train_accuracy: 88.28\n",
      "[7,     9] loss: 0.50326, train_accuracy: 81.45\n",
      "[7,    10] loss: 0.48511, train_accuracy: 84.57\n",
      "[7,    11] loss: 0.51934, train_accuracy: 79.49\n",
      "[7,    12] loss: 0.45052, train_accuracy: 85.35\n",
      "[7,    13] loss: 0.46438, train_accuracy: 83.79\n",
      "[7,    14] loss: 0.48532, train_accuracy: 82.81\n",
      "[7,    15] loss: 0.46989, train_accuracy: 83.20\n",
      "[7,    16] loss: 0.46630, train_accuracy: 84.57\n",
      "[7,    17] loss: 0.46446, train_accuracy: 83.59\n",
      "[7,    18] loss: 0.44546, train_accuracy: 83.59\n",
      "[7,    19] loss: 0.45163, train_accuracy: 82.23\n",
      "[7,    20] loss: 0.49565, train_accuracy: 83.01\n",
      "[7,    21] loss: 0.41989, train_accuracy: 84.96\n",
      "[7,    22] loss: 0.45225, train_accuracy: 84.18\n",
      "[7,    23] loss: 0.44372, train_accuracy: 84.18\n",
      "[7,    24] loss: 0.47334, train_accuracy: 81.84\n",
      "[7,    25] loss: 0.49113, train_accuracy: 81.25\n",
      "[7,    26] loss: 0.51691, train_accuracy: 81.84\n",
      "[7,    27] loss: 0.45203, train_accuracy: 84.96\n",
      "[7,    28] loss: 0.42479, train_accuracy: 84.38\n",
      "[7,    29] loss: 0.45325, train_accuracy: 85.16\n",
      "[7,    30] loss: 0.55478, train_accuracy: 80.66\n",
      "[7,    31] loss: 0.49944, train_accuracy: 80.66\n",
      "[7,    32] loss: 0.47391, train_accuracy: 83.40\n",
      "[7,    33] loss: 0.43018, train_accuracy: 85.55\n",
      "[7,    34] loss: 0.45096, train_accuracy: 83.20\n",
      "[7,    35] loss: 0.46871, train_accuracy: 83.40\n",
      "[7,    36] loss: 0.42864, train_accuracy: 86.13\n",
      "[7,    37] loss: 0.44635, train_accuracy: 84.57\n",
      "[7,    38] loss: 0.47672, train_accuracy: 82.42\n",
      "[7,    39] loss: 0.50775, train_accuracy: 82.42\n",
      "[7,    40] loss: 0.47567, train_accuracy: 83.79\n",
      "[7,    41] loss: 0.46989, train_accuracy: 81.64\n",
      "[7,    42] loss: 0.53293, train_accuracy: 81.84\n",
      "[7,    43] loss: 0.44816, train_accuracy: 82.62\n",
      "[7,    44] loss: 0.51436, train_accuracy: 80.86\n",
      "[7,    45] loss: 0.44163, train_accuracy: 85.74\n",
      "[7,    46] loss: 0.42063, train_accuracy: 84.38\n",
      "[7,    47] loss: 0.51151, train_accuracy: 81.84\n",
      "[7,    48] loss: 0.44996, train_accuracy: 84.38\n",
      "[7,    49] loss: 0.46845, train_accuracy: 83.79\n",
      "[7,    50] loss: 0.54692, train_accuracy: 81.84\n",
      "[7,    51] loss: 0.51977, train_accuracy: 81.84\n",
      "[7,    52] loss: 0.44887, train_accuracy: 84.38\n",
      "[7,    53] loss: 0.46520, train_accuracy: 83.40\n",
      "[7,    54] loss: 0.42826, train_accuracy: 85.16\n",
      "[7,    55] loss: 0.43611, train_accuracy: 85.55\n",
      "[7,    56] loss: 0.49947, train_accuracy: 83.98\n",
      "[7,    57] loss: 0.47855, train_accuracy: 82.23\n",
      "[7,    58] loss: 0.49456, train_accuracy: 83.79\n",
      "[7,    59] loss: 0.54575, train_accuracy: 78.91\n",
      "[7,    60] loss: 0.48902, train_accuracy: 83.01\n",
      "[7,    61] loss: 0.55265, train_accuracy: 79.88\n",
      "[7,    62] loss: 0.50713, train_accuracy: 82.62\n",
      "[7,    63] loss: 0.42783, train_accuracy: 85.94\n",
      "[7,    64] loss: 0.52831, train_accuracy: 81.05\n",
      "[7,    65] loss: 0.52427, train_accuracy: 83.40\n",
      "[7,    66] loss: 0.46424, train_accuracy: 83.20\n",
      "[7,    67] loss: 0.50087, train_accuracy: 81.25\n",
      "[7,    68] loss: 0.52977, train_accuracy: 81.64\n",
      "[7,    69] loss: 0.41928, train_accuracy: 84.57\n",
      "[7,    70] loss: 0.53783, train_accuracy: 80.27\n",
      "[7,    71] loss: 0.51411, train_accuracy: 80.86\n",
      "[7,    72] loss: 0.52246, train_accuracy: 80.27\n",
      "[7,    73] loss: 0.48987, train_accuracy: 81.45\n",
      "[7,    74] loss: 0.54384, train_accuracy: 78.91\n",
      "[7,    75] loss: 0.53666, train_accuracy: 81.25\n",
      "[7,    76] loss: 0.47300, train_accuracy: 83.59\n",
      "[7,    77] loss: 0.48914, train_accuracy: 82.03\n",
      "[7,    78] loss: 0.50526, train_accuracy: 83.20\n",
      "[7,    79] loss: 0.43081, train_accuracy: 83.98\n",
      "[7,    80] loss: 0.49801, train_accuracy: 83.20\n",
      "[7,    81] loss: 0.54099, train_accuracy: 79.69\n",
      "[7,    82] loss: 0.54546, train_accuracy: 80.47\n",
      "[7,    83] loss: 0.54401, train_accuracy: 81.05\n",
      "[7,    84] loss: 0.53156, train_accuracy: 80.47\n",
      "[7,    85] loss: 0.47777, train_accuracy: 83.40\n",
      "[7,    86] loss: 0.48909, train_accuracy: 82.81\n",
      "[7,    87] loss: 0.50115, train_accuracy: 81.25\n",
      "[7,    88] loss: 0.53869, train_accuracy: 81.84\n",
      "[7,    89] loss: 0.52225, train_accuracy: 81.64\n",
      "[7,    90] loss: 0.49727, train_accuracy: 81.25\n",
      "[7,    91] loss: 0.52090, train_accuracy: 81.05\n",
      "[7,    92] loss: 0.46862, train_accuracy: 84.77\n",
      "[7,    93] loss: 0.55003, train_accuracy: 79.69\n",
      "[7,    94] loss: 0.49337, train_accuracy: 82.42\n",
      "[7,    95] loss: 0.54468, train_accuracy: 78.91\n",
      "[7,    96] loss: 0.55750, train_accuracy: 80.66\n",
      "[7,    97] loss: 0.45130, train_accuracy: 83.79\n",
      "[7,    98] loss: 0.49434, train_accuracy: 81.55\n",
      "duration: 24 s - train loss: 0.48526 - train accuracy: 82.78 - validation loss: 1.26 - validation accuracy: 62.34 \n",
      "[8,     1] loss: 0.39984, train_accuracy: 86.33\n",
      "[8,     2] loss: 0.47494, train_accuracy: 83.20\n",
      "[8,     3] loss: 0.46177, train_accuracy: 85.16\n",
      "[8,     4] loss: 0.41638, train_accuracy: 84.96\n",
      "[8,     5] loss: 0.47727, train_accuracy: 84.18\n",
      "[8,     6] loss: 0.48056, train_accuracy: 82.62\n",
      "[8,     7] loss: 0.43074, train_accuracy: 83.59\n",
      "[8,     8] loss: 0.48635, train_accuracy: 83.20\n",
      "[8,     9] loss: 0.44946, train_accuracy: 84.96\n",
      "[8,    10] loss: 0.46500, train_accuracy: 85.35\n",
      "[8,    11] loss: 0.37454, train_accuracy: 88.09\n",
      "[8,    12] loss: 0.44878, train_accuracy: 83.98\n",
      "[8,    13] loss: 0.46229, train_accuracy: 83.98\n",
      "[8,    14] loss: 0.46799, train_accuracy: 83.01\n",
      "[8,    15] loss: 0.44855, train_accuracy: 83.98\n",
      "[8,    16] loss: 0.46645, train_accuracy: 83.59\n",
      "[8,    17] loss: 0.40097, train_accuracy: 85.35\n",
      "[8,    18] loss: 0.36666, train_accuracy: 88.48\n",
      "[8,    19] loss: 0.40519, train_accuracy: 85.74\n",
      "[8,    20] loss: 0.43318, train_accuracy: 83.40\n",
      "[8,    21] loss: 0.44033, train_accuracy: 84.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,    22] loss: 0.43440, train_accuracy: 85.16\n",
      "[8,    23] loss: 0.46771, train_accuracy: 83.20\n",
      "[8,    24] loss: 0.45225, train_accuracy: 84.18\n",
      "[8,    25] loss: 0.43926, train_accuracy: 84.18\n",
      "[8,    26] loss: 0.47653, train_accuracy: 81.84\n",
      "[8,    27] loss: 0.48711, train_accuracy: 82.23\n",
      "[8,    28] loss: 0.46429, train_accuracy: 83.79\n",
      "[8,    29] loss: 0.45167, train_accuracy: 83.98\n",
      "[8,    30] loss: 0.44803, train_accuracy: 83.20\n",
      "[8,    31] loss: 0.42739, train_accuracy: 84.96\n",
      "[8,    32] loss: 0.46523, train_accuracy: 82.81\n",
      "[8,    33] loss: 0.51405, train_accuracy: 81.84\n",
      "[8,    34] loss: 0.42826, train_accuracy: 85.35\n",
      "[8,    35] loss: 0.44733, train_accuracy: 83.98\n",
      "[8,    36] loss: 0.49444, train_accuracy: 82.42\n",
      "[8,    37] loss: 0.50036, train_accuracy: 80.86\n",
      "[8,    38] loss: 0.40928, train_accuracy: 84.96\n",
      "[8,    39] loss: 0.42524, train_accuracy: 83.98\n",
      "[8,    40] loss: 0.43900, train_accuracy: 83.40\n",
      "[8,    41] loss: 0.40250, train_accuracy: 85.35\n",
      "[8,    42] loss: 0.43418, train_accuracy: 84.57\n",
      "[8,    43] loss: 0.43698, train_accuracy: 83.79\n",
      "[8,    44] loss: 0.44998, train_accuracy: 83.40\n",
      "[8,    45] loss: 0.47461, train_accuracy: 82.42\n",
      "[8,    46] loss: 0.48054, train_accuracy: 80.86\n",
      "[8,    47] loss: 0.39941, train_accuracy: 86.91\n",
      "[8,    48] loss: 0.43775, train_accuracy: 86.72\n",
      "[8,    49] loss: 0.43828, train_accuracy: 84.18\n",
      "[8,    50] loss: 0.45348, train_accuracy: 84.77\n",
      "[8,    51] loss: 0.45216, train_accuracy: 83.40\n",
      "[8,    52] loss: 0.47332, train_accuracy: 83.98\n",
      "[8,    53] loss: 0.45435, train_accuracy: 84.38\n",
      "[8,    54] loss: 0.51263, train_accuracy: 82.23\n",
      "[8,    55] loss: 0.46271, train_accuracy: 83.98\n",
      "[8,    56] loss: 0.47910, train_accuracy: 83.98\n",
      "[8,    57] loss: 0.41996, train_accuracy: 85.55\n",
      "[8,    58] loss: 0.51720, train_accuracy: 80.08\n",
      "[8,    59] loss: 0.52112, train_accuracy: 81.64\n",
      "[8,    60] loss: 0.48469, train_accuracy: 84.57\n",
      "[8,    61] loss: 0.45180, train_accuracy: 83.98\n",
      "[8,    62] loss: 0.57112, train_accuracy: 80.08\n",
      "[8,    63] loss: 0.48317, train_accuracy: 83.40\n",
      "[8,    64] loss: 0.43757, train_accuracy: 86.33\n",
      "[8,    65] loss: 0.41871, train_accuracy: 86.13\n",
      "[8,    66] loss: 0.45860, train_accuracy: 82.42\n",
      "[8,    67] loss: 0.54471, train_accuracy: 79.69\n",
      "[8,    68] loss: 0.50978, train_accuracy: 82.03\n",
      "[8,    69] loss: 0.49626, train_accuracy: 82.23\n",
      "[8,    70] loss: 0.43719, train_accuracy: 82.81\n",
      "[8,    71] loss: 0.48079, train_accuracy: 84.57\n",
      "[8,    72] loss: 0.47162, train_accuracy: 82.03\n",
      "[8,    73] loss: 0.42463, train_accuracy: 85.94\n",
      "[8,    74] loss: 0.54780, train_accuracy: 80.08\n",
      "[8,    75] loss: 0.49402, train_accuracy: 81.45\n",
      "[8,    76] loss: 0.48666, train_accuracy: 81.25\n",
      "[8,    77] loss: 0.58513, train_accuracy: 78.52\n",
      "[8,    78] loss: 0.51060, train_accuracy: 81.25\n",
      "[8,    79] loss: 0.53304, train_accuracy: 78.52\n",
      "[8,    80] loss: 0.49778, train_accuracy: 83.20\n",
      "[8,    81] loss: 0.47135, train_accuracy: 83.40\n",
      "[8,    82] loss: 0.49857, train_accuracy: 80.47\n",
      "[8,    83] loss: 0.60313, train_accuracy: 80.08\n",
      "[8,    84] loss: 0.46908, train_accuracy: 82.03\n",
      "[8,    85] loss: 0.52139, train_accuracy: 83.20\n",
      "[8,    86] loss: 0.47845, train_accuracy: 83.59\n",
      "[8,    87] loss: 0.47161, train_accuracy: 82.62\n",
      "[8,    88] loss: 0.52066, train_accuracy: 78.32\n",
      "[8,    89] loss: 0.45882, train_accuracy: 84.96\n",
      "[8,    90] loss: 0.46245, train_accuracy: 83.98\n",
      "[8,    91] loss: 0.46450, train_accuracy: 82.81\n",
      "[8,    92] loss: 0.47964, train_accuracy: 82.81\n",
      "[8,    93] loss: 0.45274, train_accuracy: 84.18\n",
      "[8,    94] loss: 0.42945, train_accuracy: 86.91\n",
      "[8,    95] loss: 0.52243, train_accuracy: 80.86\n",
      "[8,    96] loss: 0.57931, train_accuracy: 79.88\n",
      "[8,    97] loss: 0.45160, train_accuracy: 83.59\n",
      "[8,    98] loss: 0.48467, train_accuracy: 83.33\n",
      "duration: 24 s - train loss: 0.46709 - train accuracy: 83.40 - validation loss: 1.29 - validation accuracy: 62.30 \n",
      "stopped early after 5 epochs without decrease of validation loss\n",
      "Finished Training\n",
      "cw done\n",
      "pgd done\n",
      "compression rate:  0.875\n",
      "[1,     1] loss: 3.40443, train_accuracy: 27.54\n",
      "[1,     2] loss: 3.19933, train_accuracy: 29.49\n",
      "[1,     3] loss: 2.99374, train_accuracy: 26.95\n",
      "[1,     4] loss: 2.78105, train_accuracy: 30.27\n",
      "[1,     5] loss: 2.70988, train_accuracy: 31.45\n",
      "[1,     6] loss: 2.32140, train_accuracy: 35.55\n",
      "[1,     7] loss: 2.25559, train_accuracy: 37.89\n",
      "[1,     8] loss: 2.29825, train_accuracy: 36.52\n",
      "[1,     9] loss: 2.04470, train_accuracy: 40.23\n",
      "[1,    10] loss: 2.13090, train_accuracy: 39.45\n",
      "[1,    11] loss: 1.94474, train_accuracy: 40.43\n",
      "[1,    12] loss: 1.90609, train_accuracy: 44.73\n",
      "[1,    13] loss: 1.86226, train_accuracy: 46.88\n",
      "[1,    14] loss: 2.00310, train_accuracy: 43.36\n",
      "[1,    15] loss: 1.66464, train_accuracy: 50.20\n",
      "[1,    16] loss: 1.74576, train_accuracy: 46.29\n",
      "[1,    17] loss: 1.82454, train_accuracy: 45.70\n",
      "[1,    18] loss: 1.76478, train_accuracy: 43.55\n",
      "[1,    19] loss: 1.71287, train_accuracy: 47.27\n",
      "[1,    20] loss: 1.74472, train_accuracy: 48.24\n",
      "[1,    21] loss: 1.56721, train_accuracy: 49.80\n",
      "[1,    22] loss: 1.75255, train_accuracy: 47.27\n",
      "[1,    23] loss: 1.70602, train_accuracy: 47.85\n",
      "[1,    24] loss: 1.60249, train_accuracy: 49.80\n",
      "[1,    25] loss: 1.57454, train_accuracy: 49.61\n",
      "[1,    26] loss: 1.47086, train_accuracy: 55.86\n",
      "[1,    27] loss: 1.36484, train_accuracy: 54.49\n",
      "[1,    28] loss: 1.41345, train_accuracy: 51.95\n",
      "[1,    29] loss: 1.48923, train_accuracy: 53.12\n",
      "[1,    30] loss: 1.53962, train_accuracy: 51.56\n",
      "[1,    31] loss: 1.48134, train_accuracy: 54.10\n",
      "[1,    32] loss: 1.66259, train_accuracy: 50.59\n",
      "[1,    33] loss: 1.52234, train_accuracy: 51.37\n",
      "[1,    34] loss: 1.46090, train_accuracy: 53.91\n",
      "[1,    35] loss: 1.42622, train_accuracy: 54.10\n",
      "[1,    36] loss: 1.41887, train_accuracy: 54.69\n",
      "[1,    37] loss: 1.37093, train_accuracy: 54.10\n",
      "[1,    38] loss: 1.42079, train_accuracy: 50.59\n",
      "[1,    39] loss: 1.24269, train_accuracy: 58.01\n",
      "[1,    40] loss: 1.29505, train_accuracy: 58.40\n",
      "[1,    41] loss: 1.41225, train_accuracy: 51.37\n",
      "[1,    42] loss: 1.25569, train_accuracy: 57.62\n",
      "[1,    43] loss: 1.23653, train_accuracy: 59.57\n",
      "[1,    44] loss: 1.26668, train_accuracy: 56.84\n",
      "[1,    45] loss: 1.37998, train_accuracy: 54.69\n",
      "[1,    46] loss: 1.40842, train_accuracy: 53.32\n",
      "[1,    47] loss: 1.29085, train_accuracy: 53.91\n",
      "[1,    48] loss: 1.21820, train_accuracy: 55.86\n",
      "[1,    49] loss: 1.26704, train_accuracy: 57.81\n",
      "[1,    50] loss: 1.43162, train_accuracy: 51.56\n",
      "[1,    51] loss: 1.12046, train_accuracy: 62.50\n",
      "[1,    52] loss: 1.19307, train_accuracy: 60.74\n",
      "[1,    53] loss: 1.22879, train_accuracy: 57.42\n",
      "[1,    54] loss: 1.28082, train_accuracy: 56.25\n",
      "[1,    55] loss: 1.15914, train_accuracy: 62.30\n",
      "[1,    56] loss: 1.28598, train_accuracy: 55.47\n",
      "[1,    57] loss: 1.27185, train_accuracy: 55.27\n",
      "[1,    58] loss: 1.20689, train_accuracy: 59.18\n",
      "[1,    59] loss: 1.21412, train_accuracy: 58.40\n",
      "[1,    60] loss: 1.25563, train_accuracy: 56.64\n",
      "[1,    61] loss: 1.22202, train_accuracy: 59.57\n",
      "[1,    62] loss: 1.25251, train_accuracy: 56.05\n",
      "[1,    63] loss: 1.14789, train_accuracy: 61.13\n",
      "[1,    64] loss: 1.24995, train_accuracy: 55.86\n",
      "[1,    65] loss: 1.19065, train_accuracy: 61.13\n",
      "[1,    66] loss: 1.13654, train_accuracy: 60.16\n",
      "[1,    67] loss: 1.18647, train_accuracy: 58.20\n",
      "[1,    68] loss: 1.23914, train_accuracy: 60.16\n",
      "[1,    69] loss: 1.03370, train_accuracy: 62.30\n",
      "[1,    70] loss: 1.08944, train_accuracy: 61.91\n",
      "[1,    71] loss: 1.12280, train_accuracy: 61.33\n",
      "[1,    72] loss: 1.10187, train_accuracy: 63.48\n",
      "[1,    73] loss: 1.13282, train_accuracy: 60.35\n",
      "[1,    74] loss: 1.10270, train_accuracy: 60.74\n",
      "[1,    75] loss: 1.08536, train_accuracy: 63.09\n",
      "[1,    76] loss: 1.20644, train_accuracy: 60.55\n",
      "[1,    77] loss: 1.13331, train_accuracy: 62.11\n",
      "[1,    78] loss: 1.23111, train_accuracy: 56.25\n",
      "[1,    79] loss: 1.06259, train_accuracy: 60.74\n",
      "[1,    80] loss: 1.09006, train_accuracy: 62.70\n",
      "[1,    81] loss: 1.16136, train_accuracy: 58.98\n",
      "[1,    82] loss: 1.10005, train_accuracy: 62.30\n",
      "[1,    83] loss: 1.06911, train_accuracy: 63.28\n",
      "[1,    84] loss: 1.04704, train_accuracy: 64.84\n",
      "[1,    85] loss: 1.21048, train_accuracy: 57.03\n",
      "[1,    86] loss: 1.10891, train_accuracy: 61.13\n",
      "[1,    87] loss: 1.14290, train_accuracy: 60.16\n",
      "[1,    88] loss: 0.98451, train_accuracy: 64.45\n",
      "[1,    89] loss: 1.20815, train_accuracy: 58.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    90] loss: 1.04896, train_accuracy: 62.70\n",
      "[1,    91] loss: 1.06661, train_accuracy: 64.45\n",
      "[1,    92] loss: 1.05366, train_accuracy: 61.91\n",
      "[1,    93] loss: 1.14454, train_accuracy: 60.35\n",
      "[1,    94] loss: 1.05772, train_accuracy: 62.30\n",
      "[1,    95] loss: 1.01401, train_accuracy: 63.09\n",
      "[1,    96] loss: 1.00793, train_accuracy: 64.06\n",
      "[1,    97] loss: 1.03464, train_accuracy: 62.89\n",
      "[1,    98] loss: 1.12978, train_accuracy: 59.82\n",
      "duration: 25 s - train loss: 1.44987 - train accuracy: 54.08 - validation loss: 1.32 - validation accuracy: 56.44 \n",
      "[2,     1] loss: 1.10455, train_accuracy: 62.11\n",
      "[2,     2] loss: 1.10879, train_accuracy: 60.35\n",
      "[2,     3] loss: 1.13911, train_accuracy: 60.94\n",
      "[2,     4] loss: 1.02102, train_accuracy: 64.06\n",
      "[2,     5] loss: 1.00061, train_accuracy: 65.04\n",
      "[2,     6] loss: 0.99954, train_accuracy: 67.19\n",
      "[2,     7] loss: 1.01006, train_accuracy: 63.09\n",
      "[2,     8] loss: 0.89291, train_accuracy: 68.36\n",
      "[2,     9] loss: 0.99123, train_accuracy: 63.28\n",
      "[2,    10] loss: 1.04358, train_accuracy: 63.87\n",
      "[2,    11] loss: 1.12772, train_accuracy: 60.16\n",
      "[2,    12] loss: 1.09086, train_accuracy: 64.06\n",
      "[2,    13] loss: 1.07478, train_accuracy: 60.74\n",
      "[2,    14] loss: 1.01679, train_accuracy: 64.84\n",
      "[2,    15] loss: 1.01089, train_accuracy: 63.67\n",
      "[2,    16] loss: 1.00674, train_accuracy: 65.62\n",
      "[2,    17] loss: 1.01586, train_accuracy: 65.82\n",
      "[2,    18] loss: 0.95851, train_accuracy: 65.82\n",
      "[2,    19] loss: 0.92554, train_accuracy: 64.26\n",
      "[2,    20] loss: 1.01598, train_accuracy: 62.70\n",
      "[2,    21] loss: 1.01762, train_accuracy: 63.28\n",
      "[2,    22] loss: 1.07344, train_accuracy: 61.13\n",
      "[2,    23] loss: 1.01323, train_accuracy: 62.70\n",
      "[2,    24] loss: 1.06906, train_accuracy: 62.11\n",
      "[2,    25] loss: 0.99227, train_accuracy: 65.23\n",
      "[2,    26] loss: 1.05376, train_accuracy: 62.89\n",
      "[2,    27] loss: 1.01162, train_accuracy: 62.50\n",
      "[2,    28] loss: 0.98511, train_accuracy: 66.60\n",
      "[2,    29] loss: 0.89169, train_accuracy: 64.84\n",
      "[2,    30] loss: 1.04999, train_accuracy: 63.09\n",
      "[2,    31] loss: 1.01486, train_accuracy: 63.87\n",
      "[2,    32] loss: 0.93609, train_accuracy: 64.45\n",
      "[2,    33] loss: 0.93446, train_accuracy: 66.99\n",
      "[2,    34] loss: 1.05592, train_accuracy: 63.67\n",
      "[2,    35] loss: 0.97049, train_accuracy: 64.84\n",
      "[2,    36] loss: 1.03802, train_accuracy: 64.26\n",
      "[2,    37] loss: 0.96808, train_accuracy: 62.89\n",
      "[2,    38] loss: 0.89517, train_accuracy: 66.80\n",
      "[2,    39] loss: 0.93895, train_accuracy: 67.38\n",
      "[2,    40] loss: 0.98417, train_accuracy: 63.09\n",
      "[2,    41] loss: 1.04233, train_accuracy: 62.89\n",
      "[2,    42] loss: 0.92544, train_accuracy: 66.41\n",
      "[2,    43] loss: 0.96590, train_accuracy: 65.23\n",
      "[2,    44] loss: 0.97764, train_accuracy: 66.02\n",
      "[2,    45] loss: 0.99318, train_accuracy: 64.65\n",
      "[2,    46] loss: 0.97259, train_accuracy: 66.99\n",
      "[2,    47] loss: 1.00120, train_accuracy: 64.65\n",
      "[2,    48] loss: 1.00729, train_accuracy: 63.48\n",
      "[2,    49] loss: 0.93910, train_accuracy: 65.82\n",
      "[2,    50] loss: 0.92889, train_accuracy: 68.36\n",
      "[2,    51] loss: 0.96573, train_accuracy: 63.67\n",
      "[2,    52] loss: 0.93790, train_accuracy: 64.84\n",
      "[2,    53] loss: 0.94316, train_accuracy: 66.60\n",
      "[2,    54] loss: 0.95206, train_accuracy: 64.06\n",
      "[2,    55] loss: 0.96191, train_accuracy: 67.38\n",
      "[2,    56] loss: 0.95782, train_accuracy: 64.26\n",
      "[2,    57] loss: 0.89235, train_accuracy: 67.97\n",
      "[2,    58] loss: 0.98981, train_accuracy: 63.28\n",
      "[2,    59] loss: 0.95148, train_accuracy: 64.84\n",
      "[2,    60] loss: 0.88989, train_accuracy: 66.60\n",
      "[2,    61] loss: 0.93253, train_accuracy: 65.62\n",
      "[2,    62] loss: 0.94121, train_accuracy: 66.41\n",
      "[2,    63] loss: 0.93582, train_accuracy: 68.16\n",
      "[2,    64] loss: 0.89543, train_accuracy: 69.14\n",
      "[2,    65] loss: 0.98504, train_accuracy: 64.06\n",
      "[2,    66] loss: 0.93381, train_accuracy: 63.67\n",
      "[2,    67] loss: 0.88741, train_accuracy: 69.53\n",
      "[2,    68] loss: 1.05047, train_accuracy: 63.87\n",
      "[2,    69] loss: 0.97542, train_accuracy: 64.84\n",
      "[2,    70] loss: 0.90853, train_accuracy: 65.04\n",
      "[2,    71] loss: 0.85642, train_accuracy: 69.73\n",
      "[2,    72] loss: 0.96905, train_accuracy: 65.04\n",
      "[2,    73] loss: 0.90615, train_accuracy: 68.55\n",
      "[2,    74] loss: 0.97355, train_accuracy: 64.45\n",
      "[2,    75] loss: 0.98820, train_accuracy: 63.87\n",
      "[2,    76] loss: 0.94234, train_accuracy: 66.60\n",
      "[2,    77] loss: 0.95980, train_accuracy: 66.60\n",
      "[2,    78] loss: 1.00586, train_accuracy: 64.65\n",
      "[2,    79] loss: 0.90361, train_accuracy: 69.14\n",
      "[2,    80] loss: 0.95606, train_accuracy: 66.41\n",
      "[2,    81] loss: 0.90865, train_accuracy: 67.97\n",
      "[2,    82] loss: 0.82652, train_accuracy: 72.07\n",
      "[2,    83] loss: 1.04017, train_accuracy: 63.28\n",
      "[2,    84] loss: 0.94126, train_accuracy: 68.36\n",
      "[2,    85] loss: 1.01944, train_accuracy: 64.26\n",
      "[2,    86] loss: 0.96539, train_accuracy: 66.02\n",
      "[2,    87] loss: 0.99694, train_accuracy: 62.50\n",
      "[2,    88] loss: 0.87026, train_accuracy: 69.34\n",
      "[2,    89] loss: 1.05177, train_accuracy: 60.74\n",
      "[2,    90] loss: 0.88493, train_accuracy: 65.04\n",
      "[2,    91] loss: 0.97637, train_accuracy: 64.45\n",
      "[2,    92] loss: 0.91818, train_accuracy: 69.53\n",
      "[2,    93] loss: 0.90843, train_accuracy: 68.55\n",
      "[2,    94] loss: 0.94155, train_accuracy: 66.02\n",
      "[2,    95] loss: 0.86930, train_accuracy: 68.36\n",
      "[2,    96] loss: 0.93919, train_accuracy: 65.82\n",
      "[2,    97] loss: 0.92508, train_accuracy: 67.77\n",
      "[2,    98] loss: 0.89746, train_accuracy: 67.56\n",
      "duration: 25 s - train loss: 0.97380 - train accuracy: 65.20 - validation loss: 1.20 - validation accuracy: 59.58 \n",
      "[3,     1] loss: 0.98428, train_accuracy: 64.84\n",
      "[3,     2] loss: 0.93088, train_accuracy: 67.58\n",
      "[3,     3] loss: 0.93904, train_accuracy: 65.04\n",
      "[3,     4] loss: 0.91588, train_accuracy: 66.21\n",
      "[3,     5] loss: 0.92665, train_accuracy: 66.41\n",
      "[3,     6] loss: 0.88880, train_accuracy: 69.92\n",
      "[3,     7] loss: 0.86301, train_accuracy: 68.95\n",
      "[3,     8] loss: 0.92147, train_accuracy: 65.62\n",
      "[3,     9] loss: 0.92872, train_accuracy: 65.82\n",
      "[3,    10] loss: 0.93143, train_accuracy: 69.14\n",
      "[3,    11] loss: 0.84280, train_accuracy: 69.92\n",
      "[3,    12] loss: 0.79600, train_accuracy: 70.70\n",
      "[3,    13] loss: 0.94973, train_accuracy: 66.41\n",
      "[3,    14] loss: 0.89670, train_accuracy: 68.75\n",
      "[3,    15] loss: 0.89523, train_accuracy: 67.58\n",
      "[3,    16] loss: 0.88153, train_accuracy: 66.60\n",
      "[3,    17] loss: 0.91825, train_accuracy: 68.36\n",
      "[3,    18] loss: 0.90775, train_accuracy: 67.38\n",
      "[3,    19] loss: 0.89194, train_accuracy: 67.19\n",
      "[3,    20] loss: 0.86244, train_accuracy: 68.95\n",
      "[3,    21] loss: 0.81722, train_accuracy: 70.31\n",
      "[3,    22] loss: 0.87316, train_accuracy: 67.97\n",
      "[3,    23] loss: 0.82934, train_accuracy: 68.95\n",
      "[3,    24] loss: 0.89554, train_accuracy: 67.58\n",
      "[3,    25] loss: 0.96671, train_accuracy: 67.38\n",
      "[3,    26] loss: 0.87915, train_accuracy: 66.99\n",
      "[3,    27] loss: 0.87919, train_accuracy: 66.60\n",
      "[3,    28] loss: 0.84924, train_accuracy: 69.73\n",
      "[3,    29] loss: 0.92043, train_accuracy: 66.41\n",
      "[3,    30] loss: 0.91329, train_accuracy: 66.80\n",
      "[3,    31] loss: 0.86829, train_accuracy: 67.58\n",
      "[3,    32] loss: 0.85171, train_accuracy: 70.12\n",
      "[3,    33] loss: 0.82766, train_accuracy: 71.68\n",
      "[3,    34] loss: 0.85168, train_accuracy: 69.34\n",
      "[3,    35] loss: 0.89629, train_accuracy: 67.97\n",
      "[3,    36] loss: 0.84601, train_accuracy: 68.16\n",
      "[3,    37] loss: 0.77883, train_accuracy: 70.90\n",
      "[3,    38] loss: 0.90789, train_accuracy: 66.99\n",
      "[3,    39] loss: 0.85827, train_accuracy: 66.80\n",
      "[3,    40] loss: 0.97881, train_accuracy: 67.38\n",
      "[3,    41] loss: 0.86866, train_accuracy: 68.55\n",
      "[3,    42] loss: 0.94753, train_accuracy: 67.38\n",
      "[3,    43] loss: 0.82498, train_accuracy: 71.88\n",
      "[3,    44] loss: 0.85840, train_accuracy: 70.31\n",
      "[3,    45] loss: 0.83631, train_accuracy: 69.73\n",
      "[3,    46] loss: 0.85958, train_accuracy: 67.97\n",
      "[3,    47] loss: 0.84444, train_accuracy: 68.95\n",
      "[3,    48] loss: 0.98325, train_accuracy: 64.65\n",
      "[3,    49] loss: 0.78876, train_accuracy: 69.14\n",
      "[3,    50] loss: 0.91872, train_accuracy: 66.21\n",
      "[3,    51] loss: 0.82688, train_accuracy: 68.75\n",
      "[3,    52] loss: 0.85998, train_accuracy: 68.55\n",
      "[3,    53] loss: 0.78619, train_accuracy: 71.68\n",
      "[3,    54] loss: 0.93616, train_accuracy: 67.77\n",
      "[3,    55] loss: 0.88552, train_accuracy: 68.16\n",
      "[3,    56] loss: 0.84862, train_accuracy: 68.75\n",
      "[3,    57] loss: 0.89104, train_accuracy: 66.99\n",
      "[3,    58] loss: 0.88579, train_accuracy: 68.16\n",
      "[3,    59] loss: 0.93703, train_accuracy: 66.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    60] loss: 0.97827, train_accuracy: 66.60\n",
      "[3,    61] loss: 0.86630, train_accuracy: 69.34\n",
      "[3,    62] loss: 0.85550, train_accuracy: 70.31\n",
      "[3,    63] loss: 0.90250, train_accuracy: 67.38\n",
      "[3,    64] loss: 0.89560, train_accuracy: 69.34\n",
      "[3,    65] loss: 0.92977, train_accuracy: 66.80\n",
      "[3,    66] loss: 0.85045, train_accuracy: 67.38\n",
      "[3,    67] loss: 0.86874, train_accuracy: 69.14\n",
      "[3,    68] loss: 0.91934, train_accuracy: 68.75\n",
      "[3,    69] loss: 0.84534, train_accuracy: 68.16\n",
      "[3,    70] loss: 0.89575, train_accuracy: 66.99\n",
      "[3,    71] loss: 0.84589, train_accuracy: 68.95\n",
      "[3,    72] loss: 0.87957, train_accuracy: 67.97\n",
      "[3,    73] loss: 0.92305, train_accuracy: 66.41\n",
      "[3,    74] loss: 0.90635, train_accuracy: 67.58\n",
      "[3,    75] loss: 0.96797, train_accuracy: 67.38\n",
      "[3,    76] loss: 0.89432, train_accuracy: 67.38\n",
      "[3,    77] loss: 0.90415, train_accuracy: 67.77\n",
      "[3,    78] loss: 0.81596, train_accuracy: 70.31\n",
      "[3,    79] loss: 0.82914, train_accuracy: 69.14\n",
      "[3,    80] loss: 0.82069, train_accuracy: 69.92\n",
      "[3,    81] loss: 0.86867, train_accuracy: 67.97\n",
      "[3,    82] loss: 0.91666, train_accuracy: 66.99\n",
      "[3,    83] loss: 0.77941, train_accuracy: 72.66\n",
      "[3,    84] loss: 0.85852, train_accuracy: 69.73\n",
      "[3,    85] loss: 0.81560, train_accuracy: 70.90\n",
      "[3,    86] loss: 0.82461, train_accuracy: 67.97\n",
      "[3,    87] loss: 0.86241, train_accuracy: 66.99\n",
      "[3,    88] loss: 0.94747, train_accuracy: 67.19\n",
      "[3,    89] loss: 0.85943, train_accuracy: 68.75\n",
      "[3,    90] loss: 0.85610, train_accuracy: 70.51\n",
      "[3,    91] loss: 0.85492, train_accuracy: 68.55\n",
      "[3,    92] loss: 0.96253, train_accuracy: 66.80\n",
      "[3,    93] loss: 0.92152, train_accuracy: 66.99\n",
      "[3,    94] loss: 0.77806, train_accuracy: 73.05\n",
      "[3,    95] loss: 0.91512, train_accuracy: 66.99\n",
      "[3,    96] loss: 0.85804, train_accuracy: 68.95\n",
      "[3,    97] loss: 0.78872, train_accuracy: 70.51\n",
      "[3,    98] loss: 0.84407, train_accuracy: 71.13\n",
      "duration: 24 s - train loss: 0.88016 - train accuracy: 68.29 - validation loss: 1.15 - validation accuracy: 61.11 \n",
      "[4,     1] loss: 0.78286, train_accuracy: 72.07\n",
      "[4,     2] loss: 0.80795, train_accuracy: 70.70\n",
      "[4,     3] loss: 0.89545, train_accuracy: 69.53\n",
      "[4,     4] loss: 0.84073, train_accuracy: 67.97\n",
      "[4,     5] loss: 0.89708, train_accuracy: 69.92\n",
      "[4,     6] loss: 0.84471, train_accuracy: 68.16\n",
      "[4,     7] loss: 0.85817, train_accuracy: 71.48\n",
      "[4,     8] loss: 0.80775, train_accuracy: 70.12\n",
      "[4,     9] loss: 0.83490, train_accuracy: 71.29\n",
      "[4,    10] loss: 0.81155, train_accuracy: 68.95\n",
      "[4,    11] loss: 0.77884, train_accuracy: 69.73\n",
      "[4,    12] loss: 0.77102, train_accuracy: 72.85\n",
      "[4,    13] loss: 0.80481, train_accuracy: 69.14\n",
      "[4,    14] loss: 0.85390, train_accuracy: 72.07\n",
      "[4,    15] loss: 0.87606, train_accuracy: 67.38\n",
      "[4,    16] loss: 0.79649, train_accuracy: 72.07\n",
      "[4,    17] loss: 0.77431, train_accuracy: 72.07\n",
      "[4,    18] loss: 0.79925, train_accuracy: 71.68\n",
      "[4,    19] loss: 0.89429, train_accuracy: 66.41\n",
      "[4,    20] loss: 0.86841, train_accuracy: 69.73\n",
      "[4,    21] loss: 0.84712, train_accuracy: 69.92\n",
      "[4,    22] loss: 0.78221, train_accuracy: 72.07\n",
      "[4,    23] loss: 0.75922, train_accuracy: 72.27\n",
      "[4,    24] loss: 0.85191, train_accuracy: 67.77\n",
      "[4,    25] loss: 0.76430, train_accuracy: 72.46\n",
      "[4,    26] loss: 0.89335, train_accuracy: 66.80\n",
      "[4,    27] loss: 0.86057, train_accuracy: 67.77\n",
      "[4,    28] loss: 0.89931, train_accuracy: 66.80\n",
      "[4,    29] loss: 0.83989, train_accuracy: 68.95\n",
      "[4,    30] loss: 0.88292, train_accuracy: 67.97\n",
      "[4,    31] loss: 0.82970, train_accuracy: 72.66\n",
      "[4,    32] loss: 0.75342, train_accuracy: 72.27\n",
      "[4,    33] loss: 0.84710, train_accuracy: 70.12\n",
      "[4,    34] loss: 0.80124, train_accuracy: 70.12\n",
      "[4,    35] loss: 0.79156, train_accuracy: 73.63\n",
      "[4,    36] loss: 0.86893, train_accuracy: 69.92\n",
      "[4,    37] loss: 0.86683, train_accuracy: 69.53\n",
      "[4,    38] loss: 0.80086, train_accuracy: 71.68\n",
      "[4,    39] loss: 0.84766, train_accuracy: 69.73\n",
      "[4,    40] loss: 0.77245, train_accuracy: 72.46\n",
      "[4,    41] loss: 0.79918, train_accuracy: 70.51\n",
      "[4,    42] loss: 0.96643, train_accuracy: 66.60\n",
      "[4,    43] loss: 0.83780, train_accuracy: 69.53\n",
      "[4,    44] loss: 0.78748, train_accuracy: 71.48\n",
      "[4,    45] loss: 0.86396, train_accuracy: 68.75\n",
      "[4,    46] loss: 0.80862, train_accuracy: 69.53\n",
      "[4,    47] loss: 0.84469, train_accuracy: 70.12\n",
      "[4,    48] loss: 0.82681, train_accuracy: 71.29\n",
      "[4,    49] loss: 0.72730, train_accuracy: 75.59\n",
      "[4,    50] loss: 0.80975, train_accuracy: 69.92\n",
      "[4,    51] loss: 0.78799, train_accuracy: 72.85\n",
      "[4,    52] loss: 0.84582, train_accuracy: 70.31\n",
      "[4,    53] loss: 0.82225, train_accuracy: 69.53\n",
      "[4,    54] loss: 0.86385, train_accuracy: 70.70\n",
      "[4,    55] loss: 0.90676, train_accuracy: 67.97\n",
      "[4,    56] loss: 0.85245, train_accuracy: 66.99\n",
      "[4,    57] loss: 0.91989, train_accuracy: 66.41\n",
      "[4,    58] loss: 0.81711, train_accuracy: 69.92\n",
      "[4,    59] loss: 0.82790, train_accuracy: 71.29\n",
      "[4,    60] loss: 0.97197, train_accuracy: 67.38\n",
      "[4,    61] loss: 0.87741, train_accuracy: 69.92\n",
      "[4,    62] loss: 0.83390, train_accuracy: 69.53\n",
      "[4,    63] loss: 0.80239, train_accuracy: 71.48\n",
      "[4,    64] loss: 0.75139, train_accuracy: 72.66\n",
      "[4,    65] loss: 0.73055, train_accuracy: 74.41\n",
      "[4,    66] loss: 0.78115, train_accuracy: 70.90\n",
      "[4,    67] loss: 0.85379, train_accuracy: 69.14\n",
      "[4,    68] loss: 0.87895, train_accuracy: 67.97\n",
      "[4,    69] loss: 0.91763, train_accuracy: 66.60\n",
      "[4,    70] loss: 0.94527, train_accuracy: 65.23\n",
      "[4,    71] loss: 0.80011, train_accuracy: 70.12\n",
      "[4,    72] loss: 0.75257, train_accuracy: 73.63\n",
      "[4,    73] loss: 0.75233, train_accuracy: 75.00\n",
      "[4,    74] loss: 0.79122, train_accuracy: 68.36\n",
      "[4,    75] loss: 0.81906, train_accuracy: 70.90\n",
      "[4,    76] loss: 0.79042, train_accuracy: 71.48\n",
      "[4,    77] loss: 0.77186, train_accuracy: 72.07\n",
      "[4,    78] loss: 0.85691, train_accuracy: 67.38\n",
      "[4,    79] loss: 0.86062, train_accuracy: 69.53\n",
      "[4,    80] loss: 0.81350, train_accuracy: 70.90\n",
      "[4,    81] loss: 0.80527, train_accuracy: 70.12\n",
      "[4,    82] loss: 0.73921, train_accuracy: 73.63\n",
      "[4,    83] loss: 0.83045, train_accuracy: 67.97\n",
      "[4,    84] loss: 0.78493, train_accuracy: 70.90\n",
      "[4,    85] loss: 0.83545, train_accuracy: 73.44\n",
      "[4,    86] loss: 0.77656, train_accuracy: 71.68\n",
      "[4,    87] loss: 0.81383, train_accuracy: 69.34\n",
      "[4,    88] loss: 0.84066, train_accuracy: 68.55\n",
      "[4,    89] loss: 0.80806, train_accuracy: 71.09\n",
      "[4,    90] loss: 0.82763, train_accuracy: 68.95\n",
      "[4,    91] loss: 0.76986, train_accuracy: 71.48\n",
      "[4,    92] loss: 0.88058, train_accuracy: 68.95\n",
      "[4,    93] loss: 0.75154, train_accuracy: 72.07\n",
      "[4,    94] loss: 0.81152, train_accuracy: 71.48\n",
      "[4,    95] loss: 0.86548, train_accuracy: 67.58\n",
      "[4,    96] loss: 0.88675, train_accuracy: 68.95\n",
      "[4,    97] loss: 0.88955, train_accuracy: 67.97\n",
      "[4,    98] loss: 0.79404, train_accuracy: 73.21\n",
      "duration: 24 s - train loss: 0.82795 - train accuracy: 70.20 - validation loss: 1.13 - validation accuracy: 61.83 \n",
      "[5,     1] loss: 0.75198, train_accuracy: 73.05\n",
      "[5,     2] loss: 0.73666, train_accuracy: 72.07\n",
      "[5,     3] loss: 0.75717, train_accuracy: 73.05\n",
      "[5,     4] loss: 0.81804, train_accuracy: 71.29\n",
      "[5,     5] loss: 0.78050, train_accuracy: 69.92\n",
      "[5,     6] loss: 0.71575, train_accuracy: 75.20\n",
      "[5,     7] loss: 0.81605, train_accuracy: 71.29\n",
      "[5,     8] loss: 0.86443, train_accuracy: 68.75\n",
      "[5,     9] loss: 0.71170, train_accuracy: 74.41\n",
      "[5,    10] loss: 0.80480, train_accuracy: 70.51\n",
      "[5,    11] loss: 0.73068, train_accuracy: 73.63\n",
      "[5,    12] loss: 0.77907, train_accuracy: 70.90\n",
      "[5,    13] loss: 0.74344, train_accuracy: 73.24\n",
      "[5,    14] loss: 0.74029, train_accuracy: 75.20\n",
      "[5,    15] loss: 0.77637, train_accuracy: 73.63\n",
      "[5,    16] loss: 0.77118, train_accuracy: 71.48\n",
      "[5,    17] loss: 0.81086, train_accuracy: 72.07\n",
      "[5,    18] loss: 0.83824, train_accuracy: 68.95\n",
      "[5,    19] loss: 0.77479, train_accuracy: 71.68\n",
      "[5,    20] loss: 0.86484, train_accuracy: 68.95\n",
      "[5,    21] loss: 0.76421, train_accuracy: 74.02\n",
      "[5,    22] loss: 0.76812, train_accuracy: 71.88\n",
      "[5,    23] loss: 0.82942, train_accuracy: 69.34\n",
      "[5,    24] loss: 0.77330, train_accuracy: 71.48\n",
      "[5,    25] loss: 0.75968, train_accuracy: 72.85\n",
      "[5,    26] loss: 0.77193, train_accuracy: 71.68\n",
      "[5,    27] loss: 0.83211, train_accuracy: 69.53\n",
      "[5,    28] loss: 0.78028, train_accuracy: 72.66\n",
      "[5,    29] loss: 0.77260, train_accuracy: 74.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,    30] loss: 0.73639, train_accuracy: 74.02\n",
      "[5,    31] loss: 0.72091, train_accuracy: 73.44\n",
      "[5,    32] loss: 0.78724, train_accuracy: 72.07\n",
      "[5,    33] loss: 0.80688, train_accuracy: 70.51\n",
      "[5,    34] loss: 0.84538, train_accuracy: 68.95\n",
      "[5,    35] loss: 0.88075, train_accuracy: 68.75\n",
      "[5,    36] loss: 0.74115, train_accuracy: 73.83\n",
      "[5,    37] loss: 0.83622, train_accuracy: 70.31\n",
      "[5,    38] loss: 0.79119, train_accuracy: 69.92\n",
      "[5,    39] loss: 0.78460, train_accuracy: 71.48\n",
      "[5,    40] loss: 0.92799, train_accuracy: 67.77\n",
      "[5,    41] loss: 0.92350, train_accuracy: 69.14\n",
      "[5,    42] loss: 0.73309, train_accuracy: 74.22\n",
      "[5,    43] loss: 0.80770, train_accuracy: 72.85\n",
      "[5,    44] loss: 0.82810, train_accuracy: 70.31\n",
      "[5,    45] loss: 0.80240, train_accuracy: 71.29\n",
      "[5,    46] loss: 0.76208, train_accuracy: 72.27\n",
      "[5,    47] loss: 0.85305, train_accuracy: 70.70\n",
      "[5,    48] loss: 0.81299, train_accuracy: 71.68\n",
      "[5,    49] loss: 0.77116, train_accuracy: 73.63\n",
      "[5,    50] loss: 0.70740, train_accuracy: 71.88\n",
      "[5,    51] loss: 0.91069, train_accuracy: 69.34\n",
      "[5,    52] loss: 0.77264, train_accuracy: 70.70\n",
      "[5,    53] loss: 0.75662, train_accuracy: 71.68\n",
      "[5,    54] loss: 0.76679, train_accuracy: 70.90\n",
      "[5,    55] loss: 0.77870, train_accuracy: 72.07\n",
      "[5,    56] loss: 0.88702, train_accuracy: 69.73\n",
      "[5,    57] loss: 0.79845, train_accuracy: 73.24\n",
      "[5,    58] loss: 0.85321, train_accuracy: 71.68\n",
      "[5,    59] loss: 0.75545, train_accuracy: 74.02\n",
      "[5,    60] loss: 0.83063, train_accuracy: 72.07\n",
      "[5,    61] loss: 0.74341, train_accuracy: 73.63\n",
      "[5,    62] loss: 0.81895, train_accuracy: 70.12\n",
      "[5,    63] loss: 0.80826, train_accuracy: 69.53\n",
      "[5,    64] loss: 0.80100, train_accuracy: 72.27\n",
      "[5,    65] loss: 0.74165, train_accuracy: 75.00\n",
      "[5,    66] loss: 0.84766, train_accuracy: 69.53\n",
      "[5,    67] loss: 0.75287, train_accuracy: 73.63\n",
      "[5,    68] loss: 0.84924, train_accuracy: 69.73\n",
      "[5,    69] loss: 0.69598, train_accuracy: 74.22\n",
      "[5,    70] loss: 0.73399, train_accuracy: 75.59\n",
      "[5,    71] loss: 0.83959, train_accuracy: 69.34\n",
      "[5,    72] loss: 0.77678, train_accuracy: 70.51\n",
      "[5,    73] loss: 0.78643, train_accuracy: 73.05\n",
      "[5,    74] loss: 0.78357, train_accuracy: 71.68\n",
      "[5,    75] loss: 0.77726, train_accuracy: 71.29\n",
      "[5,    76] loss: 0.79870, train_accuracy: 71.29\n",
      "[5,    77] loss: 0.75196, train_accuracy: 75.39\n",
      "[5,    78] loss: 0.83728, train_accuracy: 71.09\n",
      "[5,    79] loss: 0.74747, train_accuracy: 73.05\n",
      "[5,    80] loss: 0.73840, train_accuracy: 71.68\n",
      "[5,    81] loss: 0.78760, train_accuracy: 72.66\n",
      "[5,    82] loss: 0.81813, train_accuracy: 70.70\n",
      "[5,    83] loss: 0.84745, train_accuracy: 70.12\n",
      "[5,    84] loss: 0.81677, train_accuracy: 70.12\n",
      "[5,    85] loss: 0.87908, train_accuracy: 67.58\n",
      "[5,    86] loss: 0.76459, train_accuracy: 72.66\n",
      "[5,    87] loss: 0.83163, train_accuracy: 72.07\n",
      "[5,    88] loss: 0.77486, train_accuracy: 72.27\n",
      "[5,    89] loss: 0.82884, train_accuracy: 70.90\n",
      "[5,    90] loss: 0.73816, train_accuracy: 73.05\n",
      "[5,    91] loss: 0.81726, train_accuracy: 70.31\n",
      "[5,    92] loss: 0.80442, train_accuracy: 69.92\n",
      "[5,    93] loss: 0.77430, train_accuracy: 71.09\n",
      "[5,    94] loss: 0.80289, train_accuracy: 69.73\n",
      "[5,    95] loss: 0.83502, train_accuracy: 70.51\n",
      "[5,    96] loss: 0.82539, train_accuracy: 73.05\n",
      "[5,    97] loss: 0.83417, train_accuracy: 69.14\n",
      "[5,    98] loss: 0.74824, train_accuracy: 70.83\n",
      "duration: 24 s - train loss: 0.79355 - train accuracy: 71.63 - validation loss: 1.12 - validation accuracy: 62.42 \n",
      "[6,     1] loss: 0.71748, train_accuracy: 76.37\n",
      "[6,     2] loss: 0.67999, train_accuracy: 77.15\n",
      "[6,     3] loss: 0.69108, train_accuracy: 75.78\n",
      "[6,     4] loss: 0.77585, train_accuracy: 70.51\n",
      "[6,     5] loss: 0.75353, train_accuracy: 73.63\n",
      "[6,     6] loss: 0.74471, train_accuracy: 71.48\n",
      "[6,     7] loss: 0.84871, train_accuracy: 70.12\n",
      "[6,     8] loss: 0.75079, train_accuracy: 74.41\n",
      "[6,     9] loss: 0.70269, train_accuracy: 74.41\n",
      "[6,    10] loss: 0.77472, train_accuracy: 70.31\n",
      "[6,    11] loss: 0.77526, train_accuracy: 71.29\n",
      "[6,    12] loss: 0.78119, train_accuracy: 71.88\n",
      "[6,    13] loss: 0.78877, train_accuracy: 70.31\n",
      "[6,    14] loss: 0.74004, train_accuracy: 72.85\n",
      "[6,    15] loss: 0.73292, train_accuracy: 74.41\n",
      "[6,    16] loss: 0.73616, train_accuracy: 73.63\n",
      "[6,    17] loss: 0.79560, train_accuracy: 73.24\n",
      "[6,    18] loss: 0.73669, train_accuracy: 73.83\n",
      "[6,    19] loss: 0.74644, train_accuracy: 73.83\n",
      "[6,    20] loss: 0.73893, train_accuracy: 74.61\n",
      "[6,    21] loss: 0.81054, train_accuracy: 71.29\n",
      "[6,    22] loss: 0.77772, train_accuracy: 72.85\n",
      "[6,    23] loss: 0.75388, train_accuracy: 74.22\n",
      "[6,    24] loss: 0.73829, train_accuracy: 75.00\n",
      "[6,    25] loss: 0.71731, train_accuracy: 75.78\n",
      "[6,    26] loss: 0.72175, train_accuracy: 75.20\n",
      "[6,    27] loss: 0.74475, train_accuracy: 74.02\n",
      "[6,    28] loss: 0.72647, train_accuracy: 73.24\n",
      "[6,    29] loss: 0.70984, train_accuracy: 74.41\n",
      "[6,    30] loss: 0.79055, train_accuracy: 70.51\n",
      "[6,    31] loss: 0.69969, train_accuracy: 74.80\n",
      "[6,    32] loss: 0.82032, train_accuracy: 70.31\n",
      "[6,    33] loss: 0.81261, train_accuracy: 72.46\n",
      "[6,    34] loss: 0.72426, train_accuracy: 74.80\n",
      "[6,    35] loss: 0.81210, train_accuracy: 71.88\n",
      "[6,    36] loss: 0.74105, train_accuracy: 72.85\n",
      "[6,    37] loss: 0.80728, train_accuracy: 70.31\n",
      "[6,    38] loss: 0.79136, train_accuracy: 73.05\n",
      "[6,    39] loss: 0.78645, train_accuracy: 72.07\n",
      "[6,    40] loss: 0.78822, train_accuracy: 70.31\n",
      "[6,    41] loss: 0.80840, train_accuracy: 70.51\n",
      "[6,    42] loss: 0.81077, train_accuracy: 70.31\n",
      "[6,    43] loss: 0.89376, train_accuracy: 67.77\n",
      "[6,    44] loss: 0.82901, train_accuracy: 70.51\n",
      "[6,    45] loss: 0.84575, train_accuracy: 67.58\n",
      "[6,    46] loss: 0.74327, train_accuracy: 72.07\n",
      "[6,    47] loss: 0.73231, train_accuracy: 74.22\n",
      "[6,    48] loss: 0.80632, train_accuracy: 70.90\n",
      "[6,    49] loss: 0.79210, train_accuracy: 73.63\n",
      "[6,    50] loss: 0.71638, train_accuracy: 76.95\n",
      "[6,    51] loss: 0.83556, train_accuracy: 69.92\n",
      "[6,    52] loss: 0.79008, train_accuracy: 68.75\n",
      "[6,    53] loss: 0.78350, train_accuracy: 72.07\n",
      "[6,    54] loss: 0.86973, train_accuracy: 66.99\n",
      "[6,    55] loss: 0.75109, train_accuracy: 72.85\n",
      "[6,    56] loss: 0.81818, train_accuracy: 68.16\n",
      "[6,    57] loss: 0.84812, train_accuracy: 69.73\n",
      "[6,    58] loss: 0.79570, train_accuracy: 70.12\n",
      "[6,    59] loss: 0.75951, train_accuracy: 74.02\n",
      "[6,    60] loss: 0.71409, train_accuracy: 73.05\n",
      "[6,    61] loss: 0.75147, train_accuracy: 75.39\n",
      "[6,    62] loss: 0.76625, train_accuracy: 72.85\n",
      "[6,    63] loss: 0.73963, train_accuracy: 73.24\n",
      "[6,    64] loss: 0.78485, train_accuracy: 72.27\n",
      "[6,    65] loss: 0.80313, train_accuracy: 71.48\n",
      "[6,    66] loss: 0.78930, train_accuracy: 71.29\n",
      "[6,    67] loss: 0.78966, train_accuracy: 72.27\n",
      "[6,    68] loss: 0.73468, train_accuracy: 73.83\n",
      "[6,    69] loss: 0.79800, train_accuracy: 69.34\n",
      "[6,    70] loss: 0.78068, train_accuracy: 68.55\n",
      "[6,    71] loss: 0.78383, train_accuracy: 72.66\n",
      "[6,    72] loss: 0.80876, train_accuracy: 71.09\n",
      "[6,    73] loss: 0.75100, train_accuracy: 73.83\n",
      "[6,    74] loss: 0.72913, train_accuracy: 72.46\n",
      "[6,    75] loss: 0.72959, train_accuracy: 73.83\n",
      "[6,    76] loss: 0.74082, train_accuracy: 72.66\n",
      "[6,    77] loss: 0.76161, train_accuracy: 73.44\n",
      "[6,    78] loss: 0.77160, train_accuracy: 73.83\n",
      "[6,    79] loss: 0.76831, train_accuracy: 71.88\n",
      "[6,    80] loss: 0.80653, train_accuracy: 72.85\n",
      "[6,    81] loss: 0.83865, train_accuracy: 70.31\n",
      "[6,    82] loss: 0.76821, train_accuracy: 72.07\n",
      "[6,    83] loss: 0.84554, train_accuracy: 69.14\n",
      "[6,    84] loss: 0.76250, train_accuracy: 73.05\n",
      "[6,    85] loss: 0.79138, train_accuracy: 70.51\n",
      "[6,    86] loss: 0.79537, train_accuracy: 71.88\n",
      "[6,    87] loss: 0.70654, train_accuracy: 73.44\n",
      "[6,    88] loss: 0.69654, train_accuracy: 74.80\n",
      "[6,    89] loss: 0.76679, train_accuracy: 73.63\n",
      "[6,    90] loss: 0.80155, train_accuracy: 69.34\n",
      "[6,    91] loss: 0.78038, train_accuracy: 71.29\n",
      "[6,    92] loss: 0.81290, train_accuracy: 72.07\n",
      "[6,    93] loss: 0.78226, train_accuracy: 71.29\n",
      "[6,    94] loss: 0.73154, train_accuracy: 74.22\n",
      "[6,    95] loss: 0.81257, train_accuracy: 71.09\n",
      "[6,    96] loss: 0.72618, train_accuracy: 75.20\n",
      "[6,    97] loss: 0.73325, train_accuracy: 73.44\n",
      "[6,    98] loss: 0.80321, train_accuracy: 71.43\n",
      "duration: 23 s - train loss: 0.77116 - train accuracy: 72.35 - validation loss: 1.10 - validation accuracy: 63.14 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,     1] loss: 0.69217, train_accuracy: 75.39\n",
      "[7,     2] loss: 0.65587, train_accuracy: 76.17\n",
      "[7,     3] loss: 0.69997, train_accuracy: 77.54\n",
      "[7,     4] loss: 0.70057, train_accuracy: 73.44\n",
      "[7,     5] loss: 0.67384, train_accuracy: 76.76\n",
      "[7,     6] loss: 0.71741, train_accuracy: 73.44\n",
      "[7,     7] loss: 0.72575, train_accuracy: 72.46\n",
      "[7,     8] loss: 0.71067, train_accuracy: 74.02\n",
      "[7,     9] loss: 0.75863, train_accuracy: 73.24\n",
      "[7,    10] loss: 0.73488, train_accuracy: 76.17\n",
      "[7,    11] loss: 0.69517, train_accuracy: 74.41\n",
      "[7,    12] loss: 0.76401, train_accuracy: 71.29\n",
      "[7,    13] loss: 0.68712, train_accuracy: 76.95\n",
      "[7,    14] loss: 0.67286, train_accuracy: 74.41\n",
      "[7,    15] loss: 0.68215, train_accuracy: 75.98\n",
      "[7,    16] loss: 0.78544, train_accuracy: 72.46\n",
      "[7,    17] loss: 0.74158, train_accuracy: 73.05\n",
      "[7,    18] loss: 0.74576, train_accuracy: 73.24\n",
      "[7,    19] loss: 0.77822, train_accuracy: 73.63\n",
      "[7,    20] loss: 0.77932, train_accuracy: 73.05\n",
      "[7,    21] loss: 0.69082, train_accuracy: 77.73\n",
      "[7,    22] loss: 0.83928, train_accuracy: 70.90\n",
      "[7,    23] loss: 0.71458, train_accuracy: 76.76\n",
      "[7,    24] loss: 0.70852, train_accuracy: 72.07\n",
      "[7,    25] loss: 0.80493, train_accuracy: 70.12\n",
      "[7,    26] loss: 0.71205, train_accuracy: 72.46\n",
      "[7,    27] loss: 0.83388, train_accuracy: 69.34\n",
      "[7,    28] loss: 0.71822, train_accuracy: 73.24\n",
      "[7,    29] loss: 0.76402, train_accuracy: 75.20\n",
      "[7,    30] loss: 0.70471, train_accuracy: 73.24\n",
      "[7,    31] loss: 0.65874, train_accuracy: 75.98\n",
      "[7,    32] loss: 0.72508, train_accuracy: 72.85\n",
      "[7,    33] loss: 0.73581, train_accuracy: 74.41\n",
      "[7,    34] loss: 0.71954, train_accuracy: 71.68\n",
      "[7,    35] loss: 0.74849, train_accuracy: 71.09\n",
      "[7,    36] loss: 0.73047, train_accuracy: 73.05\n",
      "[7,    37] loss: 0.76741, train_accuracy: 73.05\n",
      "[7,    38] loss: 0.74139, train_accuracy: 73.44\n",
      "[7,    39] loss: 0.73541, train_accuracy: 72.66\n",
      "[7,    40] loss: 0.83471, train_accuracy: 72.27\n",
      "[7,    41] loss: 0.81151, train_accuracy: 69.73\n",
      "[7,    42] loss: 0.76055, train_accuracy: 73.83\n",
      "[7,    43] loss: 0.76690, train_accuracy: 75.00\n",
      "[7,    44] loss: 0.76956, train_accuracy: 70.90\n",
      "[7,    45] loss: 0.81023, train_accuracy: 69.92\n",
      "[7,    46] loss: 0.78832, train_accuracy: 71.09\n",
      "[7,    47] loss: 0.78037, train_accuracy: 73.83\n",
      "[7,    48] loss: 0.70207, train_accuracy: 74.41\n",
      "[7,    49] loss: 0.73414, train_accuracy: 74.41\n",
      "[7,    50] loss: 0.67952, train_accuracy: 75.98\n",
      "[7,    51] loss: 0.66526, train_accuracy: 74.02\n",
      "[7,    52] loss: 0.80090, train_accuracy: 71.88\n",
      "[7,    53] loss: 0.75170, train_accuracy: 73.44\n",
      "[7,    54] loss: 0.77197, train_accuracy: 74.02\n",
      "[7,    55] loss: 0.77112, train_accuracy: 73.44\n",
      "[7,    56] loss: 0.82055, train_accuracy: 70.31\n",
      "[7,    57] loss: 0.72751, train_accuracy: 74.02\n",
      "[7,    58] loss: 0.78857, train_accuracy: 71.48\n",
      "[7,    59] loss: 0.71146, train_accuracy: 73.24\n",
      "[7,    60] loss: 0.82323, train_accuracy: 71.29\n",
      "[7,    61] loss: 0.79565, train_accuracy: 69.34\n",
      "[7,    62] loss: 0.69478, train_accuracy: 75.98\n",
      "[7,    63] loss: 0.74231, train_accuracy: 72.85\n",
      "[7,    64] loss: 0.77027, train_accuracy: 71.68\n",
      "[7,    65] loss: 0.77762, train_accuracy: 74.02\n",
      "[7,    66] loss: 0.76473, train_accuracy: 73.05\n",
      "[7,    67] loss: 0.83443, train_accuracy: 70.51\n",
      "[7,    68] loss: 0.76529, train_accuracy: 73.63\n",
      "[7,    69] loss: 0.71679, train_accuracy: 75.20\n",
      "[7,    70] loss: 0.82971, train_accuracy: 69.73\n",
      "[7,    71] loss: 0.75712, train_accuracy: 72.85\n",
      "[7,    72] loss: 0.80452, train_accuracy: 71.68\n",
      "[7,    73] loss: 0.79018, train_accuracy: 70.90\n",
      "[7,    74] loss: 0.81064, train_accuracy: 69.73\n",
      "[7,    75] loss: 0.82505, train_accuracy: 72.07\n",
      "[7,    76] loss: 0.63925, train_accuracy: 75.20\n",
      "[7,    77] loss: 0.72971, train_accuracy: 72.46\n",
      "[7,    78] loss: 0.71189, train_accuracy: 74.41\n",
      "[7,    79] loss: 0.75025, train_accuracy: 73.05\n",
      "[7,    80] loss: 0.65055, train_accuracy: 77.15\n",
      "[7,    81] loss: 0.75795, train_accuracy: 72.66\n",
      "[7,    82] loss: 0.77691, train_accuracy: 71.88\n",
      "[7,    83] loss: 0.80330, train_accuracy: 72.07\n",
      "[7,    84] loss: 0.72728, train_accuracy: 74.41\n",
      "[7,    85] loss: 0.83166, train_accuracy: 70.51\n",
      "[7,    86] loss: 0.73765, train_accuracy: 72.27\n",
      "[7,    87] loss: 0.81580, train_accuracy: 72.27\n",
      "[7,    88] loss: 0.75195, train_accuracy: 71.68\n",
      "[7,    89] loss: 0.82791, train_accuracy: 72.85\n",
      "[7,    90] loss: 0.71893, train_accuracy: 75.20\n",
      "[7,    91] loss: 0.79824, train_accuracy: 73.44\n",
      "[7,    92] loss: 0.78904, train_accuracy: 71.68\n",
      "[7,    93] loss: 0.77289, train_accuracy: 74.80\n",
      "[7,    94] loss: 0.80930, train_accuracy: 72.66\n",
      "[7,    95] loss: 0.70254, train_accuracy: 75.98\n",
      "[7,    96] loss: 0.72637, train_accuracy: 72.27\n",
      "[7,    97] loss: 0.72178, train_accuracy: 74.61\n",
      "[7,    98] loss: 0.73688, train_accuracy: 70.83\n",
      "duration: 24 s - train loss: 0.74992 - train accuracy: 73.19 - validation loss: 1.10 - validation accuracy: 63.75 \n",
      "[8,     1] loss: 0.76276, train_accuracy: 71.48\n",
      "[8,     2] loss: 0.68443, train_accuracy: 75.78\n",
      "[8,     3] loss: 0.78965, train_accuracy: 69.53\n",
      "[8,     4] loss: 0.75585, train_accuracy: 73.83\n",
      "[8,     5] loss: 0.77903, train_accuracy: 71.68\n",
      "[8,     6] loss: 0.70351, train_accuracy: 74.41\n",
      "[8,     7] loss: 0.70072, train_accuracy: 76.17\n",
      "[8,     8] loss: 0.71988, train_accuracy: 75.98\n",
      "[8,     9] loss: 0.68182, train_accuracy: 75.39\n",
      "[8,    10] loss: 0.71752, train_accuracy: 74.80\n",
      "[8,    11] loss: 0.74528, train_accuracy: 73.83\n",
      "[8,    12] loss: 0.69303, train_accuracy: 75.98\n",
      "[8,    13] loss: 0.74212, train_accuracy: 73.63\n",
      "[8,    14] loss: 0.73798, train_accuracy: 69.92\n",
      "[8,    15] loss: 0.72506, train_accuracy: 75.00\n",
      "[8,    16] loss: 0.62271, train_accuracy: 77.93\n",
      "[8,    17] loss: 0.73564, train_accuracy: 75.00\n",
      "[8,    18] loss: 0.80823, train_accuracy: 70.31\n",
      "[8,    19] loss: 0.70910, train_accuracy: 75.00\n",
      "[8,    20] loss: 0.72005, train_accuracy: 74.41\n",
      "[8,    21] loss: 0.70643, train_accuracy: 75.39\n",
      "[8,    22] loss: 0.62848, train_accuracy: 79.49\n",
      "[8,    23] loss: 0.73390, train_accuracy: 72.07\n",
      "[8,    24] loss: 0.65483, train_accuracy: 77.73\n",
      "[8,    25] loss: 0.76065, train_accuracy: 72.46\n",
      "[8,    26] loss: 0.67339, train_accuracy: 74.61\n",
      "[8,    27] loss: 0.67878, train_accuracy: 73.24\n",
      "[8,    28] loss: 0.83305, train_accuracy: 71.29\n",
      "[8,    29] loss: 0.78124, train_accuracy: 70.90\n",
      "[8,    30] loss: 0.71826, train_accuracy: 75.20\n",
      "[8,    31] loss: 0.74732, train_accuracy: 73.05\n",
      "[8,    32] loss: 0.79555, train_accuracy: 74.22\n",
      "[8,    33] loss: 0.76432, train_accuracy: 74.41\n",
      "[8,    34] loss: 0.74594, train_accuracy: 73.44\n",
      "[8,    35] loss: 0.73191, train_accuracy: 75.59\n",
      "[8,    36] loss: 0.68836, train_accuracy: 76.17\n",
      "[8,    37] loss: 0.73578, train_accuracy: 72.27\n",
      "[8,    38] loss: 0.76383, train_accuracy: 73.44\n",
      "[8,    39] loss: 0.65185, train_accuracy: 75.20\n",
      "[8,    40] loss: 0.68970, train_accuracy: 76.37\n",
      "[8,    41] loss: 0.82637, train_accuracy: 70.31\n",
      "[8,    42] loss: 0.74813, train_accuracy: 74.02\n",
      "[8,    43] loss: 0.66028, train_accuracy: 77.15\n",
      "[8,    44] loss: 0.77784, train_accuracy: 74.80\n",
      "[8,    45] loss: 0.72317, train_accuracy: 77.54\n",
      "[8,    46] loss: 0.74353, train_accuracy: 72.85\n",
      "[8,    47] loss: 0.67251, train_accuracy: 76.76\n",
      "[8,    48] loss: 0.73226, train_accuracy: 73.83\n",
      "[8,    49] loss: 0.66369, train_accuracy: 75.59\n",
      "[8,    50] loss: 0.70330, train_accuracy: 73.83\n",
      "[8,    51] loss: 0.82913, train_accuracy: 68.95\n",
      "[8,    52] loss: 0.68177, train_accuracy: 74.61\n",
      "[8,    53] loss: 0.76650, train_accuracy: 71.48\n",
      "[8,    54] loss: 0.66610, train_accuracy: 76.17\n",
      "[8,    55] loss: 0.68623, train_accuracy: 75.78\n",
      "[8,    56] loss: 0.74895, train_accuracy: 72.85\n",
      "[8,    57] loss: 0.74554, train_accuracy: 73.44\n",
      "[8,    58] loss: 0.79499, train_accuracy: 72.66\n",
      "[8,    59] loss: 0.67283, train_accuracy: 77.15\n",
      "[8,    60] loss: 0.70921, train_accuracy: 75.39\n",
      "[8,    61] loss: 0.73929, train_accuracy: 75.20\n",
      "[8,    62] loss: 0.68062, train_accuracy: 75.98\n",
      "[8,    63] loss: 0.74971, train_accuracy: 74.02\n",
      "[8,    64] loss: 0.70056, train_accuracy: 74.22\n",
      "[8,    65] loss: 0.67611, train_accuracy: 75.98\n",
      "[8,    66] loss: 0.75786, train_accuracy: 74.22\n",
      "[8,    67] loss: 0.68122, train_accuracy: 75.20\n",
      "[8,    68] loss: 0.71658, train_accuracy: 73.24\n",
      "[8,    69] loss: 0.72013, train_accuracy: 71.68\n",
      "[8,    70] loss: 0.74726, train_accuracy: 71.88\n",
      "[8,    71] loss: 0.72657, train_accuracy: 74.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,    72] loss: 0.73373, train_accuracy: 74.22\n",
      "[8,    73] loss: 0.76470, train_accuracy: 72.07\n",
      "[8,    74] loss: 0.72519, train_accuracy: 73.63\n",
      "[8,    75] loss: 0.82390, train_accuracy: 70.12\n",
      "[8,    76] loss: 0.72453, train_accuracy: 74.61\n",
      "[8,    77] loss: 0.75417, train_accuracy: 72.07\n",
      "[8,    78] loss: 0.77655, train_accuracy: 70.31\n",
      "[8,    79] loss: 0.69450, train_accuracy: 75.20\n",
      "[8,    80] loss: 0.77158, train_accuracy: 74.02\n",
      "[8,    81] loss: 0.74840, train_accuracy: 71.68\n",
      "[8,    82] loss: 0.73375, train_accuracy: 72.46\n",
      "[8,    83] loss: 0.69908, train_accuracy: 74.80\n",
      "[8,    84] loss: 0.68380, train_accuracy: 76.37\n",
      "[8,    85] loss: 0.74404, train_accuracy: 73.63\n",
      "[8,    86] loss: 0.71724, train_accuracy: 73.24\n",
      "[8,    87] loss: 0.84948, train_accuracy: 69.73\n",
      "[8,    88] loss: 0.74147, train_accuracy: 73.24\n",
      "[8,    89] loss: 0.80846, train_accuracy: 70.70\n",
      "[8,    90] loss: 0.79332, train_accuracy: 74.02\n",
      "[8,    91] loss: 0.69589, train_accuracy: 76.95\n",
      "[8,    92] loss: 0.83032, train_accuracy: 69.14\n",
      "[8,    93] loss: 0.83177, train_accuracy: 71.68\n",
      "[8,    94] loss: 0.71452, train_accuracy: 72.07\n",
      "[8,    95] loss: 0.84891, train_accuracy: 69.53\n",
      "[8,    96] loss: 0.72456, train_accuracy: 73.63\n",
      "[8,    97] loss: 0.73381, train_accuracy: 73.63\n",
      "[8,    98] loss: 0.87658, train_accuracy: 66.96\n",
      "duration: 25 s - train loss: 0.73480 - train accuracy: 73.75 - validation loss: 1.10 - validation accuracy: 63.50 \n",
      "[9,     1] loss: 0.69188, train_accuracy: 76.37\n",
      "[9,     2] loss: 0.76387, train_accuracy: 72.85\n",
      "[9,     3] loss: 0.71257, train_accuracy: 75.20\n",
      "[9,     4] loss: 0.77911, train_accuracy: 74.61\n",
      "[9,     5] loss: 0.68684, train_accuracy: 75.98\n",
      "[9,     6] loss: 0.73493, train_accuracy: 73.83\n",
      "[9,     7] loss: 0.67934, train_accuracy: 75.00\n",
      "[9,     8] loss: 0.67239, train_accuracy: 76.95\n",
      "[9,     9] loss: 0.75367, train_accuracy: 75.98\n",
      "[9,    10] loss: 0.70629, train_accuracy: 75.20\n",
      "[9,    11] loss: 0.74266, train_accuracy: 75.78\n",
      "[9,    12] loss: 0.72956, train_accuracy: 72.66\n",
      "[9,    13] loss: 0.67568, train_accuracy: 75.39\n",
      "[9,    14] loss: 0.65778, train_accuracy: 77.34\n",
      "[9,    15] loss: 0.72609, train_accuracy: 73.44\n",
      "[9,    16] loss: 0.68490, train_accuracy: 75.59\n",
      "[9,    17] loss: 0.74840, train_accuracy: 71.68\n",
      "[9,    18] loss: 0.70621, train_accuracy: 74.22\n",
      "[9,    19] loss: 0.67078, train_accuracy: 73.83\n",
      "[9,    20] loss: 0.77182, train_accuracy: 73.05\n",
      "[9,    21] loss: 0.69699, train_accuracy: 74.80\n",
      "[9,    22] loss: 0.72223, train_accuracy: 75.20\n",
      "[9,    23] loss: 0.69882, train_accuracy: 76.17\n",
      "[9,    24] loss: 0.66957, train_accuracy: 78.52\n",
      "[9,    25] loss: 0.71223, train_accuracy: 74.22\n",
      "[9,    26] loss: 0.68090, train_accuracy: 76.95\n",
      "[9,    27] loss: 0.71496, train_accuracy: 75.39\n",
      "[9,    28] loss: 0.78526, train_accuracy: 70.12\n",
      "[9,    29] loss: 0.66637, train_accuracy: 76.76\n",
      "[9,    30] loss: 0.80039, train_accuracy: 72.27\n",
      "[9,    31] loss: 0.68131, train_accuracy: 73.63\n",
      "[9,    32] loss: 0.73621, train_accuracy: 72.85\n",
      "[9,    33] loss: 0.73143, train_accuracy: 73.83\n",
      "[9,    34] loss: 0.71800, train_accuracy: 72.27\n",
      "[9,    35] loss: 0.70004, train_accuracy: 73.63\n",
      "[9,    36] loss: 0.76433, train_accuracy: 70.12\n",
      "[9,    37] loss: 0.72480, train_accuracy: 74.80\n",
      "[9,    38] loss: 0.75790, train_accuracy: 71.09\n",
      "[9,    39] loss: 0.74080, train_accuracy: 71.09\n",
      "[9,    40] loss: 0.68490, train_accuracy: 75.98\n",
      "[9,    41] loss: 0.71038, train_accuracy: 72.46\n",
      "[9,    42] loss: 0.71704, train_accuracy: 73.63\n",
      "[9,    43] loss: 0.71417, train_accuracy: 76.37\n",
      "[9,    44] loss: 0.77688, train_accuracy: 74.61\n",
      "[9,    45] loss: 0.76233, train_accuracy: 70.70\n",
      "[9,    46] loss: 0.74964, train_accuracy: 71.88\n",
      "[9,    47] loss: 0.69657, train_accuracy: 75.20\n",
      "[9,    48] loss: 0.68662, train_accuracy: 74.61\n",
      "[9,    49] loss: 0.77767, train_accuracy: 70.70\n",
      "[9,    50] loss: 0.71966, train_accuracy: 73.05\n",
      "[9,    51] loss: 0.70766, train_accuracy: 74.61\n",
      "[9,    52] loss: 0.70209, train_accuracy: 73.05\n",
      "[9,    53] loss: 0.71001, train_accuracy: 75.20\n",
      "[9,    54] loss: 0.68815, train_accuracy: 76.17\n",
      "[9,    55] loss: 0.67248, train_accuracy: 77.15\n",
      "[9,    56] loss: 0.72345, train_accuracy: 75.00\n",
      "[9,    57] loss: 0.72734, train_accuracy: 74.61\n",
      "[9,    58] loss: 0.72063, train_accuracy: 74.22\n",
      "[9,    59] loss: 0.69670, train_accuracy: 72.46\n",
      "[9,    60] loss: 0.70015, train_accuracy: 72.46\n",
      "[9,    61] loss: 0.72836, train_accuracy: 72.66\n",
      "[9,    62] loss: 0.76830, train_accuracy: 72.46\n",
      "[9,    63] loss: 0.66890, train_accuracy: 75.39\n",
      "[9,    64] loss: 0.73873, train_accuracy: 72.07\n",
      "[9,    65] loss: 0.73856, train_accuracy: 73.24\n",
      "[9,    66] loss: 0.76331, train_accuracy: 72.66\n",
      "[9,    67] loss: 0.77765, train_accuracy: 71.48\n",
      "[9,    68] loss: 0.69857, train_accuracy: 77.54\n",
      "[9,    69] loss: 0.78900, train_accuracy: 72.46\n",
      "[9,    70] loss: 0.76262, train_accuracy: 72.85\n",
      "[9,    71] loss: 0.66217, train_accuracy: 75.20\n",
      "[9,    72] loss: 0.76124, train_accuracy: 73.63\n",
      "[9,    73] loss: 0.75111, train_accuracy: 74.41\n",
      "[9,    74] loss: 0.73074, train_accuracy: 73.83\n",
      "[9,    75] loss: 0.71584, train_accuracy: 76.56\n",
      "[9,    76] loss: 0.69780, train_accuracy: 73.44\n",
      "[9,    77] loss: 0.72860, train_accuracy: 73.24\n",
      "[9,    78] loss: 0.64055, train_accuracy: 75.78\n",
      "[9,    79] loss: 0.66685, train_accuracy: 74.22\n",
      "[9,    80] loss: 0.84564, train_accuracy: 68.36\n",
      "[9,    81] loss: 0.77156, train_accuracy: 72.07\n",
      "[9,    82] loss: 0.66655, train_accuracy: 77.73\n",
      "[9,    83] loss: 0.76435, train_accuracy: 73.63\n",
      "[9,    84] loss: 0.69204, train_accuracy: 75.20\n",
      "[9,    85] loss: 0.75307, train_accuracy: 75.39\n",
      "[9,    86] loss: 0.71200, train_accuracy: 74.22\n",
      "[9,    87] loss: 0.73218, train_accuracy: 74.80\n",
      "[9,    88] loss: 0.66004, train_accuracy: 75.78\n",
      "[9,    89] loss: 0.63828, train_accuracy: 77.93\n",
      "[9,    90] loss: 0.73010, train_accuracy: 73.83\n",
      "[9,    91] loss: 0.73503, train_accuracy: 73.63\n",
      "[9,    92] loss: 0.75092, train_accuracy: 73.63\n",
      "[9,    93] loss: 0.70284, train_accuracy: 74.80\n",
      "[9,    94] loss: 0.70877, train_accuracy: 75.39\n",
      "[9,    95] loss: 0.73873, train_accuracy: 73.63\n",
      "[9,    96] loss: 0.77004, train_accuracy: 71.09\n",
      "[9,    97] loss: 0.74370, train_accuracy: 75.20\n",
      "[9,    98] loss: 0.80157, train_accuracy: 71.13\n",
      "duration: 26 s - train loss: 0.72192 - train accuracy: 74.12 - validation loss: 1.10 - validation accuracy: 63.60 \n",
      "[10,     1] loss: 0.70967, train_accuracy: 75.59\n",
      "[10,     2] loss: 0.75634, train_accuracy: 72.85\n",
      "[10,     3] loss: 0.67260, train_accuracy: 77.93\n",
      "[10,     4] loss: 0.69411, train_accuracy: 75.98\n",
      "[10,     5] loss: 0.73252, train_accuracy: 74.61\n",
      "[10,     6] loss: 0.69658, train_accuracy: 76.56\n",
      "[10,     7] loss: 0.70768, train_accuracy: 75.59\n",
      "[10,     8] loss: 0.78457, train_accuracy: 71.48\n",
      "[10,     9] loss: 0.75489, train_accuracy: 74.41\n",
      "[10,    10] loss: 0.64428, train_accuracy: 76.56\n",
      "[10,    11] loss: 0.73275, train_accuracy: 73.63\n",
      "[10,    12] loss: 0.66202, train_accuracy: 75.20\n",
      "[10,    13] loss: 0.66355, train_accuracy: 77.54\n",
      "[10,    14] loss: 0.65639, train_accuracy: 74.61\n",
      "[10,    15] loss: 0.73436, train_accuracy: 74.80\n",
      "[10,    16] loss: 0.62517, train_accuracy: 76.17\n",
      "[10,    17] loss: 0.70210, train_accuracy: 75.59\n",
      "[10,    18] loss: 0.68641, train_accuracy: 77.15\n",
      "[10,    19] loss: 0.68324, train_accuracy: 75.78\n",
      "[10,    20] loss: 0.70607, train_accuracy: 73.24\n",
      "[10,    21] loss: 0.73009, train_accuracy: 73.83\n",
      "[10,    22] loss: 0.72349, train_accuracy: 73.63\n",
      "[10,    23] loss: 0.68057, train_accuracy: 75.39\n",
      "[10,    24] loss: 0.64611, train_accuracy: 75.78\n",
      "[10,    25] loss: 0.75110, train_accuracy: 73.05\n",
      "[10,    26] loss: 0.68316, train_accuracy: 75.98\n",
      "[10,    27] loss: 0.71335, train_accuracy: 74.41\n",
      "[10,    28] loss: 0.64065, train_accuracy: 77.73\n",
      "[10,    29] loss: 0.61338, train_accuracy: 76.17\n",
      "[10,    30] loss: 0.78010, train_accuracy: 72.66\n",
      "[10,    31] loss: 0.64895, train_accuracy: 75.78\n",
      "[10,    32] loss: 0.71394, train_accuracy: 73.44\n",
      "[10,    33] loss: 0.69857, train_accuracy: 73.24\n",
      "[10,    34] loss: 0.68957, train_accuracy: 76.76\n",
      "[10,    35] loss: 0.70247, train_accuracy: 73.63\n",
      "[10,    36] loss: 0.64873, train_accuracy: 77.15\n",
      "[10,    37] loss: 0.70725, train_accuracy: 76.37\n",
      "[10,    38] loss: 0.70509, train_accuracy: 74.02\n",
      "[10,    39] loss: 0.70576, train_accuracy: 75.78\n",
      "[10,    40] loss: 0.73935, train_accuracy: 73.63\n",
      "[10,    41] loss: 0.77560, train_accuracy: 71.09\n",
      "[10,    42] loss: 0.79518, train_accuracy: 72.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,    43] loss: 0.76364, train_accuracy: 73.05\n",
      "[10,    44] loss: 0.70324, train_accuracy: 75.20\n",
      "[10,    45] loss: 0.72867, train_accuracy: 71.48\n",
      "[10,    46] loss: 0.74477, train_accuracy: 72.07\n",
      "[10,    47] loss: 0.71067, train_accuracy: 73.63\n",
      "[10,    48] loss: 0.78564, train_accuracy: 73.83\n",
      "[10,    49] loss: 0.70896, train_accuracy: 74.61\n",
      "[10,    50] loss: 0.69714, train_accuracy: 76.17\n",
      "[10,    51] loss: 0.72832, train_accuracy: 74.61\n",
      "[10,    52] loss: 0.61575, train_accuracy: 77.73\n",
      "[10,    53] loss: 0.62166, train_accuracy: 79.88\n",
      "[10,    54] loss: 0.75750, train_accuracy: 72.46\n",
      "[10,    55] loss: 0.81610, train_accuracy: 71.29\n",
      "[10,    56] loss: 0.71683, train_accuracy: 74.61\n",
      "[10,    57] loss: 0.79125, train_accuracy: 70.12\n",
      "[10,    58] loss: 0.68939, train_accuracy: 73.24\n",
      "[10,    59] loss: 0.70427, train_accuracy: 75.78\n",
      "[10,    60] loss: 0.79259, train_accuracy: 72.85\n",
      "[10,    61] loss: 0.72853, train_accuracy: 74.80\n",
      "[10,    62] loss: 0.67217, train_accuracy: 74.61\n",
      "[10,    63] loss: 0.71791, train_accuracy: 75.59\n",
      "[10,    64] loss: 0.73121, train_accuracy: 72.85\n",
      "[10,    65] loss: 0.70652, train_accuracy: 74.80\n",
      "[10,    66] loss: 0.67362, train_accuracy: 75.20\n",
      "[10,    67] loss: 0.67770, train_accuracy: 75.78\n",
      "[10,    68] loss: 0.68446, train_accuracy: 75.20\n",
      "[10,    69] loss: 0.70271, train_accuracy: 74.02\n",
      "[10,    70] loss: 0.75063, train_accuracy: 72.66\n",
      "[10,    71] loss: 0.67532, train_accuracy: 75.78\n",
      "[10,    72] loss: 0.67666, train_accuracy: 78.32\n",
      "[10,    73] loss: 0.72597, train_accuracy: 74.22\n",
      "[10,    74] loss: 0.67253, train_accuracy: 76.56\n",
      "[10,    75] loss: 0.63164, train_accuracy: 76.37\n",
      "[10,    76] loss: 0.66015, train_accuracy: 75.00\n",
      "[10,    77] loss: 0.76281, train_accuracy: 74.22\n",
      "[10,    78] loss: 0.75283, train_accuracy: 73.05\n",
      "[10,    79] loss: 0.68783, train_accuracy: 76.76\n",
      "[10,    80] loss: 0.68258, train_accuracy: 75.00\n",
      "[10,    81] loss: 0.77836, train_accuracy: 72.46\n",
      "[10,    82] loss: 0.75809, train_accuracy: 72.27\n",
      "[10,    83] loss: 0.78875, train_accuracy: 72.07\n",
      "[10,    84] loss: 0.80724, train_accuracy: 72.66\n",
      "[10,    85] loss: 0.62103, train_accuracy: 77.34\n",
      "[10,    86] loss: 0.76373, train_accuracy: 75.20\n",
      "[10,    87] loss: 0.69459, train_accuracy: 76.37\n",
      "[10,    88] loss: 0.68758, train_accuracy: 75.98\n",
      "[10,    89] loss: 0.70244, train_accuracy: 76.95\n",
      "[10,    90] loss: 0.73921, train_accuracy: 75.00\n",
      "[10,    91] loss: 0.65486, train_accuracy: 75.39\n",
      "[10,    92] loss: 0.78487, train_accuracy: 71.88\n",
      "[10,    93] loss: 0.76645, train_accuracy: 72.85\n",
      "[10,    94] loss: 0.78764, train_accuracy: 72.07\n",
      "[10,    95] loss: 0.66980, train_accuracy: 75.78\n",
      "[10,    96] loss: 0.75549, train_accuracy: 72.66\n",
      "[10,    97] loss: 0.77741, train_accuracy: 73.63\n",
      "[10,    98] loss: 0.67027, train_accuracy: 75.00\n",
      "duration: 24 s - train loss: 0.71179 - train accuracy: 74.66 - validation loss: 1.10 - validation accuracy: 63.37 \n",
      "[11,     1] loss: 0.65031, train_accuracy: 77.15\n",
      "[11,     2] loss: 0.65283, train_accuracy: 77.34\n",
      "[11,     3] loss: 0.64460, train_accuracy: 77.73\n",
      "[11,     4] loss: 0.72290, train_accuracy: 75.00\n",
      "[11,     5] loss: 0.64800, train_accuracy: 76.56\n",
      "[11,     6] loss: 0.69144, train_accuracy: 77.73\n",
      "[11,     7] loss: 0.71642, train_accuracy: 72.66\n",
      "[11,     8] loss: 0.72408, train_accuracy: 72.07\n",
      "[11,     9] loss: 0.71620, train_accuracy: 74.61\n",
      "[11,    10] loss: 0.72515, train_accuracy: 72.46\n",
      "[11,    11] loss: 0.76902, train_accuracy: 71.68\n",
      "[11,    12] loss: 0.64836, train_accuracy: 77.15\n",
      "[11,    13] loss: 0.68134, train_accuracy: 74.61\n",
      "[11,    14] loss: 0.70286, train_accuracy: 73.63\n",
      "[11,    15] loss: 0.68995, train_accuracy: 74.80\n",
      "[11,    16] loss: 0.65936, train_accuracy: 76.95\n",
      "[11,    17] loss: 0.66985, train_accuracy: 76.76\n",
      "[11,    18] loss: 0.70130, train_accuracy: 74.22\n",
      "[11,    19] loss: 0.64469, train_accuracy: 76.95\n",
      "[11,    20] loss: 0.75331, train_accuracy: 75.00\n",
      "[11,    21] loss: 0.65231, train_accuracy: 76.56\n",
      "[11,    22] loss: 0.68402, train_accuracy: 76.76\n",
      "[11,    23] loss: 0.65744, train_accuracy: 76.76\n",
      "[11,    24] loss: 0.71808, train_accuracy: 75.20\n",
      "[11,    25] loss: 0.69772, train_accuracy: 75.20\n",
      "[11,    26] loss: 0.72584, train_accuracy: 74.41\n",
      "[11,    27] loss: 0.63864, train_accuracy: 78.12\n",
      "[11,    28] loss: 0.66274, train_accuracy: 76.76\n",
      "[11,    29] loss: 0.68023, train_accuracy: 75.78\n",
      "[11,    30] loss: 0.82483, train_accuracy: 72.27\n",
      "[11,    31] loss: 0.73716, train_accuracy: 74.02\n",
      "[11,    32] loss: 0.68846, train_accuracy: 75.00\n",
      "[11,    33] loss: 0.71362, train_accuracy: 74.22\n",
      "[11,    34] loss: 0.67277, train_accuracy: 75.78\n",
      "[11,    35] loss: 0.68461, train_accuracy: 76.95\n",
      "[11,    36] loss: 0.74595, train_accuracy: 74.02\n",
      "[11,    37] loss: 0.65598, train_accuracy: 76.37\n",
      "[11,    38] loss: 0.67182, train_accuracy: 76.76\n",
      "[11,    39] loss: 0.65907, train_accuracy: 77.93\n",
      "[11,    40] loss: 0.66874, train_accuracy: 77.15\n",
      "[11,    41] loss: 0.69423, train_accuracy: 75.20\n",
      "[11,    42] loss: 0.63047, train_accuracy: 78.71\n",
      "[11,    43] loss: 0.63048, train_accuracy: 76.76\n",
      "[11,    44] loss: 0.66337, train_accuracy: 75.00\n",
      "[11,    45] loss: 0.65214, train_accuracy: 75.78\n",
      "[11,    46] loss: 0.80321, train_accuracy: 72.27\n",
      "[11,    47] loss: 0.66043, train_accuracy: 75.39\n",
      "[11,    48] loss: 0.69913, train_accuracy: 77.34\n",
      "[11,    49] loss: 0.69098, train_accuracy: 74.80\n",
      "[11,    50] loss: 0.63322, train_accuracy: 77.34\n",
      "[11,    51] loss: 0.70394, train_accuracy: 74.80\n",
      "[11,    52] loss: 0.81013, train_accuracy: 71.48\n",
      "[11,    53] loss: 0.72311, train_accuracy: 75.39\n",
      "[11,    54] loss: 0.66976, train_accuracy: 76.17\n",
      "[11,    55] loss: 0.79091, train_accuracy: 71.29\n",
      "[11,    56] loss: 0.66333, train_accuracy: 74.80\n",
      "[11,    57] loss: 0.75454, train_accuracy: 72.07\n",
      "[11,    58] loss: 0.68340, train_accuracy: 73.44\n",
      "[11,    59] loss: 0.63968, train_accuracy: 78.32\n",
      "[11,    60] loss: 0.72862, train_accuracy: 74.02\n",
      "[11,    61] loss: 0.68836, train_accuracy: 76.37\n",
      "[11,    62] loss: 0.69082, train_accuracy: 75.59\n",
      "[11,    63] loss: 0.69280, train_accuracy: 75.20\n",
      "[11,    64] loss: 0.71703, train_accuracy: 75.39\n",
      "[11,    65] loss: 0.75772, train_accuracy: 70.90\n",
      "[11,    66] loss: 0.68999, train_accuracy: 75.59\n",
      "[11,    67] loss: 0.73647, train_accuracy: 73.05\n",
      "[11,    68] loss: 0.74870, train_accuracy: 74.22\n",
      "[11,    69] loss: 0.64841, train_accuracy: 76.56\n",
      "[11,    70] loss: 0.63844, train_accuracy: 76.37\n",
      "[11,    71] loss: 0.70988, train_accuracy: 76.37\n",
      "[11,    72] loss: 0.71103, train_accuracy: 73.83\n",
      "[11,    73] loss: 0.75482, train_accuracy: 72.46\n",
      "[11,    74] loss: 0.67330, train_accuracy: 76.76\n",
      "[11,    75] loss: 0.68247, train_accuracy: 75.20\n",
      "[11,    76] loss: 0.78057, train_accuracy: 71.88\n",
      "[11,    77] loss: 0.72150, train_accuracy: 76.37\n",
      "[11,    78] loss: 0.70786, train_accuracy: 73.83\n",
      "[11,    79] loss: 0.61306, train_accuracy: 78.71\n",
      "[11,    80] loss: 0.74690, train_accuracy: 73.63\n",
      "[11,    81] loss: 0.69055, train_accuracy: 75.98\n",
      "[11,    82] loss: 0.70445, train_accuracy: 74.61\n",
      "[11,    83] loss: 0.72707, train_accuracy: 73.63\n",
      "[11,    84] loss: 0.77572, train_accuracy: 71.68\n",
      "[11,    85] loss: 0.71883, train_accuracy: 74.02\n",
      "[11,    86] loss: 0.72697, train_accuracy: 73.63\n",
      "[11,    87] loss: 0.77394, train_accuracy: 73.05\n",
      "[11,    88] loss: 0.74804, train_accuracy: 71.88\n",
      "[11,    89] loss: 0.75757, train_accuracy: 73.83\n",
      "[11,    90] loss: 0.66897, train_accuracy: 74.02\n",
      "[11,    91] loss: 0.74210, train_accuracy: 74.22\n",
      "[11,    92] loss: 0.79850, train_accuracy: 69.92\n",
      "[11,    93] loss: 0.67895, train_accuracy: 75.78\n",
      "[11,    94] loss: 0.69383, train_accuracy: 75.98\n",
      "[11,    95] loss: 0.68813, train_accuracy: 75.39\n",
      "[11,    96] loss: 0.68267, train_accuracy: 75.59\n",
      "[11,    97] loss: 0.75301, train_accuracy: 74.80\n",
      "[11,    98] loss: 0.68467, train_accuracy: 73.51\n",
      "duration: 23 s - train loss: 0.70103 - train accuracy: 75.01 - validation loss: 1.10 - validation accuracy: 63.84 \n",
      "[12,     1] loss: 0.66667, train_accuracy: 74.41\n",
      "[12,     2] loss: 0.61857, train_accuracy: 79.49\n",
      "[12,     3] loss: 0.66466, train_accuracy: 77.34\n",
      "[12,     4] loss: 0.74017, train_accuracy: 75.39\n",
      "[12,     5] loss: 0.65266, train_accuracy: 75.00\n",
      "[12,     6] loss: 0.70293, train_accuracy: 74.61\n",
      "[12,     7] loss: 0.72668, train_accuracy: 75.59\n",
      "[12,     8] loss: 0.65822, train_accuracy: 78.32\n",
      "[12,     9] loss: 0.65342, train_accuracy: 76.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,    10] loss: 0.72874, train_accuracy: 74.22\n",
      "[12,    11] loss: 0.65915, train_accuracy: 77.15\n",
      "[12,    12] loss: 0.60807, train_accuracy: 79.30\n",
      "[12,    13] loss: 0.76818, train_accuracy: 73.05\n",
      "[12,    14] loss: 0.65425, train_accuracy: 77.93\n",
      "[12,    15] loss: 0.76413, train_accuracy: 69.92\n",
      "[12,    16] loss: 0.73690, train_accuracy: 73.05\n",
      "[12,    17] loss: 0.68020, train_accuracy: 75.59\n",
      "[12,    18] loss: 0.73779, train_accuracy: 71.48\n",
      "[12,    19] loss: 0.69559, train_accuracy: 75.39\n",
      "[12,    20] loss: 0.66989, train_accuracy: 78.52\n",
      "[12,    21] loss: 0.59834, train_accuracy: 80.66\n",
      "[12,    22] loss: 0.62350, train_accuracy: 76.76\n",
      "[12,    23] loss: 0.67873, train_accuracy: 76.95\n",
      "[12,    24] loss: 0.75380, train_accuracy: 73.83\n",
      "[12,    25] loss: 0.72728, train_accuracy: 76.56\n",
      "[12,    26] loss: 0.71045, train_accuracy: 74.22\n",
      "[12,    27] loss: 0.69831, train_accuracy: 74.61\n",
      "[12,    28] loss: 0.68844, train_accuracy: 73.63\n",
      "[12,    29] loss: 0.65443, train_accuracy: 78.71\n",
      "[12,    30] loss: 0.62817, train_accuracy: 76.95\n",
      "[12,    31] loss: 0.64624, train_accuracy: 77.34\n",
      "[12,    32] loss: 0.63860, train_accuracy: 74.80\n",
      "[12,    33] loss: 0.73182, train_accuracy: 72.46\n",
      "[12,    34] loss: 0.66290, train_accuracy: 78.12\n",
      "[12,    35] loss: 0.69267, train_accuracy: 74.41\n",
      "[12,    36] loss: 0.81174, train_accuracy: 71.68\n",
      "[12,    37] loss: 0.71231, train_accuracy: 76.95\n",
      "[12,    38] loss: 0.70983, train_accuracy: 75.59\n",
      "[12,    39] loss: 0.73385, train_accuracy: 73.83\n",
      "[12,    40] loss: 0.64233, train_accuracy: 75.20\n",
      "[12,    41] loss: 0.76215, train_accuracy: 72.66\n",
      "[12,    42] loss: 0.64120, train_accuracy: 78.12\n",
      "[12,    43] loss: 0.59007, train_accuracy: 76.76\n",
      "[12,    44] loss: 0.70415, train_accuracy: 73.83\n",
      "[12,    45] loss: 0.73834, train_accuracy: 74.80\n",
      "[12,    46] loss: 0.70127, train_accuracy: 74.61\n",
      "[12,    47] loss: 0.70432, train_accuracy: 75.20\n",
      "[12,    48] loss: 0.64397, train_accuracy: 76.56\n",
      "[12,    49] loss: 0.64454, train_accuracy: 76.17\n",
      "[12,    50] loss: 0.71533, train_accuracy: 73.24\n",
      "[12,    51] loss: 0.69720, train_accuracy: 76.37\n",
      "[12,    52] loss: 0.70271, train_accuracy: 74.61\n",
      "[12,    53] loss: 0.71487, train_accuracy: 75.98\n",
      "[12,    54] loss: 0.69684, train_accuracy: 76.17\n",
      "[12,    55] loss: 0.70565, train_accuracy: 74.02\n",
      "[12,    56] loss: 0.64960, train_accuracy: 74.80\n",
      "[12,    57] loss: 0.64011, train_accuracy: 76.56\n",
      "[12,    58] loss: 0.64688, train_accuracy: 78.12\n",
      "[12,    59] loss: 0.72775, train_accuracy: 73.24\n",
      "[12,    60] loss: 0.73847, train_accuracy: 74.02\n",
      "[12,    61] loss: 0.71038, train_accuracy: 74.61\n",
      "[12,    62] loss: 0.71820, train_accuracy: 72.66\n",
      "[12,    63] loss: 0.79831, train_accuracy: 70.70\n",
      "[12,    64] loss: 0.61614, train_accuracy: 76.56\n",
      "[12,    65] loss: 0.69611, train_accuracy: 75.59\n",
      "[12,    66] loss: 0.67771, train_accuracy: 76.56\n",
      "[12,    67] loss: 0.65535, train_accuracy: 75.39\n",
      "[12,    68] loss: 0.71970, train_accuracy: 74.41\n",
      "[12,    69] loss: 0.75808, train_accuracy: 72.46\n",
      "[12,    70] loss: 0.70659, train_accuracy: 77.15\n",
      "[12,    71] loss: 0.67098, train_accuracy: 75.78\n",
      "[12,    72] loss: 0.73308, train_accuracy: 75.59\n",
      "[12,    73] loss: 0.69622, train_accuracy: 73.63\n",
      "[12,    74] loss: 0.68756, train_accuracy: 74.61\n",
      "[12,    75] loss: 0.67279, train_accuracy: 75.59\n",
      "[12,    76] loss: 0.70947, train_accuracy: 76.37\n",
      "[12,    77] loss: 0.71514, train_accuracy: 74.02\n",
      "[12,    78] loss: 0.72985, train_accuracy: 75.20\n",
      "[12,    79] loss: 0.68254, train_accuracy: 73.44\n",
      "[12,    80] loss: 0.71467, train_accuracy: 74.80\n",
      "[12,    81] loss: 0.69403, train_accuracy: 74.61\n",
      "[12,    82] loss: 0.66230, train_accuracy: 76.56\n",
      "[12,    83] loss: 0.69726, train_accuracy: 76.56\n",
      "[12,    84] loss: 0.71427, train_accuracy: 73.83\n",
      "[12,    85] loss: 0.69013, train_accuracy: 76.37\n",
      "[12,    86] loss: 0.70436, train_accuracy: 77.93\n",
      "[12,    87] loss: 0.78606, train_accuracy: 71.68\n",
      "[12,    88] loss: 0.68325, train_accuracy: 76.17\n",
      "[12,    89] loss: 0.68406, train_accuracy: 75.59\n",
      "[12,    90] loss: 0.71319, train_accuracy: 73.63\n",
      "[12,    91] loss: 0.66640, train_accuracy: 74.80\n",
      "[12,    92] loss: 0.66473, train_accuracy: 75.78\n",
      "[12,    93] loss: 0.71761, train_accuracy: 74.41\n",
      "[12,    94] loss: 0.68624, train_accuracy: 75.20\n",
      "[12,    95] loss: 0.65079, train_accuracy: 77.15\n",
      "[12,    96] loss: 0.64240, train_accuracy: 75.39\n",
      "[12,    97] loss: 0.67534, train_accuracy: 74.80\n",
      "[12,    98] loss: 0.66150, train_accuracy: 76.19\n",
      "duration: 23 s - train loss: 0.69142 - train accuracy: 75.34 - validation loss: 1.10 - validation accuracy: 63.78 \n",
      "stopped early after 5 epochs without decrease of validation loss\n",
      "Finished Training\n",
      "cw done\n",
      "pgd done\n",
      "compression rate:  0.9375\n",
      "[1,     1] loss: 3.27929, train_accuracy: 20.90\n",
      "[1,     2] loss: 2.91676, train_accuracy: 22.27\n",
      "[1,     3] loss: 2.98372, train_accuracy: 22.46\n",
      "[1,     4] loss: 2.80835, train_accuracy: 24.41\n",
      "[1,     5] loss: 2.86427, train_accuracy: 21.48\n",
      "[1,     6] loss: 2.69395, train_accuracy: 26.76\n",
      "[1,     7] loss: 2.58508, train_accuracy: 28.52\n",
      "[1,     8] loss: 2.45624, train_accuracy: 28.52\n",
      "[1,     9] loss: 2.71193, train_accuracy: 25.00\n",
      "[1,    10] loss: 2.33177, train_accuracy: 29.49\n",
      "[1,    11] loss: 2.44260, train_accuracy: 28.91\n",
      "[1,    12] loss: 2.33205, train_accuracy: 30.47\n",
      "[1,    13] loss: 2.24868, train_accuracy: 33.20\n",
      "[1,    14] loss: 2.05320, train_accuracy: 35.74\n",
      "[1,    15] loss: 2.09390, train_accuracy: 37.30\n",
      "[1,    16] loss: 2.07909, train_accuracy: 33.79\n",
      "[1,    17] loss: 2.01211, train_accuracy: 37.30\n",
      "[1,    18] loss: 1.82160, train_accuracy: 41.41\n",
      "[1,    19] loss: 1.96875, train_accuracy: 40.62\n",
      "[1,    20] loss: 1.92112, train_accuracy: 37.70\n",
      "[1,    21] loss: 1.83742, train_accuracy: 41.02\n",
      "[1,    22] loss: 1.94726, train_accuracy: 39.26\n",
      "[1,    23] loss: 1.82541, train_accuracy: 43.75\n",
      "[1,    24] loss: 1.72938, train_accuracy: 46.88\n",
      "[1,    25] loss: 1.86602, train_accuracy: 40.04\n",
      "[1,    26] loss: 1.79884, train_accuracy: 41.60\n",
      "[1,    27] loss: 1.72896, train_accuracy: 41.99\n",
      "[1,    28] loss: 1.73505, train_accuracy: 42.77\n",
      "[1,    29] loss: 1.64144, train_accuracy: 47.46\n",
      "[1,    30] loss: 1.66327, train_accuracy: 45.51\n",
      "[1,    31] loss: 1.72488, train_accuracy: 42.38\n",
      "[1,    32] loss: 1.70968, train_accuracy: 44.73\n",
      "[1,    33] loss: 1.77415, train_accuracy: 43.75\n",
      "[1,    34] loss: 1.67700, train_accuracy: 42.77\n",
      "[1,    35] loss: 1.59125, train_accuracy: 45.12\n",
      "[1,    36] loss: 1.64983, train_accuracy: 46.29\n",
      "[1,    37] loss: 1.53093, train_accuracy: 47.46\n",
      "[1,    38] loss: 1.61088, train_accuracy: 45.90\n",
      "[1,    39] loss: 1.52695, train_accuracy: 46.09\n",
      "[1,    40] loss: 1.60463, train_accuracy: 42.77\n",
      "[1,    41] loss: 1.58877, train_accuracy: 45.31\n",
      "[1,    42] loss: 1.55515, train_accuracy: 46.48\n",
      "[1,    43] loss: 1.53294, train_accuracy: 49.80\n",
      "[1,    44] loss: 1.41945, train_accuracy: 50.20\n",
      "[1,    45] loss: 1.48924, train_accuracy: 48.83\n",
      "[1,    46] loss: 1.61013, train_accuracy: 46.88\n",
      "[1,    47] loss: 1.51777, train_accuracy: 47.46\n",
      "[1,    48] loss: 1.49555, train_accuracy: 50.39\n",
      "[1,    49] loss: 1.42370, train_accuracy: 49.41\n",
      "[1,    50] loss: 1.54918, train_accuracy: 46.48\n",
      "[1,    51] loss: 1.40914, train_accuracy: 53.32\n",
      "[1,    52] loss: 1.49357, train_accuracy: 47.07\n",
      "[1,    53] loss: 1.32588, train_accuracy: 52.73\n",
      "[1,    54] loss: 1.32551, train_accuracy: 53.32\n",
      "[1,    55] loss: 1.48002, train_accuracy: 50.78\n",
      "[1,    56] loss: 1.40705, train_accuracy: 48.63\n",
      "[1,    57] loss: 1.50660, train_accuracy: 49.41\n",
      "[1,    58] loss: 1.37865, train_accuracy: 53.91\n",
      "[1,    59] loss: 1.38514, train_accuracy: 51.37\n",
      "[1,    60] loss: 1.41675, train_accuracy: 50.39\n",
      "[1,    61] loss: 1.34236, train_accuracy: 53.52\n",
      "[1,    62] loss: 1.38250, train_accuracy: 48.44\n",
      "[1,    63] loss: 1.35751, train_accuracy: 51.56\n",
      "[1,    64] loss: 1.42333, train_accuracy: 50.00\n",
      "[1,    65] loss: 1.46965, train_accuracy: 48.63\n",
      "[1,    66] loss: 1.39743, train_accuracy: 52.73\n",
      "[1,    67] loss: 1.32250, train_accuracy: 53.71\n",
      "[1,    68] loss: 1.30814, train_accuracy: 53.52\n",
      "[1,    69] loss: 1.46642, train_accuracy: 49.22\n",
      "[1,    70] loss: 1.32177, train_accuracy: 51.76\n",
      "[1,    71] loss: 1.44697, train_accuracy: 52.34\n",
      "[1,    72] loss: 1.25160, train_accuracy: 56.45\n",
      "[1,    73] loss: 1.34794, train_accuracy: 54.49\n",
      "[1,    74] loss: 1.32543, train_accuracy: 53.32\n",
      "[1,    75] loss: 1.34897, train_accuracy: 51.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    76] loss: 1.39148, train_accuracy: 48.83\n",
      "[1,    77] loss: 1.34071, train_accuracy: 53.91\n",
      "[1,    78] loss: 1.18982, train_accuracy: 58.98\n",
      "[1,    79] loss: 1.36360, train_accuracy: 50.39\n",
      "[1,    80] loss: 1.37938, train_accuracy: 49.22\n",
      "[1,    81] loss: 1.38103, train_accuracy: 49.61\n",
      "[1,    82] loss: 1.31455, train_accuracy: 53.71\n",
      "[1,    83] loss: 1.34620, train_accuracy: 53.71\n",
      "[1,    84] loss: 1.22726, train_accuracy: 57.03\n",
      "[1,    85] loss: 1.24067, train_accuracy: 56.45\n",
      "[1,    86] loss: 1.32561, train_accuracy: 55.47\n",
      "[1,    87] loss: 1.32909, train_accuracy: 52.73\n",
      "[1,    88] loss: 1.26578, train_accuracy: 53.71\n",
      "[1,    89] loss: 1.23530, train_accuracy: 57.62\n",
      "[1,    90] loss: 1.36016, train_accuracy: 51.17\n",
      "[1,    91] loss: 1.18888, train_accuracy: 57.03\n",
      "[1,    92] loss: 1.30612, train_accuracy: 54.49\n",
      "[1,    93] loss: 1.25687, train_accuracy: 55.08\n",
      "[1,    94] loss: 1.30353, train_accuracy: 52.93\n",
      "[1,    95] loss: 1.23576, train_accuracy: 54.49\n",
      "[1,    96] loss: 1.26739, train_accuracy: 55.27\n",
      "[1,    97] loss: 1.29380, train_accuracy: 53.32\n",
      "[1,    98] loss: 1.28476, train_accuracy: 57.14\n",
      "duration: 24 s - train loss: 1.65743 - train accuracy: 45.91 - validation loss: 1.35 - validation accuracy: 52.71 \n",
      "[2,     1] loss: 1.27813, train_accuracy: 55.66\n",
      "[2,     2] loss: 1.27021, train_accuracy: 59.18\n",
      "[2,     3] loss: 1.13723, train_accuracy: 59.18\n",
      "[2,     4] loss: 1.25905, train_accuracy: 55.08\n",
      "[2,     5] loss: 1.25225, train_accuracy: 57.42\n",
      "[2,     6] loss: 1.18343, train_accuracy: 59.18\n",
      "[2,     7] loss: 1.24322, train_accuracy: 57.23\n",
      "[2,     8] loss: 1.27858, train_accuracy: 55.66\n",
      "[2,     9] loss: 1.15412, train_accuracy: 62.70\n",
      "[2,    10] loss: 1.27148, train_accuracy: 57.03\n",
      "[2,    11] loss: 1.14019, train_accuracy: 59.38\n",
      "[2,    12] loss: 1.25156, train_accuracy: 52.93\n",
      "[2,    13] loss: 1.29511, train_accuracy: 52.54\n",
      "[2,    14] loss: 1.09549, train_accuracy: 61.33\n",
      "[2,    15] loss: 1.25996, train_accuracy: 56.84\n",
      "[2,    16] loss: 1.17428, train_accuracy: 56.25\n",
      "[2,    17] loss: 1.25945, train_accuracy: 55.27\n",
      "[2,    18] loss: 1.26090, train_accuracy: 55.27\n",
      "[2,    19] loss: 1.27530, train_accuracy: 54.49\n",
      "[2,    20] loss: 1.17928, train_accuracy: 57.62\n",
      "[2,    21] loss: 1.23750, train_accuracy: 55.86\n",
      "[2,    22] loss: 1.22268, train_accuracy: 57.03\n",
      "[2,    23] loss: 1.25121, train_accuracy: 55.08\n",
      "[2,    24] loss: 1.26047, train_accuracy: 56.25\n",
      "[2,    25] loss: 1.15711, train_accuracy: 59.96\n",
      "[2,    26] loss: 1.34118, train_accuracy: 53.12\n",
      "[2,    27] loss: 1.16080, train_accuracy: 58.98\n",
      "[2,    28] loss: 1.11665, train_accuracy: 60.35\n",
      "[2,    29] loss: 1.20006, train_accuracy: 57.42\n",
      "[2,    30] loss: 1.11136, train_accuracy: 61.91\n",
      "[2,    31] loss: 1.23370, train_accuracy: 58.40\n",
      "[2,    32] loss: 1.18011, train_accuracy: 58.79\n",
      "[2,    33] loss: 1.18989, train_accuracy: 56.84\n",
      "[2,    34] loss: 1.14606, train_accuracy: 58.59\n",
      "[2,    35] loss: 1.21601, train_accuracy: 57.23\n",
      "[2,    36] loss: 1.11558, train_accuracy: 58.01\n",
      "[2,    37] loss: 1.09403, train_accuracy: 61.72\n",
      "[2,    38] loss: 1.20061, train_accuracy: 57.42\n",
      "[2,    39] loss: 1.25213, train_accuracy: 52.93\n",
      "[2,    40] loss: 1.17828, train_accuracy: 58.40\n",
      "[2,    41] loss: 1.26188, train_accuracy: 56.45\n",
      "[2,    42] loss: 1.11421, train_accuracy: 60.16\n",
      "[2,    43] loss: 1.11490, train_accuracy: 59.38\n",
      "[2,    44] loss: 1.16736, train_accuracy: 56.25\n",
      "[2,    45] loss: 1.22755, train_accuracy: 55.47\n",
      "[2,    46] loss: 1.13570, train_accuracy: 60.16\n",
      "[2,    47] loss: 1.08845, train_accuracy: 60.55\n",
      "[2,    48] loss: 1.14947, train_accuracy: 61.33\n",
      "[2,    49] loss: 1.21889, train_accuracy: 56.84\n",
      "[2,    50] loss: 1.14737, train_accuracy: 58.20\n",
      "[2,    51] loss: 1.18906, train_accuracy: 55.47\n",
      "[2,    52] loss: 1.08848, train_accuracy: 61.72\n",
      "[2,    53] loss: 1.13794, train_accuracy: 57.81\n",
      "[2,    54] loss: 1.12834, train_accuracy: 59.18\n",
      "[2,    55] loss: 1.14940, train_accuracy: 57.03\n",
      "[2,    56] loss: 1.15275, train_accuracy: 58.01\n",
      "[2,    57] loss: 1.13550, train_accuracy: 59.18\n",
      "[2,    58] loss: 1.18515, train_accuracy: 57.81\n",
      "[2,    59] loss: 1.24904, train_accuracy: 57.81\n",
      "[2,    60] loss: 1.18253, train_accuracy: 56.64\n",
      "[2,    61] loss: 1.16078, train_accuracy: 59.38\n",
      "[2,    62] loss: 1.02539, train_accuracy: 63.87\n",
      "[2,    63] loss: 1.12940, train_accuracy: 58.79\n",
      "[2,    64] loss: 1.11484, train_accuracy: 60.74\n",
      "[2,    65] loss: 1.12903, train_accuracy: 59.38\n",
      "[2,    66] loss: 1.12965, train_accuracy: 60.74\n",
      "[2,    67] loss: 1.11967, train_accuracy: 59.96\n",
      "[2,    68] loss: 1.23758, train_accuracy: 55.66\n",
      "[2,    69] loss: 1.13733, train_accuracy: 59.77\n",
      "[2,    70] loss: 1.18437, train_accuracy: 57.23\n",
      "[2,    71] loss: 1.10994, train_accuracy: 60.16\n",
      "[2,    72] loss: 1.12734, train_accuracy: 60.55\n",
      "[2,    73] loss: 1.09253, train_accuracy: 60.55\n",
      "[2,    74] loss: 1.01048, train_accuracy: 64.26\n",
      "[2,    75] loss: 1.15552, train_accuracy: 58.01\n",
      "[2,    76] loss: 1.07579, train_accuracy: 61.33\n",
      "[2,    77] loss: 1.17368, train_accuracy: 59.96\n",
      "[2,    78] loss: 1.05766, train_accuracy: 62.30\n",
      "[2,    79] loss: 1.09347, train_accuracy: 60.55\n",
      "[2,    80] loss: 1.04781, train_accuracy: 62.50\n",
      "[2,    81] loss: 1.17094, train_accuracy: 60.35\n",
      "[2,    82] loss: 1.08081, train_accuracy: 61.33\n",
      "[2,    83] loss: 1.17090, train_accuracy: 57.81\n",
      "[2,    84] loss: 1.04724, train_accuracy: 64.45\n",
      "[2,    85] loss: 1.03234, train_accuracy: 66.02\n",
      "[2,    86] loss: 1.11032, train_accuracy: 60.16\n",
      "[2,    87] loss: 1.17885, train_accuracy: 58.59\n",
      "[2,    88] loss: 1.02962, train_accuracy: 62.11\n",
      "[2,    89] loss: 1.15117, train_accuracy: 58.40\n",
      "[2,    90] loss: 1.09752, train_accuracy: 61.91\n",
      "[2,    91] loss: 1.04924, train_accuracy: 62.70\n",
      "[2,    92] loss: 1.09271, train_accuracy: 57.62\n",
      "[2,    93] loss: 1.05683, train_accuracy: 61.72\n",
      "[2,    94] loss: 1.16467, train_accuracy: 58.98\n",
      "[2,    95] loss: 1.21307, train_accuracy: 58.01\n",
      "[2,    96] loss: 1.14844, train_accuracy: 58.01\n",
      "[2,    97] loss: 1.18203, train_accuracy: 56.84\n",
      "[2,    98] loss: 1.10600, train_accuracy: 61.90\n",
      "duration: 23 s - train loss: 1.16330 - train accuracy: 58.70 - validation loss: 1.22 - validation accuracy: 57.11 \n",
      "[3,     1] loss: 1.05215, train_accuracy: 62.70\n",
      "[3,     2] loss: 1.09839, train_accuracy: 60.55\n",
      "[3,     3] loss: 1.04971, train_accuracy: 61.72\n",
      "[3,     4] loss: 0.98157, train_accuracy: 64.84\n",
      "[3,     5] loss: 1.11543, train_accuracy: 59.57\n",
      "[3,     6] loss: 1.02937, train_accuracy: 63.28\n",
      "[3,     7] loss: 1.03167, train_accuracy: 63.09\n",
      "[3,     8] loss: 1.02489, train_accuracy: 62.70\n",
      "[3,     9] loss: 1.07255, train_accuracy: 62.89\n",
      "[3,    10] loss: 1.14941, train_accuracy: 58.79\n",
      "[3,    11] loss: 1.09685, train_accuracy: 60.35\n",
      "[3,    12] loss: 1.02807, train_accuracy: 60.94\n",
      "[3,    13] loss: 1.13269, train_accuracy: 58.20\n",
      "[3,    14] loss: 1.04526, train_accuracy: 63.28\n",
      "[3,    15] loss: 1.02280, train_accuracy: 63.67\n",
      "[3,    16] loss: 1.11706, train_accuracy: 58.98\n",
      "[3,    17] loss: 1.04419, train_accuracy: 63.48\n",
      "[3,    18] loss: 1.00091, train_accuracy: 64.65\n",
      "[3,    19] loss: 1.12168, train_accuracy: 61.52\n",
      "[3,    20] loss: 1.01925, train_accuracy: 62.11\n",
      "[3,    21] loss: 1.09147, train_accuracy: 61.72\n",
      "[3,    22] loss: 1.20400, train_accuracy: 56.64\n",
      "[3,    23] loss: 1.01913, train_accuracy: 61.72\n",
      "[3,    24] loss: 1.06041, train_accuracy: 61.52\n",
      "[3,    25] loss: 1.03206, train_accuracy: 63.48\n",
      "[3,    26] loss: 1.12253, train_accuracy: 61.33\n",
      "[3,    27] loss: 1.06049, train_accuracy: 63.87\n",
      "[3,    28] loss: 1.13915, train_accuracy: 60.35\n",
      "[3,    29] loss: 1.07294, train_accuracy: 61.52\n",
      "[3,    30] loss: 1.10517, train_accuracy: 62.11\n",
      "[3,    31] loss: 1.03751, train_accuracy: 62.70\n",
      "[3,    32] loss: 1.02622, train_accuracy: 63.09\n",
      "[3,    33] loss: 1.09045, train_accuracy: 60.94\n",
      "[3,    34] loss: 1.04745, train_accuracy: 62.30\n",
      "[3,    35] loss: 1.13559, train_accuracy: 57.81\n",
      "[3,    36] loss: 0.98214, train_accuracy: 63.87\n",
      "[3,    37] loss: 1.13664, train_accuracy: 60.55\n",
      "[3,    38] loss: 1.09441, train_accuracy: 61.91\n",
      "[3,    39] loss: 0.97183, train_accuracy: 63.67\n",
      "[3,    40] loss: 1.06619, train_accuracy: 63.48\n",
      "[3,    41] loss: 1.11000, train_accuracy: 60.35\n",
      "[3,    42] loss: 1.09657, train_accuracy: 58.79\n",
      "[3,    43] loss: 1.06959, train_accuracy: 61.13\n",
      "[3,    44] loss: 1.04029, train_accuracy: 63.67\n",
      "[3,    45] loss: 1.07390, train_accuracy: 60.55\n",
      "[3,    46] loss: 1.11077, train_accuracy: 60.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    47] loss: 1.14461, train_accuracy: 59.18\n",
      "[3,    48] loss: 1.06189, train_accuracy: 61.72\n",
      "[3,    49] loss: 0.95389, train_accuracy: 67.38\n",
      "[3,    50] loss: 1.11152, train_accuracy: 60.35\n",
      "[3,    51] loss: 0.99595, train_accuracy: 66.02\n",
      "[3,    52] loss: 1.00123, train_accuracy: 65.04\n",
      "[3,    53] loss: 1.00287, train_accuracy: 66.99\n",
      "[3,    54] loss: 1.12640, train_accuracy: 60.35\n",
      "[3,    55] loss: 1.05957, train_accuracy: 65.23\n",
      "[3,    56] loss: 1.04616, train_accuracy: 63.28\n",
      "[3,    57] loss: 1.11242, train_accuracy: 58.98\n",
      "[3,    58] loss: 1.03533, train_accuracy: 62.50\n",
      "[3,    59] loss: 1.00422, train_accuracy: 64.26\n",
      "[3,    60] loss: 1.04351, train_accuracy: 59.38\n",
      "[3,    61] loss: 0.98319, train_accuracy: 65.23\n",
      "[3,    62] loss: 1.07155, train_accuracy: 60.55\n",
      "[3,    63] loss: 1.03165, train_accuracy: 62.11\n",
      "[3,    64] loss: 1.04951, train_accuracy: 63.67\n",
      "[3,    65] loss: 0.99023, train_accuracy: 66.21\n",
      "[3,    66] loss: 1.02670, train_accuracy: 64.26\n",
      "[3,    67] loss: 1.05965, train_accuracy: 61.52\n",
      "[3,    68] loss: 0.95984, train_accuracy: 64.65\n",
      "[3,    69] loss: 1.09268, train_accuracy: 59.77\n",
      "[3,    70] loss: 1.05541, train_accuracy: 60.74\n",
      "[3,    71] loss: 1.01942, train_accuracy: 64.84\n",
      "[3,    72] loss: 1.15028, train_accuracy: 58.40\n",
      "[3,    73] loss: 1.07558, train_accuracy: 59.38\n",
      "[3,    74] loss: 1.08672, train_accuracy: 63.48\n",
      "[3,    75] loss: 1.00685, train_accuracy: 61.13\n",
      "[3,    76] loss: 1.05229, train_accuracy: 61.91\n",
      "[3,    77] loss: 1.08295, train_accuracy: 61.72\n",
      "[3,    78] loss: 1.04156, train_accuracy: 62.50\n",
      "[3,    79] loss: 1.13593, train_accuracy: 59.57\n",
      "[3,    80] loss: 1.06340, train_accuracy: 61.52\n",
      "[3,    81] loss: 1.07476, train_accuracy: 60.35\n",
      "[3,    82] loss: 0.98308, train_accuracy: 63.48\n",
      "[3,    83] loss: 1.06210, train_accuracy: 63.28\n",
      "[3,    84] loss: 1.02762, train_accuracy: 60.94\n",
      "[3,    85] loss: 0.97747, train_accuracy: 65.23\n",
      "[3,    86] loss: 0.96215, train_accuracy: 64.06\n",
      "[3,    87] loss: 0.96698, train_accuracy: 65.04\n",
      "[3,    88] loss: 1.07936, train_accuracy: 59.96\n",
      "[3,    89] loss: 1.07106, train_accuracy: 61.13\n",
      "[3,    90] loss: 1.02567, train_accuracy: 63.09\n",
      "[3,    91] loss: 1.02179, train_accuracy: 63.67\n",
      "[3,    92] loss: 1.14074, train_accuracy: 58.79\n",
      "[3,    93] loss: 1.02016, train_accuracy: 63.87\n",
      "[3,    94] loss: 1.05180, train_accuracy: 62.50\n",
      "[3,    95] loss: 1.03337, train_accuracy: 62.89\n",
      "[3,    96] loss: 1.08594, train_accuracy: 62.50\n",
      "[3,    97] loss: 1.08231, train_accuracy: 60.74\n",
      "[3,    98] loss: 1.03269, train_accuracy: 66.96\n",
      "duration: 25 s - train loss: 1.05780 - train accuracy: 62.14 - validation loss: 1.17 - validation accuracy: 59.14 \n",
      "[4,     1] loss: 1.04891, train_accuracy: 62.30\n",
      "[4,     2] loss: 0.92311, train_accuracy: 66.80\n",
      "[4,     3] loss: 1.02787, train_accuracy: 62.70\n",
      "[4,     4] loss: 0.94719, train_accuracy: 65.82\n",
      "[4,     5] loss: 1.01408, train_accuracy: 63.48\n",
      "[4,     6] loss: 1.01499, train_accuracy: 62.50\n",
      "[4,     7] loss: 1.01718, train_accuracy: 64.26\n",
      "[4,     8] loss: 0.98211, train_accuracy: 64.26\n",
      "[4,     9] loss: 0.96948, train_accuracy: 62.70\n",
      "[4,    10] loss: 1.06198, train_accuracy: 62.89\n",
      "[4,    11] loss: 0.95143, train_accuracy: 66.99\n",
      "[4,    12] loss: 1.00623, train_accuracy: 64.26\n",
      "[4,    13] loss: 1.07826, train_accuracy: 59.57\n",
      "[4,    14] loss: 1.06073, train_accuracy: 60.55\n",
      "[4,    15] loss: 1.10419, train_accuracy: 60.35\n",
      "[4,    16] loss: 1.02812, train_accuracy: 62.50\n",
      "[4,    17] loss: 1.00024, train_accuracy: 64.45\n",
      "[4,    18] loss: 1.05312, train_accuracy: 60.74\n",
      "[4,    19] loss: 1.02028, train_accuracy: 63.87\n",
      "[4,    20] loss: 1.06747, train_accuracy: 60.55\n",
      "[4,    21] loss: 0.99960, train_accuracy: 64.84\n",
      "[4,    22] loss: 1.04643, train_accuracy: 63.67\n",
      "[4,    23] loss: 0.96565, train_accuracy: 66.02\n",
      "[4,    24] loss: 0.96079, train_accuracy: 66.21\n",
      "[4,    25] loss: 0.97703, train_accuracy: 66.80\n",
      "[4,    26] loss: 0.99736, train_accuracy: 62.70\n",
      "[4,    27] loss: 1.09615, train_accuracy: 62.50\n",
      "[4,    28] loss: 1.01676, train_accuracy: 64.45\n",
      "[4,    29] loss: 1.04783, train_accuracy: 61.52\n",
      "[4,    30] loss: 1.12721, train_accuracy: 62.70\n",
      "[4,    31] loss: 1.04089, train_accuracy: 62.30\n",
      "[4,    32] loss: 0.99791, train_accuracy: 65.23\n",
      "[4,    33] loss: 1.07609, train_accuracy: 57.81\n",
      "[4,    34] loss: 0.90054, train_accuracy: 68.36\n",
      "[4,    35] loss: 0.99743, train_accuracy: 62.70\n",
      "[4,    36] loss: 1.00648, train_accuracy: 63.87\n",
      "[4,    37] loss: 0.94065, train_accuracy: 65.43\n",
      "[4,    38] loss: 0.97699, train_accuracy: 64.65\n",
      "[4,    39] loss: 0.96593, train_accuracy: 65.82\n",
      "[4,    40] loss: 1.11074, train_accuracy: 61.33\n",
      "[4,    41] loss: 1.02177, train_accuracy: 63.48\n",
      "[4,    42] loss: 1.02193, train_accuracy: 63.87\n",
      "[4,    43] loss: 0.96133, train_accuracy: 66.60\n",
      "[4,    44] loss: 0.91650, train_accuracy: 68.75\n",
      "[4,    45] loss: 0.93659, train_accuracy: 66.02\n",
      "[4,    46] loss: 0.98811, train_accuracy: 64.26\n",
      "[4,    47] loss: 1.01739, train_accuracy: 63.28\n",
      "[4,    48] loss: 1.02705, train_accuracy: 64.65\n",
      "[4,    49] loss: 0.98016, train_accuracy: 63.87\n",
      "[4,    50] loss: 1.01411, train_accuracy: 63.28\n",
      "[4,    51] loss: 1.09235, train_accuracy: 58.01\n",
      "[4,    52] loss: 0.97701, train_accuracy: 63.67\n",
      "[4,    53] loss: 1.01005, train_accuracy: 66.02\n",
      "[4,    54] loss: 0.93421, train_accuracy: 66.99\n",
      "[4,    55] loss: 0.97072, train_accuracy: 63.48\n",
      "[4,    56] loss: 1.08324, train_accuracy: 62.30\n",
      "[4,    57] loss: 1.00149, train_accuracy: 62.30\n",
      "[4,    58] loss: 1.04073, train_accuracy: 60.94\n",
      "[4,    59] loss: 1.07629, train_accuracy: 62.30\n",
      "[4,    60] loss: 0.98279, train_accuracy: 64.26\n",
      "[4,    61] loss: 1.03104, train_accuracy: 62.30\n",
      "[4,    62] loss: 1.06636, train_accuracy: 60.74\n",
      "[4,    63] loss: 0.97700, train_accuracy: 63.09\n",
      "[4,    64] loss: 1.03819, train_accuracy: 64.06\n",
      "[4,    65] loss: 0.98288, train_accuracy: 65.43\n",
      "[4,    66] loss: 0.96028, train_accuracy: 66.02\n",
      "[4,    67] loss: 1.03069, train_accuracy: 63.67\n",
      "[4,    68] loss: 1.00903, train_accuracy: 64.45\n",
      "[4,    69] loss: 0.93585, train_accuracy: 67.58\n",
      "[4,    70] loss: 0.94666, train_accuracy: 67.77\n",
      "[4,    71] loss: 0.99206, train_accuracy: 65.43\n",
      "[4,    72] loss: 1.00022, train_accuracy: 63.48\n",
      "[4,    73] loss: 0.99670, train_accuracy: 65.23\n",
      "[4,    74] loss: 1.07556, train_accuracy: 59.57\n",
      "[4,    75] loss: 0.98486, train_accuracy: 65.04\n",
      "[4,    76] loss: 1.05838, train_accuracy: 62.11\n",
      "[4,    77] loss: 1.06251, train_accuracy: 59.96\n",
      "[4,    78] loss: 1.04881, train_accuracy: 61.72\n",
      "[4,    79] loss: 0.99061, train_accuracy: 65.62\n",
      "[4,    80] loss: 0.98990, train_accuracy: 64.84\n",
      "[4,    81] loss: 1.06773, train_accuracy: 62.30\n",
      "[4,    82] loss: 1.01236, train_accuracy: 63.28\n",
      "[4,    83] loss: 1.02924, train_accuracy: 63.87\n",
      "[4,    84] loss: 0.96342, train_accuracy: 64.84\n",
      "[4,    85] loss: 0.92692, train_accuracy: 64.26\n",
      "[4,    86] loss: 1.01615, train_accuracy: 62.50\n",
      "[4,    87] loss: 0.93937, train_accuracy: 65.04\n",
      "[4,    88] loss: 0.99768, train_accuracy: 62.70\n",
      "[4,    89] loss: 1.01480, train_accuracy: 62.11\n",
      "[4,    90] loss: 0.99150, train_accuracy: 65.04\n",
      "[4,    91] loss: 0.96107, train_accuracy: 66.80\n",
      "[4,    92] loss: 1.00845, train_accuracy: 65.82\n",
      "[4,    93] loss: 0.98084, train_accuracy: 62.50\n",
      "[4,    94] loss: 0.97347, train_accuracy: 65.23\n",
      "[4,    95] loss: 0.93643, train_accuracy: 68.75\n",
      "[4,    96] loss: 1.03140, train_accuracy: 64.26\n",
      "[4,    97] loss: 0.93016, train_accuracy: 68.95\n",
      "[4,    98] loss: 1.01927, train_accuracy: 64.58\n",
      "duration: 24 s - train loss: 1.00670 - train accuracy: 63.87 - validation loss: 1.14 - validation accuracy: 59.73 \n",
      "[5,     1] loss: 0.94361, train_accuracy: 65.23\n",
      "[5,     2] loss: 0.93735, train_accuracy: 63.87\n",
      "[5,     3] loss: 0.96490, train_accuracy: 66.60\n",
      "[5,     4] loss: 0.97030, train_accuracy: 68.36\n",
      "[5,     5] loss: 0.99144, train_accuracy: 65.82\n",
      "[5,     6] loss: 1.01981, train_accuracy: 61.33\n",
      "[5,     7] loss: 0.94375, train_accuracy: 64.65\n",
      "[5,     8] loss: 1.04174, train_accuracy: 61.72\n",
      "[5,     9] loss: 0.97756, train_accuracy: 66.02\n",
      "[5,    10] loss: 0.94097, train_accuracy: 67.38\n",
      "[5,    11] loss: 1.01738, train_accuracy: 63.67\n",
      "[5,    12] loss: 1.03610, train_accuracy: 63.48\n",
      "[5,    13] loss: 1.02704, train_accuracy: 62.70\n",
      "[5,    14] loss: 0.94354, train_accuracy: 68.75\n",
      "[5,    15] loss: 1.04460, train_accuracy: 64.06\n",
      "[5,    16] loss: 1.02415, train_accuracy: 64.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,    17] loss: 1.03460, train_accuracy: 62.89\n",
      "[5,    18] loss: 0.97510, train_accuracy: 62.89\n",
      "[5,    19] loss: 1.06685, train_accuracy: 60.74\n",
      "[5,    20] loss: 0.93591, train_accuracy: 68.16\n",
      "[5,    21] loss: 1.03919, train_accuracy: 62.11\n",
      "[5,    22] loss: 0.92816, train_accuracy: 66.80\n",
      "[5,    23] loss: 0.93696, train_accuracy: 67.77\n",
      "[5,    24] loss: 0.88172, train_accuracy: 67.38\n",
      "[5,    25] loss: 0.92972, train_accuracy: 67.19\n",
      "[5,    26] loss: 0.94978, train_accuracy: 66.60\n",
      "[5,    27] loss: 1.01826, train_accuracy: 63.28\n",
      "[5,    28] loss: 0.91985, train_accuracy: 66.99\n",
      "[5,    29] loss: 0.93114, train_accuracy: 64.06\n",
      "[5,    30] loss: 1.01579, train_accuracy: 66.02\n",
      "[5,    31] loss: 1.06921, train_accuracy: 63.48\n",
      "[5,    32] loss: 0.97876, train_accuracy: 67.38\n",
      "[5,    33] loss: 0.99058, train_accuracy: 63.87\n",
      "[5,    34] loss: 0.91236, train_accuracy: 67.77\n",
      "[5,    35] loss: 0.94704, train_accuracy: 67.19\n",
      "[5,    36] loss: 1.11467, train_accuracy: 60.94\n",
      "[5,    37] loss: 1.00349, train_accuracy: 63.09\n",
      "[5,    38] loss: 1.00503, train_accuracy: 63.28\n",
      "[5,    39] loss: 0.90890, train_accuracy: 66.41\n",
      "[5,    40] loss: 1.00818, train_accuracy: 62.30\n",
      "[5,    41] loss: 0.82231, train_accuracy: 73.44\n",
      "[5,    42] loss: 0.93860, train_accuracy: 68.95\n",
      "[5,    43] loss: 1.04976, train_accuracy: 62.11\n",
      "[5,    44] loss: 0.94895, train_accuracy: 66.60\n",
      "[5,    45] loss: 0.98725, train_accuracy: 64.26\n",
      "[5,    46] loss: 0.91083, train_accuracy: 68.36\n",
      "[5,    47] loss: 1.00433, train_accuracy: 63.48\n",
      "[5,    48] loss: 1.07350, train_accuracy: 62.11\n",
      "[5,    49] loss: 0.94354, train_accuracy: 66.21\n",
      "[5,    50] loss: 0.93259, train_accuracy: 64.84\n",
      "[5,    51] loss: 0.91164, train_accuracy: 67.97\n",
      "[5,    52] loss: 0.99863, train_accuracy: 62.89\n",
      "[5,    53] loss: 0.94979, train_accuracy: 66.99\n",
      "[5,    54] loss: 0.91877, train_accuracy: 67.77\n",
      "[5,    55] loss: 0.99510, train_accuracy: 65.23\n",
      "[5,    56] loss: 1.05865, train_accuracy: 61.91\n",
      "[5,    57] loss: 0.95455, train_accuracy: 66.80\n",
      "[5,    58] loss: 0.89056, train_accuracy: 67.77\n",
      "[5,    59] loss: 0.96081, train_accuracy: 64.45\n",
      "[5,    60] loss: 0.93303, train_accuracy: 65.23\n",
      "[5,    61] loss: 1.03306, train_accuracy: 64.45\n",
      "[5,    62] loss: 1.01529, train_accuracy: 63.28\n",
      "[5,    63] loss: 0.90554, train_accuracy: 68.75\n",
      "[5,    64] loss: 0.99178, train_accuracy: 65.04\n",
      "[5,    65] loss: 1.04424, train_accuracy: 61.91\n",
      "[5,    66] loss: 0.99308, train_accuracy: 64.84\n",
      "[5,    67] loss: 1.06476, train_accuracy: 61.13\n",
      "[5,    68] loss: 1.00425, train_accuracy: 63.48\n",
      "[5,    69] loss: 0.92056, train_accuracy: 65.62\n",
      "[5,    70] loss: 1.00685, train_accuracy: 66.21\n",
      "[5,    71] loss: 1.04427, train_accuracy: 64.06\n",
      "[5,    72] loss: 1.05888, train_accuracy: 61.13\n",
      "[5,    73] loss: 0.87083, train_accuracy: 68.36\n",
      "[5,    74] loss: 0.99916, train_accuracy: 64.26\n",
      "[5,    75] loss: 0.94057, train_accuracy: 68.16\n",
      "[5,    76] loss: 0.95594, train_accuracy: 65.62\n",
      "[5,    77] loss: 1.00823, train_accuracy: 63.09\n",
      "[5,    78] loss: 0.96377, train_accuracy: 67.77\n",
      "[5,    79] loss: 0.94366, train_accuracy: 62.70\n",
      "[5,    80] loss: 1.02531, train_accuracy: 63.67\n",
      "[5,    81] loss: 0.97881, train_accuracy: 66.02\n",
      "[5,    82] loss: 0.82277, train_accuracy: 69.73\n",
      "[5,    83] loss: 0.93144, train_accuracy: 66.41\n",
      "[5,    84] loss: 1.01778, train_accuracy: 66.41\n",
      "[5,    85] loss: 0.98076, train_accuracy: 64.84\n",
      "[5,    86] loss: 0.98981, train_accuracy: 64.84\n",
      "[5,    87] loss: 0.99426, train_accuracy: 65.82\n",
      "[5,    88] loss: 0.96070, train_accuracy: 67.58\n",
      "[5,    89] loss: 0.91454, train_accuracy: 67.77\n",
      "[5,    90] loss: 0.98022, train_accuracy: 64.84\n",
      "[5,    91] loss: 0.98359, train_accuracy: 65.23\n",
      "[5,    92] loss: 0.97749, train_accuracy: 64.84\n",
      "[5,    93] loss: 0.90309, train_accuracy: 67.19\n",
      "[5,    94] loss: 0.93264, train_accuracy: 66.21\n",
      "[5,    95] loss: 0.90934, train_accuracy: 67.77\n",
      "[5,    96] loss: 0.98002, train_accuracy: 65.82\n",
      "[5,    97] loss: 0.94189, train_accuracy: 63.28\n",
      "[5,    98] loss: 0.99140, train_accuracy: 65.18\n",
      "duration: 25 s - train loss: 0.97438 - train accuracy: 65.28 - validation loss: 1.12 - validation accuracy: 60.31 \n",
      "[6,     1] loss: 0.92382, train_accuracy: 67.97\n",
      "[6,     2] loss: 0.94536, train_accuracy: 66.60\n",
      "[6,     3] loss: 0.91132, train_accuracy: 68.55\n",
      "[6,     4] loss: 0.91239, train_accuracy: 67.19\n",
      "[6,     5] loss: 1.00616, train_accuracy: 65.82\n",
      "[6,     6] loss: 0.94527, train_accuracy: 68.36\n",
      "[6,     7] loss: 0.99953, train_accuracy: 63.28\n",
      "[6,     8] loss: 0.95743, train_accuracy: 66.02\n",
      "[6,     9] loss: 0.94551, train_accuracy: 65.82\n",
      "[6,    10] loss: 1.03499, train_accuracy: 61.72\n",
      "[6,    11] loss: 0.93618, train_accuracy: 66.02\n",
      "[6,    12] loss: 1.04581, train_accuracy: 64.84\n",
      "[6,    13] loss: 0.93576, train_accuracy: 68.55\n",
      "[6,    14] loss: 0.95399, train_accuracy: 67.19\n",
      "[6,    15] loss: 0.96147, train_accuracy: 66.21\n",
      "[6,    16] loss: 0.97456, train_accuracy: 66.02\n",
      "[6,    17] loss: 0.92987, train_accuracy: 66.60\n",
      "[6,    18] loss: 1.03930, train_accuracy: 60.16\n",
      "[6,    19] loss: 0.97755, train_accuracy: 63.48\n",
      "[6,    20] loss: 0.89017, train_accuracy: 68.55\n",
      "[6,    21] loss: 0.98865, train_accuracy: 65.43\n",
      "[6,    22] loss: 0.90224, train_accuracy: 67.77\n",
      "[6,    23] loss: 0.93728, train_accuracy: 69.34\n",
      "[6,    24] loss: 0.92796, train_accuracy: 66.99\n",
      "[6,    25] loss: 0.95075, train_accuracy: 65.62\n",
      "[6,    26] loss: 0.94022, train_accuracy: 67.58\n",
      "[6,    27] loss: 0.96365, train_accuracy: 64.26\n",
      "[6,    28] loss: 0.88986, train_accuracy: 70.12\n",
      "[6,    29] loss: 0.94586, train_accuracy: 68.36\n",
      "[6,    30] loss: 0.97461, train_accuracy: 65.23\n",
      "[6,    31] loss: 0.98279, train_accuracy: 65.23\n",
      "[6,    32] loss: 0.93345, train_accuracy: 67.19\n",
      "[6,    33] loss: 0.90555, train_accuracy: 68.16\n",
      "[6,    34] loss: 1.00406, train_accuracy: 63.28\n",
      "[6,    35] loss: 0.88317, train_accuracy: 68.16\n",
      "[6,    36] loss: 0.85902, train_accuracy: 71.48\n",
      "[6,    37] loss: 0.91846, train_accuracy: 68.95\n",
      "[6,    38] loss: 1.00167, train_accuracy: 65.04\n",
      "[6,    39] loss: 0.97957, train_accuracy: 65.62\n",
      "[6,    40] loss: 0.98318, train_accuracy: 65.23\n",
      "[6,    41] loss: 0.98889, train_accuracy: 65.04\n",
      "[6,    42] loss: 1.00284, train_accuracy: 65.23\n",
      "[6,    43] loss: 0.85871, train_accuracy: 67.97\n",
      "[6,    44] loss: 0.97833, train_accuracy: 65.62\n",
      "[6,    45] loss: 0.93303, train_accuracy: 64.45\n",
      "[6,    46] loss: 0.94729, train_accuracy: 66.02\n",
      "[6,    47] loss: 0.97612, train_accuracy: 64.65\n",
      "[6,    48] loss: 1.01418, train_accuracy: 62.50\n",
      "[6,    49] loss: 0.99007, train_accuracy: 62.11\n",
      "[6,    50] loss: 0.91290, train_accuracy: 67.58\n",
      "[6,    51] loss: 0.94995, train_accuracy: 66.99\n",
      "[6,    52] loss: 0.89624, train_accuracy: 67.38\n",
      "[6,    53] loss: 1.03065, train_accuracy: 62.30\n",
      "[6,    54] loss: 0.92207, train_accuracy: 67.19\n",
      "[6,    55] loss: 0.91969, train_accuracy: 66.99\n",
      "[6,    56] loss: 0.93213, train_accuracy: 65.43\n",
      "[6,    57] loss: 1.00638, train_accuracy: 65.23\n",
      "[6,    58] loss: 1.00014, train_accuracy: 62.50\n",
      "[6,    59] loss: 1.00435, train_accuracy: 65.62\n",
      "[6,    60] loss: 1.02444, train_accuracy: 63.09\n",
      "[6,    61] loss: 0.91894, train_accuracy: 66.60\n",
      "[6,    62] loss: 0.97731, train_accuracy: 66.02\n",
      "[6,    63] loss: 0.96745, train_accuracy: 65.04\n",
      "[6,    64] loss: 0.99023, train_accuracy: 64.26\n",
      "[6,    65] loss: 0.91310, train_accuracy: 66.60\n",
      "[6,    66] loss: 0.91235, train_accuracy: 66.02\n",
      "[6,    67] loss: 1.02867, train_accuracy: 64.26\n",
      "[6,    68] loss: 0.90039, train_accuracy: 67.19\n",
      "[6,    69] loss: 0.90721, train_accuracy: 68.36\n",
      "[6,    70] loss: 0.87956, train_accuracy: 67.38\n",
      "[6,    71] loss: 0.88952, train_accuracy: 68.36\n",
      "[6,    72] loss: 1.03085, train_accuracy: 63.28\n",
      "[6,    73] loss: 0.96670, train_accuracy: 64.84\n",
      "[6,    74] loss: 0.90338, train_accuracy: 67.58\n",
      "[6,    75] loss: 0.91004, train_accuracy: 67.19\n",
      "[6,    76] loss: 0.95012, train_accuracy: 65.62\n",
      "[6,    77] loss: 0.87493, train_accuracy: 67.97\n",
      "[6,    78] loss: 1.00397, train_accuracy: 63.67\n",
      "[6,    79] loss: 1.00416, train_accuracy: 62.11\n",
      "[6,    80] loss: 0.98515, train_accuracy: 64.26\n",
      "[6,    81] loss: 0.92443, train_accuracy: 66.02\n",
      "[6,    82] loss: 0.90994, train_accuracy: 67.38\n",
      "[6,    83] loss: 0.93578, train_accuracy: 65.23\n",
      "[6,    84] loss: 0.92433, train_accuracy: 67.77\n",
      "[6,    85] loss: 0.84970, train_accuracy: 69.92\n",
      "[6,    86] loss: 0.92465, train_accuracy: 67.97\n",
      "[6,    87] loss: 0.91719, train_accuracy: 66.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    88] loss: 1.00316, train_accuracy: 61.13\n",
      "[6,    89] loss: 1.01950, train_accuracy: 63.48\n",
      "[6,    90] loss: 0.96794, train_accuracy: 64.65\n",
      "[6,    91] loss: 0.97899, train_accuracy: 66.41\n",
      "[6,    92] loss: 0.97322, train_accuracy: 65.62\n",
      "[6,    93] loss: 0.96537, train_accuracy: 67.38\n",
      "[6,    94] loss: 0.95883, train_accuracy: 65.43\n",
      "[6,    95] loss: 0.90156, train_accuracy: 66.60\n",
      "[6,    96] loss: 0.88368, train_accuracy: 67.19\n",
      "[6,    97] loss: 1.00896, train_accuracy: 63.09\n",
      "[6,    98] loss: 0.98936, train_accuracy: 67.86\n",
      "duration: 25 s - train loss: 0.95242 - train accuracy: 66.00 - validation loss: 1.11 - validation accuracy: 61.02 \n",
      "[7,     1] loss: 0.93769, train_accuracy: 67.19\n",
      "[7,     2] loss: 0.89039, train_accuracy: 66.21\n",
      "[7,     3] loss: 0.93091, train_accuracy: 68.55\n",
      "[7,     4] loss: 0.86906, train_accuracy: 70.51\n",
      "[7,     5] loss: 0.92979, train_accuracy: 66.60\n",
      "[7,     6] loss: 0.94913, train_accuracy: 64.84\n",
      "[7,     7] loss: 0.93346, train_accuracy: 66.02\n",
      "[7,     8] loss: 0.94288, train_accuracy: 66.41\n",
      "[7,     9] loss: 0.96110, train_accuracy: 66.60\n",
      "[7,    10] loss: 0.93192, train_accuracy: 65.62\n",
      "[7,    11] loss: 0.98984, train_accuracy: 63.48\n",
      "[7,    12] loss: 1.00069, train_accuracy: 65.43\n",
      "[7,    13] loss: 0.89284, train_accuracy: 69.34\n",
      "[7,    14] loss: 0.99668, train_accuracy: 65.82\n",
      "[7,    15] loss: 0.94024, train_accuracy: 64.65\n",
      "[7,    16] loss: 0.89548, train_accuracy: 67.19\n",
      "[7,    17] loss: 0.91490, train_accuracy: 65.62\n",
      "[7,    18] loss: 0.96953, train_accuracy: 65.23\n",
      "[7,    19] loss: 1.10758, train_accuracy: 61.72\n",
      "[7,    20] loss: 1.02672, train_accuracy: 64.26\n",
      "[7,    21] loss: 0.88075, train_accuracy: 67.38\n",
      "[7,    22] loss: 0.91992, train_accuracy: 67.19\n",
      "[7,    23] loss: 1.01001, train_accuracy: 64.65\n",
      "[7,    24] loss: 0.94456, train_accuracy: 65.62\n",
      "[7,    25] loss: 0.87461, train_accuracy: 69.14\n",
      "[7,    26] loss: 0.88117, train_accuracy: 69.14\n",
      "[7,    27] loss: 0.96256, train_accuracy: 68.36\n",
      "[7,    28] loss: 0.93929, train_accuracy: 66.02\n",
      "[7,    29] loss: 0.88279, train_accuracy: 69.53\n",
      "[7,    30] loss: 0.90141, train_accuracy: 67.77\n",
      "[7,    31] loss: 0.95279, train_accuracy: 66.02\n",
      "[7,    32] loss: 0.94104, train_accuracy: 64.84\n",
      "[7,    33] loss: 1.01651, train_accuracy: 62.70\n",
      "[7,    34] loss: 0.90316, train_accuracy: 67.19\n",
      "[7,    35] loss: 0.88647, train_accuracy: 69.92\n",
      "[7,    36] loss: 0.97738, train_accuracy: 64.26\n",
      "[7,    37] loss: 0.94785, train_accuracy: 65.62\n",
      "[7,    38] loss: 0.87484, train_accuracy: 68.55\n",
      "[7,    39] loss: 0.87369, train_accuracy: 69.92\n",
      "[7,    40] loss: 0.88072, train_accuracy: 65.43\n",
      "[7,    41] loss: 0.96409, train_accuracy: 67.38\n",
      "[7,    42] loss: 0.89642, train_accuracy: 68.36\n",
      "[7,    43] loss: 0.89550, train_accuracy: 66.80\n",
      "[7,    44] loss: 0.96004, train_accuracy: 66.80\n",
      "[7,    45] loss: 0.85897, train_accuracy: 69.92\n",
      "[7,    46] loss: 0.99002, train_accuracy: 64.84\n",
      "[7,    47] loss: 0.83938, train_accuracy: 70.70\n",
      "[7,    48] loss: 0.99678, train_accuracy: 66.41\n",
      "[7,    49] loss: 0.92575, train_accuracy: 67.58\n",
      "[7,    50] loss: 0.93167, train_accuracy: 68.36\n",
      "[7,    51] loss: 0.93286, train_accuracy: 66.99\n",
      "[7,    52] loss: 0.91748, train_accuracy: 67.38\n",
      "[7,    53] loss: 0.98193, train_accuracy: 66.21\n",
      "[7,    54] loss: 0.88421, train_accuracy: 67.97\n",
      "[7,    55] loss: 0.90637, train_accuracy: 66.80\n",
      "[7,    56] loss: 0.96062, train_accuracy: 66.21\n",
      "[7,    57] loss: 0.93745, train_accuracy: 65.82\n",
      "[7,    58] loss: 0.90543, train_accuracy: 68.95\n",
      "[7,    59] loss: 0.93395, train_accuracy: 65.23\n",
      "[7,    60] loss: 0.94495, train_accuracy: 67.58\n",
      "[7,    61] loss: 0.93032, train_accuracy: 66.21\n",
      "[7,    62] loss: 0.86697, train_accuracy: 69.53\n",
      "[7,    63] loss: 0.99302, train_accuracy: 66.41\n",
      "[7,    64] loss: 0.89541, train_accuracy: 66.21\n",
      "[7,    65] loss: 1.03475, train_accuracy: 62.30\n",
      "[7,    66] loss: 0.89481, train_accuracy: 65.82\n",
      "[7,    67] loss: 0.91325, train_accuracy: 67.97\n",
      "[7,    68] loss: 0.90315, train_accuracy: 67.77\n",
      "[7,    69] loss: 0.97349, train_accuracy: 63.09\n",
      "[7,    70] loss: 0.89164, train_accuracy: 68.55\n",
      "[7,    71] loss: 0.95032, train_accuracy: 64.65\n",
      "[7,    72] loss: 0.93327, train_accuracy: 67.19\n",
      "[7,    73] loss: 0.94132, train_accuracy: 67.97\n",
      "[7,    74] loss: 0.92218, train_accuracy: 68.36\n",
      "[7,    75] loss: 0.86503, train_accuracy: 69.53\n",
      "[7,    76] loss: 0.92954, train_accuracy: 66.21\n",
      "[7,    77] loss: 0.91089, train_accuracy: 66.99\n",
      "[7,    78] loss: 0.88156, train_accuracy: 67.19\n",
      "[7,    79] loss: 0.97951, train_accuracy: 64.65\n",
      "[7,    80] loss: 0.95137, train_accuracy: 67.97\n",
      "[7,    81] loss: 0.90782, train_accuracy: 67.38\n",
      "[7,    82] loss: 0.96622, train_accuracy: 66.02\n",
      "[7,    83] loss: 0.91376, train_accuracy: 66.80\n",
      "[7,    84] loss: 0.90834, train_accuracy: 66.21\n",
      "[7,    85] loss: 0.96946, train_accuracy: 65.82\n",
      "[7,    86] loss: 1.01537, train_accuracy: 66.60\n",
      "[7,    87] loss: 0.94584, train_accuracy: 65.23\n",
      "[7,    88] loss: 0.97410, train_accuracy: 66.80\n",
      "[7,    89] loss: 0.92886, train_accuracy: 68.55\n",
      "[7,    90] loss: 0.96663, train_accuracy: 66.80\n",
      "[7,    91] loss: 0.89132, train_accuracy: 67.58\n",
      "[7,    92] loss: 0.88799, train_accuracy: 67.58\n",
      "[7,    93] loss: 0.90208, train_accuracy: 66.99\n",
      "[7,    94] loss: 0.93603, train_accuracy: 65.04\n",
      "[7,    95] loss: 1.00083, train_accuracy: 65.23\n",
      "[7,    96] loss: 0.93119, train_accuracy: 65.82\n",
      "[7,    97] loss: 0.93170, train_accuracy: 67.19\n",
      "[7,    98] loss: 0.92420, train_accuracy: 65.18\n",
      "duration: 23 s - train loss: 0.93357 - train accuracy: 66.72 - validation loss: 1.10 - validation accuracy: 61.31 \n",
      "[8,     1] loss: 0.90579, train_accuracy: 67.77\n",
      "[8,     2] loss: 0.95249, train_accuracy: 65.62\n",
      "[8,     3] loss: 0.87375, train_accuracy: 70.12\n",
      "[8,     4] loss: 0.86977, train_accuracy: 69.53\n",
      "[8,     5] loss: 0.82635, train_accuracy: 71.09\n",
      "[8,     6] loss: 0.90868, train_accuracy: 68.95\n",
      "[8,     7] loss: 0.85024, train_accuracy: 68.55\n",
      "[8,     8] loss: 0.92208, train_accuracy: 66.02\n",
      "[8,     9] loss: 0.98157, train_accuracy: 66.60\n",
      "[8,    10] loss: 0.90486, train_accuracy: 67.77\n",
      "[8,    11] loss: 0.93577, train_accuracy: 65.62\n",
      "[8,    12] loss: 0.89225, train_accuracy: 67.77\n",
      "[8,    13] loss: 0.94907, train_accuracy: 68.16\n",
      "[8,    14] loss: 0.96172, train_accuracy: 67.38\n",
      "[8,    15] loss: 0.88893, train_accuracy: 67.19\n",
      "[8,    16] loss: 0.91434, train_accuracy: 68.95\n",
      "[8,    17] loss: 0.96939, train_accuracy: 67.19\n",
      "[8,    18] loss: 1.00939, train_accuracy: 66.60\n",
      "[8,    19] loss: 0.91166, train_accuracy: 67.77\n",
      "[8,    20] loss: 0.88931, train_accuracy: 67.58\n",
      "[8,    21] loss: 0.94763, train_accuracy: 66.21\n",
      "[8,    22] loss: 0.83209, train_accuracy: 70.90\n",
      "[8,    23] loss: 0.86959, train_accuracy: 70.90\n",
      "[8,    24] loss: 0.92953, train_accuracy: 68.95\n",
      "[8,    25] loss: 0.93538, train_accuracy: 65.23\n",
      "[8,    26] loss: 0.88128, train_accuracy: 69.34\n",
      "[8,    27] loss: 0.92999, train_accuracy: 68.95\n",
      "[8,    28] loss: 0.98998, train_accuracy: 63.67\n",
      "[8,    29] loss: 0.86830, train_accuracy: 70.70\n",
      "[8,    30] loss: 0.90518, train_accuracy: 67.58\n",
      "[8,    31] loss: 0.94963, train_accuracy: 64.45\n",
      "[8,    32] loss: 0.85613, train_accuracy: 67.77\n",
      "[8,    33] loss: 0.86073, train_accuracy: 70.12\n",
      "[8,    34] loss: 0.96150, train_accuracy: 66.80\n",
      "[8,    35] loss: 0.98168, train_accuracy: 65.04\n",
      "[8,    36] loss: 0.92414, train_accuracy: 67.58\n",
      "[8,    37] loss: 0.93689, train_accuracy: 67.19\n",
      "[8,    38] loss: 0.94465, train_accuracy: 67.38\n",
      "[8,    39] loss: 0.89290, train_accuracy: 66.60\n",
      "[8,    40] loss: 0.97943, train_accuracy: 65.04\n",
      "[8,    41] loss: 0.96911, train_accuracy: 65.04\n",
      "[8,    42] loss: 0.90687, train_accuracy: 67.77\n",
      "[8,    43] loss: 0.93219, train_accuracy: 65.23\n",
      "[8,    44] loss: 1.00780, train_accuracy: 65.62\n",
      "[8,    45] loss: 0.87365, train_accuracy: 68.75\n",
      "[8,    46] loss: 0.89068, train_accuracy: 67.77\n",
      "[8,    47] loss: 0.95034, train_accuracy: 66.02\n",
      "[8,    48] loss: 0.91469, train_accuracy: 67.58\n",
      "[8,    49] loss: 0.88593, train_accuracy: 69.14\n",
      "[8,    50] loss: 0.91183, train_accuracy: 67.77\n",
      "[8,    51] loss: 0.90767, train_accuracy: 66.02\n",
      "[8,    52] loss: 0.91789, train_accuracy: 67.97\n",
      "[8,    53] loss: 0.95243, train_accuracy: 66.02\n",
      "[8,    54] loss: 0.86884, train_accuracy: 67.97\n",
      "[8,    55] loss: 0.95749, train_accuracy: 65.43\n",
      "[8,    56] loss: 0.98157, train_accuracy: 64.65\n",
      "[8,    57] loss: 0.92434, train_accuracy: 65.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,    58] loss: 0.97336, train_accuracy: 64.65\n",
      "[8,    59] loss: 0.95266, train_accuracy: 64.26\n",
      "[8,    60] loss: 0.96148, train_accuracy: 66.41\n",
      "[8,    61] loss: 0.85963, train_accuracy: 67.77\n",
      "[8,    62] loss: 0.89474, train_accuracy: 67.58\n",
      "[8,    63] loss: 0.91023, train_accuracy: 68.95\n",
      "[8,    64] loss: 0.94161, train_accuracy: 66.80\n",
      "[8,    65] loss: 0.92817, train_accuracy: 66.21\n",
      "[8,    66] loss: 0.95967, train_accuracy: 65.82\n",
      "[8,    67] loss: 0.86397, train_accuracy: 69.14\n",
      "[8,    68] loss: 1.07253, train_accuracy: 60.74\n",
      "[8,    69] loss: 0.93960, train_accuracy: 68.55\n",
      "[8,    70] loss: 0.98555, train_accuracy: 65.82\n",
      "[8,    71] loss: 0.92618, train_accuracy: 65.62\n",
      "[8,    72] loss: 0.90192, train_accuracy: 66.99\n",
      "[8,    73] loss: 0.87419, train_accuracy: 68.95\n",
      "[8,    74] loss: 0.87431, train_accuracy: 67.97\n",
      "[8,    75] loss: 0.91386, train_accuracy: 68.95\n",
      "[8,    76] loss: 0.95306, train_accuracy: 65.23\n",
      "[8,    77] loss: 0.95822, train_accuracy: 67.97\n",
      "[8,    78] loss: 0.91742, train_accuracy: 68.55\n",
      "[8,    79] loss: 0.91473, train_accuracy: 69.34\n",
      "[8,    80] loss: 0.93742, train_accuracy: 65.82\n",
      "[8,    81] loss: 0.88233, train_accuracy: 68.95\n",
      "[8,    82] loss: 0.88731, train_accuracy: 68.55\n",
      "[8,    83] loss: 0.90705, train_accuracy: 67.58\n",
      "[8,    84] loss: 0.85895, train_accuracy: 72.46\n",
      "[8,    85] loss: 0.94170, train_accuracy: 67.19\n",
      "[8,    86] loss: 0.96907, train_accuracy: 66.80\n",
      "[8,    87] loss: 0.89510, train_accuracy: 66.60\n",
      "[8,    88] loss: 0.96173, train_accuracy: 65.62\n",
      "[8,    89] loss: 0.91887, train_accuracy: 67.77\n",
      "[8,    90] loss: 0.89544, train_accuracy: 68.55\n",
      "[8,    91] loss: 0.85320, train_accuracy: 68.75\n",
      "[8,    92] loss: 0.84558, train_accuracy: 70.90\n",
      "[8,    93] loss: 0.90896, train_accuracy: 68.36\n",
      "[8,    94] loss: 0.94084, train_accuracy: 68.36\n",
      "[8,    95] loss: 0.90499, train_accuracy: 66.21\n",
      "[8,    96] loss: 0.93254, train_accuracy: 66.60\n",
      "[8,    97] loss: 0.94783, train_accuracy: 65.82\n",
      "[8,    98] loss: 0.89677, train_accuracy: 67.26\n",
      "duration: 24 s - train loss: 0.92051 - train accuracy: 67.36 - validation loss: 1.09 - validation accuracy: 61.83 \n",
      "[9,     1] loss: 0.88490, train_accuracy: 68.75\n",
      "[9,     2] loss: 0.92166, train_accuracy: 68.75\n",
      "[9,     3] loss: 0.84491, train_accuracy: 68.95\n",
      "[9,     4] loss: 0.96360, train_accuracy: 65.82\n",
      "[9,     5] loss: 0.89801, train_accuracy: 67.38\n",
      "[9,     6] loss: 0.82608, train_accuracy: 69.73\n",
      "[9,     7] loss: 0.89867, train_accuracy: 69.53\n",
      "[9,     8] loss: 0.83798, train_accuracy: 68.55\n",
      "[9,     9] loss: 0.84533, train_accuracy: 68.95\n",
      "[9,    10] loss: 0.86746, train_accuracy: 68.95\n",
      "[9,    11] loss: 0.85193, train_accuracy: 68.36\n",
      "[9,    12] loss: 0.94063, train_accuracy: 68.55\n",
      "[9,    13] loss: 0.83370, train_accuracy: 68.16\n",
      "[9,    14] loss: 0.91234, train_accuracy: 67.97\n",
      "[9,    15] loss: 0.84896, train_accuracy: 68.95\n",
      "[9,    16] loss: 0.89299, train_accuracy: 69.73\n",
      "[9,    17] loss: 0.92388, train_accuracy: 66.02\n",
      "[9,    18] loss: 0.91980, train_accuracy: 64.84\n",
      "[9,    19] loss: 0.97297, train_accuracy: 65.23\n",
      "[9,    20] loss: 0.90618, train_accuracy: 69.92\n",
      "[9,    21] loss: 0.85328, train_accuracy: 71.29\n",
      "[9,    22] loss: 0.87183, train_accuracy: 69.92\n",
      "[9,    23] loss: 0.94356, train_accuracy: 66.41\n",
      "[9,    24] loss: 0.92135, train_accuracy: 66.60\n",
      "[9,    25] loss: 0.86355, train_accuracy: 71.88\n",
      "[9,    26] loss: 0.87474, train_accuracy: 68.75\n",
      "[9,    27] loss: 0.90458, train_accuracy: 68.55\n",
      "[9,    28] loss: 0.87500, train_accuracy: 69.14\n",
      "[9,    29] loss: 0.88213, train_accuracy: 69.73\n",
      "[9,    30] loss: 0.84767, train_accuracy: 70.70\n",
      "[9,    31] loss: 0.84649, train_accuracy: 69.14\n",
      "[9,    32] loss: 0.88923, train_accuracy: 66.80\n",
      "[9,    33] loss: 0.95313, train_accuracy: 63.67\n",
      "[9,    34] loss: 0.85364, train_accuracy: 71.29\n",
      "[9,    35] loss: 0.89639, train_accuracy: 66.80\n",
      "[9,    36] loss: 0.92785, train_accuracy: 68.75\n",
      "[9,    37] loss: 0.89021, train_accuracy: 68.55\n",
      "[9,    38] loss: 0.83294, train_accuracy: 69.92\n",
      "[9,    39] loss: 0.86532, train_accuracy: 69.53\n",
      "[9,    40] loss: 0.86598, train_accuracy: 68.55\n",
      "[9,    41] loss: 0.97315, train_accuracy: 67.97\n",
      "[9,    42] loss: 0.96248, train_accuracy: 66.99\n",
      "[9,    43] loss: 0.89203, train_accuracy: 69.34\n",
      "[9,    44] loss: 0.98836, train_accuracy: 65.04\n",
      "[9,    45] loss: 0.98713, train_accuracy: 65.23\n",
      "[9,    46] loss: 0.93767, train_accuracy: 66.02\n",
      "[9,    47] loss: 0.92376, train_accuracy: 66.99\n",
      "[9,    48] loss: 0.82376, train_accuracy: 69.14\n",
      "[9,    49] loss: 0.90999, train_accuracy: 68.55\n",
      "[9,    50] loss: 0.91982, train_accuracy: 67.19\n",
      "[9,    51] loss: 0.96309, train_accuracy: 64.06\n",
      "[9,    52] loss: 0.90552, train_accuracy: 66.41\n",
      "[9,    53] loss: 0.87329, train_accuracy: 68.36\n",
      "[9,    54] loss: 0.99346, train_accuracy: 65.23\n",
      "[9,    55] loss: 0.93669, train_accuracy: 66.99\n",
      "[9,    56] loss: 0.88157, train_accuracy: 69.73\n",
      "[9,    57] loss: 0.96395, train_accuracy: 67.38\n",
      "[9,    58] loss: 0.98342, train_accuracy: 64.06\n",
      "[9,    59] loss: 0.92998, train_accuracy: 65.62\n",
      "[9,    60] loss: 0.93768, train_accuracy: 67.97\n",
      "[9,    61] loss: 0.93278, train_accuracy: 67.77\n",
      "[9,    62] loss: 0.96708, train_accuracy: 65.82\n",
      "[9,    63] loss: 0.91663, train_accuracy: 68.55\n",
      "[9,    64] loss: 0.92038, train_accuracy: 67.58\n",
      "[9,    65] loss: 0.88906, train_accuracy: 68.16\n",
      "[9,    66] loss: 0.93738, train_accuracy: 67.97\n",
      "[9,    67] loss: 0.96008, train_accuracy: 66.41\n",
      "[9,    68] loss: 0.91196, train_accuracy: 66.99\n",
      "[9,    69] loss: 0.86219, train_accuracy: 70.51\n",
      "[9,    70] loss: 0.89839, train_accuracy: 68.95\n",
      "[9,    71] loss: 0.98174, train_accuracy: 64.45\n",
      "[9,    72] loss: 0.92082, train_accuracy: 68.55\n",
      "[9,    73] loss: 0.94578, train_accuracy: 68.95\n",
      "[9,    74] loss: 1.02851, train_accuracy: 62.30\n",
      "[9,    75] loss: 0.87762, train_accuracy: 68.55\n",
      "[9,    76] loss: 0.98542, train_accuracy: 66.80\n",
      "[9,    77] loss: 0.99958, train_accuracy: 62.50\n",
      "[9,    78] loss: 0.88408, train_accuracy: 67.58\n",
      "[9,    79] loss: 0.91929, train_accuracy: 67.38\n",
      "[9,    80] loss: 0.88964, train_accuracy: 67.77\n",
      "[9,    81] loss: 0.92549, train_accuracy: 65.82\n",
      "[9,    82] loss: 0.92155, train_accuracy: 65.23\n",
      "[9,    83] loss: 0.91237, train_accuracy: 67.38\n",
      "[9,    84] loss: 0.92143, train_accuracy: 67.19\n",
      "[9,    85] loss: 0.85457, train_accuracy: 69.34\n",
      "[9,    86] loss: 0.96114, train_accuracy: 64.06\n",
      "[9,    87] loss: 0.94747, train_accuracy: 64.84\n",
      "[9,    88] loss: 0.92647, train_accuracy: 66.41\n",
      "[9,    89] loss: 0.80959, train_accuracy: 71.29\n",
      "[9,    90] loss: 0.86482, train_accuracy: 69.92\n",
      "[9,    91] loss: 0.93243, train_accuracy: 66.41\n",
      "[9,    92] loss: 0.84923, train_accuracy: 70.90\n",
      "[9,    93] loss: 0.98332, train_accuracy: 64.65\n",
      "[9,    94] loss: 0.93552, train_accuracy: 68.75\n",
      "[9,    95] loss: 0.89831, train_accuracy: 68.16\n",
      "[9,    96] loss: 0.96962, train_accuracy: 66.41\n",
      "[9,    97] loss: 0.85443, train_accuracy: 70.51\n",
      "[9,    98] loss: 0.88761, train_accuracy: 69.64\n",
      "duration: 22 s - train loss: 0.90940 - train accuracy: 67.73 - validation loss: 1.09 - validation accuracy: 61.79 \n",
      "[10,     1] loss: 0.83912, train_accuracy: 71.09\n",
      "[10,     2] loss: 0.96825, train_accuracy: 65.62\n",
      "[10,     3] loss: 0.89284, train_accuracy: 68.55\n",
      "[10,     4] loss: 0.81929, train_accuracy: 71.88\n",
      "[10,     5] loss: 0.80387, train_accuracy: 72.27\n",
      "[10,     6] loss: 0.93083, train_accuracy: 68.16\n",
      "[10,     7] loss: 0.91473, train_accuracy: 67.77\n",
      "[10,     8] loss: 0.99377, train_accuracy: 65.23\n",
      "[10,     9] loss: 0.92374, train_accuracy: 67.19\n",
      "[10,    10] loss: 0.93174, train_accuracy: 64.84\n",
      "[10,    11] loss: 0.84972, train_accuracy: 71.68\n",
      "[10,    12] loss: 0.90550, train_accuracy: 66.99\n",
      "[10,    13] loss: 0.90543, train_accuracy: 66.99\n",
      "[10,    14] loss: 0.81168, train_accuracy: 71.29\n",
      "[10,    15] loss: 0.87538, train_accuracy: 67.19\n",
      "[10,    16] loss: 0.97544, train_accuracy: 66.99\n",
      "[10,    17] loss: 0.80035, train_accuracy: 71.88\n",
      "[10,    18] loss: 0.89091, train_accuracy: 68.16\n",
      "[10,    19] loss: 0.87056, train_accuracy: 68.95\n",
      "[10,    20] loss: 0.82164, train_accuracy: 72.85\n",
      "[10,    21] loss: 0.88698, train_accuracy: 69.53\n",
      "[10,    22] loss: 0.82633, train_accuracy: 70.51\n",
      "[10,    23] loss: 0.86922, train_accuracy: 70.31\n",
      "[10,    24] loss: 0.88927, train_accuracy: 67.38\n",
      "[10,    25] loss: 0.92270, train_accuracy: 69.14\n",
      "[10,    26] loss: 0.92436, train_accuracy: 69.92\n",
      "[10,    27] loss: 0.84543, train_accuracy: 67.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,    28] loss: 0.87959, train_accuracy: 69.14\n",
      "[10,    29] loss: 0.94008, train_accuracy: 64.65\n",
      "[10,    30] loss: 0.87558, train_accuracy: 68.36\n",
      "[10,    31] loss: 0.94132, train_accuracy: 67.19\n",
      "[10,    32] loss: 0.92189, train_accuracy: 67.97\n",
      "[10,    33] loss: 0.86316, train_accuracy: 67.77\n",
      "[10,    34] loss: 0.86326, train_accuracy: 71.88\n",
      "[10,    35] loss: 0.88068, train_accuracy: 69.34\n",
      "[10,    36] loss: 1.02186, train_accuracy: 65.04\n",
      "[10,    37] loss: 0.95729, train_accuracy: 66.21\n",
      "[10,    38] loss: 0.92735, train_accuracy: 67.19\n",
      "[10,    39] loss: 0.88213, train_accuracy: 66.80\n",
      "[10,    40] loss: 0.92978, train_accuracy: 67.77\n",
      "[10,    41] loss: 0.90400, train_accuracy: 68.55\n",
      "[10,    42] loss: 0.93207, train_accuracy: 65.23\n",
      "[10,    43] loss: 0.89479, train_accuracy: 67.58\n",
      "[10,    44] loss: 0.94229, train_accuracy: 65.43\n",
      "[10,    45] loss: 0.88829, train_accuracy: 67.97\n",
      "[10,    46] loss: 0.88059, train_accuracy: 67.58\n",
      "[10,    47] loss: 0.90159, train_accuracy: 65.23\n",
      "[10,    48] loss: 0.90768, train_accuracy: 66.41\n",
      "[10,    49] loss: 0.92704, train_accuracy: 64.26\n",
      "[10,    50] loss: 0.91346, train_accuracy: 70.31\n",
      "[10,    51] loss: 0.93011, train_accuracy: 66.02\n",
      "[10,    52] loss: 0.83296, train_accuracy: 69.14\n",
      "[10,    53] loss: 0.85692, train_accuracy: 71.68\n",
      "[10,    54] loss: 0.88179, train_accuracy: 71.09\n",
      "[10,    55] loss: 0.95122, train_accuracy: 66.99\n",
      "[10,    56] loss: 0.93440, train_accuracy: 68.55\n",
      "[10,    57] loss: 0.92026, train_accuracy: 69.14\n",
      "[10,    58] loss: 0.84230, train_accuracy: 69.14\n",
      "[10,    59] loss: 0.98128, train_accuracy: 66.02\n",
      "[10,    60] loss: 0.84938, train_accuracy: 69.34\n",
      "[10,    61] loss: 0.91544, train_accuracy: 67.58\n",
      "[10,    62] loss: 0.88004, train_accuracy: 66.99\n",
      "[10,    63] loss: 0.89797, train_accuracy: 66.99\n",
      "[10,    64] loss: 0.89258, train_accuracy: 66.21\n",
      "[10,    65] loss: 0.90892, train_accuracy: 66.60\n",
      "[10,    66] loss: 0.94107, train_accuracy: 67.77\n",
      "[10,    67] loss: 0.85032, train_accuracy: 70.31\n",
      "[10,    68] loss: 0.93424, train_accuracy: 66.21\n",
      "[10,    69] loss: 0.83177, train_accuracy: 71.88\n",
      "[10,    70] loss: 0.93098, train_accuracy: 66.99\n",
      "[10,    71] loss: 0.85435, train_accuracy: 70.51\n",
      "[10,    72] loss: 0.93159, train_accuracy: 67.38\n",
      "[10,    73] loss: 0.97090, train_accuracy: 64.84\n",
      "[10,    74] loss: 0.89388, train_accuracy: 68.75\n",
      "[10,    75] loss: 0.89955, train_accuracy: 66.99\n",
      "[10,    76] loss: 0.94195, train_accuracy: 65.43\n",
      "[10,    77] loss: 0.90347, train_accuracy: 68.16\n",
      "[10,    78] loss: 0.86505, train_accuracy: 70.12\n",
      "[10,    79] loss: 0.98368, train_accuracy: 63.48\n",
      "[10,    80] loss: 0.81453, train_accuracy: 69.73\n",
      "[10,    81] loss: 0.87031, train_accuracy: 70.70\n",
      "[10,    82] loss: 0.89891, train_accuracy: 67.19\n",
      "[10,    83] loss: 0.84827, train_accuracy: 68.95\n",
      "[10,    84] loss: 0.97837, train_accuracy: 65.43\n",
      "[10,    85] loss: 0.96225, train_accuracy: 62.70\n",
      "[10,    86] loss: 0.85402, train_accuracy: 71.29\n",
      "[10,    87] loss: 0.87030, train_accuracy: 70.12\n",
      "[10,    88] loss: 0.89045, train_accuracy: 67.77\n",
      "[10,    89] loss: 0.91641, train_accuracy: 67.38\n",
      "[10,    90] loss: 0.88595, train_accuracy: 66.99\n",
      "[10,    91] loss: 0.83397, train_accuracy: 70.70\n",
      "[10,    92] loss: 0.87732, train_accuracy: 70.90\n",
      "[10,    93] loss: 0.90483, train_accuracy: 67.58\n",
      "[10,    94] loss: 0.92347, train_accuracy: 68.95\n",
      "[10,    95] loss: 0.93788, train_accuracy: 66.41\n",
      "[10,    96] loss: 0.92493, train_accuracy: 64.06\n",
      "[10,    97] loss: 0.96541, train_accuracy: 66.60\n",
      "[10,    98] loss: 0.89046, train_accuracy: 68.75\n",
      "duration: 23 s - train loss: 0.89920 - train accuracy: 68.06 - validation loss: 1.09 - validation accuracy: 61.92 \n",
      "[11,     1] loss: 0.84743, train_accuracy: 68.55\n",
      "[11,     2] loss: 0.92988, train_accuracy: 66.99\n",
      "[11,     3] loss: 0.95644, train_accuracy: 63.87\n",
      "[11,     4] loss: 0.91826, train_accuracy: 69.73\n",
      "[11,     5] loss: 0.88915, train_accuracy: 66.99\n",
      "[11,     6] loss: 0.96855, train_accuracy: 65.23\n",
      "[11,     7] loss: 0.83849, train_accuracy: 69.53\n",
      "[11,     8] loss: 0.89658, train_accuracy: 66.41\n",
      "[11,     9] loss: 0.91619, train_accuracy: 68.36\n",
      "[11,    10] loss: 0.90470, train_accuracy: 70.31\n",
      "[11,    11] loss: 0.91022, train_accuracy: 66.60\n",
      "[11,    12] loss: 0.84514, train_accuracy: 68.36\n",
      "[11,    13] loss: 0.81605, train_accuracy: 72.66\n",
      "[11,    14] loss: 0.88704, train_accuracy: 68.55\n",
      "[11,    15] loss: 0.87345, train_accuracy: 66.99\n",
      "[11,    16] loss: 0.89476, train_accuracy: 66.80\n",
      "[11,    17] loss: 0.85409, train_accuracy: 68.95\n",
      "[11,    18] loss: 0.90375, train_accuracy: 68.55\n",
      "[11,    19] loss: 0.88127, train_accuracy: 67.58\n",
      "[11,    20] loss: 0.95233, train_accuracy: 66.21\n",
      "[11,    21] loss: 0.82484, train_accuracy: 70.31\n",
      "[11,    22] loss: 0.87716, train_accuracy: 69.34\n",
      "[11,    23] loss: 0.85948, train_accuracy: 72.66\n",
      "[11,    24] loss: 0.86411, train_accuracy: 71.09\n",
      "[11,    25] loss: 0.84533, train_accuracy: 71.29\n",
      "[11,    26] loss: 0.88864, train_accuracy: 66.41\n",
      "[11,    27] loss: 0.89648, train_accuracy: 70.12\n",
      "[11,    28] loss: 0.89535, train_accuracy: 67.58\n",
      "[11,    29] loss: 0.82217, train_accuracy: 71.09\n",
      "[11,    30] loss: 0.88280, train_accuracy: 68.95\n",
      "[11,    31] loss: 0.96438, train_accuracy: 66.99\n",
      "[11,    32] loss: 0.83771, train_accuracy: 70.31\n",
      "[11,    33] loss: 0.82518, train_accuracy: 70.12\n",
      "[11,    34] loss: 0.92007, train_accuracy: 67.58\n",
      "[11,    35] loss: 0.92532, train_accuracy: 68.36\n",
      "[11,    36] loss: 0.91867, train_accuracy: 69.14\n",
      "[11,    37] loss: 0.81199, train_accuracy: 70.51\n",
      "[11,    38] loss: 0.91369, train_accuracy: 68.55\n",
      "[11,    39] loss: 0.89446, train_accuracy: 67.77\n",
      "[11,    40] loss: 0.88349, train_accuracy: 67.97\n",
      "[11,    41] loss: 0.80709, train_accuracy: 71.88\n",
      "[11,    42] loss: 0.97387, train_accuracy: 65.23\n",
      "[11,    43] loss: 0.84917, train_accuracy: 71.88\n",
      "[11,    44] loss: 0.92276, train_accuracy: 66.21\n",
      "[11,    45] loss: 0.89411, train_accuracy: 67.97\n",
      "[11,    46] loss: 0.87086, train_accuracy: 71.29\n",
      "[11,    47] loss: 0.87333, train_accuracy: 65.23\n",
      "[11,    48] loss: 0.80642, train_accuracy: 69.73\n",
      "[11,    49] loss: 0.92896, train_accuracy: 65.82\n",
      "[11,    50] loss: 0.88282, train_accuracy: 66.80\n",
      "[11,    51] loss: 0.90653, train_accuracy: 67.97\n",
      "[11,    52] loss: 0.95210, train_accuracy: 66.02\n",
      "[11,    53] loss: 0.91358, train_accuracy: 67.38\n",
      "[11,    54] loss: 0.80377, train_accuracy: 70.51\n",
      "[11,    55] loss: 0.91538, train_accuracy: 69.14\n",
      "[11,    56] loss: 0.85286, train_accuracy: 71.29\n",
      "[11,    57] loss: 0.95618, train_accuracy: 67.77\n",
      "[11,    58] loss: 0.83607, train_accuracy: 72.27\n",
      "[11,    59] loss: 0.89764, train_accuracy: 67.58\n",
      "[11,    60] loss: 0.94434, train_accuracy: 67.58\n",
      "[11,    61] loss: 0.86118, train_accuracy: 67.77\n",
      "[11,    62] loss: 0.86169, train_accuracy: 68.55\n",
      "[11,    63] loss: 0.84495, train_accuracy: 72.27\n",
      "[11,    64] loss: 0.80166, train_accuracy: 72.07\n",
      "[11,    65] loss: 1.00709, train_accuracy: 60.16\n",
      "[11,    66] loss: 0.88417, train_accuracy: 69.14\n",
      "[11,    67] loss: 0.86823, train_accuracy: 67.58\n",
      "[11,    68] loss: 0.87387, train_accuracy: 68.36\n",
      "[11,    69] loss: 0.89650, train_accuracy: 67.58\n",
      "[11,    70] loss: 0.90789, train_accuracy: 68.36\n",
      "[11,    71] loss: 0.83977, train_accuracy: 70.51\n",
      "[11,    72] loss: 0.94054, train_accuracy: 67.19\n",
      "[11,    73] loss: 0.89311, train_accuracy: 68.75\n",
      "[11,    74] loss: 0.85846, train_accuracy: 70.70\n",
      "[11,    75] loss: 0.91530, train_accuracy: 65.82\n",
      "[11,    76] loss: 0.94598, train_accuracy: 63.87\n",
      "[11,    77] loss: 0.96929, train_accuracy: 65.82\n",
      "[11,    78] loss: 0.96086, train_accuracy: 67.77\n",
      "[11,    79] loss: 0.83403, train_accuracy: 71.09\n",
      "[11,    80] loss: 0.89258, train_accuracy: 69.34\n",
      "[11,    81] loss: 0.85911, train_accuracy: 68.95\n",
      "[11,    82] loss: 0.95221, train_accuracy: 65.04\n",
      "[11,    83] loss: 0.89373, train_accuracy: 68.55\n",
      "[11,    84] loss: 0.83250, train_accuracy: 72.46\n",
      "[11,    85] loss: 0.82177, train_accuracy: 70.31\n",
      "[11,    86] loss: 0.85527, train_accuracy: 68.55\n",
      "[11,    87] loss: 0.87320, train_accuracy: 70.12\n",
      "[11,    88] loss: 0.87584, train_accuracy: 70.12\n",
      "[11,    89] loss: 0.93703, train_accuracy: 66.41\n",
      "[11,    90] loss: 0.94163, train_accuracy: 69.73\n",
      "[11,    91] loss: 0.89473, train_accuracy: 68.95\n",
      "[11,    92] loss: 0.97182, train_accuracy: 61.52\n",
      "[11,    93] loss: 0.94245, train_accuracy: 64.45\n",
      "[11,    94] loss: 0.86575, train_accuracy: 68.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,    95] loss: 0.84442, train_accuracy: 71.09\n",
      "[11,    96] loss: 0.89900, train_accuracy: 66.80\n",
      "[11,    97] loss: 0.88640, train_accuracy: 69.34\n",
      "[11,    98] loss: 0.95221, train_accuracy: 66.07\n",
      "duration: 22 s - train loss: 0.88958 - train accuracy: 68.40 - validation loss: 1.09 - validation accuracy: 61.96 \n",
      "[12,     1] loss: 0.86257, train_accuracy: 69.73\n",
      "[12,     2] loss: 0.82130, train_accuracy: 71.68\n",
      "[12,     3] loss: 0.80004, train_accuracy: 73.05\n",
      "[12,     4] loss: 0.83781, train_accuracy: 69.92\n",
      "[12,     5] loss: 0.89260, train_accuracy: 69.92\n",
      "[12,     6] loss: 0.89911, train_accuracy: 66.80\n",
      "[12,     7] loss: 0.84054, train_accuracy: 67.77\n",
      "[12,     8] loss: 0.84377, train_accuracy: 70.12\n",
      "[12,     9] loss: 0.93444, train_accuracy: 67.97\n",
      "[12,    10] loss: 0.80241, train_accuracy: 73.83\n",
      "[12,    11] loss: 0.84102, train_accuracy: 67.77\n",
      "[12,    12] loss: 0.90731, train_accuracy: 68.75\n",
      "[12,    13] loss: 0.83507, train_accuracy: 70.12\n",
      "[12,    14] loss: 0.86195, train_accuracy: 69.53\n",
      "[12,    15] loss: 0.81595, train_accuracy: 72.07\n",
      "[12,    16] loss: 0.93423, train_accuracy: 68.36\n",
      "[12,    17] loss: 0.89878, train_accuracy: 68.16\n",
      "[12,    18] loss: 0.84827, train_accuracy: 70.51\n",
      "[12,    19] loss: 0.90085, train_accuracy: 66.99\n",
      "[12,    20] loss: 0.83675, train_accuracy: 70.31\n",
      "[12,    21] loss: 0.90417, train_accuracy: 67.58\n",
      "[12,    22] loss: 1.01715, train_accuracy: 64.65\n",
      "[12,    23] loss: 0.86964, train_accuracy: 68.36\n",
      "[12,    24] loss: 0.85078, train_accuracy: 70.90\n",
      "[12,    25] loss: 0.93597, train_accuracy: 67.19\n",
      "[12,    26] loss: 0.86587, train_accuracy: 68.95\n",
      "[12,    27] loss: 0.89755, train_accuracy: 68.16\n",
      "[12,    28] loss: 0.82211, train_accuracy: 72.46\n",
      "[12,    29] loss: 0.78344, train_accuracy: 72.66\n",
      "[12,    30] loss: 0.82325, train_accuracy: 71.09\n",
      "[12,    31] loss: 0.87553, train_accuracy: 68.95\n",
      "[12,    32] loss: 0.88366, train_accuracy: 67.19\n",
      "[12,    33] loss: 0.92944, train_accuracy: 66.41\n",
      "[12,    34] loss: 0.89241, train_accuracy: 66.80\n",
      "[12,    35] loss: 0.86919, train_accuracy: 69.53\n",
      "[12,    36] loss: 0.90705, train_accuracy: 67.58\n",
      "[12,    37] loss: 0.90756, train_accuracy: 67.58\n",
      "[12,    38] loss: 0.88580, train_accuracy: 70.70\n",
      "[12,    39] loss: 0.89908, train_accuracy: 68.75\n",
      "[12,    40] loss: 0.91373, train_accuracy: 66.21\n",
      "[12,    41] loss: 0.92459, train_accuracy: 68.36\n",
      "[12,    42] loss: 0.82405, train_accuracy: 70.31\n",
      "[12,    43] loss: 0.95107, train_accuracy: 65.23\n",
      "[12,    44] loss: 0.89172, train_accuracy: 68.75\n",
      "[12,    45] loss: 0.85291, train_accuracy: 70.31\n",
      "[12,    46] loss: 0.88366, train_accuracy: 69.14\n",
      "[12,    47] loss: 0.87301, train_accuracy: 69.14\n",
      "[12,    48] loss: 0.89577, train_accuracy: 67.77\n",
      "[12,    49] loss: 0.88929, train_accuracy: 68.95\n",
      "[12,    50] loss: 0.91656, train_accuracy: 68.16\n",
      "[12,    51] loss: 0.91558, train_accuracy: 68.55\n",
      "[12,    52] loss: 0.92587, train_accuracy: 68.75\n",
      "[12,    53] loss: 0.94325, train_accuracy: 67.38\n",
      "[12,    54] loss: 0.93704, train_accuracy: 65.62\n",
      "[12,    55] loss: 0.89014, train_accuracy: 67.77\n",
      "[12,    56] loss: 0.90875, train_accuracy: 66.41\n",
      "[12,    57] loss: 0.87709, train_accuracy: 69.34\n",
      "[12,    58] loss: 0.88268, train_accuracy: 68.55\n",
      "[12,    59] loss: 0.88550, train_accuracy: 67.77\n",
      "[12,    60] loss: 0.90436, train_accuracy: 68.16\n",
      "[12,    61] loss: 0.90972, train_accuracy: 66.80\n",
      "[12,    62] loss: 0.87590, train_accuracy: 70.31\n",
      "[12,    63] loss: 0.92195, train_accuracy: 67.19\n",
      "[12,    64] loss: 0.94524, train_accuracy: 66.80\n",
      "[12,    65] loss: 0.91611, train_accuracy: 68.16\n",
      "[12,    66] loss: 0.81542, train_accuracy: 69.73\n",
      "[12,    67] loss: 0.87830, train_accuracy: 70.31\n",
      "[12,    68] loss: 0.87367, train_accuracy: 68.55\n",
      "[12,    69] loss: 0.83103, train_accuracy: 68.16\n",
      "[12,    70] loss: 0.90450, train_accuracy: 67.19\n",
      "[12,    71] loss: 0.91045, train_accuracy: 68.95\n",
      "[12,    72] loss: 0.94594, train_accuracy: 66.02\n",
      "[12,    73] loss: 0.88079, train_accuracy: 69.73\n",
      "[12,    74] loss: 0.90763, train_accuracy: 67.19\n",
      "[12,    75] loss: 0.86189, train_accuracy: 67.97\n",
      "[12,    76] loss: 0.90802, train_accuracy: 68.16\n",
      "[12,    77] loss: 0.91190, train_accuracy: 70.12\n",
      "[12,    78] loss: 0.87932, train_accuracy: 69.34\n",
      "[12,    79] loss: 0.89450, train_accuracy: 68.55\n",
      "[12,    80] loss: 0.90500, train_accuracy: 68.95\n",
      "[12,    81] loss: 0.88176, train_accuracy: 69.53\n",
      "[12,    82] loss: 0.87813, train_accuracy: 68.55\n",
      "[12,    83] loss: 0.90063, train_accuracy: 68.36\n",
      "[12,    84] loss: 0.84770, train_accuracy: 69.14\n",
      "[12,    85] loss: 0.84835, train_accuracy: 71.48\n",
      "[12,    86] loss: 0.92041, train_accuracy: 68.55\n",
      "[12,    87] loss: 0.86491, train_accuracy: 70.90\n",
      "[12,    88] loss: 0.86875, train_accuracy: 67.97\n",
      "[12,    89] loss: 0.86786, train_accuracy: 69.34\n",
      "[12,    90] loss: 0.86022, train_accuracy: 68.55\n",
      "[12,    91] loss: 0.85288, train_accuracy: 67.19\n",
      "[12,    92] loss: 0.89195, train_accuracy: 69.92\n",
      "[12,    93] loss: 0.96256, train_accuracy: 66.60\n",
      "[12,    94] loss: 0.84878, train_accuracy: 68.55\n",
      "[12,    95] loss: 0.93749, train_accuracy: 66.60\n",
      "[12,    96] loss: 0.84309, train_accuracy: 70.31\n",
      "[12,    97] loss: 0.88138, train_accuracy: 68.75\n",
      "[12,    98] loss: 0.88518, train_accuracy: 68.45\n",
      "duration: 23 s - train loss: 0.88409 - train accuracy: 68.74 - validation loss: 1.08 - validation accuracy: 62.14 \n",
      "[13,     1] loss: 0.87034, train_accuracy: 68.55\n",
      "[13,     2] loss: 0.93409, train_accuracy: 69.34\n",
      "[13,     3] loss: 0.89794, train_accuracy: 68.16\n",
      "[13,     4] loss: 0.93936, train_accuracy: 67.38\n",
      "[13,     5] loss: 0.86680, train_accuracy: 69.53\n",
      "[13,     6] loss: 0.94536, train_accuracy: 68.95\n",
      "[13,     7] loss: 0.82379, train_accuracy: 70.51\n",
      "[13,     8] loss: 0.92740, train_accuracy: 66.02\n",
      "[13,     9] loss: 0.81384, train_accuracy: 71.68\n",
      "[13,    10] loss: 0.88223, train_accuracy: 68.36\n",
      "[13,    11] loss: 0.85405, train_accuracy: 69.73\n",
      "[13,    12] loss: 0.84157, train_accuracy: 69.53\n",
      "[13,    13] loss: 0.88725, train_accuracy: 67.58\n",
      "[13,    14] loss: 0.87791, train_accuracy: 67.58\n",
      "[13,    15] loss: 0.81344, train_accuracy: 72.07\n",
      "[13,    16] loss: 0.84154, train_accuracy: 72.07\n",
      "[13,    17] loss: 0.87970, train_accuracy: 68.95\n",
      "[13,    18] loss: 0.82820, train_accuracy: 70.90\n",
      "[13,    19] loss: 0.93503, train_accuracy: 68.16\n",
      "[13,    20] loss: 0.87734, train_accuracy: 69.92\n",
      "[13,    21] loss: 0.84932, train_accuracy: 72.07\n",
      "[13,    22] loss: 0.89108, train_accuracy: 66.99\n",
      "[13,    23] loss: 0.86086, train_accuracy: 70.31\n",
      "[13,    24] loss: 0.88107, train_accuracy: 69.14\n",
      "[13,    25] loss: 0.81008, train_accuracy: 73.05\n",
      "[13,    26] loss: 0.83132, train_accuracy: 73.44\n",
      "[13,    27] loss: 0.91484, train_accuracy: 68.95\n",
      "[13,    28] loss: 0.86415, train_accuracy: 72.07\n",
      "[13,    29] loss: 0.77823, train_accuracy: 71.09\n",
      "[13,    30] loss: 0.91024, train_accuracy: 66.60\n",
      "[13,    31] loss: 0.83829, train_accuracy: 68.16\n",
      "[13,    32] loss: 0.88897, train_accuracy: 68.95\n",
      "[13,    33] loss: 0.89795, train_accuracy: 69.14\n",
      "[13,    34] loss: 0.86145, train_accuracy: 69.14\n",
      "[13,    35] loss: 0.92957, train_accuracy: 64.26\n",
      "[13,    36] loss: 0.75970, train_accuracy: 73.63\n",
      "[13,    37] loss: 0.94597, train_accuracy: 67.38\n",
      "[13,    38] loss: 0.83825, train_accuracy: 68.36\n",
      "[13,    39] loss: 0.76597, train_accuracy: 70.70\n",
      "[13,    40] loss: 0.97725, train_accuracy: 65.82\n",
      "[13,    41] loss: 0.79986, train_accuracy: 71.48\n",
      "[13,    42] loss: 0.93617, train_accuracy: 67.19\n",
      "[13,    43] loss: 0.97523, train_accuracy: 67.19\n",
      "[13,    44] loss: 0.87655, train_accuracy: 67.77\n",
      "[13,    45] loss: 0.85610, train_accuracy: 69.14\n",
      "[13,    46] loss: 0.86046, train_accuracy: 71.09\n",
      "[13,    47] loss: 0.93532, train_accuracy: 65.62\n",
      "[13,    48] loss: 0.82058, train_accuracy: 69.73\n",
      "[13,    49] loss: 0.92933, train_accuracy: 66.60\n",
      "[13,    50] loss: 0.93835, train_accuracy: 66.99\n",
      "[13,    51] loss: 0.89156, train_accuracy: 68.75\n",
      "[13,    52] loss: 0.91956, train_accuracy: 66.21\n",
      "[13,    53] loss: 0.89245, train_accuracy: 68.55\n",
      "[13,    54] loss: 0.77730, train_accuracy: 71.88\n",
      "[13,    55] loss: 0.84139, train_accuracy: 69.73\n",
      "[13,    56] loss: 0.90408, train_accuracy: 67.77\n",
      "[13,    57] loss: 0.86740, train_accuracy: 69.14\n",
      "[13,    58] loss: 0.87691, train_accuracy: 67.77\n",
      "[13,    59] loss: 0.85504, train_accuracy: 68.16\n",
      "[13,    60] loss: 0.91931, train_accuracy: 66.99\n",
      "[13,    61] loss: 0.87879, train_accuracy: 67.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13,    62] loss: 0.86360, train_accuracy: 67.19\n",
      "[13,    63] loss: 0.79228, train_accuracy: 73.24\n",
      "[13,    64] loss: 0.87452, train_accuracy: 68.36\n",
      "[13,    65] loss: 0.95952, train_accuracy: 66.02\n",
      "[13,    66] loss: 0.86185, train_accuracy: 69.14\n",
      "[13,    67] loss: 0.92095, train_accuracy: 66.60\n",
      "[13,    68] loss: 0.87238, train_accuracy: 70.12\n",
      "[13,    69] loss: 0.87082, train_accuracy: 69.34\n",
      "[13,    70] loss: 0.93108, train_accuracy: 65.43\n",
      "[13,    71] loss: 0.85988, train_accuracy: 67.38\n",
      "[13,    72] loss: 0.85587, train_accuracy: 69.73\n",
      "[13,    73] loss: 0.85232, train_accuracy: 69.73\n",
      "[13,    74] loss: 0.84200, train_accuracy: 69.34\n",
      "[13,    75] loss: 0.86081, train_accuracy: 70.12\n",
      "[13,    76] loss: 0.88275, train_accuracy: 68.55\n",
      "[13,    77] loss: 0.95118, train_accuracy: 64.06\n",
      "[13,    78] loss: 0.85485, train_accuracy: 70.31\n",
      "[13,    79] loss: 0.89480, train_accuracy: 67.19\n",
      "[13,    80] loss: 0.78402, train_accuracy: 72.07\n",
      "[13,    81] loss: 0.84181, train_accuracy: 70.12\n",
      "[13,    82] loss: 0.89364, train_accuracy: 69.92\n",
      "[13,    83] loss: 0.90987, train_accuracy: 68.16\n",
      "[13,    84] loss: 0.90381, train_accuracy: 67.38\n",
      "[13,    85] loss: 0.90721, train_accuracy: 67.19\n",
      "[13,    86] loss: 0.90137, train_accuracy: 67.97\n",
      "[13,    87] loss: 0.91931, train_accuracy: 67.19\n",
      "[13,    88] loss: 0.94380, train_accuracy: 68.75\n",
      "[13,    89] loss: 0.83408, train_accuracy: 70.51\n",
      "[13,    90] loss: 0.90669, train_accuracy: 67.77\n",
      "[13,    91] loss: 0.95835, train_accuracy: 66.41\n",
      "[13,    92] loss: 0.87752, train_accuracy: 67.38\n",
      "[13,    93] loss: 0.83509, train_accuracy: 68.75\n",
      "[13,    94] loss: 0.90021, train_accuracy: 67.58\n",
      "[13,    95] loss: 0.76029, train_accuracy: 72.27\n",
      "[13,    96] loss: 0.84445, train_accuracy: 71.48\n",
      "[13,    97] loss: 0.96229, train_accuracy: 66.80\n",
      "[13,    98] loss: 0.82230, train_accuracy: 72.02\n",
      "duration: 24 s - train loss: 0.87644 - train accuracy: 68.89 - validation loss: 1.08 - validation accuracy: 62.13 \n",
      "[14,     1] loss: 0.84232, train_accuracy: 68.36\n",
      "[14,     2] loss: 0.90198, train_accuracy: 68.36\n",
      "[14,     3] loss: 0.81326, train_accuracy: 70.70\n",
      "[14,     4] loss: 0.88341, train_accuracy: 70.31\n",
      "[14,     5] loss: 0.74414, train_accuracy: 73.63\n",
      "[14,     6] loss: 0.96342, train_accuracy: 64.84\n",
      "[14,     7] loss: 0.91960, train_accuracy: 68.16\n",
      "[14,     8] loss: 0.83098, train_accuracy: 68.16\n",
      "[14,     9] loss: 0.88516, train_accuracy: 68.55\n",
      "[14,    10] loss: 0.88423, train_accuracy: 67.97\n",
      "[14,    11] loss: 0.87347, train_accuracy: 70.31\n",
      "[14,    12] loss: 0.79776, train_accuracy: 73.63\n",
      "[14,    13] loss: 0.86628, train_accuracy: 68.36\n",
      "[14,    14] loss: 0.86737, train_accuracy: 69.73\n",
      "[14,    15] loss: 0.92451, train_accuracy: 66.60\n",
      "[14,    16] loss: 0.89898, train_accuracy: 65.82\n",
      "[14,    17] loss: 0.83210, train_accuracy: 69.53\n",
      "[14,    18] loss: 0.76614, train_accuracy: 71.48\n",
      "[14,    19] loss: 0.89458, train_accuracy: 70.51\n",
      "[14,    20] loss: 0.92681, train_accuracy: 67.97\n",
      "[14,    21] loss: 0.81828, train_accuracy: 73.83\n",
      "[14,    22] loss: 0.82578, train_accuracy: 72.46\n",
      "[14,    23] loss: 0.94672, train_accuracy: 65.43\n",
      "[14,    24] loss: 0.82116, train_accuracy: 69.53\n",
      "[14,    25] loss: 0.84827, train_accuracy: 69.14\n",
      "[14,    26] loss: 0.98012, train_accuracy: 66.02\n",
      "[14,    27] loss: 0.87480, train_accuracy: 67.58\n",
      "[14,    28] loss: 0.92670, train_accuracy: 67.19\n",
      "[14,    29] loss: 0.83471, train_accuracy: 70.70\n",
      "[14,    30] loss: 0.90546, train_accuracy: 67.19\n",
      "[14,    31] loss: 0.78953, train_accuracy: 72.27\n",
      "[14,    32] loss: 0.84841, train_accuracy: 68.16\n",
      "[14,    33] loss: 0.90425, train_accuracy: 66.60\n",
      "[14,    34] loss: 0.87439, train_accuracy: 69.92\n",
      "[14,    35] loss: 0.97519, train_accuracy: 64.26\n",
      "[14,    36] loss: 0.77661, train_accuracy: 70.31\n",
      "[14,    37] loss: 0.91049, train_accuracy: 67.19\n",
      "[14,    38] loss: 0.83622, train_accuracy: 69.73\n",
      "[14,    39] loss: 0.97850, train_accuracy: 66.21\n",
      "[14,    40] loss: 0.84344, train_accuracy: 72.07\n",
      "[14,    41] loss: 0.86047, train_accuracy: 70.31\n",
      "[14,    42] loss: 0.90006, train_accuracy: 68.75\n",
      "[14,    43] loss: 0.84664, train_accuracy: 68.16\n",
      "[14,    44] loss: 0.88650, train_accuracy: 67.58\n",
      "[14,    45] loss: 0.89096, train_accuracy: 67.38\n",
      "[14,    46] loss: 0.84669, train_accuracy: 70.90\n",
      "[14,    47] loss: 0.82749, train_accuracy: 71.09\n",
      "[14,    48] loss: 0.83202, train_accuracy: 72.07\n",
      "[14,    49] loss: 0.78741, train_accuracy: 72.27\n",
      "[14,    50] loss: 0.90813, train_accuracy: 69.73\n",
      "[14,    51] loss: 0.84078, train_accuracy: 73.83\n",
      "[14,    52] loss: 0.84282, train_accuracy: 69.92\n",
      "[14,    53] loss: 0.90137, train_accuracy: 65.43\n",
      "[14,    54] loss: 0.77658, train_accuracy: 71.68\n",
      "[14,    55] loss: 0.86584, train_accuracy: 69.73\n",
      "[14,    56] loss: 0.91259, train_accuracy: 66.99\n",
      "[14,    57] loss: 0.94377, train_accuracy: 66.80\n",
      "[14,    58] loss: 0.84923, train_accuracy: 67.19\n",
      "[14,    59] loss: 0.91039, train_accuracy: 67.38\n",
      "[14,    60] loss: 0.82383, train_accuracy: 68.95\n",
      "[14,    61] loss: 0.86592, train_accuracy: 70.90\n",
      "[14,    62] loss: 0.91261, train_accuracy: 68.95\n",
      "[14,    63] loss: 0.90159, train_accuracy: 67.97\n",
      "[14,    64] loss: 0.89807, train_accuracy: 66.41\n",
      "[14,    65] loss: 0.93330, train_accuracy: 67.58\n",
      "[14,    66] loss: 0.95469, train_accuracy: 67.19\n",
      "[14,    67] loss: 0.86667, train_accuracy: 69.14\n",
      "[14,    68] loss: 0.94232, train_accuracy: 65.23\n",
      "[14,    69] loss: 0.92143, train_accuracy: 69.14\n",
      "[14,    70] loss: 0.76990, train_accuracy: 74.02\n",
      "[14,    71] loss: 0.85118, train_accuracy: 70.90\n",
      "[14,    72] loss: 0.91160, train_accuracy: 70.70\n",
      "[14,    73] loss: 0.85774, train_accuracy: 69.14\n",
      "[14,    74] loss: 0.86270, train_accuracy: 66.60\n",
      "[14,    75] loss: 0.87617, train_accuracy: 68.16\n",
      "[14,    76] loss: 0.83493, train_accuracy: 69.34\n",
      "[14,    77] loss: 0.89447, train_accuracy: 67.38\n",
      "[14,    78] loss: 0.82989, train_accuracy: 68.36\n",
      "[14,    79] loss: 0.81880, train_accuracy: 72.07\n",
      "[14,    80] loss: 0.89678, train_accuracy: 66.02\n",
      "[14,    81] loss: 0.77092, train_accuracy: 75.20\n",
      "[14,    82] loss: 0.87803, train_accuracy: 68.75\n",
      "[14,    83] loss: 0.88400, train_accuracy: 67.58\n",
      "[14,    84] loss: 0.91637, train_accuracy: 68.55\n",
      "[14,    85] loss: 0.86243, train_accuracy: 67.97\n",
      "[14,    86] loss: 0.93257, train_accuracy: 64.65\n",
      "[14,    87] loss: 0.84794, train_accuracy: 69.73\n",
      "[14,    88] loss: 0.77450, train_accuracy: 71.88\n",
      "[14,    89] loss: 0.90411, train_accuracy: 69.53\n",
      "[14,    90] loss: 0.85484, train_accuracy: 70.51\n",
      "[14,    91] loss: 0.93274, train_accuracy: 67.38\n",
      "[14,    92] loss: 0.85601, train_accuracy: 71.88\n",
      "[14,    93] loss: 0.87980, train_accuracy: 67.97\n",
      "[14,    94] loss: 0.82090, train_accuracy: 71.68\n",
      "[14,    95] loss: 0.92596, train_accuracy: 68.16\n",
      "[14,    96] loss: 0.81089, train_accuracy: 71.29\n",
      "[14,    97] loss: 0.87996, train_accuracy: 70.31\n",
      "[14,    98] loss: 0.96337, train_accuracy: 66.67\n",
      "duration: 25 s - train loss: 0.87128 - train accuracy: 69.08 - validation loss: 1.08 - validation accuracy: 62.42 \n",
      "[15,     1] loss: 0.86447, train_accuracy: 69.14\n",
      "[15,     2] loss: 0.79795, train_accuracy: 71.29\n",
      "[15,     3] loss: 0.84470, train_accuracy: 67.97\n",
      "[15,     4] loss: 0.83642, train_accuracy: 72.27\n",
      "[15,     5] loss: 0.89020, train_accuracy: 67.19\n",
      "[15,     6] loss: 0.88013, train_accuracy: 68.95\n",
      "[15,     7] loss: 0.83948, train_accuracy: 70.70\n",
      "[15,     8] loss: 0.86560, train_accuracy: 71.48\n",
      "[15,     9] loss: 0.90717, train_accuracy: 65.82\n",
      "[15,    10] loss: 0.88444, train_accuracy: 68.75\n",
      "[15,    11] loss: 0.84683, train_accuracy: 69.34\n",
      "[15,    12] loss: 0.98067, train_accuracy: 63.87\n",
      "[15,    13] loss: 0.88252, train_accuracy: 69.14\n",
      "[15,    14] loss: 0.88666, train_accuracy: 69.14\n",
      "[15,    15] loss: 0.83488, train_accuracy: 70.12\n",
      "[15,    16] loss: 0.88764, train_accuracy: 70.12\n",
      "[15,    17] loss: 0.87593, train_accuracy: 68.75\n",
      "[15,    18] loss: 0.94195, train_accuracy: 67.97\n",
      "[15,    19] loss: 0.89423, train_accuracy: 67.97\n",
      "[15,    20] loss: 0.86080, train_accuracy: 70.51\n",
      "[15,    21] loss: 0.89702, train_accuracy: 68.75\n",
      "[15,    22] loss: 0.91626, train_accuracy: 66.80\n",
      "[15,    23] loss: 0.78634, train_accuracy: 72.66\n",
      "[15,    24] loss: 0.83137, train_accuracy: 71.68\n",
      "[15,    25] loss: 0.75001, train_accuracy: 74.41\n",
      "[15,    26] loss: 0.84570, train_accuracy: 71.88\n",
      "[15,    27] loss: 0.83360, train_accuracy: 68.95\n",
      "[15,    28] loss: 0.86954, train_accuracy: 69.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15,    29] loss: 0.86663, train_accuracy: 70.70\n",
      "[15,    30] loss: 0.89905, train_accuracy: 68.95\n",
      "[15,    31] loss: 0.76869, train_accuracy: 73.24\n",
      "[15,    32] loss: 0.84930, train_accuracy: 71.29\n",
      "[15,    33] loss: 0.89917, train_accuracy: 71.48\n",
      "[15,    34] loss: 0.88794, train_accuracy: 68.75\n",
      "[15,    35] loss: 0.92486, train_accuracy: 67.77\n",
      "[15,    36] loss: 0.93670, train_accuracy: 68.55\n",
      "[15,    37] loss: 0.80955, train_accuracy: 72.27\n",
      "[15,    38] loss: 0.87863, train_accuracy: 68.55\n",
      "[15,    39] loss: 0.88210, train_accuracy: 65.23\n",
      "[15,    40] loss: 0.83506, train_accuracy: 72.27\n",
      "[15,    41] loss: 0.87953, train_accuracy: 70.31\n",
      "[15,    42] loss: 0.87265, train_accuracy: 69.92\n",
      "[15,    43] loss: 0.78708, train_accuracy: 72.66\n",
      "[15,    44] loss: 0.85674, train_accuracy: 70.12\n",
      "[15,    45] loss: 0.85230, train_accuracy: 71.09\n",
      "[15,    46] loss: 0.85048, train_accuracy: 70.51\n",
      "[15,    47] loss: 0.84102, train_accuracy: 69.34\n",
      "[15,    48] loss: 0.87132, train_accuracy: 69.73\n",
      "[15,    49] loss: 0.88692, train_accuracy: 68.95\n",
      "[15,    50] loss: 0.81221, train_accuracy: 71.29\n",
      "[15,    51] loss: 0.91958, train_accuracy: 67.19\n",
      "[15,    52] loss: 0.79262, train_accuracy: 71.68\n",
      "[15,    53] loss: 0.80861, train_accuracy: 70.31\n",
      "[15,    54] loss: 0.89156, train_accuracy: 66.21\n",
      "[15,    55] loss: 0.84784, train_accuracy: 69.53\n",
      "[15,    56] loss: 0.86387, train_accuracy: 71.29\n",
      "[15,    57] loss: 0.98705, train_accuracy: 64.84\n",
      "[15,    58] loss: 0.84426, train_accuracy: 68.36\n",
      "[15,    59] loss: 0.87354, train_accuracy: 69.14\n",
      "[15,    60] loss: 0.86692, train_accuracy: 69.34\n",
      "[15,    61] loss: 0.85588, train_accuracy: 71.48\n",
      "[15,    62] loss: 0.82024, train_accuracy: 72.07\n",
      "[15,    63] loss: 0.84979, train_accuracy: 69.73\n",
      "[15,    64] loss: 0.85948, train_accuracy: 71.48\n",
      "[15,    65] loss: 0.82520, train_accuracy: 70.70\n",
      "[15,    66] loss: 0.89746, train_accuracy: 66.80\n",
      "[15,    67] loss: 0.89401, train_accuracy: 68.55\n",
      "[15,    68] loss: 0.83232, train_accuracy: 70.31\n",
      "[15,    69] loss: 0.91877, train_accuracy: 65.62\n",
      "[15,    70] loss: 0.90192, train_accuracy: 68.55\n",
      "[15,    71] loss: 0.80326, train_accuracy: 70.90\n",
      "[15,    72] loss: 0.80058, train_accuracy: 71.48\n",
      "[15,    73] loss: 0.80978, train_accuracy: 71.09\n",
      "[15,    74] loss: 0.84613, train_accuracy: 69.53\n",
      "[15,    75] loss: 0.95081, train_accuracy: 66.21\n",
      "[15,    76] loss: 0.90822, train_accuracy: 68.36\n",
      "[15,    77] loss: 0.85637, train_accuracy: 69.34\n",
      "[15,    78] loss: 0.84469, train_accuracy: 68.55\n",
      "[15,    79] loss: 0.85484, train_accuracy: 66.60\n",
      "[15,    80] loss: 0.92463, train_accuracy: 65.43\n",
      "[15,    81] loss: 0.89452, train_accuracy: 69.92\n",
      "[15,    82] loss: 0.86704, train_accuracy: 69.14\n",
      "[15,    83] loss: 0.78157, train_accuracy: 71.88\n",
      "[15,    84] loss: 0.88349, train_accuracy: 70.12\n",
      "[15,    85] loss: 0.97891, train_accuracy: 65.04\n",
      "[15,    86] loss: 0.89740, train_accuracy: 69.14\n",
      "[15,    87] loss: 0.95831, train_accuracy: 67.38\n",
      "[15,    88] loss: 0.95323, train_accuracy: 65.62\n",
      "[15,    89] loss: 0.81066, train_accuracy: 71.29\n",
      "[15,    90] loss: 0.80918, train_accuracy: 71.09\n",
      "[15,    91] loss: 0.82119, train_accuracy: 72.07\n",
      "[15,    92] loss: 0.93288, train_accuracy: 67.77\n",
      "[15,    93] loss: 0.81648, train_accuracy: 71.48\n",
      "[15,    94] loss: 0.89805, train_accuracy: 67.77\n",
      "[15,    95] loss: 0.82811, train_accuracy: 70.70\n",
      "[15,    96] loss: 0.85822, train_accuracy: 68.95\n",
      "[15,    97] loss: 0.79086, train_accuracy: 73.05\n",
      "[15,    98] loss: 0.96852, train_accuracy: 66.37\n",
      "duration: 24 s - train loss: 0.86612 - train accuracy: 69.46 - validation loss: 1.08 - validation accuracy: 62.26 \n",
      "[16,     1] loss: 0.84228, train_accuracy: 69.34\n",
      "[16,     2] loss: 0.85923, train_accuracy: 68.95\n",
      "[16,     3] loss: 0.83026, train_accuracy: 72.07\n",
      "[16,     4] loss: 0.90700, train_accuracy: 68.36\n",
      "[16,     5] loss: 0.86102, train_accuracy: 68.95\n",
      "[16,     6] loss: 0.73461, train_accuracy: 75.39\n",
      "[16,     7] loss: 0.85699, train_accuracy: 67.77\n",
      "[16,     8] loss: 0.93431, train_accuracy: 66.41\n",
      "[16,     9] loss: 0.89550, train_accuracy: 67.77\n",
      "[16,    10] loss: 0.89556, train_accuracy: 67.58\n",
      "[16,    11] loss: 0.84671, train_accuracy: 69.53\n",
      "[16,    12] loss: 0.83229, train_accuracy: 71.48\n",
      "[16,    13] loss: 0.78363, train_accuracy: 73.63\n",
      "[16,    14] loss: 0.80321, train_accuracy: 72.07\n",
      "[16,    15] loss: 0.88034, train_accuracy: 68.75\n",
      "[16,    16] loss: 0.88496, train_accuracy: 68.95\n",
      "[16,    17] loss: 0.91744, train_accuracy: 66.21\n",
      "[16,    18] loss: 0.88992, train_accuracy: 66.21\n",
      "[16,    19] loss: 0.88636, train_accuracy: 68.16\n",
      "[16,    20] loss: 0.84636, train_accuracy: 70.90\n",
      "[16,    21] loss: 0.85887, train_accuracy: 68.75\n",
      "[16,    22] loss: 0.83526, train_accuracy: 69.53\n",
      "[16,    23] loss: 0.86836, train_accuracy: 71.29\n",
      "[16,    24] loss: 0.77544, train_accuracy: 72.07\n",
      "[16,    25] loss: 0.86495, train_accuracy: 67.77\n",
      "[16,    26] loss: 0.86805, train_accuracy: 69.34\n",
      "[16,    27] loss: 0.80286, train_accuracy: 74.61\n",
      "[16,    28] loss: 0.82801, train_accuracy: 70.90\n",
      "[16,    29] loss: 0.96160, train_accuracy: 64.26\n",
      "[16,    30] loss: 0.92304, train_accuracy: 66.41\n",
      "[16,    31] loss: 0.97869, train_accuracy: 65.04\n",
      "[16,    32] loss: 0.78041, train_accuracy: 73.44\n",
      "[16,    33] loss: 0.81265, train_accuracy: 70.70\n",
      "[16,    34] loss: 0.85274, train_accuracy: 73.24\n",
      "[16,    35] loss: 0.77716, train_accuracy: 72.46\n",
      "[16,    36] loss: 0.83519, train_accuracy: 72.46\n",
      "[16,    37] loss: 0.82213, train_accuracy: 69.73\n",
      "[16,    38] loss: 0.85613, train_accuracy: 71.29\n",
      "[16,    39] loss: 0.79716, train_accuracy: 69.73\n",
      "[16,    40] loss: 1.03614, train_accuracy: 63.09\n",
      "[16,    41] loss: 0.82955, train_accuracy: 71.88\n",
      "[16,    42] loss: 0.83563, train_accuracy: 73.24\n",
      "[16,    43] loss: 0.80606, train_accuracy: 71.48\n",
      "[16,    44] loss: 0.87369, train_accuracy: 70.31\n",
      "[16,    45] loss: 0.79816, train_accuracy: 71.29\n",
      "[16,    46] loss: 0.94358, train_accuracy: 67.58\n",
      "[16,    47] loss: 0.88765, train_accuracy: 70.31\n",
      "[16,    48] loss: 0.90625, train_accuracy: 68.16\n",
      "[16,    49] loss: 0.83284, train_accuracy: 69.53\n",
      "[16,    50] loss: 0.88884, train_accuracy: 65.62\n",
      "[16,    51] loss: 0.89835, train_accuracy: 69.73\n",
      "[16,    52] loss: 0.91180, train_accuracy: 67.38\n",
      "[16,    53] loss: 0.80078, train_accuracy: 70.90\n",
      "[16,    54] loss: 0.85175, train_accuracy: 68.36\n",
      "[16,    55] loss: 0.89099, train_accuracy: 68.36\n",
      "[16,    56] loss: 0.86836, train_accuracy: 66.60\n",
      "[16,    57] loss: 0.82343, train_accuracy: 71.48\n",
      "[16,    58] loss: 0.80061, train_accuracy: 72.46\n",
      "[16,    59] loss: 0.81390, train_accuracy: 70.12\n",
      "[16,    60] loss: 0.90748, train_accuracy: 66.41\n",
      "[16,    61] loss: 0.87429, train_accuracy: 68.16\n",
      "[16,    62] loss: 0.86941, train_accuracy: 70.12\n",
      "[16,    63] loss: 0.81084, train_accuracy: 73.24\n",
      "[16,    64] loss: 0.92999, train_accuracy: 67.38\n",
      "[16,    65] loss: 0.82781, train_accuracy: 70.31\n",
      "[16,    66] loss: 0.90152, train_accuracy: 68.16\n",
      "[16,    67] loss: 0.74398, train_accuracy: 73.83\n",
      "[16,    68] loss: 0.89261, train_accuracy: 68.16\n",
      "[16,    69] loss: 0.77433, train_accuracy: 72.66\n",
      "[16,    70] loss: 0.90188, train_accuracy: 69.53\n",
      "[16,    71] loss: 0.82290, train_accuracy: 71.09\n",
      "[16,    72] loss: 0.78508, train_accuracy: 71.09\n",
      "[16,    73] loss: 0.93115, train_accuracy: 65.82\n",
      "[16,    74] loss: 0.91987, train_accuracy: 67.77\n",
      "[16,    75] loss: 0.80345, train_accuracy: 70.90\n",
      "[16,    76] loss: 0.89392, train_accuracy: 66.21\n",
      "[16,    77] loss: 0.90780, train_accuracy: 68.95\n",
      "[16,    78] loss: 0.89381, train_accuracy: 67.38\n",
      "[16,    79] loss: 0.81791, train_accuracy: 68.55\n",
      "[16,    80] loss: 0.88835, train_accuracy: 70.90\n",
      "[16,    81] loss: 0.92518, train_accuracy: 66.41\n",
      "[16,    82] loss: 0.90603, train_accuracy: 66.80\n",
      "[16,    83] loss: 0.91754, train_accuracy: 68.16\n",
      "[16,    84] loss: 0.83555, train_accuracy: 69.92\n",
      "[16,    85] loss: 0.87922, train_accuracy: 70.90\n",
      "[16,    86] loss: 0.78779, train_accuracy: 71.68\n",
      "[16,    87] loss: 0.97936, train_accuracy: 65.43\n",
      "[16,    88] loss: 0.85491, train_accuracy: 68.36\n",
      "[16,    89] loss: 0.85790, train_accuracy: 67.19\n",
      "[16,    90] loss: 0.78429, train_accuracy: 73.63\n",
      "[16,    91] loss: 0.92921, train_accuracy: 68.16\n",
      "[16,    92] loss: 0.82901, train_accuracy: 70.51\n",
      "[16,    93] loss: 0.92791, train_accuracy: 70.51\n",
      "[16,    94] loss: 0.81630, train_accuracy: 72.27\n",
      "[16,    95] loss: 0.83919, train_accuracy: 69.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,    96] loss: 0.84176, train_accuracy: 69.92\n",
      "[16,    97] loss: 0.92499, train_accuracy: 69.14\n",
      "[16,    98] loss: 0.83059, train_accuracy: 70.54\n",
      "duration: 24 s - train loss: 0.86072 - train accuracy: 69.54 - validation loss: 1.08 - validation accuracy: 62.31 \n",
      "[17,     1] loss: 0.82085, train_accuracy: 68.55\n",
      "[17,     2] loss: 0.76267, train_accuracy: 73.05\n",
      "[17,     3] loss: 0.77627, train_accuracy: 74.02\n",
      "[17,     4] loss: 0.79598, train_accuracy: 72.66\n",
      "[17,     5] loss: 0.81698, train_accuracy: 71.29\n",
      "[17,     6] loss: 0.85135, train_accuracy: 71.09\n",
      "[17,     7] loss: 0.89824, train_accuracy: 67.38\n",
      "[17,     8] loss: 0.81004, train_accuracy: 72.27\n",
      "[17,     9] loss: 0.76715, train_accuracy: 72.46\n",
      "[17,    10] loss: 0.79472, train_accuracy: 73.63\n",
      "[17,    11] loss: 0.79862, train_accuracy: 72.27\n",
      "[17,    12] loss: 0.94414, train_accuracy: 66.02\n",
      "[17,    13] loss: 0.83574, train_accuracy: 70.31\n",
      "[17,    14] loss: 0.82137, train_accuracy: 71.29\n",
      "[17,    15] loss: 0.82732, train_accuracy: 70.90\n",
      "[17,    16] loss: 0.88535, train_accuracy: 68.75\n",
      "[17,    17] loss: 0.70601, train_accuracy: 76.37\n",
      "[17,    18] loss: 0.77490, train_accuracy: 73.83\n",
      "[17,    19] loss: 0.87933, train_accuracy: 70.70\n",
      "[17,    20] loss: 0.87260, train_accuracy: 67.97\n",
      "[17,    21] loss: 0.90967, train_accuracy: 66.02\n",
      "[17,    22] loss: 0.88917, train_accuracy: 69.34\n",
      "[17,    23] loss: 0.89899, train_accuracy: 68.16\n",
      "[17,    24] loss: 0.82254, train_accuracy: 70.31\n",
      "[17,    25] loss: 0.88359, train_accuracy: 67.38\n",
      "[17,    26] loss: 0.80063, train_accuracy: 72.46\n",
      "[17,    27] loss: 0.80747, train_accuracy: 70.70\n",
      "[17,    28] loss: 0.78876, train_accuracy: 70.90\n",
      "[17,    29] loss: 0.80644, train_accuracy: 71.09\n",
      "[17,    30] loss: 0.92160, train_accuracy: 69.34\n",
      "[17,    31] loss: 0.87978, train_accuracy: 67.77\n",
      "[17,    32] loss: 0.86208, train_accuracy: 71.48\n",
      "[17,    33] loss: 0.88387, train_accuracy: 68.75\n",
      "[17,    34] loss: 0.83850, train_accuracy: 68.55\n",
      "[17,    35] loss: 0.91930, train_accuracy: 67.97\n",
      "[17,    36] loss: 0.93689, train_accuracy: 66.80\n",
      "[17,    37] loss: 0.85787, train_accuracy: 69.34\n",
      "[17,    38] loss: 0.87589, train_accuracy: 68.36\n",
      "[17,    39] loss: 0.86839, train_accuracy: 68.55\n",
      "[17,    40] loss: 0.81785, train_accuracy: 68.16\n",
      "[17,    41] loss: 0.87082, train_accuracy: 68.95\n",
      "[17,    42] loss: 0.87511, train_accuracy: 67.77\n",
      "[17,    43] loss: 0.92358, train_accuracy: 66.99\n",
      "[17,    44] loss: 0.89785, train_accuracy: 67.97\n",
      "[17,    45] loss: 0.79822, train_accuracy: 71.48\n",
      "[17,    46] loss: 0.80980, train_accuracy: 73.05\n",
      "[17,    47] loss: 0.84834, train_accuracy: 69.73\n",
      "[17,    48] loss: 0.85160, train_accuracy: 70.90\n",
      "[17,    49] loss: 0.77362, train_accuracy: 70.51\n",
      "[17,    50] loss: 0.90801, train_accuracy: 68.55\n",
      "[17,    51] loss: 0.84715, train_accuracy: 71.09\n",
      "[17,    52] loss: 0.88336, train_accuracy: 65.62\n",
      "[17,    53] loss: 0.90083, train_accuracy: 66.80\n",
      "[17,    54] loss: 0.77549, train_accuracy: 72.27\n",
      "[17,    55] loss: 0.88496, train_accuracy: 68.55\n",
      "[17,    56] loss: 0.89649, train_accuracy: 69.14\n",
      "[17,    57] loss: 0.96132, train_accuracy: 68.75\n",
      "[17,    58] loss: 0.87332, train_accuracy: 71.09\n",
      "[17,    59] loss: 0.84254, train_accuracy: 70.31\n",
      "[17,    60] loss: 0.87091, train_accuracy: 70.12\n",
      "[17,    61] loss: 0.87323, train_accuracy: 68.36\n",
      "[17,    62] loss: 0.90520, train_accuracy: 66.60\n",
      "[17,    63] loss: 0.88356, train_accuracy: 69.34\n",
      "[17,    64] loss: 0.97558, train_accuracy: 68.75\n",
      "[17,    65] loss: 0.85567, train_accuracy: 70.70\n",
      "[17,    66] loss: 0.88893, train_accuracy: 69.34\n",
      "[17,    67] loss: 0.93304, train_accuracy: 64.26\n",
      "[17,    68] loss: 0.88133, train_accuracy: 71.68\n",
      "[17,    69] loss: 0.82879, train_accuracy: 68.36\n",
      "[17,    70] loss: 0.84163, train_accuracy: 67.38\n",
      "[17,    71] loss: 0.83904, train_accuracy: 71.09\n",
      "[17,    72] loss: 0.97568, train_accuracy: 67.38\n",
      "[17,    73] loss: 0.82166, train_accuracy: 70.70\n",
      "[17,    74] loss: 0.84721, train_accuracy: 70.90\n",
      "[17,    75] loss: 0.77873, train_accuracy: 71.09\n",
      "[17,    76] loss: 0.87779, train_accuracy: 69.73\n",
      "[17,    77] loss: 0.82251, train_accuracy: 69.34\n",
      "[17,    78] loss: 0.86109, train_accuracy: 69.92\n",
      "[17,    79] loss: 0.95524, train_accuracy: 67.97\n",
      "[17,    80] loss: 0.87112, train_accuracy: 68.55\n",
      "[17,    81] loss: 0.87561, train_accuracy: 67.77\n",
      "[17,    82] loss: 0.85898, train_accuracy: 70.12\n",
      "[17,    83] loss: 0.83207, train_accuracy: 69.14\n",
      "[17,    84] loss: 0.83526, train_accuracy: 71.48\n",
      "[17,    85] loss: 0.80744, train_accuracy: 71.68\n",
      "[17,    86] loss: 0.84573, train_accuracy: 70.12\n",
      "[17,    87] loss: 0.88195, train_accuracy: 67.19\n",
      "[17,    88] loss: 0.84484, train_accuracy: 69.34\n",
      "[17,    89] loss: 0.89154, train_accuracy: 67.19\n",
      "[17,    90] loss: 0.83025, train_accuracy: 70.31\n",
      "[17,    91] loss: 0.88860, train_accuracy: 66.41\n",
      "[17,    92] loss: 0.88952, train_accuracy: 69.92\n",
      "[17,    93] loss: 0.88095, train_accuracy: 70.12\n",
      "[17,    94] loss: 0.83816, train_accuracy: 70.51\n",
      "[17,    95] loss: 0.81189, train_accuracy: 70.51\n",
      "[17,    96] loss: 0.90207, train_accuracy: 66.21\n",
      "[17,    97] loss: 0.90770, train_accuracy: 68.36\n",
      "[17,    98] loss: 0.82925, train_accuracy: 68.45\n",
      "duration: 24 s - train loss: 0.85685 - train accuracy: 69.61 - validation loss: 1.08 - validation accuracy: 62.34 \n",
      "[18,     1] loss: 0.83702, train_accuracy: 73.24\n",
      "[18,     2] loss: 0.88059, train_accuracy: 68.95\n",
      "[18,     3] loss: 0.80848, train_accuracy: 72.07\n",
      "[18,     4] loss: 0.84146, train_accuracy: 68.95\n",
      "[18,     5] loss: 0.84089, train_accuracy: 69.73\n",
      "[18,     6] loss: 0.93523, train_accuracy: 68.95\n",
      "[18,     7] loss: 0.82799, train_accuracy: 71.48\n",
      "[18,     8] loss: 0.88901, train_accuracy: 67.38\n",
      "[18,     9] loss: 0.86008, train_accuracy: 69.73\n",
      "[18,    10] loss: 0.81556, train_accuracy: 71.09\n",
      "[18,    11] loss: 0.86954, train_accuracy: 68.95\n",
      "[18,    12] loss: 0.85760, train_accuracy: 70.51\n",
      "[18,    13] loss: 0.78681, train_accuracy: 69.14\n",
      "[18,    14] loss: 0.84052, train_accuracy: 70.31\n",
      "[18,    15] loss: 0.82080, train_accuracy: 69.53\n",
      "[18,    16] loss: 0.87386, train_accuracy: 68.55\n",
      "[18,    17] loss: 0.79591, train_accuracy: 74.02\n",
      "[18,    18] loss: 0.81909, train_accuracy: 71.68\n",
      "[18,    19] loss: 0.94255, train_accuracy: 66.99\n",
      "[18,    20] loss: 0.90124, train_accuracy: 69.53\n",
      "[18,    21] loss: 0.77491, train_accuracy: 71.48\n",
      "[18,    22] loss: 0.83432, train_accuracy: 71.68\n",
      "[18,    23] loss: 0.87250, train_accuracy: 68.75\n",
      "[18,    24] loss: 0.83995, train_accuracy: 71.29\n",
      "[18,    25] loss: 0.85098, train_accuracy: 69.53\n",
      "[18,    26] loss: 0.80548, train_accuracy: 71.68\n",
      "[18,    27] loss: 0.81453, train_accuracy: 70.31\n",
      "[18,    28] loss: 0.90438, train_accuracy: 68.16\n",
      "[18,    29] loss: 0.85949, train_accuracy: 66.02\n",
      "[18,    30] loss: 0.88409, train_accuracy: 67.97\n",
      "[18,    31] loss: 0.78527, train_accuracy: 72.85\n",
      "[18,    32] loss: 0.78159, train_accuracy: 73.63\n",
      "[18,    33] loss: 0.83444, train_accuracy: 70.31\n",
      "[18,    34] loss: 0.85595, train_accuracy: 70.70\n",
      "[18,    35] loss: 0.84494, train_accuracy: 68.95\n",
      "[18,    36] loss: 0.83793, train_accuracy: 70.31\n",
      "[18,    37] loss: 0.77264, train_accuracy: 71.68\n",
      "[18,    38] loss: 0.84837, train_accuracy: 70.12\n",
      "[18,    39] loss: 0.84520, train_accuracy: 73.24\n",
      "[18,    40] loss: 0.80561, train_accuracy: 72.27\n",
      "[18,    41] loss: 0.85931, train_accuracy: 69.14\n",
      "[18,    42] loss: 0.84588, train_accuracy: 68.75\n",
      "[18,    43] loss: 0.91835, train_accuracy: 66.80\n",
      "[18,    44] loss: 0.86671, train_accuracy: 68.36\n",
      "[18,    45] loss: 0.84173, train_accuracy: 70.70\n",
      "[18,    46] loss: 0.79224, train_accuracy: 69.34\n",
      "[18,    47] loss: 0.88650, train_accuracy: 68.55\n",
      "[18,    48] loss: 0.83317, train_accuracy: 69.92\n",
      "[18,    49] loss: 0.93971, train_accuracy: 70.12\n",
      "[18,    50] loss: 0.84279, train_accuracy: 69.34\n",
      "[18,    51] loss: 0.89214, train_accuracy: 67.38\n",
      "[18,    52] loss: 0.87689, train_accuracy: 69.34\n",
      "[18,    53] loss: 0.91151, train_accuracy: 66.80\n",
      "[18,    54] loss: 0.85722, train_accuracy: 69.34\n",
      "[18,    55] loss: 0.82312, train_accuracy: 69.34\n",
      "[18,    56] loss: 0.77770, train_accuracy: 72.46\n",
      "[18,    57] loss: 0.84688, train_accuracy: 68.75\n",
      "[18,    58] loss: 0.83806, train_accuracy: 69.14\n",
      "[18,    59] loss: 0.81364, train_accuracy: 70.31\n",
      "[18,    60] loss: 0.94402, train_accuracy: 67.19\n",
      "[18,    61] loss: 0.90935, train_accuracy: 69.92\n",
      "[18,    62] loss: 0.88386, train_accuracy: 69.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    63] loss: 0.81799, train_accuracy: 71.29\n",
      "[18,    64] loss: 0.84422, train_accuracy: 67.19\n",
      "[18,    65] loss: 0.86432, train_accuracy: 69.92\n",
      "[18,    66] loss: 0.79836, train_accuracy: 71.29\n",
      "[18,    67] loss: 0.85918, train_accuracy: 70.70\n",
      "[18,    68] loss: 0.87735, train_accuracy: 70.12\n",
      "[18,    69] loss: 0.81942, train_accuracy: 70.31\n",
      "[18,    70] loss: 0.92133, train_accuracy: 69.53\n",
      "[18,    71] loss: 0.82966, train_accuracy: 71.09\n",
      "[18,    72] loss: 0.85452, train_accuracy: 69.73\n",
      "[18,    73] loss: 0.88909, train_accuracy: 67.19\n",
      "[18,    74] loss: 0.88987, train_accuracy: 71.09\n",
      "[18,    75] loss: 0.92115, train_accuracy: 66.80\n",
      "[18,    76] loss: 0.81115, train_accuracy: 70.12\n",
      "[18,    77] loss: 0.87563, train_accuracy: 70.90\n",
      "[18,    78] loss: 0.82587, train_accuracy: 70.70\n",
      "[18,    79] loss: 0.85220, train_accuracy: 69.53\n",
      "[18,    80] loss: 0.79867, train_accuracy: 71.48\n",
      "[18,    81] loss: 0.92477, train_accuracy: 66.99\n",
      "[18,    82] loss: 0.81414, train_accuracy: 70.12\n",
      "[18,    83] loss: 0.79622, train_accuracy: 70.90\n",
      "[18,    84] loss: 0.89488, train_accuracy: 69.34\n",
      "[18,    85] loss: 0.91115, train_accuracy: 67.19\n",
      "[18,    86] loss: 0.83345, train_accuracy: 72.66\n",
      "[18,    87] loss: 0.82767, train_accuracy: 70.90\n",
      "[18,    88] loss: 0.87693, train_accuracy: 67.97\n",
      "[18,    89] loss: 0.90900, train_accuracy: 70.31\n",
      "[18,    90] loss: 0.83220, train_accuracy: 69.92\n",
      "[18,    91] loss: 0.87543, train_accuracy: 68.95\n",
      "[18,    92] loss: 0.87544, train_accuracy: 67.58\n",
      "[18,    93] loss: 0.87365, train_accuracy: 69.34\n",
      "[18,    94] loss: 0.83862, train_accuracy: 70.51\n",
      "[18,    95] loss: 0.72475, train_accuracy: 75.78\n",
      "[18,    96] loss: 0.91403, train_accuracy: 68.36\n",
      "[18,    97] loss: 0.85121, train_accuracy: 69.53\n",
      "[18,    98] loss: 0.92648, train_accuracy: 66.96\n",
      "duration: 24 s - train loss: 0.85253 - train accuracy: 69.84 - validation loss: 1.07 - validation accuracy: 62.36 \n",
      "[19,     1] loss: 0.82508, train_accuracy: 72.27\n",
      "[19,     2] loss: 0.81675, train_accuracy: 71.88\n",
      "[19,     3] loss: 0.84028, train_accuracy: 68.16\n",
      "[19,     4] loss: 0.83538, train_accuracy: 70.51\n",
      "[19,     5] loss: 0.80011, train_accuracy: 72.07\n",
      "[19,     6] loss: 0.89479, train_accuracy: 67.77\n",
      "[19,     7] loss: 0.79698, train_accuracy: 71.68\n",
      "[19,     8] loss: 0.83420, train_accuracy: 69.92\n",
      "[19,     9] loss: 0.80578, train_accuracy: 70.90\n",
      "[19,    10] loss: 0.78492, train_accuracy: 73.63\n",
      "[19,    11] loss: 0.84012, train_accuracy: 73.44\n",
      "[19,    12] loss: 0.86200, train_accuracy: 67.19\n",
      "[19,    13] loss: 0.85987, train_accuracy: 67.97\n",
      "[19,    14] loss: 0.78553, train_accuracy: 73.05\n",
      "[19,    15] loss: 0.83271, train_accuracy: 71.29\n",
      "[19,    16] loss: 0.82381, train_accuracy: 69.92\n",
      "[19,    17] loss: 0.85759, train_accuracy: 68.16\n",
      "[19,    18] loss: 0.97449, train_accuracy: 68.16\n",
      "[19,    19] loss: 0.86900, train_accuracy: 69.92\n",
      "[19,    20] loss: 0.89761, train_accuracy: 68.36\n",
      "[19,    21] loss: 0.79451, train_accuracy: 72.27\n",
      "[19,    22] loss: 0.84659, train_accuracy: 70.12\n",
      "[19,    23] loss: 0.81194, train_accuracy: 72.85\n",
      "[19,    24] loss: 0.88944, train_accuracy: 70.90\n",
      "[19,    25] loss: 0.78889, train_accuracy: 72.27\n",
      "[19,    26] loss: 0.86144, train_accuracy: 67.77\n",
      "[19,    27] loss: 0.88134, train_accuracy: 68.95\n",
      "[19,    28] loss: 0.81348, train_accuracy: 71.29\n",
      "[19,    29] loss: 0.85009, train_accuracy: 67.77\n",
      "[19,    30] loss: 0.83080, train_accuracy: 72.46\n",
      "[19,    31] loss: 0.80998, train_accuracy: 72.27\n",
      "[19,    32] loss: 0.79069, train_accuracy: 73.05\n",
      "[19,    33] loss: 0.79237, train_accuracy: 71.48\n",
      "[19,    34] loss: 0.84474, train_accuracy: 69.34\n",
      "[19,    35] loss: 0.87910, train_accuracy: 69.53\n",
      "[19,    36] loss: 0.87308, train_accuracy: 67.77\n",
      "[19,    37] loss: 0.78843, train_accuracy: 69.73\n",
      "[19,    38] loss: 0.87950, train_accuracy: 68.55\n",
      "[19,    39] loss: 0.85305, train_accuracy: 71.09\n",
      "[19,    40] loss: 0.85842, train_accuracy: 69.73\n",
      "[19,    41] loss: 0.91897, train_accuracy: 66.99\n",
      "[19,    42] loss: 0.86418, train_accuracy: 69.53\n",
      "[19,    43] loss: 0.81585, train_accuracy: 72.85\n",
      "[19,    44] loss: 0.82293, train_accuracy: 72.07\n",
      "[19,    45] loss: 0.82808, train_accuracy: 69.92\n",
      "[19,    46] loss: 0.78445, train_accuracy: 72.46\n",
      "[19,    47] loss: 0.86823, train_accuracy: 70.70\n",
      "[19,    48] loss: 0.80613, train_accuracy: 71.09\n",
      "[19,    49] loss: 0.85083, train_accuracy: 67.77\n",
      "[19,    50] loss: 0.92197, train_accuracy: 67.77\n",
      "[19,    51] loss: 0.84703, train_accuracy: 69.92\n",
      "[19,    52] loss: 0.82927, train_accuracy: 69.34\n",
      "[19,    53] loss: 0.82388, train_accuracy: 69.73\n",
      "[19,    54] loss: 0.81095, train_accuracy: 71.68\n",
      "[19,    55] loss: 0.87543, train_accuracy: 68.95\n",
      "[19,    56] loss: 0.93235, train_accuracy: 65.82\n",
      "[19,    57] loss: 0.86138, train_accuracy: 70.31\n",
      "[19,    58] loss: 0.77658, train_accuracy: 72.85\n",
      "[19,    59] loss: 0.85879, train_accuracy: 71.09\n",
      "[19,    60] loss: 0.91200, train_accuracy: 69.92\n",
      "[19,    61] loss: 0.84538, train_accuracy: 68.36\n",
      "[19,    62] loss: 0.89520, train_accuracy: 70.51\n",
      "[19,    63] loss: 0.84396, train_accuracy: 69.34\n",
      "[19,    64] loss: 0.82111, train_accuracy: 69.34\n",
      "[19,    65] loss: 0.91766, train_accuracy: 65.04\n",
      "[19,    66] loss: 0.88597, train_accuracy: 70.70\n",
      "[19,    67] loss: 0.86449, train_accuracy: 67.97\n",
      "[19,    68] loss: 0.80503, train_accuracy: 71.68\n",
      "[19,    69] loss: 0.80673, train_accuracy: 69.92\n",
      "[19,    70] loss: 0.78293, train_accuracy: 73.24\n",
      "[19,    71] loss: 0.82436, train_accuracy: 69.34\n",
      "[19,    72] loss: 0.91351, train_accuracy: 70.51\n",
      "[19,    73] loss: 0.84580, train_accuracy: 71.48\n",
      "[19,    74] loss: 0.85961, train_accuracy: 70.51\n",
      "[19,    75] loss: 0.80907, train_accuracy: 70.12\n",
      "[19,    76] loss: 0.84914, train_accuracy: 70.31\n",
      "[19,    77] loss: 0.90753, train_accuracy: 68.55\n",
      "[19,    78] loss: 0.82830, train_accuracy: 67.77\n",
      "[19,    79] loss: 0.88482, train_accuracy: 69.14\n",
      "[19,    80] loss: 0.89196, train_accuracy: 67.19\n",
      "[19,    81] loss: 0.87446, train_accuracy: 68.75\n",
      "[19,    82] loss: 0.88142, train_accuracy: 68.55\n",
      "[19,    83] loss: 0.82187, train_accuracy: 71.09\n",
      "[19,    84] loss: 0.83238, train_accuracy: 72.66\n",
      "[19,    85] loss: 0.82685, train_accuracy: 69.92\n",
      "[19,    86] loss: 0.79940, train_accuracy: 71.68\n",
      "[19,    87] loss: 0.79711, train_accuracy: 72.46\n",
      "[19,    88] loss: 0.92036, train_accuracy: 67.38\n",
      "[19,    89] loss: 0.86806, train_accuracy: 69.14\n",
      "[19,    90] loss: 0.90571, train_accuracy: 66.99\n",
      "[19,    91] loss: 0.86729, train_accuracy: 71.29\n",
      "[19,    92] loss: 0.90639, train_accuracy: 70.12\n",
      "[19,    93] loss: 0.84625, train_accuracy: 69.53\n",
      "[19,    94] loss: 0.85387, train_accuracy: 69.34\n",
      "[19,    95] loss: 0.88850, train_accuracy: 67.77\n",
      "[19,    96] loss: 0.85815, train_accuracy: 69.34\n",
      "[19,    97] loss: 0.87937, train_accuracy: 66.99\n",
      "[19,    98] loss: 0.83002, train_accuracy: 70.83\n",
      "duration: 24 s - train loss: 0.84821 - train accuracy: 70.01 - validation loss: 1.08 - validation accuracy: 62.31 \n",
      "[20,     1] loss: 0.84735, train_accuracy: 69.14\n",
      "[20,     2] loss: 0.82540, train_accuracy: 68.95\n",
      "[20,     3] loss: 0.84492, train_accuracy: 70.12\n",
      "[20,     4] loss: 0.85955, train_accuracy: 71.29\n",
      "[20,     5] loss: 0.88717, train_accuracy: 68.95\n",
      "[20,     6] loss: 0.87134, train_accuracy: 68.36\n",
      "[20,     7] loss: 0.79808, train_accuracy: 71.88\n",
      "[20,     8] loss: 0.82096, train_accuracy: 73.24\n",
      "[20,     9] loss: 0.81088, train_accuracy: 70.31\n",
      "[20,    10] loss: 0.88669, train_accuracy: 69.73\n",
      "[20,    11] loss: 0.84278, train_accuracy: 71.48\n",
      "[20,    12] loss: 0.86739, train_accuracy: 70.12\n",
      "[20,    13] loss: 0.81983, train_accuracy: 71.29\n",
      "[20,    14] loss: 0.86344, train_accuracy: 69.14\n",
      "[20,    15] loss: 0.78683, train_accuracy: 73.24\n",
      "[20,    16] loss: 0.86722, train_accuracy: 68.55\n",
      "[20,    17] loss: 0.85424, train_accuracy: 69.14\n",
      "[20,    18] loss: 0.86297, train_accuracy: 71.68\n",
      "[20,    19] loss: 0.85320, train_accuracy: 69.53\n",
      "[20,    20] loss: 0.88868, train_accuracy: 67.58\n",
      "[20,    21] loss: 0.85853, train_accuracy: 69.92\n",
      "[20,    22] loss: 0.77026, train_accuracy: 73.24\n",
      "[20,    23] loss: 0.82063, train_accuracy: 71.29\n",
      "[20,    24] loss: 0.88505, train_accuracy: 68.75\n",
      "[20,    25] loss: 0.81636, train_accuracy: 72.85\n",
      "[20,    26] loss: 0.88599, train_accuracy: 69.73\n",
      "[20,    27] loss: 0.82313, train_accuracy: 70.90\n",
      "[20,    28] loss: 0.89804, train_accuracy: 69.34\n",
      "[20,    29] loss: 0.88103, train_accuracy: 69.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,    30] loss: 0.82383, train_accuracy: 72.27\n",
      "[20,    31] loss: 0.79074, train_accuracy: 71.09\n",
      "[20,    32] loss: 0.79394, train_accuracy: 70.12\n",
      "[20,    33] loss: 0.86947, train_accuracy: 69.34\n",
      "[20,    34] loss: 0.86101, train_accuracy: 69.53\n",
      "[20,    35] loss: 0.81953, train_accuracy: 72.85\n",
      "[20,    36] loss: 0.81717, train_accuracy: 69.53\n",
      "[20,    37] loss: 0.90287, train_accuracy: 67.38\n",
      "[20,    38] loss: 0.77697, train_accuracy: 72.66\n",
      "[20,    39] loss: 0.81861, train_accuracy: 70.12\n",
      "[20,    40] loss: 0.92206, train_accuracy: 67.58\n",
      "[20,    41] loss: 0.79143, train_accuracy: 73.83\n",
      "[20,    42] loss: 0.82477, train_accuracy: 71.09\n",
      "[20,    43] loss: 0.89041, train_accuracy: 69.53\n",
      "[20,    44] loss: 0.87090, train_accuracy: 68.36\n",
      "[20,    45] loss: 0.73865, train_accuracy: 75.00\n",
      "[20,    46] loss: 0.85140, train_accuracy: 70.70\n",
      "[20,    47] loss: 0.82297, train_accuracy: 72.85\n",
      "[20,    48] loss: 0.81319, train_accuracy: 71.09\n",
      "[20,    49] loss: 0.83570, train_accuracy: 70.31\n",
      "[20,    50] loss: 0.86807, train_accuracy: 70.51\n",
      "[20,    51] loss: 0.81952, train_accuracy: 72.66\n",
      "[20,    52] loss: 0.83227, train_accuracy: 69.34\n",
      "[20,    53] loss: 0.87288, train_accuracy: 65.23\n",
      "[20,    54] loss: 0.93316, train_accuracy: 67.77\n",
      "[20,    55] loss: 0.88351, train_accuracy: 67.19\n",
      "[20,    56] loss: 0.80539, train_accuracy: 71.88\n",
      "[20,    57] loss: 0.82728, train_accuracy: 68.36\n",
      "[20,    58] loss: 0.85954, train_accuracy: 70.12\n",
      "[20,    59] loss: 0.88173, train_accuracy: 70.70\n",
      "[20,    60] loss: 0.87277, train_accuracy: 67.19\n",
      "[20,    61] loss: 0.92445, train_accuracy: 65.04\n",
      "[20,    62] loss: 0.82984, train_accuracy: 69.92\n",
      "[20,    63] loss: 0.90313, train_accuracy: 70.70\n",
      "[20,    64] loss: 0.86141, train_accuracy: 70.70\n",
      "[20,    65] loss: 0.82556, train_accuracy: 68.36\n",
      "[20,    66] loss: 0.86257, train_accuracy: 66.99\n",
      "[20,    67] loss: 0.79434, train_accuracy: 72.07\n",
      "[20,    68] loss: 0.79656, train_accuracy: 71.88\n",
      "[20,    69] loss: 0.78803, train_accuracy: 70.90\n",
      "[20,    70] loss: 0.86619, train_accuracy: 69.53\n",
      "[20,    71] loss: 0.88256, train_accuracy: 69.53\n",
      "[20,    72] loss: 0.89507, train_accuracy: 68.16\n",
      "[20,    73] loss: 0.83424, train_accuracy: 69.14\n",
      "[20,    74] loss: 0.78920, train_accuracy: 73.05\n",
      "[20,    75] loss: 0.90101, train_accuracy: 68.95\n",
      "[20,    76] loss: 0.84077, train_accuracy: 69.73\n",
      "[20,    77] loss: 0.87752, train_accuracy: 67.77\n",
      "[20,    78] loss: 0.85466, train_accuracy: 68.55\n",
      "[20,    79] loss: 0.82725, train_accuracy: 71.29\n",
      "[20,    80] loss: 0.76260, train_accuracy: 74.61\n",
      "[20,    81] loss: 0.81432, train_accuracy: 71.09\n",
      "[20,    82] loss: 0.81870, train_accuracy: 74.02\n",
      "[20,    83] loss: 0.82721, train_accuracy: 72.07\n",
      "[20,    84] loss: 0.86862, train_accuracy: 71.29\n",
      "[20,    85] loss: 0.86562, train_accuracy: 70.51\n",
      "[20,    86] loss: 0.88377, train_accuracy: 70.90\n",
      "[20,    87] loss: 0.83654, train_accuracy: 71.88\n",
      "[20,    88] loss: 0.87233, train_accuracy: 69.73\n",
      "[20,    89] loss: 0.84523, train_accuracy: 72.07\n",
      "[20,    90] loss: 0.81637, train_accuracy: 70.70\n",
      "[20,    91] loss: 0.83411, train_accuracy: 70.90\n",
      "[20,    92] loss: 0.84517, train_accuracy: 69.53\n",
      "[20,    93] loss: 0.82834, train_accuracy: 68.55\n",
      "[20,    94] loss: 0.85928, train_accuracy: 68.95\n",
      "[20,    95] loss: 0.84637, train_accuracy: 70.12\n",
      "[20,    96] loss: 0.78134, train_accuracy: 71.68\n",
      "[20,    97] loss: 0.85337, train_accuracy: 68.16\n",
      "[20,    98] loss: 0.85370, train_accuracy: 68.45\n",
      "duration: 24 s - train loss: 0.84446 - train accuracy: 70.24 - validation loss: 1.08 - validation accuracy: 62.51 \n",
      "[21,     1] loss: 0.82568, train_accuracy: 69.53\n",
      "[21,     2] loss: 0.83415, train_accuracy: 71.48\n",
      "[21,     3] loss: 0.84974, train_accuracy: 71.48\n",
      "[21,     4] loss: 0.80058, train_accuracy: 73.24\n",
      "[21,     5] loss: 0.83893, train_accuracy: 69.92\n",
      "[21,     6] loss: 0.81854, train_accuracy: 71.29\n",
      "[21,     7] loss: 0.82785, train_accuracy: 70.70\n",
      "[21,     8] loss: 0.84189, train_accuracy: 70.51\n",
      "[21,     9] loss: 0.82460, train_accuracy: 70.70\n",
      "[21,    10] loss: 0.82877, train_accuracy: 73.63\n",
      "[21,    11] loss: 0.79942, train_accuracy: 69.14\n",
      "[21,    12] loss: 0.76598, train_accuracy: 74.80\n",
      "[21,    13] loss: 0.76925, train_accuracy: 73.83\n",
      "[21,    14] loss: 0.88162, train_accuracy: 69.14\n",
      "[21,    15] loss: 0.82626, train_accuracy: 72.27\n",
      "[21,    16] loss: 0.86314, train_accuracy: 69.92\n",
      "[21,    17] loss: 0.82824, train_accuracy: 69.73\n",
      "[21,    18] loss: 0.82753, train_accuracy: 70.70\n",
      "[21,    19] loss: 0.83119, train_accuracy: 71.88\n",
      "[21,    20] loss: 0.80994, train_accuracy: 71.09\n",
      "[21,    21] loss: 0.82283, train_accuracy: 70.90\n",
      "[21,    22] loss: 0.90073, train_accuracy: 70.31\n",
      "[21,    23] loss: 0.88870, train_accuracy: 67.97\n",
      "[21,    24] loss: 0.90424, train_accuracy: 68.16\n",
      "[21,    25] loss: 0.81368, train_accuracy: 69.73\n",
      "[21,    26] loss: 0.87920, train_accuracy: 68.16\n",
      "[21,    27] loss: 0.85843, train_accuracy: 70.12\n",
      "[21,    28] loss: 0.87582, train_accuracy: 66.99\n",
      "[21,    29] loss: 0.88750, train_accuracy: 66.80\n",
      "[21,    30] loss: 0.86668, train_accuracy: 70.12\n",
      "[21,    31] loss: 0.80807, train_accuracy: 73.05\n",
      "[21,    32] loss: 0.79940, train_accuracy: 71.48\n",
      "[21,    33] loss: 0.91800, train_accuracy: 65.04\n",
      "[21,    34] loss: 0.85487, train_accuracy: 69.73\n",
      "[21,    35] loss: 0.91435, train_accuracy: 68.55\n",
      "[21,    36] loss: 0.85988, train_accuracy: 67.38\n",
      "[21,    37] loss: 0.78687, train_accuracy: 70.12\n",
      "[21,    38] loss: 0.90761, train_accuracy: 66.80\n",
      "[21,    39] loss: 0.87277, train_accuracy: 72.85\n",
      "[21,    40] loss: 0.90074, train_accuracy: 69.92\n",
      "[21,    41] loss: 0.85376, train_accuracy: 71.48\n",
      "[21,    42] loss: 0.82731, train_accuracy: 71.68\n",
      "[21,    43] loss: 0.81381, train_accuracy: 70.12\n",
      "[21,    44] loss: 0.88046, train_accuracy: 68.16\n",
      "[21,    45] loss: 0.85935, train_accuracy: 70.51\n",
      "[21,    46] loss: 0.77022, train_accuracy: 72.66\n",
      "[21,    47] loss: 0.82687, train_accuracy: 71.68\n",
      "[21,    48] loss: 0.89584, train_accuracy: 70.12\n",
      "[21,    49] loss: 0.78217, train_accuracy: 71.48\n",
      "[21,    50] loss: 0.80468, train_accuracy: 70.31\n",
      "[21,    51] loss: 0.82357, train_accuracy: 69.34\n",
      "[21,    52] loss: 0.88017, train_accuracy: 68.95\n",
      "[21,    53] loss: 0.81326, train_accuracy: 72.07\n",
      "[21,    54] loss: 0.84932, train_accuracy: 69.92\n",
      "[21,    55] loss: 0.83257, train_accuracy: 70.70\n",
      "[21,    56] loss: 0.79153, train_accuracy: 73.63\n",
      "[21,    57] loss: 0.89841, train_accuracy: 67.38\n",
      "[21,    58] loss: 0.81633, train_accuracy: 69.14\n",
      "[21,    59] loss: 0.95071, train_accuracy: 67.77\n",
      "[21,    60] loss: 0.80089, train_accuracy: 72.27\n",
      "[21,    61] loss: 0.87977, train_accuracy: 68.16\n",
      "[21,    62] loss: 0.80454, train_accuracy: 71.68\n",
      "[21,    63] loss: 0.88466, train_accuracy: 67.77\n",
      "[21,    64] loss: 0.80287, train_accuracy: 71.09\n",
      "[21,    65] loss: 0.82446, train_accuracy: 71.48\n",
      "[21,    66] loss: 0.82975, train_accuracy: 72.27\n",
      "[21,    67] loss: 0.81252, train_accuracy: 71.09\n",
      "[21,    68] loss: 0.78552, train_accuracy: 71.09\n",
      "[21,    69] loss: 0.77060, train_accuracy: 74.02\n",
      "[21,    70] loss: 0.86011, train_accuracy: 70.70\n",
      "[21,    71] loss: 0.83639, train_accuracy: 71.68\n",
      "[21,    72] loss: 0.82489, train_accuracy: 72.85\n",
      "[21,    73] loss: 0.96707, train_accuracy: 65.82\n",
      "[21,    74] loss: 0.84931, train_accuracy: 68.55\n",
      "[21,    75] loss: 0.87203, train_accuracy: 66.80\n",
      "[21,    76] loss: 0.88502, train_accuracy: 69.14\n",
      "[21,    77] loss: 0.90568, train_accuracy: 65.82\n",
      "[21,    78] loss: 0.82374, train_accuracy: 68.16\n",
      "[21,    79] loss: 0.81567, train_accuracy: 69.92\n",
      "[21,    80] loss: 0.84775, train_accuracy: 71.29\n",
      "[21,    81] loss: 0.78807, train_accuracy: 72.07\n",
      "[21,    82] loss: 0.84677, train_accuracy: 71.88\n",
      "[21,    83] loss: 0.86842, train_accuracy: 70.12\n",
      "[21,    84] loss: 0.91489, train_accuracy: 67.97\n",
      "[21,    85] loss: 0.84885, train_accuracy: 69.73\n",
      "[21,    86] loss: 0.86334, train_accuracy: 70.51\n",
      "[21,    87] loss: 0.81407, train_accuracy: 70.70\n",
      "[21,    88] loss: 0.81685, train_accuracy: 71.68\n",
      "[21,    89] loss: 0.82792, train_accuracy: 72.07\n",
      "[21,    90] loss: 0.83187, train_accuracy: 69.73\n",
      "[21,    91] loss: 0.80283, train_accuracy: 68.36\n",
      "[21,    92] loss: 0.84036, train_accuracy: 70.70\n",
      "[21,    93] loss: 0.87642, train_accuracy: 68.16\n",
      "[21,    94] loss: 0.82826, train_accuracy: 69.53\n",
      "[21,    95] loss: 0.82282, train_accuracy: 70.51\n",
      "[21,    96] loss: 0.85445, train_accuracy: 69.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21,    97] loss: 0.85645, train_accuracy: 67.38\n",
      "[21,    98] loss: 0.81864, train_accuracy: 71.73\n",
      "duration: 25 s - train loss: 0.84274 - train accuracy: 70.21 - validation loss: 1.08 - validation accuracy: 62.59 \n",
      "[22,     1] loss: 0.88381, train_accuracy: 67.97\n",
      "[22,     2] loss: 0.82424, train_accuracy: 70.31\n",
      "[22,     3] loss: 0.80804, train_accuracy: 71.48\n",
      "[22,     4] loss: 0.83496, train_accuracy: 70.12\n",
      "[22,     5] loss: 0.78535, train_accuracy: 70.90\n",
      "[22,     6] loss: 0.88623, train_accuracy: 67.19\n",
      "[22,     7] loss: 0.82410, train_accuracy: 71.29\n",
      "[22,     8] loss: 0.76520, train_accuracy: 72.85\n",
      "[22,     9] loss: 0.82453, train_accuracy: 69.92\n",
      "[22,    10] loss: 0.87297, train_accuracy: 69.14\n",
      "[22,    11] loss: 0.91808, train_accuracy: 68.16\n",
      "[22,    12] loss: 0.85648, train_accuracy: 68.75\n",
      "[22,    13] loss: 0.84969, train_accuracy: 70.90\n",
      "[22,    14] loss: 0.76880, train_accuracy: 73.83\n",
      "[22,    15] loss: 0.78363, train_accuracy: 70.12\n",
      "[22,    16] loss: 0.85905, train_accuracy: 71.29\n",
      "[22,    17] loss: 0.81934, train_accuracy: 71.88\n",
      "[22,    18] loss: 0.82662, train_accuracy: 69.73\n",
      "[22,    19] loss: 0.80752, train_accuracy: 71.48\n",
      "[22,    20] loss: 0.83921, train_accuracy: 71.09\n",
      "[22,    21] loss: 0.78533, train_accuracy: 72.66\n",
      "[22,    22] loss: 0.83466, train_accuracy: 70.12\n",
      "[22,    23] loss: 0.85916, train_accuracy: 68.16\n",
      "[22,    24] loss: 0.81154, train_accuracy: 73.44\n",
      "[22,    25] loss: 0.87081, train_accuracy: 68.75\n",
      "[22,    26] loss: 0.72758, train_accuracy: 73.83\n",
      "[22,    27] loss: 0.85517, train_accuracy: 69.14\n",
      "[22,    28] loss: 0.87849, train_accuracy: 67.77\n",
      "[22,    29] loss: 0.85671, train_accuracy: 70.31\n",
      "[22,    30] loss: 0.76696, train_accuracy: 69.53\n",
      "[22,    31] loss: 0.78192, train_accuracy: 73.24\n",
      "[22,    32] loss: 0.86561, train_accuracy: 68.95\n",
      "[22,    33] loss: 0.86127, train_accuracy: 69.34\n",
      "[22,    34] loss: 0.81415, train_accuracy: 71.29\n",
      "[22,    35] loss: 0.83363, train_accuracy: 71.88\n",
      "[22,    36] loss: 0.91474, train_accuracy: 68.95\n",
      "[22,    37] loss: 0.84713, train_accuracy: 70.70\n",
      "[22,    38] loss: 0.77479, train_accuracy: 72.85\n",
      "[22,    39] loss: 0.86469, train_accuracy: 69.73\n",
      "[22,    40] loss: 0.86020, train_accuracy: 70.31\n",
      "[22,    41] loss: 0.84516, train_accuracy: 72.66\n",
      "[22,    42] loss: 0.83142, train_accuracy: 73.05\n",
      "[22,    43] loss: 0.82781, train_accuracy: 70.51\n",
      "[22,    44] loss: 0.88204, train_accuracy: 67.58\n",
      "[22,    45] loss: 0.75770, train_accuracy: 71.48\n",
      "[22,    46] loss: 0.89347, train_accuracy: 71.09\n",
      "[22,    47] loss: 0.83557, train_accuracy: 70.90\n",
      "[22,    48] loss: 0.83435, train_accuracy: 69.14\n",
      "[22,    49] loss: 0.83458, train_accuracy: 69.92\n",
      "[22,    50] loss: 0.80360, train_accuracy: 70.70\n",
      "[22,    51] loss: 0.78620, train_accuracy: 73.05\n",
      "[22,    52] loss: 0.82263, train_accuracy: 72.85\n",
      "[22,    53] loss: 0.85096, train_accuracy: 70.31\n",
      "[22,    54] loss: 0.83346, train_accuracy: 68.36\n",
      "[22,    55] loss: 0.89175, train_accuracy: 67.97\n",
      "[22,    56] loss: 0.87558, train_accuracy: 70.51\n",
      "[22,    57] loss: 0.79659, train_accuracy: 71.29\n",
      "[22,    58] loss: 0.85134, train_accuracy: 69.73\n",
      "[22,    59] loss: 0.80820, train_accuracy: 70.70\n",
      "[22,    60] loss: 0.83118, train_accuracy: 70.12\n",
      "[22,    61] loss: 0.87949, train_accuracy: 68.55\n",
      "[22,    62] loss: 0.84247, train_accuracy: 72.66\n",
      "[22,    63] loss: 0.85188, train_accuracy: 67.97\n",
      "[22,    64] loss: 0.85676, train_accuracy: 69.34\n",
      "[22,    65] loss: 0.85474, train_accuracy: 68.16\n",
      "[22,    66] loss: 0.84477, train_accuracy: 68.95\n",
      "[22,    67] loss: 0.80344, train_accuracy: 71.88\n",
      "[22,    68] loss: 0.83213, train_accuracy: 71.68\n",
      "[22,    69] loss: 0.91521, train_accuracy: 69.92\n",
      "[22,    70] loss: 0.86612, train_accuracy: 66.41\n",
      "[22,    71] loss: 0.79980, train_accuracy: 72.27\n",
      "[22,    72] loss: 0.90831, train_accuracy: 68.75\n",
      "[22,    73] loss: 0.84635, train_accuracy: 68.55\n",
      "[22,    74] loss: 0.82420, train_accuracy: 72.46\n",
      "[22,    75] loss: 0.80426, train_accuracy: 72.66\n",
      "[22,    76] loss: 0.79360, train_accuracy: 74.02\n",
      "[22,    77] loss: 0.87104, train_accuracy: 68.16\n",
      "[22,    78] loss: 0.89757, train_accuracy: 69.92\n",
      "[22,    79] loss: 0.92151, train_accuracy: 69.73\n",
      "[22,    80] loss: 0.84627, train_accuracy: 70.90\n",
      "[22,    81] loss: 0.84704, train_accuracy: 69.34\n",
      "[22,    82] loss: 0.85804, train_accuracy: 70.90\n",
      "[22,    83] loss: 0.81163, train_accuracy: 71.88\n",
      "[22,    84] loss: 0.81113, train_accuracy: 70.90\n",
      "[22,    85] loss: 0.85362, train_accuracy: 70.31\n",
      "[22,    86] loss: 0.83212, train_accuracy: 68.36\n",
      "[22,    87] loss: 0.89477, train_accuracy: 68.16\n",
      "[22,    88] loss: 0.83647, train_accuracy: 69.53\n",
      "[22,    89] loss: 0.87672, train_accuracy: 70.12\n",
      "[22,    90] loss: 0.88266, train_accuracy: 68.36\n",
      "[22,    91] loss: 0.80091, train_accuracy: 71.88\n",
      "[22,    92] loss: 0.84668, train_accuracy: 72.46\n",
      "[22,    93] loss: 0.81594, train_accuracy: 70.90\n",
      "[22,    94] loss: 0.81651, train_accuracy: 71.29\n",
      "[22,    95] loss: 0.82018, train_accuracy: 69.92\n",
      "[22,    96] loss: 0.86286, train_accuracy: 68.36\n",
      "[22,    97] loss: 0.90507, train_accuracy: 70.12\n",
      "[22,    98] loss: 0.78986, train_accuracy: 72.32\n",
      "duration: 25 s - train loss: 0.83896 - train accuracy: 70.40 - validation loss: 1.08 - validation accuracy: 62.77 \n",
      "[23,     1] loss: 0.94515, train_accuracy: 68.75\n",
      "[23,     2] loss: 0.81876, train_accuracy: 69.34\n",
      "[23,     3] loss: 0.79607, train_accuracy: 70.12\n",
      "[23,     4] loss: 0.80693, train_accuracy: 71.09\n",
      "[23,     5] loss: 0.81099, train_accuracy: 72.46\n",
      "[23,     6] loss: 0.88846, train_accuracy: 68.55\n",
      "[23,     7] loss: 0.87451, train_accuracy: 70.31\n",
      "[23,     8] loss: 0.81172, train_accuracy: 73.24\n",
      "[23,     9] loss: 0.77118, train_accuracy: 73.24\n",
      "[23,    10] loss: 0.82046, train_accuracy: 70.90\n",
      "[23,    11] loss: 0.78242, train_accuracy: 70.31\n",
      "[23,    12] loss: 0.85636, train_accuracy: 70.90\n",
      "[23,    13] loss: 0.79759, train_accuracy: 70.12\n",
      "[23,    14] loss: 0.84525, train_accuracy: 70.31\n",
      "[23,    15] loss: 0.78408, train_accuracy: 71.68\n",
      "[23,    16] loss: 0.79457, train_accuracy: 72.66\n",
      "[23,    17] loss: 0.81382, train_accuracy: 70.31\n",
      "[23,    18] loss: 0.89057, train_accuracy: 70.12\n",
      "[23,    19] loss: 0.83251, train_accuracy: 70.90\n",
      "[23,    20] loss: 0.81986, train_accuracy: 68.16\n",
      "[23,    21] loss: 0.76043, train_accuracy: 73.05\n",
      "[23,    22] loss: 0.86772, train_accuracy: 71.48\n",
      "[23,    23] loss: 0.81501, train_accuracy: 70.51\n",
      "[23,    24] loss: 0.87437, train_accuracy: 70.31\n",
      "[23,    25] loss: 0.82633, train_accuracy: 71.29\n",
      "[23,    26] loss: 0.81908, train_accuracy: 70.70\n",
      "[23,    27] loss: 0.80440, train_accuracy: 70.12\n",
      "[23,    28] loss: 0.88740, train_accuracy: 67.77\n",
      "[23,    29] loss: 0.76085, train_accuracy: 71.68\n",
      "[23,    30] loss: 0.93220, train_accuracy: 67.38\n",
      "[23,    31] loss: 0.79885, train_accuracy: 72.85\n",
      "[23,    32] loss: 0.84664, train_accuracy: 69.34\n",
      "[23,    33] loss: 0.83084, train_accuracy: 70.70\n",
      "[23,    34] loss: 0.86501, train_accuracy: 69.92\n",
      "[23,    35] loss: 0.85522, train_accuracy: 70.12\n",
      "[23,    36] loss: 0.81963, train_accuracy: 69.92\n",
      "[23,    37] loss: 0.85303, train_accuracy: 69.14\n",
      "[23,    38] loss: 0.84643, train_accuracy: 69.53\n",
      "[23,    39] loss: 0.90250, train_accuracy: 70.12\n",
      "[23,    40] loss: 0.82279, train_accuracy: 69.73\n",
      "[23,    41] loss: 0.90704, train_accuracy: 68.75\n",
      "[23,    42] loss: 0.79687, train_accuracy: 72.46\n",
      "[23,    43] loss: 0.80387, train_accuracy: 69.92\n",
      "[23,    44] loss: 0.75435, train_accuracy: 74.22\n",
      "[23,    45] loss: 0.83748, train_accuracy: 72.66\n",
      "[23,    46] loss: 0.86544, train_accuracy: 69.73\n",
      "[23,    47] loss: 0.86255, train_accuracy: 69.73\n",
      "[23,    48] loss: 0.88264, train_accuracy: 69.53\n",
      "[23,    49] loss: 0.80292, train_accuracy: 71.48\n",
      "[23,    50] loss: 0.92860, train_accuracy: 66.80\n",
      "[23,    51] loss: 0.76280, train_accuracy: 73.24\n",
      "[23,    52] loss: 0.79065, train_accuracy: 70.31\n",
      "[23,    53] loss: 0.81344, train_accuracy: 71.09\n",
      "[23,    54] loss: 0.77047, train_accuracy: 72.27\n",
      "[23,    55] loss: 0.82880, train_accuracy: 70.31\n",
      "[23,    56] loss: 0.85459, train_accuracy: 69.34\n",
      "[23,    57] loss: 0.83523, train_accuracy: 70.12\n",
      "[23,    58] loss: 0.83105, train_accuracy: 70.90\n",
      "[23,    59] loss: 0.81766, train_accuracy: 69.73\n",
      "[23,    60] loss: 0.81616, train_accuracy: 70.70\n",
      "[23,    61] loss: 0.79294, train_accuracy: 72.46\n",
      "[23,    62] loss: 0.77786, train_accuracy: 70.12\n",
      "[23,    63] loss: 0.88043, train_accuracy: 67.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23,    64] loss: 0.76802, train_accuracy: 73.83\n",
      "[23,    65] loss: 0.87542, train_accuracy: 68.36\n",
      "[23,    66] loss: 0.77040, train_accuracy: 72.27\n",
      "[23,    67] loss: 0.90749, train_accuracy: 66.80\n",
      "[23,    68] loss: 0.84779, train_accuracy: 69.34\n",
      "[23,    69] loss: 0.84901, train_accuracy: 69.53\n",
      "[23,    70] loss: 0.86084, train_accuracy: 68.55\n",
      "[23,    71] loss: 0.94943, train_accuracy: 65.04\n",
      "[23,    72] loss: 0.82837, train_accuracy: 70.12\n",
      "[23,    73] loss: 0.90126, train_accuracy: 68.36\n",
      "[23,    74] loss: 0.83996, train_accuracy: 71.09\n",
      "[23,    75] loss: 0.86564, train_accuracy: 70.51\n",
      "[23,    76] loss: 0.88117, train_accuracy: 70.12\n",
      "[23,    77] loss: 0.87036, train_accuracy: 69.14\n",
      "[23,    78] loss: 0.82191, train_accuracy: 72.27\n",
      "[23,    79] loss: 0.82629, train_accuracy: 71.48\n",
      "[23,    80] loss: 0.81973, train_accuracy: 70.31\n",
      "[23,    81] loss: 0.86298, train_accuracy: 67.19\n",
      "[23,    82] loss: 0.88396, train_accuracy: 70.70\n",
      "[23,    83] loss: 0.87345, train_accuracy: 68.95\n",
      "[23,    84] loss: 0.91595, train_accuracy: 67.97\n",
      "[23,    85] loss: 0.72075, train_accuracy: 74.22\n",
      "[23,    86] loss: 0.80322, train_accuracy: 73.83\n",
      "[23,    87] loss: 0.87230, train_accuracy: 68.36\n",
      "[23,    88] loss: 0.78865, train_accuracy: 71.09\n",
      "[23,    89] loss: 0.88230, train_accuracy: 67.38\n",
      "[23,    90] loss: 0.86380, train_accuracy: 68.95\n",
      "[23,    91] loss: 0.88893, train_accuracy: 68.36\n",
      "[23,    92] loss: 0.82184, train_accuracy: 71.68\n",
      "[23,    93] loss: 0.82524, train_accuracy: 68.95\n",
      "[23,    94] loss: 0.79904, train_accuracy: 72.46\n",
      "[23,    95] loss: 0.91096, train_accuracy: 69.14\n",
      "[23,    96] loss: 0.82392, train_accuracy: 69.14\n",
      "[23,    97] loss: 0.85070, train_accuracy: 69.73\n",
      "[23,    98] loss: 0.79171, train_accuracy: 71.13\n",
      "duration: 24 s - train loss: 0.83701 - train accuracy: 70.30 - validation loss: 1.08 - validation accuracy: 62.44 \n",
      "stopped early after 5 epochs without decrease of validation loss\n",
      "Finished Training\n",
      "cw done\n",
      "pgd done\n"
     ]
    }
   ],
   "source": [
    "standard_stats = run('standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55078125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_stats['1']['l2_robustness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l2_robustness</th>\n",
       "      <th>linf_robustness</th>\n",
       "      <th>clean_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.109372</td>\n",
       "      <td>53.906250</td>\n",
       "      <td>62.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.570312</td>\n",
       "      <td>52.343747</td>\n",
       "      <td>62.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.890626</td>\n",
       "      <td>58.007813</td>\n",
       "      <td>62.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65.820310</td>\n",
       "      <td>58.789062</td>\n",
       "      <td>63.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64.843749</td>\n",
       "      <td>56.249998</td>\n",
       "      <td>62.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    l2_robustness  linf_robustness  clean_accuracy\n",
       "1       62.109372        53.906250           62.07\n",
       "2       59.570312        52.343747           62.11\n",
       "4       62.890626        58.007813           62.30\n",
       "8       65.820310        58.789062           63.78\n",
       "16      64.843749        56.249998           62.44"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=standard_stats).T\n",
    "df['l2_robustness'] = df['l2_robustness']*10000\n",
    "df['linf_robustness'] = df['linf_robustness']*10000\n",
    "df.to_pickle('./results/preliminary-standard-no-augmentation.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "[1,     1] loss: 2.95128, train_accuracy: 10.35\n",
      "[1,    11] loss: 2.32203, train_accuracy: 20.90\n",
      "[1,    21] loss: 2.07043, train_accuracy: 25.78\n",
      "[1,    31] loss: 2.01518, train_accuracy: 26.56\n",
      "[1,    41] loss: 2.03410, train_accuracy: 25.59\n",
      "[1,    51] loss: 1.96823, train_accuracy: 27.73\n",
      "[1,    61] loss: 2.02681, train_accuracy: 29.30\n",
      "[1,    71] loss: 1.99444, train_accuracy: 30.27\n",
      "[1,    81] loss: 1.97469, train_accuracy: 28.91\n",
      "[1,    91] loss: 1.94731, train_accuracy: 29.30\n",
      "duration: 60 s - train loss: 2.02881 - train accuracy: 27.44 - validation loss: 1.65035 - validation accuracy: 40.17 \n",
      "[2,     1] loss: 1.80543, train_accuracy: 33.79\n",
      "[2,    11] loss: 1.87866, train_accuracy: 33.98\n",
      "[2,    21] loss: 1.83539, train_accuracy: 33.59\n",
      "[2,    31] loss: 1.79033, train_accuracy: 33.59\n",
      "[2,    41] loss: 1.78200, train_accuracy: 35.35\n",
      "[2,    51] loss: 1.79811, train_accuracy: 32.62\n",
      "[2,    61] loss: 1.79824, train_accuracy: 35.55\n",
      "[2,    71] loss: 1.75369, train_accuracy: 37.11\n",
      "[2,    81] loss: 1.78967, train_accuracy: 36.72\n",
      "[2,    91] loss: 1.67541, train_accuracy: 39.65\n",
      "duration: 59 s - train loss: 1.81281 - train accuracy: 33.68 - validation loss: 1.53457 - validation accuracy: 44.19 \n",
      "[3,     1] loss: 1.82272, train_accuracy: 33.59\n",
      "[3,    11] loss: 1.75866, train_accuracy: 35.74\n",
      "[3,    21] loss: 1.81013, train_accuracy: 34.38\n",
      "[3,    31] loss: 1.72559, train_accuracy: 36.13\n",
      "[3,    41] loss: 1.73519, train_accuracy: 35.94\n",
      "[3,    51] loss: 1.83551, train_accuracy: 33.40\n",
      "[3,    61] loss: 1.78472, train_accuracy: 36.72\n",
      "[3,    71] loss: 1.77932, train_accuracy: 37.30\n",
      "[3,    81] loss: 1.71026, train_accuracy: 39.06\n",
      "[3,    91] loss: 1.79589, train_accuracy: 34.38\n",
      "duration: 59 s - train loss: 1.74531 - train accuracy: 36.43 - validation loss: 1.45571 - validation accuracy: 47.53 \n",
      "Finished Training\n",
      "cw done\n",
      "pgd done\n",
      "[1,     1] loss: 1.83651, train_accuracy: 36.72\n",
      "[1,    11] loss: 1.84260, train_accuracy: 32.62\n",
      "[1,    21] loss: 1.69228, train_accuracy: 38.09\n",
      "[1,    31] loss: 1.74114, train_accuracy: 36.52\n",
      "[1,    41] loss: 1.74328, train_accuracy: 40.43\n",
      "[1,    51] loss: 1.73512, train_accuracy: 34.18\n",
      "[1,    61] loss: 1.64837, train_accuracy: 43.95\n",
      "[1,    71] loss: 1.68989, train_accuracy: 39.45\n",
      "[1,    81] loss: 1.65230, train_accuracy: 39.45\n",
      "[1,    91] loss: 1.71870, train_accuracy: 39.06\n",
      "duration: 60 s - train loss: 1.69432 - train accuracy: 38.43 - validation loss: 1.41945 - validation accuracy: 49.78 \n",
      "[2,     1] loss: 1.63460, train_accuracy: 39.06\n",
      "[2,    11] loss: 1.71439, train_accuracy: 36.72\n",
      "[2,    21] loss: 1.60665, train_accuracy: 42.97\n",
      "[2,    31] loss: 1.55264, train_accuracy: 43.16\n",
      "[2,    41] loss: 1.64825, train_accuracy: 40.23\n",
      "[2,    51] loss: 1.75090, train_accuracy: 35.35\n",
      "[2,    61] loss: 1.66090, train_accuracy: 43.75\n",
      "[2,    71] loss: 1.61994, train_accuracy: 41.41\n",
      "[2,    81] loss: 1.63923, train_accuracy: 40.04\n",
      "[2,    91] loss: 1.62606, train_accuracy: 42.19\n",
      "duration: 59 s - train loss: 1.65682 - train accuracy: 40.25 - validation loss: 1.38509 - validation accuracy: 50.78 \n",
      "[3,     1] loss: 1.67358, train_accuracy: 38.09\n",
      "[3,    11] loss: 1.68951, train_accuracy: 39.06\n",
      "[3,    21] loss: 1.53507, train_accuracy: 47.27\n",
      "[3,    31] loss: 1.64640, train_accuracy: 41.21\n",
      "[3,    41] loss: 1.63054, train_accuracy: 39.45\n",
      "[3,    51] loss: 1.56767, train_accuracy: 43.16\n",
      "[3,    61] loss: 1.64944, train_accuracy: 40.82\n",
      "[3,    71] loss: 1.56264, train_accuracy: 43.16\n",
      "[3,    81] loss: 1.68582, train_accuracy: 40.04\n",
      "[3,    91] loss: 1.74373, train_accuracy: 36.91\n",
      "duration: 56 s - train loss: 1.64067 - train accuracy: 40.93 - validation loss: 1.34775 - validation accuracy: 52.41 \n",
      "Finished Training\n",
      "cw done\n",
      "pgd done\n",
      "[1,     1] loss: 1.84098, train_accuracy: 36.52\n",
      "[1,    11] loss: 1.72843, train_accuracy: 39.65\n",
      "[1,    21] loss: 1.60337, train_accuracy: 42.19\n",
      "[1,    31] loss: 1.61846, train_accuracy: 39.45\n",
      "[1,    41] loss: 1.57058, train_accuracy: 43.95\n",
      "[1,    51] loss: 1.54782, train_accuracy: 42.97\n",
      "[1,    61] loss: 1.64790, train_accuracy: 40.04\n",
      "[1,    71] loss: 1.60503, train_accuracy: 42.77\n",
      "[1,    81] loss: 1.56124, train_accuracy: 42.77\n",
      "[1,    91] loss: 1.53785, train_accuracy: 47.85\n",
      "duration: 55 s - train loss: 1.62835 - train accuracy: 41.31 - validation loss: 1.32873 - validation accuracy: 53.28 \n",
      "[2,     1] loss: 1.60106, train_accuracy: 43.55\n",
      "[2,    11] loss: 1.62249, train_accuracy: 43.16\n",
      "[2,    21] loss: 1.62289, train_accuracy: 43.16\n",
      "[2,    31] loss: 1.62514, train_accuracy: 40.62\n",
      "[2,    41] loss: 1.59298, train_accuracy: 45.51\n",
      "[2,    51] loss: 1.63635, train_accuracy: 40.43\n",
      "[2,    61] loss: 1.54910, train_accuracy: 43.75\n",
      "[2,    71] loss: 1.60386, train_accuracy: 40.82\n",
      "[2,    81] loss: 1.56039, train_accuracy: 44.73\n",
      "[2,    91] loss: 1.49191, train_accuracy: 44.14\n",
      "duration: 55 s - train loss: 1.58168 - train accuracy: 43.15 - validation loss: 1.29632 - validation accuracy: 54.31 \n",
      "[3,     1] loss: 1.48296, train_accuracy: 48.24\n",
      "[3,    11] loss: 1.56409, train_accuracy: 44.73\n",
      "[3,    21] loss: 1.55765, train_accuracy: 42.38\n",
      "[3,    31] loss: 1.56963, train_accuracy: 41.02\n",
      "[3,    41] loss: 1.57962, train_accuracy: 42.77\n",
      "[3,    51] loss: 1.55277, train_accuracy: 43.55\n",
      "[3,    61] loss: 1.60122, train_accuracy: 44.53\n",
      "[3,    71] loss: 1.53400, train_accuracy: 45.12\n",
      "[3,    81] loss: 1.59175, train_accuracy: 44.92\n",
      "[3,    91] loss: 1.55194, train_accuracy: 43.95\n",
      "duration: 55 s - train loss: 1.57029 - train accuracy: 43.61 - validation loss: 1.27683 - validation accuracy: 55.16 \n",
      "Finished Training\n",
      "cw done\n",
      "pgd done\n",
      "[1,     1] loss: 1.99632, train_accuracy: 24.22\n",
      "[1,    11] loss: 1.67571, train_accuracy: 35.35\n",
      "[1,    21] loss: 1.66215, train_accuracy: 39.84\n",
      "[1,    31] loss: 1.61821, train_accuracy: 42.58\n",
      "[1,    41] loss: 1.61517, train_accuracy: 42.58\n",
      "[1,    51] loss: 1.64700, train_accuracy: 40.62\n",
      "[1,    61] loss: 1.64805, train_accuracy: 40.82\n",
      "[1,    71] loss: 1.55603, train_accuracy: 43.55\n",
      "[1,    81] loss: 1.51311, train_accuracy: 43.95\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-34022e9da5db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfast_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fast'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-97a9decee754>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(training_method)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprune_magnitude_global_unstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#print(fit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-network-pruning/src/models.py\u001b[0m in \u001b[0;36mfit_fast\u001b[0;34m(self, train_loader, val_loader, epochs, device, eps, number_of_replays)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_replays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_fit_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_fast_with_double_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_replays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-network-pruning/src/training.py\u001b[0m in \u001b[0;36m_fit_fast\u001b[0;34m(model, train_loader, val_loader, epochs, device, eps)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0macc_epoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mavg_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_epoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-network-pruning/src/training.py\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(labels, outputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fast_stats = run('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "[1,     1] loss: 4.04980, train_accuracy: 4.44\n",
      "[1,     2] loss: 3.13854, train_accuracy: 5.86\n",
      "[1,     3] loss: 2.63508, train_accuracy: 10.21\n",
      "[1,     4] loss: 2.44655, train_accuracy: 15.32\n",
      "[1,     5] loss: 2.31197, train_accuracy: 18.89\n",
      "[1,     6] loss: 2.36261, train_accuracy: 16.88\n",
      "[1,     7] loss: 2.33470, train_accuracy: 19.06\n",
      "[1,     8] loss: 2.32105, train_accuracy: 18.72\n",
      "[1,     9] loss: 2.27571, train_accuracy: 18.08\n",
      "[1,    10] loss: 2.23458, train_accuracy: 20.93\n",
      "[1,    11] loss: 2.20737, train_accuracy: 20.59\n",
      "[1,    12] loss: 2.24530, train_accuracy: 20.59\n",
      "[1,    13] loss: 2.24561, train_accuracy: 17.91\n",
      "[1,    14] loss: 2.16499, train_accuracy: 22.10\n",
      "[1,    15] loss: 2.18761, train_accuracy: 21.57\n",
      "[1,    16] loss: 2.17943, train_accuracy: 19.81\n",
      "[1,    17] loss: 2.14748, train_accuracy: 21.29\n",
      "[1,    18] loss: 2.14471, train_accuracy: 21.15\n",
      "[1,    19] loss: 2.21635, train_accuracy: 20.65\n",
      "[1,    20] loss: 2.14575, train_accuracy: 20.34\n",
      "[1,    21] loss: 2.19734, train_accuracy: 19.28\n",
      "[1,    22] loss: 2.16090, train_accuracy: 21.62\n",
      "[1,    23] loss: 2.15158, train_accuracy: 20.03\n",
      "[1,    24] loss: 2.12945, train_accuracy: 22.85\n",
      "[1,    25] loss: 2.12371, train_accuracy: 21.85\n",
      "[1,    26] loss: 2.15004, train_accuracy: 20.79\n",
      "[1,    27] loss: 2.14213, train_accuracy: 22.07\n",
      "[1,    28] loss: 2.13870, train_accuracy: 23.41\n",
      "[1,    29] loss: 2.11488, train_accuracy: 23.86\n",
      "[1,    30] loss: 2.09465, train_accuracy: 25.98\n",
      "[1,    31] loss: 2.08048, train_accuracy: 26.00\n",
      "[1,    32] loss: 2.08122, train_accuracy: 24.25\n",
      "[1,    33] loss: 2.10216, train_accuracy: 23.07\n",
      "[1,    34] loss: 2.09687, train_accuracy: 23.21\n",
      "[1,    35] loss: 2.10180, train_accuracy: 21.09\n",
      "[1,    36] loss: 2.11782, train_accuracy: 22.77\n",
      "[1,    37] loss: 2.11187, train_accuracy: 24.97\n",
      "[1,    38] loss: 1.99908, train_accuracy: 25.11\n",
      "[1,    39] loss: 2.19096, train_accuracy: 21.09\n",
      "[1,    40] loss: 2.08323, train_accuracy: 22.38\n",
      "[1,    41] loss: 2.05315, train_accuracy: 25.61\n",
      "[1,    42] loss: 2.02884, train_accuracy: 23.41\n",
      "[1,    43] loss: 2.05355, train_accuracy: 23.91\n",
      "[1,    44] loss: 2.07716, train_accuracy: 24.00\n",
      "[1,    45] loss: 2.08261, train_accuracy: 21.32\n",
      "[1,    46] loss: 2.06677, train_accuracy: 24.50\n",
      "[1,    47] loss: 2.08327, train_accuracy: 24.58\n",
      "[1,    48] loss: 2.12773, train_accuracy: 21.76\n",
      "[1,    49] loss: 2.10016, train_accuracy: 21.82\n",
      "[1,    50] loss: 2.08355, train_accuracy: 22.88\n",
      "[1,    51] loss: 2.06790, train_accuracy: 25.47\n",
      "[1,    52] loss: 2.04641, train_accuracy: 26.62\n",
      "[1,    53] loss: 2.13854, train_accuracy: 21.68\n",
      "[1,    54] loss: 2.04303, train_accuracy: 26.28\n",
      "[1,    55] loss: 2.05451, train_accuracy: 25.64\n",
      "[1,    56] loss: 2.02892, train_accuracy: 23.49\n",
      "[1,    57] loss: 2.01958, train_accuracy: 25.36\n",
      "[1,    58] loss: 2.05937, train_accuracy: 23.44\n",
      "[1,    59] loss: 2.06612, train_accuracy: 25.70\n",
      "[1,    60] loss: 2.07573, train_accuracy: 24.11\n",
      "[1,    61] loss: 2.04114, train_accuracy: 24.89\n",
      "[1,    62] loss: 2.07344, train_accuracy: 24.47\n",
      "[1,    63] loss: 2.02471, train_accuracy: 26.23\n",
      "[1,    64] loss: 2.06699, train_accuracy: 21.37\n",
      "[1,    65] loss: 2.03674, train_accuracy: 27.20\n",
      "[1,    66] loss: 2.08183, train_accuracy: 23.55\n",
      "[1,    67] loss: 1.98741, train_accuracy: 27.37\n",
      "[1,    68] loss: 2.05325, train_accuracy: 24.78\n",
      "[1,    69] loss: 2.05717, train_accuracy: 24.44\n",
      "[1,    70] loss: 2.08150, train_accuracy: 22.96\n",
      "[1,    71] loss: 2.01770, train_accuracy: 26.31\n",
      "[1,    72] loss: 2.06743, train_accuracy: 21.68\n",
      "[1,    73] loss: 2.02195, train_accuracy: 24.44\n",
      "[1,    74] loss: 2.06858, train_accuracy: 23.72\n",
      "[1,    75] loss: 1.98233, train_accuracy: 23.35\n",
      "[1,    76] loss: 2.01700, train_accuracy: 25.64\n",
      "[1,    77] loss: 2.02703, train_accuracy: 26.84\n",
      "[1,    78] loss: 1.99732, train_accuracy: 26.51\n",
      "[1,    79] loss: 1.99230, train_accuracy: 26.12\n",
      "[1,    80] loss: 2.01913, train_accuracy: 24.19\n",
      "[1,    81] loss: 2.11134, train_accuracy: 22.49\n",
      "[1,    82] loss: 2.05457, train_accuracy: 22.68\n",
      "[1,    83] loss: 2.03224, train_accuracy: 25.73\n",
      "[1,    84] loss: 2.02496, train_accuracy: 22.68\n",
      "[1,    85] loss: 2.00904, train_accuracy: 26.79\n",
      "[1,    86] loss: 1.99838, train_accuracy: 24.33\n",
      "[1,    87] loss: 2.08586, train_accuracy: 22.07\n",
      "[1,    88] loss: 1.97846, train_accuracy: 26.70\n",
      "[1,    89] loss: 2.01392, train_accuracy: 24.72\n",
      "[1,    90] loss: 1.99052, train_accuracy: 26.81\n",
      "[1,    91] loss: 1.98854, train_accuracy: 28.24\n",
      "[1,    92] loss: 2.04246, train_accuracy: 23.69\n",
      "[1,    93] loss: 2.00620, train_accuracy: 25.08\n",
      "[1,    94] loss: 2.00862, train_accuracy: 25.84\n",
      "[1,    95] loss: 2.00938, train_accuracy: 27.06\n",
      "[1,    96] loss: 1.92585, train_accuracy: 29.32\n",
      "[1,    97] loss: 1.98658, train_accuracy: 27.26\n",
      "[1,    98] loss: 1.96286, train_accuracy: 25.09\n",
      "duration: 63 s - train loss: 104.33285 - train accuracy: 1122.15 - validation loss: 1.82 - validation accuracy: 34.49 \n",
      "[2,     1] loss: 1.99287, train_accuracy: 29.07\n",
      "[2,     2] loss: 1.98921, train_accuracy: 25.59\n",
      "[2,     3] loss: 1.97427, train_accuracy: 26.45\n",
      "[2,     4] loss: 1.96662, train_accuracy: 28.24\n",
      "[2,     5] loss: 1.97793, train_accuracy: 26.65\n",
      "[2,     6] loss: 2.01366, train_accuracy: 25.53\n",
      "[2,     7] loss: 1.97081, train_accuracy: 26.53\n",
      "[2,     8] loss: 1.98374, train_accuracy: 25.67\n",
      "[2,     9] loss: 1.95818, train_accuracy: 25.81\n",
      "[2,    10] loss: 1.98652, train_accuracy: 24.97\n",
      "[2,    11] loss: 1.94863, train_accuracy: 27.12\n",
      "[2,    12] loss: 1.94271, train_accuracy: 28.12\n",
      "[2,    13] loss: 1.95246, train_accuracy: 27.26\n",
      "[2,    14] loss: 2.08117, train_accuracy: 25.22\n",
      "[2,    15] loss: 2.02630, train_accuracy: 25.53\n",
      "[2,    16] loss: 2.04464, train_accuracy: 23.55\n",
      "[2,    17] loss: 1.99249, train_accuracy: 27.59\n",
      "[2,    18] loss: 1.98041, train_accuracy: 25.20\n",
      "[2,    19] loss: 1.98289, train_accuracy: 27.40\n",
      "[2,    20] loss: 1.98436, train_accuracy: 24.47\n",
      "[2,    21] loss: 2.03108, train_accuracy: 25.56\n",
      "[2,    22] loss: 1.99577, train_accuracy: 24.22\n",
      "[2,    23] loss: 1.91935, train_accuracy: 26.90\n",
      "[2,    24] loss: 1.96778, train_accuracy: 28.68\n",
      "[2,    25] loss: 1.97098, train_accuracy: 27.40\n",
      "[2,    26] loss: 2.01032, train_accuracy: 24.16\n",
      "[2,    27] loss: 1.99801, train_accuracy: 25.06\n",
      "[2,    28] loss: 1.91802, train_accuracy: 29.69\n",
      "[2,    29] loss: 1.96475, train_accuracy: 26.00\n",
      "[2,    30] loss: 2.02520, train_accuracy: 23.44\n",
      "[2,    31] loss: 1.99921, train_accuracy: 25.56\n",
      "[2,    32] loss: 1.94820, train_accuracy: 25.75\n",
      "[2,    33] loss: 1.97549, train_accuracy: 27.20\n",
      "[2,    34] loss: 1.97715, train_accuracy: 26.84\n",
      "[2,    35] loss: 2.03550, train_accuracy: 25.50\n",
      "[2,    36] loss: 1.99350, train_accuracy: 26.48\n",
      "[2,    37] loss: 1.93222, train_accuracy: 26.95\n",
      "[2,    38] loss: 2.00467, train_accuracy: 25.86\n",
      "[2,    39] loss: 1.97302, train_accuracy: 27.96\n",
      "[2,    40] loss: 1.99176, train_accuracy: 26.42\n",
      "[2,    41] loss: 1.91130, train_accuracy: 28.01\n",
      "[2,    42] loss: 2.00009, train_accuracy: 24.75\n",
      "[2,    43] loss: 1.95383, train_accuracy: 27.68\n",
      "[2,    44] loss: 1.95704, train_accuracy: 27.29\n",
      "[2,    45] loss: 1.91814, train_accuracy: 30.41\n",
      "[2,    46] loss: 1.98525, train_accuracy: 27.43\n",
      "[2,    47] loss: 2.01787, train_accuracy: 25.81\n",
      "[2,    48] loss: 1.97776, train_accuracy: 26.28\n",
      "[2,    49] loss: 1.91733, train_accuracy: 29.07\n",
      "[2,    50] loss: 2.04699, train_accuracy: 24.64\n",
      "[2,    51] loss: 1.90539, train_accuracy: 28.21\n",
      "[2,    52] loss: 1.88235, train_accuracy: 29.63\n",
      "[2,    53] loss: 1.95741, train_accuracy: 27.65\n",
      "[2,    54] loss: 1.92423, train_accuracy: 27.76\n",
      "[2,    55] loss: 1.99077, train_accuracy: 27.29\n",
      "[2,    56] loss: 1.95184, train_accuracy: 27.65\n",
      "[2,    57] loss: 1.94359, train_accuracy: 28.88\n",
      "[2,    58] loss: 1.93244, train_accuracy: 29.38\n",
      "[2,    59] loss: 1.92663, train_accuracy: 29.63\n",
      "[2,    60] loss: 1.95002, train_accuracy: 28.12\n",
      "[2,    61] loss: 1.87686, train_accuracy: 30.75\n",
      "[2,    62] loss: 1.96353, train_accuracy: 28.85\n",
      "[2,    63] loss: 1.96925, train_accuracy: 26.81\n",
      "[2,    64] loss: 1.90934, train_accuracy: 29.44\n",
      "[2,    65] loss: 1.91778, train_accuracy: 30.41\n",
      "[2,    66] loss: 1.93101, train_accuracy: 30.94\n",
      "[2,    67] loss: 1.94899, train_accuracy: 24.83\n",
      "[2,    68] loss: 1.92092, train_accuracy: 26.34\n",
      "[2,    69] loss: 1.91439, train_accuracy: 29.94\n",
      "[2,    70] loss: 1.90840, train_accuracy: 32.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    71] loss: 1.96260, train_accuracy: 29.72\n",
      "[2,    72] loss: 1.92929, train_accuracy: 29.77\n",
      "[2,    73] loss: 1.94031, train_accuracy: 28.85\n",
      "[2,    74] loss: 1.90231, train_accuracy: 28.66\n",
      "[2,    75] loss: 2.04087, train_accuracy: 23.94\n",
      "[2,    76] loss: 1.95751, train_accuracy: 28.21\n",
      "[2,    77] loss: 1.91723, train_accuracy: 27.40\n",
      "[2,    78] loss: 1.96543, train_accuracy: 28.93\n",
      "[2,    79] loss: 1.98063, train_accuracy: 24.89\n",
      "[2,    80] loss: 1.90134, train_accuracy: 28.12\n",
      "[2,    81] loss: 1.92274, train_accuracy: 28.99\n",
      "[2,    82] loss: 1.98986, train_accuracy: 27.26\n",
      "[2,    83] loss: 1.97384, train_accuracy: 26.56\n",
      "[2,    84] loss: 1.96078, train_accuracy: 27.96\n",
      "[2,    85] loss: 1.92282, train_accuracy: 28.40\n",
      "[2,    86] loss: 1.90109, train_accuracy: 28.52\n",
      "[2,    87] loss: 1.92160, train_accuracy: 30.44\n",
      "[2,    88] loss: 1.90432, train_accuracy: 31.19\n",
      "[2,    89] loss: 1.90042, train_accuracy: 29.83\n",
      "[2,    90] loss: 1.86666, train_accuracy: 32.48\n",
      "[2,    91] loss: 1.94562, train_accuracy: 27.37\n",
      "[2,    92] loss: 1.97157, train_accuracy: 27.06\n",
      "[2,    93] loss: 1.91374, train_accuracy: 27.23\n",
      "[2,    94] loss: 1.91388, train_accuracy: 28.82\n",
      "[2,    95] loss: 1.92798, train_accuracy: 26.98\n",
      "[2,    96] loss: 1.86545, train_accuracy: 27.01\n",
      "[2,    97] loss: 1.94576, train_accuracy: 29.85\n",
      "[2,    98] loss: 2.00089, train_accuracy: 26.15\n",
      "duration: 63 s - train loss: 95.96957 - train accuracy: 1344.28 - validation loss: 1.73 - validation accuracy: 38.24 \n",
      "[3,     1] loss: 1.93920, train_accuracy: 29.69\n"
     ]
    }
   ],
   "source": [
    "free_stats = run('free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "double_stats = run('fast_double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dfacbe3fe888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbb_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-7d2c3af936e4>\u001b[0m in \u001b[0;36mbb_attack\u001b[0;34m(model, images, labels, eps)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mattack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL0BrendelBethgeAttack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mraw_advs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipped_advs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/foolbox/attacks/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# run the actual attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mxpcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/foolbox/attacks/brendel_bethge.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;31m# TODO: use call and support all types of attacks (once early_stop is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# possible in __call__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mstarting_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_attack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mbest_advs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/foolbox/attacks/blended_noise.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.8/site-packages/eagerpy/tensor/base.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bb_attack(model, images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3359, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgd_attack(model, images, labels, eps=8/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2656, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw_attack(model, images, labels, eps=8/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'L0BrendelBethgeAttackfoolbox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dfacbe3fe888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbb_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-86be568580be>\u001b[0m in \u001b[0;36mbb_attack\u001b[0;34m(model, images, labels, eps)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyTorchModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mattack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL0BrendelBethgeAttackfoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL0BrendelBethgeAttack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0movershoot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_num_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_search_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mraw_advs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipped_advs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'L0BrendelBethgeAttackfoolbox' is not defined"
     ]
    }
   ],
   "source": [
    "bb_attack(model, images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 4.13015, train_accuracy: 4.17\n",
      "[1,     2] loss: 3.66484, train_accuracy: 4.88\n",
      "[1,     3] loss: 3.12940, train_accuracy: 6.97\n",
      "[1,     4] loss: 2.90560, train_accuracy: 8.98\n",
      "[1,     5] loss: 2.72787, train_accuracy: 9.70\n",
      "[1,     6] loss: 2.53809, train_accuracy: 10.22\n",
      "[1,     7] loss: 2.40960, train_accuracy: 15.62\n",
      "[1,     8] loss: 2.43231, train_accuracy: 14.13\n",
      "[1,     9] loss: 2.44054, train_accuracy: 14.78\n",
      "[1,    10] loss: 2.36526, train_accuracy: 17.90\n",
      "[1,    11] loss: 2.37196, train_accuracy: 19.01\n",
      "[1,    12] loss: 2.28873, train_accuracy: 18.49\n",
      "[1,    13] loss: 2.31310, train_accuracy: 14.58\n",
      "[1,    14] loss: 2.30206, train_accuracy: 18.55\n",
      "[1,    15] loss: 2.27567, train_accuracy: 15.89\n",
      "[1,    16] loss: 2.21592, train_accuracy: 18.03\n",
      "[1,    17] loss: 2.19046, train_accuracy: 20.05\n",
      "[1,    18] loss: 2.15967, train_accuracy: 23.11\n",
      "[1,    19] loss: 2.23406, train_accuracy: 18.68\n",
      "[1,    20] loss: 2.25862, train_accuracy: 17.45\n",
      "[1,    21] loss: 2.12274, train_accuracy: 23.24\n",
      "[1,    22] loss: 2.17765, train_accuracy: 20.05\n",
      "[1,    23] loss: 2.17858, train_accuracy: 23.18\n",
      "[1,    24] loss: 2.23169, train_accuracy: 17.32\n",
      "[1,    25] loss: 2.18564, train_accuracy: 17.97\n",
      "[1,    26] loss: 2.19388, train_accuracy: 19.53\n",
      "[1,    27] loss: 2.15015, train_accuracy: 19.08\n",
      "[1,    28] loss: 2.12199, train_accuracy: 21.61\n",
      "[1,    29] loss: 2.18580, train_accuracy: 18.62\n",
      "[1,    30] loss: 2.16209, train_accuracy: 21.81\n",
      "[1,    31] loss: 2.14573, train_accuracy: 22.85\n",
      "[1,    32] loss: 2.13041, train_accuracy: 24.48\n",
      "[1,    33] loss: 2.16252, train_accuracy: 20.05\n",
      "[1,    34] loss: 2.13558, train_accuracy: 23.44\n",
      "[1,    35] loss: 2.16724, train_accuracy: 19.86\n",
      "[1,    36] loss: 2.21078, train_accuracy: 17.84\n",
      "[1,    37] loss: 2.18081, train_accuracy: 18.82\n",
      "[1,    38] loss: 2.14555, train_accuracy: 20.05\n",
      "[1,    39] loss: 2.11903, train_accuracy: 21.22\n",
      "[1,    40] loss: 2.17089, train_accuracy: 20.64\n",
      "[1,    41] loss: 2.19014, train_accuracy: 18.23\n",
      "[1,    42] loss: 2.15069, train_accuracy: 25.00\n",
      "[1,    43] loss: 2.12383, train_accuracy: 24.93\n",
      "[1,    44] loss: 2.07686, train_accuracy: 24.87\n",
      "[1,    45] loss: 2.10713, train_accuracy: 22.14\n",
      "[1,    46] loss: 2.08371, train_accuracy: 24.80\n",
      "[1,    47] loss: 2.16578, train_accuracy: 20.83\n",
      "[1,    48] loss: 2.16394, train_accuracy: 22.40\n",
      "[1,    49] loss: 2.09479, train_accuracy: 23.57\n",
      "[1,    50] loss: 2.19689, train_accuracy: 17.90\n",
      "[1,    51] loss: 2.14077, train_accuracy: 22.85\n",
      "[1,    52] loss: 2.09430, train_accuracy: 22.85\n",
      "[1,    53] loss: 2.10679, train_accuracy: 22.01\n",
      "[1,    54] loss: 2.15999, train_accuracy: 20.70\n",
      "[1,    55] loss: 2.20202, train_accuracy: 18.82\n",
      "[1,    56] loss: 2.14481, train_accuracy: 20.70\n",
      "[1,    57] loss: 2.10255, train_accuracy: 22.33\n",
      "[1,    58] loss: 2.05739, train_accuracy: 23.89\n",
      "[1,    59] loss: 2.07499, train_accuracy: 23.63\n",
      "[1,    60] loss: 2.09256, train_accuracy: 22.01\n",
      "[1,    61] loss: 2.14301, train_accuracy: 22.14\n",
      "[1,    62] loss: 2.12803, train_accuracy: 22.79\n",
      "[1,    63] loss: 2.04009, train_accuracy: 25.46\n",
      "[1,    64] loss: 2.10628, train_accuracy: 21.88\n",
      "[1,    65] loss: 2.10198, train_accuracy: 20.90\n",
      "[1,    66] loss: 2.08540, train_accuracy: 24.15\n",
      "[1,    67] loss: 2.07839, train_accuracy: 22.98\n",
      "[1,    68] loss: 2.07711, train_accuracy: 22.98\n",
      "[1,    69] loss: 2.06060, train_accuracy: 20.31\n",
      "[1,    70] loss: 2.06125, train_accuracy: 25.65\n",
      "[1,    71] loss: 2.08271, train_accuracy: 26.24\n",
      "[1,    72] loss: 2.01735, train_accuracy: 26.43\n",
      "[1,    73] loss: 2.06047, train_accuracy: 23.83\n",
      "[1,    74] loss: 2.08206, train_accuracy: 22.01\n",
      "[1,    75] loss: 2.01236, train_accuracy: 25.72\n",
      "[1,    76] loss: 2.02874, train_accuracy: 28.06\n",
      "[1,    77] loss: 2.05377, train_accuracy: 25.78\n",
      "[1,    78] loss: 2.12314, train_accuracy: 23.24\n",
      "[1,    79] loss: 2.07924, train_accuracy: 24.48\n",
      "[1,    80] loss: 1.98147, train_accuracy: 29.10\n",
      "[1,    81] loss: 2.04405, train_accuracy: 24.28\n",
      "[1,    82] loss: 1.98542, train_accuracy: 27.41\n",
      "[1,    83] loss: 2.08550, train_accuracy: 23.63\n",
      "[1,    84] loss: 2.03384, train_accuracy: 21.81\n",
      "[1,    85] loss: 2.02156, train_accuracy: 24.93\n",
      "[1,    86] loss: 2.08230, train_accuracy: 23.50\n",
      "[1,    87] loss: 2.01108, train_accuracy: 26.56\n",
      "[1,    88] loss: 2.12468, train_accuracy: 21.48\n",
      "[1,    89] loss: 1.99321, train_accuracy: 26.76\n",
      "[1,    90] loss: 2.01881, train_accuracy: 25.00\n",
      "[1,    91] loss: 1.95153, train_accuracy: 27.54\n",
      "[1,    92] loss: 2.01250, train_accuracy: 26.30\n",
      "[1,    93] loss: 1.99616, train_accuracy: 23.83\n",
      "[1,    94] loss: 2.03431, train_accuracy: 24.54\n",
      "[1,    95] loss: 2.03092, train_accuracy: 23.70\n",
      "[1,    96] loss: 2.03473, train_accuracy: 24.74\n",
      "[1,    97] loss: 2.06312, train_accuracy: 23.76\n",
      "[1,    98] loss: 1.99822, train_accuracy: 27.68\n",
      "duration: 353.1993157863617 - train loss:  19.75298612215081  - train accuracy:  190.92081587099128  - validation accuracy:  34.82  - validation loss:  1.7801462471485139\n",
      "duration: 353 s - train loss: 19.75299 - train accuracy: 190.92 - validation loss: 1.78 - validation accuracy: 34.82 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'hist': 'Not implemented',\n",
       " 'val_accuracy': 34.82}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_free(train_loader, test_loader, 1, device, number_of_replays=3, eps = 8/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 1.96565, train_accuracy: 28.91\n",
      "[1,    11] loss: 1.97713, train_accuracy: 27.93\n",
      "[1,    21] loss: 1.93998, train_accuracy: 27.34\n",
      "[1,    31] loss: 1.85866, train_accuracy: 31.05\n",
      "[1,    41] loss: 1.93476, train_accuracy: 29.88\n",
      "[1,    51] loss: 1.81361, train_accuracy: 33.79\n",
      "[1,    61] loss: 1.79394, train_accuracy: 34.96\n",
      "[1,    71] loss: 1.87157, train_accuracy: 32.42\n",
      "[1,    81] loss: 1.81604, train_accuracy: 33.98\n",
      "[1,    91] loss: 1.78834, train_accuracy: 31.84\n",
      "duration: 255 s - train loss: 1.84690 - train accuracy: 32.50 - validation loss: 1.53757 - validation accuracy: 44.68 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'hist': 'Not implemented',\n",
       " 'val_accuracy': 44.68}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_fast(train_loader, test_loader, 1, device,eps = 8/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 1.70809, train_accuracy: 39.65\n",
      "[1,    11] loss: 1.82264, train_accuracy: 33.59\n",
      "[1,    21] loss: 1.73971, train_accuracy: 32.81\n",
      "[1,    31] loss: 1.81496, train_accuracy: 35.94\n",
      "[1,    41] loss: 1.78697, train_accuracy: 31.45\n",
      "[1,    51] loss: 1.78453, train_accuracy: 33.20\n",
      "[1,    61] loss: 1.72529, train_accuracy: 35.55\n",
      "[1,    71] loss: 1.67665, train_accuracy: 38.67\n",
      "[1,    81] loss: 1.74809, train_accuracy: 35.55\n",
      "[1,    91] loss: 1.71799, train_accuracy: 38.67\n",
      "duration: 320 s - train loss: 1.76333 - train accuracy: 35.67 - validation loss: 1.45301 - validation accuracy: 48.06 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'hist': 'Not implemented',\n",
       " 'val_accuracy': 48.06}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_fast_with_double_update(train_loader, test_loader, 1, device,eps = 8/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [10, 9, 8,7,6,5,4,3,2,2]\n",
    "patience = 3\n",
    "check_early_stopping(losses, patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 4\n",
    "b = [5,6,7]\n",
    "list(filter(lambda x: x<a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_early_stopping(val_loss_hist, patience):\n",
    "    filter(lambda x: val_loss_hist[-1:] > x, val_loss_hist[patience:])\n",
    "    return list(filter(lambda x: val_loss_hist[-1:][0] > x, val_loss_hist[patience:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
