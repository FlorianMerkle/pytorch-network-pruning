{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.models import CifarResNet, MNIST_CNN, CIFAR_CNN\n",
    "from src.helpers import evaluate_rob_accuracy, evaluate_clean_accuracy, load_model, safe_model,_evaluate_model\n",
    "from src.data_loader import load_torchvision_dataset, load_imagenette\n",
    "#from src.pruning import identify_layers, _evaluate_sparsity\n",
    "\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 26.58990, train_accuracy: 13.67\n",
      "[1,    11] loss: 4.96804, train_accuracy: 17.38\n",
      "[1,    21] loss: 3.20883, train_accuracy: 22.46\n",
      "[1,    31] loss: 2.34026, train_accuracy: 19.73\n",
      "[1,    41] loss: 2.71840, train_accuracy: 21.88\n",
      "[1,    51] loss: 2.25298, train_accuracy: 23.24\n",
      "[1,    61] loss: 2.22834, train_accuracy: 25.98\n",
      "[1,    71] loss: 2.10803, train_accuracy: 27.54\n",
      "[1,    81] loss: 2.07775, train_accuracy: 24.22\n",
      "[1,    91] loss: 2.21451, train_accuracy: 26.76\n",
      "duration: 244 s - train loss: 3.58441 - train accuracy: 22.38 - validation loss: 1.86155 - validation accuracy: 35.52 \n",
      "[2,     1] loss: 1.86118, train_accuracy: 34.96\n",
      "[2,    11] loss: 1.94095, train_accuracy: 30.86\n",
      "[2,    21] loss: 1.79391, train_accuracy: 33.79\n",
      "[2,    31] loss: 1.94331, train_accuracy: 30.47\n",
      "[2,    41] loss: 1.78052, train_accuracy: 33.01\n",
      "[2,    51] loss: 1.83248, train_accuracy: 31.05\n",
      "[2,    61] loss: 1.79862, train_accuracy: 35.55\n",
      "[2,    71] loss: 1.84687, train_accuracy: 35.16\n",
      "[2,    81] loss: 1.75436, train_accuracy: 35.16\n",
      "[2,    91] loss: 1.72169, train_accuracy: 36.13\n",
      "duration: 205 s - train loss: 1.83323 - train accuracy: 33.68 - validation loss: 1.56501 - validation accuracy: 44.89 \n",
      "[3,     1] loss: 1.68500, train_accuracy: 40.62\n",
      "[3,    11] loss: 1.73103, train_accuracy: 35.94\n",
      "[3,    21] loss: 1.67159, train_accuracy: 35.74\n",
      "[3,    31] loss: 1.71403, train_accuracy: 38.28\n",
      "[3,    41] loss: 1.72264, train_accuracy: 40.23\n",
      "[3,    51] loss: 1.67288, train_accuracy: 40.43\n",
      "[3,    61] loss: 1.71940, train_accuracy: 39.26\n",
      "[3,    71] loss: 1.57929, train_accuracy: 42.58\n",
      "[3,    81] loss: 1.64755, train_accuracy: 38.87\n",
      "[3,    91] loss: 1.77018, train_accuracy: 37.50\n",
      "duration: 203 s - train loss: 1.67909 - train accuracy: 39.18 - validation loss: 1.50396 - validation accuracy: 45.98 \n",
      "[4,     1] loss: 1.73087, train_accuracy: 37.70\n",
      "[4,    11] loss: 1.58359, train_accuracy: 40.82\n",
      "[4,    21] loss: 1.62257, train_accuracy: 38.67\n",
      "[4,    31] loss: 1.53704, train_accuracy: 45.31\n",
      "[4,    41] loss: 1.65986, train_accuracy: 40.43\n",
      "[4,    51] loss: 1.51246, train_accuracy: 47.27\n",
      "[4,    61] loss: 1.63768, train_accuracy: 40.82\n",
      "[4,    71] loss: 1.44064, train_accuracy: 47.27\n",
      "[4,    81] loss: 1.53933, train_accuracy: 40.43\n",
      "[4,    91] loss: 1.59812, train_accuracy: 42.38\n",
      "duration: 203 s - train loss: 1.57808 - train accuracy: 42.72 - validation loss: 1.33074 - validation accuracy: 53.26 \n",
      "[5,     1] loss: 1.50495, train_accuracy: 45.12\n",
      "[5,    11] loss: 1.50702, train_accuracy: 48.63\n",
      "[5,    21] loss: 1.51948, train_accuracy: 46.09\n",
      "[5,    31] loss: 1.46409, train_accuracy: 50.20\n",
      "[5,    41] loss: 1.45309, train_accuracy: 49.02\n",
      "[5,    51] loss: 1.35568, train_accuracy: 51.76\n",
      "[5,    61] loss: 1.45570, train_accuracy: 45.90\n",
      "[5,    71] loss: 1.43408, train_accuracy: 50.00\n",
      "[5,    81] loss: 1.46446, train_accuracy: 45.51\n",
      "[5,    91] loss: 1.48030, train_accuracy: 46.88\n",
      "duration: 209 s - train loss: 1.48143 - train accuracy: 46.83 - validation loss: 1.22786 - validation accuracy: 56.63 \n",
      "[6,     1] loss: 1.43900, train_accuracy: 47.85\n",
      "[6,    11] loss: 1.50406, train_accuracy: 45.70\n",
      "[6,    21] loss: 1.42105, train_accuracy: 50.00\n",
      "[6,    31] loss: 2.13242, train_accuracy: 24.41\n",
      "[6,    41] loss: 1.81368, train_accuracy: 35.16\n",
      "[6,    51] loss: 1.70897, train_accuracy: 38.09\n",
      "[6,    61] loss: 1.68142, train_accuracy: 42.38\n",
      "[6,    71] loss: 1.60997, train_accuracy: 40.04\n",
      "[6,    81] loss: 1.58269, train_accuracy: 42.77\n",
      "[6,    91] loss: 1.46269, train_accuracy: 49.61\n",
      "duration: 203 s - train loss: 1.60281 - train accuracy: 42.77 - validation loss: 1.29550 - validation accuracy: 53.72 \n",
      "[7,     1] loss: 1.49719, train_accuracy: 46.48\n",
      "[7,    11] loss: 1.43713, train_accuracy: 50.00\n",
      "[7,    21] loss: 1.47208, train_accuracy: 46.68\n",
      "[7,    31] loss: 1.42636, train_accuracy: 48.44\n",
      "[7,    41] loss: 1.39851, train_accuracy: 49.61\n",
      "[7,    51] loss: 1.43184, train_accuracy: 48.63\n",
      "[7,    61] loss: 1.50090, train_accuracy: 48.05\n",
      "[7,    71] loss: 1.36006, train_accuracy: 54.30\n",
      "[7,    81] loss: 1.36440, train_accuracy: 50.59\n",
      "[7,    91] loss: 1.41698, train_accuracy: 49.41\n",
      "duration: 202 s - train loss: 1.42041 - train accuracy: 49.21 - validation loss: 1.15800 - validation accuracy: 59.21 \n",
      "[8,     1] loss: 1.40259, train_accuracy: 53.32\n",
      "[8,    11] loss: 1.42584, train_accuracy: 50.00\n",
      "[8,    21] loss: 1.29978, train_accuracy: 52.73\n",
      "[8,    31] loss: 1.31552, train_accuracy: 52.73\n",
      "[8,    41] loss: 1.33873, train_accuracy: 51.95\n",
      "[8,    51] loss: 1.28775, train_accuracy: 53.32\n",
      "[8,    61] loss: 1.29518, train_accuracy: 56.25\n",
      "[8,    71] loss: 1.32549, train_accuracy: 51.37\n",
      "[8,    81] loss: 1.32891, train_accuracy: 54.69\n",
      "[8,    91] loss: 1.33604, train_accuracy: 52.93\n",
      "duration: 207 s - train loss: 1.34587 - train accuracy: 52.15 - validation loss: 1.07703 - validation accuracy: 63.31 \n",
      "[9,     1] loss: 1.29811, train_accuracy: 54.10\n",
      "[9,    11] loss: 1.32798, train_accuracy: 52.34\n",
      "[9,    21] loss: 1.33230, train_accuracy: 55.08\n",
      "[9,    31] loss: 1.29622, train_accuracy: 52.93\n",
      "[9,    41] loss: 1.33134, train_accuracy: 53.71\n",
      "[9,    51] loss: 1.26004, train_accuracy: 55.08\n",
      "[9,    61] loss: 1.29247, train_accuracy: 54.88\n",
      "[9,    71] loss: 1.27823, train_accuracy: 54.69\n",
      "[9,    81] loss: 1.25861, train_accuracy: 54.49\n",
      "[9,    91] loss: 1.39259, train_accuracy: 49.02\n",
      "duration: 206 s - train loss: 1.27957 - train accuracy: 54.69 - validation loss: 0.99685 - validation accuracy: 65.38 \n",
      "[10,     1] loss: 1.25586, train_accuracy: 56.05\n",
      "[10,    11] loss: 1.18362, train_accuracy: 57.81\n",
      "[10,    21] loss: 1.23405, train_accuracy: 59.38\n",
      "[10,    31] loss: 1.21214, train_accuracy: 57.23\n",
      "[10,    41] loss: 1.25443, train_accuracy: 54.10\n",
      "[10,    51] loss: 1.27732, train_accuracy: 54.49\n",
      "[10,    61] loss: 1.23720, train_accuracy: 58.98\n",
      "[10,    71] loss: 1.24694, train_accuracy: 55.47\n",
      "[10,    81] loss: 1.15966, train_accuracy: 55.47\n",
      "[10,    91] loss: 1.25076, train_accuracy: 59.38\n",
      "duration: 203 s - train loss: 1.22436 - train accuracy: 56.78 - validation loss: 0.99279 - validation accuracy: 65.30 \n",
      "[11,     1] loss: 1.14899, train_accuracy: 61.13\n",
      "[11,    11] loss: 1.26516, train_accuracy: 56.45\n",
      "[11,    21] loss: 1.12929, train_accuracy: 60.35\n",
      "[11,    31] loss: 1.10476, train_accuracy: 65.04\n",
      "[11,    41] loss: 1.14219, train_accuracy: 59.38\n",
      "[11,    51] loss: 1.18227, train_accuracy: 57.42\n",
      "[11,    61] loss: 1.16096, train_accuracy: 59.18\n",
      "[11,    71] loss: 1.18826, train_accuracy: 57.42\n",
      "[11,    81] loss: 1.09125, train_accuracy: 63.09\n",
      "[11,    91] loss: 1.29304, train_accuracy: 55.47\n",
      "duration: 203 s - train loss: 1.18426 - train accuracy: 58.37 - validation loss: 0.93087 - validation accuracy: 68.69 \n",
      "[12,     1] loss: 1.10745, train_accuracy: 59.77\n",
      "[12,    11] loss: 1.19568, train_accuracy: 56.05\n",
      "[12,    21] loss: 1.12391, train_accuracy: 60.94\n",
      "[12,    31] loss: 1.12389, train_accuracy: 61.91\n",
      "[12,    41] loss: 1.16882, train_accuracy: 58.98\n",
      "[12,    51] loss: 1.17827, train_accuracy: 56.45\n",
      "[12,    61] loss: 1.07668, train_accuracy: 63.28\n",
      "[12,    71] loss: 1.14320, train_accuracy: 59.18\n",
      "[12,    81] loss: 1.21961, train_accuracy: 54.88\n",
      "[12,    91] loss: 1.15146, train_accuracy: 59.96\n",
      "duration: 208 s - train loss: 1.14569 - train accuracy: 59.83 - validation loss: 0.88140 - validation accuracy: 69.30 \n",
      "[13,     1] loss: 1.15944, train_accuracy: 58.40\n",
      "[13,    11] loss: 1.10290, train_accuracy: 59.96\n",
      "[13,    21] loss: 1.03484, train_accuracy: 61.52\n",
      "[13,    31] loss: 1.12640, train_accuracy: 60.94\n",
      "[13,    41] loss: 1.01024, train_accuracy: 64.06\n",
      "[13,    51] loss: 1.00026, train_accuracy: 65.04\n",
      "[13,    61] loss: 1.16775, train_accuracy: 58.98\n",
      "[13,    71] loss: 1.14201, train_accuracy: 60.74\n",
      "[13,    81] loss: 1.05613, train_accuracy: 66.80\n",
      "[13,    91] loss: 1.10938, train_accuracy: 60.16\n",
      "duration: 202 s - train loss: 1.10870 - train accuracy: 61.15 - validation loss: 0.84797 - validation accuracy: 70.72 \n",
      "[14,     1] loss: 1.08416, train_accuracy: 60.35\n",
      "[14,    11] loss: 1.13022, train_accuracy: 58.98\n",
      "[14,    21] loss: 1.11628, train_accuracy: 60.35\n",
      "[14,    31] loss: 1.12256, train_accuracy: 60.35\n",
      "[14,    41] loss: 1.06764, train_accuracy: 61.52\n",
      "[14,    51] loss: 1.00627, train_accuracy: 62.11\n",
      "[14,    61] loss: 1.19873, train_accuracy: 57.62\n",
      "[14,    71] loss: 1.16110, train_accuracy: 60.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,    81] loss: 1.06592, train_accuracy: 62.11\n",
      "[14,    91] loss: 0.99708, train_accuracy: 64.06\n",
      "duration: 203 s - train loss: 1.07524 - train accuracy: 62.20 - validation loss: 0.82494 - validation accuracy: 72.85 \n",
      "[15,     1] loss: 0.97796, train_accuracy: 66.60\n",
      "[15,    11] loss: 1.04797, train_accuracy: 63.48\n",
      "[15,    21] loss: 1.06997, train_accuracy: 64.45\n",
      "[15,    31] loss: 1.06401, train_accuracy: 63.48\n",
      "[15,    41] loss: 1.02567, train_accuracy: 63.48\n",
      "[15,    51] loss: 1.07873, train_accuracy: 60.94\n",
      "[15,    61] loss: 1.02886, train_accuracy: 62.50\n",
      "[15,    71] loss: 1.01859, train_accuracy: 65.43\n",
      "[15,    81] loss: 0.92845, train_accuracy: 67.38\n",
      "[15,    91] loss: 0.93883, train_accuracy: 65.43\n",
      "duration: 204 s - train loss: 1.03899 - train accuracy: 63.48 - validation loss: 0.77475 - validation accuracy: 74.14 \n",
      "[16,     1] loss: 0.99977, train_accuracy: 63.87\n",
      "[16,    11] loss: 1.13768, train_accuracy: 59.57\n",
      "[16,    21] loss: 1.02379, train_accuracy: 63.87\n",
      "[16,    31] loss: 1.00238, train_accuracy: 65.62\n",
      "[16,    41] loss: 1.04111, train_accuracy: 63.48\n",
      "[16,    51] loss: 0.98004, train_accuracy: 66.80\n",
      "[16,    61] loss: 0.97539, train_accuracy: 66.21\n",
      "[16,    71] loss: 0.98873, train_accuracy: 66.41\n",
      "[16,    81] loss: 1.04824, train_accuracy: 63.28\n",
      "[16,    91] loss: 1.09241, train_accuracy: 60.35\n",
      "duration: 207 s - train loss: 1.01144 - train accuracy: 64.61 - validation loss: 0.76079 - validation accuracy: 73.88 \n",
      "[17,     1] loss: 1.02255, train_accuracy: 64.45\n",
      "[17,    11] loss: 1.03985, train_accuracy: 63.48\n",
      "[17,    21] loss: 0.94333, train_accuracy: 64.45\n",
      "[17,    31] loss: 0.93084, train_accuracy: 68.55\n",
      "[17,    41] loss: 0.96076, train_accuracy: 68.36\n",
      "[17,    51] loss: 0.93202, train_accuracy: 66.80\n",
      "[17,    61] loss: 1.05261, train_accuracy: 63.67\n",
      "[17,    71] loss: 0.95510, train_accuracy: 68.16\n",
      "[17,    81] loss: 0.98900, train_accuracy: 64.45\n",
      "[17,    91] loss: 0.93582, train_accuracy: 67.58\n",
      "duration: 204 s - train loss: 0.99922 - train accuracy: 65.18 - validation loss: 0.73368 - validation accuracy: 74.95 \n",
      "[18,     1] loss: 0.94910, train_accuracy: 66.60\n",
      "[18,    11] loss: 1.01985, train_accuracy: 66.02\n",
      "[18,    21] loss: 1.05153, train_accuracy: 63.67\n",
      "[18,    31] loss: 0.95676, train_accuracy: 65.04\n",
      "[18,    41] loss: 0.91843, train_accuracy: 69.53\n",
      "[18,    51] loss: 0.98492, train_accuracy: 64.84\n",
      "[18,    61] loss: 1.04154, train_accuracy: 61.52\n",
      "[18,    71] loss: 1.01747, train_accuracy: 66.21\n",
      "[18,    81] loss: 1.11513, train_accuracy: 60.94\n",
      "[18,    91] loss: 0.97544, train_accuracy: 65.62\n",
      "duration: 203 s - train loss: 0.96804 - train accuracy: 66.06 - validation loss: 0.72306 - validation accuracy: 75.21 \n",
      "[19,     1] loss: 0.89825, train_accuracy: 67.19\n",
      "[19,    11] loss: 0.95840, train_accuracy: 65.23\n",
      "[19,    21] loss: 0.87418, train_accuracy: 69.34\n",
      "[19,    31] loss: 0.90440, train_accuracy: 67.58\n",
      "[19,    41] loss: 1.01088, train_accuracy: 64.84\n",
      "[19,    51] loss: 0.94982, train_accuracy: 64.26\n",
      "[19,    61] loss: 0.94191, train_accuracy: 66.21\n",
      "[19,    71] loss: 0.93152, train_accuracy: 68.16\n",
      "[19,    81] loss: 1.02573, train_accuracy: 66.41\n",
      "[19,    91] loss: 0.91358, train_accuracy: 69.73\n",
      "duration: 208 s - train loss: 0.94640 - train accuracy: 66.78 - validation loss: 0.67298 - validation accuracy: 77.11 \n",
      "[20,     1] loss: 0.85986, train_accuracy: 68.55\n",
      "[20,    11] loss: 0.85976, train_accuracy: 68.95\n",
      "[20,    21] loss: 0.90547, train_accuracy: 69.14\n",
      "[20,    31] loss: 0.83144, train_accuracy: 72.46\n",
      "[20,    41] loss: 0.97720, train_accuracy: 68.36\n",
      "[20,    51] loss: 0.93396, train_accuracy: 67.38\n",
      "[20,    61] loss: 0.93896, train_accuracy: 66.21\n",
      "[20,    71] loss: 0.93336, train_accuracy: 68.16\n",
      "[20,    81] loss: 0.92293, train_accuracy: 68.55\n",
      "[20,    91] loss: 0.80044, train_accuracy: 73.24\n",
      "duration: 204 s - train loss: 0.91677 - train accuracy: 68.06 - validation loss: 0.67159 - validation accuracy: 77.03 \n",
      "[21,     1] loss: 0.88265, train_accuracy: 70.90\n",
      "[21,    11] loss: 0.95440, train_accuracy: 68.16\n",
      "[21,    21] loss: 0.97510, train_accuracy: 65.82\n",
      "[21,    31] loss: 0.84907, train_accuracy: 69.53\n",
      "[21,    41] loss: 0.84777, train_accuracy: 72.46\n",
      "[21,    51] loss: 0.93673, train_accuracy: 66.80\n",
      "[21,    61] loss: 0.90940, train_accuracy: 68.55\n",
      "[21,    71] loss: 0.89655, train_accuracy: 67.77\n",
      "[21,    81] loss: 0.87600, train_accuracy: 67.77\n",
      "[21,    91] loss: 0.95776, train_accuracy: 64.06\n",
      "duration: 202 s - train loss: 0.90803 - train accuracy: 68.10 - validation loss: 0.65885 - validation accuracy: 78.02 \n",
      "[22,     1] loss: 0.92584, train_accuracy: 68.16\n",
      "[22,    11] loss: 0.77991, train_accuracy: 73.44\n",
      "[22,    21] loss: 0.88711, train_accuracy: 70.12\n",
      "[22,    31] loss: 0.90654, train_accuracy: 66.99\n",
      "[22,    41] loss: 0.86408, train_accuracy: 69.34\n",
      "[22,    51] loss: 0.93406, train_accuracy: 68.16\n",
      "[22,    61] loss: 0.93983, train_accuracy: 65.43\n",
      "[22,    71] loss: 0.96770, train_accuracy: 64.84\n",
      "[22,    81] loss: 0.96203, train_accuracy: 66.02\n",
      "[22,    91] loss: 0.92534, train_accuracy: 65.82\n",
      "duration: 204 s - train loss: 0.87768 - train accuracy: 69.22 - validation loss: 0.65070 - validation accuracy: 77.69 \n",
      "[23,     1] loss: 0.91048, train_accuracy: 68.16\n",
      "[23,    11] loss: 0.89256, train_accuracy: 69.14\n",
      "[23,    21] loss: 0.87774, train_accuracy: 68.95\n",
      "[23,    31] loss: 0.90521, train_accuracy: 70.31\n",
      "[23,    41] loss: 0.88278, train_accuracy: 70.51\n",
      "[23,    51] loss: 0.93692, train_accuracy: 65.82\n",
      "[23,    61] loss: 0.76294, train_accuracy: 71.88\n",
      "[23,    71] loss: 0.80754, train_accuracy: 71.68\n",
      "[23,    81] loss: 0.86991, train_accuracy: 69.53\n",
      "[23,    91] loss: 0.78926, train_accuracy: 73.44\n",
      "duration: 207 s - train loss: 0.87303 - train accuracy: 69.60 - validation loss: 0.67046 - validation accuracy: 77.36 \n",
      "[24,     1] loss: 0.88887, train_accuracy: 69.73\n",
      "[24,    11] loss: 0.92443, train_accuracy: 66.99\n",
      "[24,    21] loss: 0.94012, train_accuracy: 68.95\n",
      "[24,    31] loss: 0.83363, train_accuracy: 69.53\n",
      "[24,    41] loss: 0.86932, train_accuracy: 70.51\n",
      "[24,    51] loss: 0.88962, train_accuracy: 69.53\n",
      "[24,    61] loss: 0.84963, train_accuracy: 69.92\n",
      "[24,    71] loss: 0.91237, train_accuracy: 69.34\n",
      "[24,    81] loss: 0.86606, train_accuracy: 70.12\n",
      "[24,    91] loss: 0.79500, train_accuracy: 70.90\n",
      "duration: 203 s - train loss: 0.85959 - train accuracy: 69.80 - validation loss: 0.65028 - validation accuracy: 77.70 \n",
      "[25,     1] loss: 0.80271, train_accuracy: 74.02\n",
      "[25,    11] loss: 0.81119, train_accuracy: 69.92\n",
      "[25,    21] loss: 0.83587, train_accuracy: 71.48\n",
      "[25,    31] loss: 0.80671, train_accuracy: 71.48\n",
      "[25,    41] loss: 0.93047, train_accuracy: 65.23\n",
      "[25,    51] loss: 0.88057, train_accuracy: 69.73\n",
      "[25,    61] loss: 0.87830, train_accuracy: 71.29\n",
      "[25,    71] loss: 0.96500, train_accuracy: 65.62\n",
      "[25,    81] loss: 0.78108, train_accuracy: 72.27\n",
      "[25,    91] loss: 0.84858, train_accuracy: 68.75\n",
      "duration: 202 s - train loss: 0.85385 - train accuracy: 70.16 - validation loss: 0.60910 - validation accuracy: 79.38 \n",
      "[26,     1] loss: 0.89552, train_accuracy: 69.53\n",
      "[26,    11] loss: 0.89691, train_accuracy: 70.12\n",
      "[26,    21] loss: 0.85175, train_accuracy: 69.14\n",
      "[26,    31] loss: 0.89565, train_accuracy: 68.36\n",
      "[26,    41] loss: 0.86146, train_accuracy: 70.12\n",
      "[26,    51] loss: 0.80275, train_accuracy: 70.31\n",
      "[26,    61] loss: 0.83428, train_accuracy: 71.29\n",
      "[26,    71] loss: 0.77884, train_accuracy: 72.66\n",
      "[26,    81] loss: 0.84044, train_accuracy: 69.53\n",
      "[26,    91] loss: 0.88180, train_accuracy: 69.92\n",
      "duration: 209 s - train loss: 0.83137 - train accuracy: 70.92 - validation loss: 0.61186 - validation accuracy: 79.03 \n",
      "[27,     1] loss: 0.83498, train_accuracy: 71.48\n",
      "[27,    11] loss: 0.90122, train_accuracy: 66.60\n",
      "[27,    21] loss: 0.71120, train_accuracy: 75.78\n",
      "[27,    31] loss: 0.81498, train_accuracy: 73.44\n",
      "[27,    41] loss: 0.77705, train_accuracy: 70.12\n",
      "[27,    51] loss: 0.87425, train_accuracy: 71.09\n",
      "[27,    61] loss: 0.79438, train_accuracy: 70.70\n",
      "[27,    71] loss: 0.81558, train_accuracy: 72.07\n",
      "[27,    81] loss: 0.76949, train_accuracy: 73.63\n",
      "[27,    91] loss: 0.82689, train_accuracy: 70.70\n",
      "duration: 203 s - train loss: 0.81521 - train accuracy: 71.56 - validation loss: 0.57165 - validation accuracy: 81.10 \n",
      "[28,     1] loss: 0.78221, train_accuracy: 72.07\n",
      "[28,    11] loss: 0.74250, train_accuracy: 74.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28,    21] loss: 0.87341, train_accuracy: 70.31\n",
      "[28,    31] loss: 0.76306, train_accuracy: 74.22\n",
      "[28,    41] loss: 0.77835, train_accuracy: 71.88\n",
      "[28,    51] loss: 0.85514, train_accuracy: 69.73\n",
      "[28,    61] loss: 0.84042, train_accuracy: 70.51\n",
      "[28,    71] loss: 0.80664, train_accuracy: 72.66\n",
      "[28,    81] loss: 0.87626, train_accuracy: 69.92\n",
      "[28,    91] loss: 0.81195, train_accuracy: 73.44\n",
      "duration: 202 s - train loss: 0.80389 - train accuracy: 71.97 - validation loss: 0.57537 - validation accuracy: 80.05 \n",
      "[29,     1] loss: 0.73117, train_accuracy: 74.41\n",
      "[29,    11] loss: 0.82258, train_accuracy: 71.29\n",
      "[29,    21] loss: 0.80601, train_accuracy: 71.29\n",
      "[29,    31] loss: 0.85544, train_accuracy: 70.70\n",
      "[29,    41] loss: 0.76079, train_accuracy: 71.29\n",
      "[29,    51] loss: 0.84357, train_accuracy: 71.48\n",
      "[29,    61] loss: 0.77290, train_accuracy: 72.27\n",
      "[29,    71] loss: 0.84685, train_accuracy: 71.29\n",
      "[29,    81] loss: 0.82359, train_accuracy: 70.12\n",
      "[29,    91] loss: 0.77081, train_accuracy: 73.83\n",
      "duration: 205 s - train loss: 0.79136 - train accuracy: 72.34 - validation loss: 0.57072 - validation accuracy: 80.55 \n",
      "[30,     1] loss: 0.76823, train_accuracy: 72.66\n",
      "[30,    11] loss: 0.74450, train_accuracy: 75.20\n",
      "[30,    21] loss: 0.81244, train_accuracy: 71.09\n",
      "[30,    31] loss: 0.81894, train_accuracy: 70.90\n",
      "[30,    41] loss: 0.78026, train_accuracy: 73.05\n",
      "[30,    51] loss: 0.87645, train_accuracy: 70.12\n",
      "[30,    61] loss: 0.82826, train_accuracy: 71.48\n",
      "[30,    71] loss: 0.79188, train_accuracy: 72.46\n",
      "[30,    81] loss: 0.82422, train_accuracy: 72.27\n",
      "[30,    91] loss: 0.78899, train_accuracy: 72.27\n",
      "duration: 207 s - train loss: 0.80911 - train accuracy: 71.46 - validation loss: 0.58140 - validation accuracy: 80.29 \n",
      "[31,     1] loss: 0.70517, train_accuracy: 75.20\n",
      "[31,    11] loss: 0.73931, train_accuracy: 74.22\n",
      "[31,    21] loss: 0.84596, train_accuracy: 69.14\n",
      "[31,    31] loss: 0.77901, train_accuracy: 75.78\n",
      "[31,    41] loss: 0.75552, train_accuracy: 73.44\n",
      "[31,    51] loss: 0.77140, train_accuracy: 72.07\n",
      "[31,    61] loss: 0.81019, train_accuracy: 71.29\n",
      "[31,    71] loss: 0.66690, train_accuracy: 74.80\n",
      "[31,    81] loss: 0.69552, train_accuracy: 76.37\n",
      "[31,    91] loss: 0.78289, train_accuracy: 70.51\n",
      "duration: 202 s - train loss: 0.78604 - train accuracy: 72.46 - validation loss: 0.58627 - validation accuracy: 79.98 \n",
      "[32,     1] loss: 0.73430, train_accuracy: 74.41\n",
      "[32,    11] loss: 0.81294, train_accuracy: 72.46\n",
      "[32,    21] loss: 0.81734, train_accuracy: 73.63\n",
      "[32,    31] loss: 0.75153, train_accuracy: 73.24\n",
      "[32,    41] loss: 0.75456, train_accuracy: 73.83\n",
      "[32,    51] loss: 0.80629, train_accuracy: 72.46\n",
      "[32,    61] loss: 0.85313, train_accuracy: 71.29\n",
      "[32,    71] loss: 0.69692, train_accuracy: 76.17\n",
      "[32,    81] loss: 0.73934, train_accuracy: 74.02\n",
      "[32,    91] loss: 0.73877, train_accuracy: 73.05\n",
      "duration: 204 s - train loss: 0.76127 - train accuracy: 73.56 - validation loss: 0.55759 - validation accuracy: 80.89 \n",
      "[33,     1] loss: 0.75659, train_accuracy: 73.05\n",
      "[33,    11] loss: 0.72440, train_accuracy: 74.41\n",
      "[33,    21] loss: 0.72724, train_accuracy: 75.20\n",
      "[33,    31] loss: 0.66415, train_accuracy: 76.56\n",
      "[33,    41] loss: 0.75960, train_accuracy: 74.22\n",
      "[33,    51] loss: 0.68794, train_accuracy: 75.78\n",
      "[33,    61] loss: 0.69964, train_accuracy: 73.63\n",
      "[33,    71] loss: 0.80428, train_accuracy: 72.66\n",
      "[33,    81] loss: 0.76970, train_accuracy: 72.27\n",
      "[33,    91] loss: 0.72558, train_accuracy: 75.98\n",
      "duration: 208 s - train loss: 0.75186 - train accuracy: 73.71 - validation loss: 0.51140 - validation accuracy: 81.97 \n",
      "[34,     1] loss: 0.70776, train_accuracy: 78.52\n",
      "[34,    11] loss: 0.79510, train_accuracy: 71.88\n",
      "[34,    21] loss: 0.66806, train_accuracy: 76.17\n",
      "[34,    31] loss: 0.71483, train_accuracy: 75.20\n",
      "[34,    41] loss: 0.78094, train_accuracy: 72.27\n",
      "[34,    51] loss: 0.68910, train_accuracy: 77.73\n",
      "[34,    61] loss: 0.79117, train_accuracy: 73.44\n",
      "[34,    71] loss: 0.71159, train_accuracy: 75.20\n",
      "[34,    81] loss: 0.70723, train_accuracy: 76.17\n",
      "[34,    91] loss: 0.70530, train_accuracy: 74.80\n",
      "duration: 202 s - train loss: 0.73410 - train accuracy: 74.32 - validation loss: 0.52293 - validation accuracy: 82.20 \n",
      "[35,     1] loss: 0.67433, train_accuracy: 75.39\n",
      "[35,    11] loss: 0.74955, train_accuracy: 71.88\n",
      "[35,    21] loss: 0.70207, train_accuracy: 76.95\n",
      "[35,    31] loss: 0.77641, train_accuracy: 72.46\n",
      "[35,    41] loss: 0.82013, train_accuracy: 71.88\n",
      "[35,    51] loss: 0.72977, train_accuracy: 74.61\n",
      "[35,    61] loss: 0.72925, train_accuracy: 74.22\n",
      "[35,    71] loss: 0.77347, train_accuracy: 72.66\n",
      "[35,    81] loss: 0.66545, train_accuracy: 76.17\n",
      "[35,    91] loss: 0.82513, train_accuracy: 72.07\n",
      "duration: 204 s - train loss: 0.73017 - train accuracy: 74.32 - validation loss: 0.50522 - validation accuracy: 82.76 \n",
      "[36,     1] loss: 0.68095, train_accuracy: 76.56\n",
      "[36,    11] loss: 0.68816, train_accuracy: 74.22\n",
      "[36,    21] loss: 0.77011, train_accuracy: 72.66\n",
      "[36,    31] loss: 0.66437, train_accuracy: 77.93\n",
      "[36,    41] loss: 0.69671, train_accuracy: 75.20\n",
      "[36,    51] loss: 0.65133, train_accuracy: 79.69\n",
      "[36,    61] loss: 0.70318, train_accuracy: 75.59\n",
      "[36,    71] loss: 0.69532, train_accuracy: 76.56\n",
      "[36,    81] loss: 0.66261, train_accuracy: 77.54\n",
      "[36,    91] loss: 0.71197, train_accuracy: 74.61\n",
      "duration: 203 s - train loss: 0.71499 - train accuracy: 75.05 - validation loss: 0.54622 - validation accuracy: 81.17 \n",
      "[37,     1] loss: 0.69189, train_accuracy: 75.39\n",
      "[37,    11] loss: 0.74185, train_accuracy: 75.39\n",
      "[37,    21] loss: 0.67628, train_accuracy: 77.15\n",
      "[37,    31] loss: 0.76303, train_accuracy: 74.02\n",
      "[37,    41] loss: 0.70188, train_accuracy: 75.20\n",
      "[37,    51] loss: 0.76413, train_accuracy: 74.41\n",
      "[37,    61] loss: 0.70096, train_accuracy: 77.34\n",
      "[37,    71] loss: 0.63806, train_accuracy: 78.12\n",
      "[37,    81] loss: 0.69326, train_accuracy: 73.83\n",
      "[37,    91] loss: 0.70875, train_accuracy: 75.78\n",
      "duration: 208 s - train loss: 0.71785 - train accuracy: 75.01 - validation loss: 0.49707 - validation accuracy: 82.88 \n",
      "[38,     1] loss: 0.67294, train_accuracy: 75.78\n",
      "[38,    11] loss: 0.76509, train_accuracy: 75.39\n",
      "[38,    21] loss: 0.69061, train_accuracy: 74.61\n",
      "[38,    31] loss: 0.58206, train_accuracy: 77.93\n",
      "[38,    41] loss: 0.75642, train_accuracy: 71.88\n",
      "[38,    51] loss: 0.67403, train_accuracy: 75.98\n",
      "[38,    61] loss: 0.72009, train_accuracy: 74.22\n",
      "[38,    71] loss: 0.63348, train_accuracy: 78.32\n",
      "[38,    81] loss: 0.76687, train_accuracy: 71.29\n",
      "[38,    91] loss: 0.71097, train_accuracy: 74.41\n",
      "duration: 204 s - train loss: 0.69543 - train accuracy: 75.63 - validation loss: 0.50214 - validation accuracy: 82.94 \n",
      "[39,     1] loss: 0.63833, train_accuracy: 78.52\n",
      "[39,    11] loss: 0.68238, train_accuracy: 77.54\n",
      "[39,    21] loss: 0.68963, train_accuracy: 76.76\n",
      "[39,    31] loss: 0.68763, train_accuracy: 75.98\n",
      "[39,    41] loss: 0.68131, train_accuracy: 75.00\n",
      "[39,    51] loss: 0.70603, train_accuracy: 74.61\n",
      "[39,    61] loss: 0.68273, train_accuracy: 77.54\n",
      "[39,    71] loss: 0.76396, train_accuracy: 71.48\n",
      "[39,    81] loss: 0.70427, train_accuracy: 76.37\n",
      "[39,    91] loss: 0.77411, train_accuracy: 74.02\n",
      "duration: 202 s - train loss: 0.69210 - train accuracy: 75.79 - validation loss: 0.47728 - validation accuracy: 83.61 \n",
      "[40,     1] loss: 0.63914, train_accuracy: 78.91\n",
      "[40,    11] loss: 0.79218, train_accuracy: 74.41\n",
      "[40,    21] loss: 0.61885, train_accuracy: 78.91\n",
      "[40,    31] loss: 0.70230, train_accuracy: 76.37\n",
      "[40,    41] loss: 0.76175, train_accuracy: 75.00\n",
      "[40,    51] loss: 0.75162, train_accuracy: 73.05\n",
      "[40,    61] loss: 0.65968, train_accuracy: 78.71\n",
      "[40,    71] loss: 0.65911, train_accuracy: 76.17\n",
      "[40,    81] loss: 0.74079, train_accuracy: 72.27\n",
      "[40,    91] loss: 0.72049, train_accuracy: 74.41\n",
      "duration: 208 s - train loss: 0.69323 - train accuracy: 75.87 - validation loss: 0.47906 - validation accuracy: 83.46 \n",
      "[41,     1] loss: 0.64639, train_accuracy: 77.73\n",
      "[41,    11] loss: 0.74361, train_accuracy: 73.63\n",
      "[41,    21] loss: 0.64953, train_accuracy: 77.93\n",
      "[41,    31] loss: 0.64335, train_accuracy: 75.39\n",
      "[41,    41] loss: 0.68303, train_accuracy: 75.59\n",
      "[41,    51] loss: 0.69754, train_accuracy: 75.39\n",
      "[41,    61] loss: 0.64339, train_accuracy: 77.73\n",
      "[41,    71] loss: 0.67202, train_accuracy: 76.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41,    81] loss: 0.64466, train_accuracy: 78.12\n",
      "[41,    91] loss: 0.66725, train_accuracy: 78.32\n",
      "duration: 204 s - train loss: 0.67312 - train accuracy: 76.42 - validation loss: 0.49874 - validation accuracy: 83.12 \n",
      "[42,     1] loss: 0.69073, train_accuracy: 75.78\n",
      "[42,    11] loss: 0.59851, train_accuracy: 78.71\n",
      "[42,    21] loss: 0.69269, train_accuracy: 74.80\n",
      "[42,    31] loss: 0.67937, train_accuracy: 76.37\n",
      "[42,    41] loss: 0.73605, train_accuracy: 74.02\n",
      "[42,    51] loss: 0.65319, train_accuracy: 78.12\n",
      "[42,    61] loss: 0.66393, train_accuracy: 76.76\n",
      "[42,    71] loss: 0.72300, train_accuracy: 73.63\n",
      "[42,    81] loss: 0.71289, train_accuracy: 75.59\n",
      "[42,    91] loss: 0.63579, train_accuracy: 79.88\n",
      "duration: 202 s - train loss: 0.66189 - train accuracy: 76.86 - validation loss: 0.47142 - validation accuracy: 83.77 \n",
      "[43,     1] loss: 0.63230, train_accuracy: 78.52\n",
      "[43,    11] loss: 0.64205, train_accuracy: 79.30\n",
      "[43,    21] loss: 0.71912, train_accuracy: 74.80\n",
      "[43,    31] loss: 0.62589, train_accuracy: 76.95\n",
      "[43,    41] loss: 0.57105, train_accuracy: 78.12\n",
      "[43,    51] loss: 0.54449, train_accuracy: 81.05\n",
      "[43,    61] loss: 0.65101, train_accuracy: 76.37\n",
      "[43,    71] loss: 0.67342, train_accuracy: 74.61\n",
      "[43,    81] loss: 0.66137, train_accuracy: 75.39\n",
      "[43,    91] loss: 0.66108, train_accuracy: 76.37\n",
      "duration: 203 s - train loss: 0.65401 - train accuracy: 77.23 - validation loss: 0.47818 - validation accuracy: 83.80 \n",
      "[44,     1] loss: 0.68177, train_accuracy: 76.37\n",
      "[44,    11] loss: 0.64580, train_accuracy: 78.12\n",
      "[44,    21] loss: 0.68575, train_accuracy: 75.59\n",
      "[44,    31] loss: 0.61386, train_accuracy: 79.49\n",
      "[44,    41] loss: 0.62638, train_accuracy: 78.52\n",
      "[44,    51] loss: 0.68835, train_accuracy: 77.34\n",
      "[44,    61] loss: 0.60534, train_accuracy: 78.32\n",
      "[44,    71] loss: 0.61221, train_accuracy: 76.37\n",
      "[44,    81] loss: 0.60359, train_accuracy: 77.54\n",
      "[44,    91] loss: 0.73817, train_accuracy: 72.46\n",
      "duration: 210 s - train loss: 0.64332 - train accuracy: 77.67 - validation loss: 0.48051 - validation accuracy: 83.48 \n",
      "[45,     1] loss: 0.66157, train_accuracy: 77.54\n",
      "[45,    11] loss: 0.62082, train_accuracy: 77.34\n",
      "[45,    21] loss: 0.65461, train_accuracy: 76.37\n",
      "[45,    31] loss: 0.63122, train_accuracy: 78.91\n",
      "[45,    41] loss: 0.53397, train_accuracy: 82.03\n",
      "[45,    51] loss: 0.63169, train_accuracy: 77.93\n",
      "[45,    61] loss: 0.65791, train_accuracy: 78.12\n",
      "[45,    71] loss: 0.66561, train_accuracy: 76.95\n",
      "[45,    81] loss: 0.60624, train_accuracy: 80.27\n",
      "[45,    91] loss: 0.72022, train_accuracy: 74.61\n",
      "duration: 202 s - train loss: 0.63828 - train accuracy: 77.59 - validation loss: 0.45162 - validation accuracy: 84.95 \n",
      "[46,     1] loss: 0.53640, train_accuracy: 80.86\n",
      "[46,    11] loss: 0.67490, train_accuracy: 75.59\n",
      "[46,    21] loss: 0.61722, train_accuracy: 79.30\n",
      "[46,    31] loss: 0.56717, train_accuracy: 78.12\n",
      "[46,    41] loss: 0.69631, train_accuracy: 77.54\n",
      "[46,    51] loss: 0.64081, train_accuracy: 77.54\n",
      "[46,    61] loss: 0.59738, train_accuracy: 78.91\n",
      "[46,    71] loss: 0.73025, train_accuracy: 74.41\n",
      "[46,    81] loss: 0.68847, train_accuracy: 77.54\n",
      "[46,    91] loss: 0.69238, train_accuracy: 77.93\n",
      "duration: 203 s - train loss: 0.63099 - train accuracy: 78.13 - validation loss: 0.50065 - validation accuracy: 83.49 \n",
      "[47,     1] loss: 0.62004, train_accuracy: 79.10\n",
      "[47,    11] loss: 0.65271, train_accuracy: 75.98\n",
      "[47,    21] loss: 0.70546, train_accuracy: 77.34\n",
      "[47,    31] loss: 0.70314, train_accuracy: 78.32\n",
      "[47,    41] loss: 0.65137, train_accuracy: 76.37\n",
      "[47,    51] loss: 0.63182, train_accuracy: 77.15\n",
      "[47,    61] loss: 0.57429, train_accuracy: 80.08\n",
      "[47,    71] loss: 0.63641, train_accuracy: 78.12\n",
      "[47,    81] loss: 0.58067, train_accuracy: 79.30\n",
      "[47,    91] loss: 0.66194, train_accuracy: 77.73\n",
      "duration: 209 s - train loss: 0.63202 - train accuracy: 78.02 - validation loss: 0.48000 - validation accuracy: 83.96 \n",
      "[48,     1] loss: 0.57615, train_accuracy: 80.27\n",
      "[48,    11] loss: 0.66825, train_accuracy: 77.54\n",
      "[48,    21] loss: 0.61203, train_accuracy: 77.34\n",
      "[48,    31] loss: 0.67514, train_accuracy: 77.15\n",
      "[48,    41] loss: 0.64502, train_accuracy: 76.95\n",
      "[48,    51] loss: 0.61477, train_accuracy: 78.52\n",
      "[48,    61] loss: 0.62165, train_accuracy: 80.86\n",
      "[48,    71] loss: 0.63293, train_accuracy: 79.69\n",
      "[48,    81] loss: 0.73749, train_accuracy: 75.00\n",
      "[48,    91] loss: 0.66497, train_accuracy: 77.34\n",
      "duration: 202 s - train loss: 0.62885 - train accuracy: 77.96 - validation loss: 0.46564 - validation accuracy: 84.26 \n",
      "[49,     1] loss: 0.61838, train_accuracy: 77.54\n",
      "[49,    11] loss: 0.60603, train_accuracy: 77.73\n",
      "[49,    21] loss: 0.53255, train_accuracy: 80.27\n",
      "[49,    31] loss: 0.60428, train_accuracy: 77.54\n",
      "[49,    41] loss: 0.57682, train_accuracy: 79.30\n",
      "[49,    51] loss: 0.59895, train_accuracy: 80.47\n",
      "[49,    61] loss: 0.56754, train_accuracy: 79.69\n",
      "[49,    71] loss: 0.66520, train_accuracy: 77.15\n",
      "[49,    81] loss: 0.61265, train_accuracy: 78.32\n",
      "[49,    91] loss: 0.57213, train_accuracy: 78.32\n",
      "duration: 204 s - train loss: 0.61945 - train accuracy: 78.27 - validation loss: 0.46220 - validation accuracy: 84.72 \n",
      "[50,     1] loss: 0.58398, train_accuracy: 77.93\n",
      "[50,    11] loss: 0.70622, train_accuracy: 75.59\n",
      "[50,    21] loss: 0.59090, train_accuracy: 79.49\n",
      "[50,    31] loss: 0.66115, train_accuracy: 76.56\n",
      "[50,    41] loss: 0.61424, train_accuracy: 77.93\n",
      "[50,    51] loss: 0.56497, train_accuracy: 80.27\n",
      "[50,    61] loss: 0.58935, train_accuracy: 82.03\n",
      "[50,    71] loss: 0.68352, train_accuracy: 77.15\n",
      "[50,    81] loss: 0.62908, train_accuracy: 77.34\n",
      "[50,    91] loss: 0.57860, train_accuracy: 79.88\n",
      "duration: 205 s - train loss: 0.60700 - train accuracy: 78.78 - validation loss: 0.43267 - validation accuracy: 85.45 \n",
      "[51,     1] loss: 0.55725, train_accuracy: 80.27\n",
      "[51,    11] loss: 0.64435, train_accuracy: 76.37\n",
      "[51,    21] loss: 0.59717, train_accuracy: 77.93\n",
      "[51,    31] loss: 0.60721, train_accuracy: 77.93\n",
      "[51,    41] loss: 0.55145, train_accuracy: 81.64\n",
      "[51,    51] loss: 0.57033, train_accuracy: 78.71\n",
      "[51,    61] loss: 0.58280, train_accuracy: 79.49\n",
      "[51,    71] loss: 0.55293, train_accuracy: 81.25\n",
      "[51,    81] loss: 0.53073, train_accuracy: 81.84\n",
      "[51,    91] loss: 0.55003, train_accuracy: 79.88\n",
      "duration: 209 s - train loss: 0.59728 - train accuracy: 79.03 - validation loss: 0.46991 - validation accuracy: 84.52 \n",
      "[52,     1] loss: 0.64425, train_accuracy: 76.37\n",
      "[52,    11] loss: 0.56637, train_accuracy: 80.08\n",
      "[52,    21] loss: 0.53769, train_accuracy: 81.64\n",
      "[52,    31] loss: 0.61958, train_accuracy: 78.52\n",
      "[52,    41] loss: 0.55886, train_accuracy: 80.66\n",
      "[52,    51] loss: 0.59209, train_accuracy: 78.71\n",
      "[52,    61] loss: 0.57571, train_accuracy: 79.49\n",
      "[52,    71] loss: 0.61429, train_accuracy: 78.12\n",
      "[52,    81] loss: 0.63774, train_accuracy: 78.71\n",
      "[52,    91] loss: 0.59128, train_accuracy: 80.86\n",
      "duration: 202 s - train loss: 0.59545 - train accuracy: 79.22 - validation loss: 0.45999 - validation accuracy: 84.83 \n",
      "[53,     1] loss: 0.61697, train_accuracy: 78.32\n",
      "[53,    11] loss: 0.60941, train_accuracy: 79.30\n",
      "[53,    21] loss: 0.58619, train_accuracy: 78.52\n",
      "[53,    31] loss: 0.61662, train_accuracy: 79.49\n",
      "[53,    41] loss: 0.64277, train_accuracy: 77.54\n",
      "[53,    51] loss: 0.56635, train_accuracy: 80.08\n",
      "[53,    61] loss: 0.58467, train_accuracy: 79.88\n",
      "[53,    71] loss: 0.58805, train_accuracy: 78.32\n",
      "[53,    81] loss: 0.60428, train_accuracy: 78.32\n",
      "[53,    91] loss: 0.57946, train_accuracy: 78.52\n",
      "duration: 204 s - train loss: 0.59546 - train accuracy: 79.06 - validation loss: 0.43451 - validation accuracy: 85.39 \n",
      "[54,     1] loss: 0.57539, train_accuracy: 80.86\n",
      "[54,    11] loss: 0.62655, train_accuracy: 76.76\n",
      "[54,    21] loss: 0.55547, train_accuracy: 79.88\n",
      "[54,    31] loss: 0.59161, train_accuracy: 78.91\n",
      "[54,    41] loss: 0.57400, train_accuracy: 80.86\n",
      "[54,    51] loss: 0.64308, train_accuracy: 77.54\n",
      "[54,    61] loss: 0.65038, train_accuracy: 78.32\n",
      "[54,    71] loss: 0.56277, train_accuracy: 80.47\n",
      "[54,    81] loss: 0.53260, train_accuracy: 80.08\n",
      "[54,    91] loss: 0.55504, train_accuracy: 80.86\n",
      "duration: 207 s - train loss: 0.58631 - train accuracy: 79.49 - validation loss: 0.44480 - validation accuracy: 85.38 \n",
      "[55,     1] loss: 0.59977, train_accuracy: 79.10\n",
      "[55,    11] loss: 0.62391, train_accuracy: 78.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55,    21] loss: 0.65320, train_accuracy: 75.00\n",
      "[55,    31] loss: 0.61905, train_accuracy: 77.93\n",
      "[55,    41] loss: 0.54374, train_accuracy: 80.27\n",
      "[55,    51] loss: 0.61409, train_accuracy: 77.34\n",
      "[55,    61] loss: 0.55581, train_accuracy: 81.05\n",
      "[55,    71] loss: 0.60177, train_accuracy: 78.12\n",
      "[55,    81] loss: 0.54138, train_accuracy: 80.08\n",
      "[55,    91] loss: 0.54845, train_accuracy: 80.66\n",
      "duration: 202 s - train loss: 0.57976 - train accuracy: 79.79 - validation loss: 0.43790 - validation accuracy: 85.88 \n",
      "[56,     1] loss: 0.54258, train_accuracy: 82.03\n",
      "[56,    11] loss: 0.59774, train_accuracy: 79.49\n",
      "[56,    21] loss: 0.54041, train_accuracy: 79.30\n",
      "[56,    31] loss: 0.59775, train_accuracy: 80.86\n",
      "[56,    41] loss: 0.61545, train_accuracy: 78.12\n",
      "[56,    51] loss: 0.58405, train_accuracy: 79.49\n",
      "[56,    61] loss: 0.55920, train_accuracy: 80.86\n",
      "[56,    71] loss: 0.58136, train_accuracy: 79.69\n",
      "[56,    81] loss: 0.55103, train_accuracy: 80.27\n",
      "[56,    91] loss: 0.63530, train_accuracy: 76.17\n",
      "duration: 203 s - train loss: 0.57042 - train accuracy: 80.23 - validation loss: 0.44490 - validation accuracy: 85.04 \n",
      "[57,     1] loss: 0.55796, train_accuracy: 78.91\n",
      "[57,    11] loss: 0.66012, train_accuracy: 76.37\n",
      "[57,    21] loss: 0.53105, train_accuracy: 80.66\n",
      "[57,    31] loss: 0.62712, train_accuracy: 79.10\n",
      "[57,    41] loss: 0.55998, train_accuracy: 80.66\n",
      "[57,    51] loss: 0.59293, train_accuracy: 79.10\n",
      "[57,    61] loss: 0.65397, train_accuracy: 76.37\n",
      "[57,    71] loss: 0.55534, train_accuracy: 81.25\n",
      "[57,    81] loss: 0.60715, train_accuracy: 78.12\n",
      "[57,    91] loss: 0.58979, train_accuracy: 81.05\n",
      "duration: 203 s - train loss: 0.57017 - train accuracy: 79.98 - validation loss: 0.46257 - validation accuracy: 85.38 \n",
      "[58,     1] loss: 0.52127, train_accuracy: 82.81\n",
      "[58,    11] loss: 0.61125, train_accuracy: 78.12\n",
      "[58,    21] loss: 0.56096, train_accuracy: 78.52\n",
      "[58,    31] loss: 0.56243, train_accuracy: 79.88\n",
      "[58,    41] loss: 0.60205, train_accuracy: 80.27\n",
      "[58,    51] loss: 0.59411, train_accuracy: 79.30\n",
      "[58,    61] loss: 0.46652, train_accuracy: 83.98\n",
      "[58,    71] loss: 0.63103, train_accuracy: 77.93\n",
      "[58,    81] loss: 0.57354, train_accuracy: 77.15\n",
      "[58,    91] loss: 0.56814, train_accuracy: 78.12\n",
      "duration: 207 s - train loss: 0.56394 - train accuracy: 80.16 - validation loss: 0.43387 - validation accuracy: 85.72 \n",
      "[59,     1] loss: 0.57418, train_accuracy: 79.49\n",
      "[59,    11] loss: 0.61259, train_accuracy: 77.34\n",
      "[59,    21] loss: 0.55685, train_accuracy: 81.64\n",
      "[59,    31] loss: 0.54551, train_accuracy: 79.88\n",
      "[59,    41] loss: 0.62735, train_accuracy: 77.34\n",
      "[59,    51] loss: 0.55133, train_accuracy: 80.08\n",
      "[59,    61] loss: 0.57657, train_accuracy: 80.27\n",
      "[59,    71] loss: 0.49574, train_accuracy: 83.98\n",
      "[59,    81] loss: 0.66405, train_accuracy: 76.95\n",
      "[59,    91] loss: 0.54904, train_accuracy: 81.45\n",
      "duration: 204 s - train loss: 0.56256 - train accuracy: 80.42 - validation loss: 0.40956 - validation accuracy: 86.07 \n",
      "[60,     1] loss: 0.50713, train_accuracy: 82.42\n",
      "[60,    11] loss: 0.59881, train_accuracy: 78.91\n",
      "[60,    21] loss: 0.57561, train_accuracy: 80.08\n",
      "[60,    31] loss: 0.51523, train_accuracy: 83.01\n",
      "[60,    41] loss: 0.54728, train_accuracy: 82.23\n",
      "[60,    51] loss: 0.52561, train_accuracy: 80.47\n",
      "[60,    61] loss: 0.51415, train_accuracy: 80.86\n",
      "[60,    71] loss: 0.54699, train_accuracy: 81.05\n",
      "[60,    81] loss: 0.63533, train_accuracy: 78.91\n",
      "[60,    91] loss: 0.54884, train_accuracy: 83.20\n",
      "duration: 202 s - train loss: 0.55731 - train accuracy: 80.45 - validation loss: 0.42497 - validation accuracy: 86.28 \n",
      "[61,     1] loss: 0.59227, train_accuracy: 79.30\n",
      "[61,    11] loss: 0.54328, train_accuracy: 81.84\n",
      "[61,    21] loss: 0.47520, train_accuracy: 84.38\n",
      "[61,    31] loss: 0.55854, train_accuracy: 80.66\n",
      "[61,    41] loss: 0.62950, train_accuracy: 77.34\n",
      "[61,    51] loss: 0.52174, train_accuracy: 81.84\n",
      "[61,    61] loss: 0.56003, train_accuracy: 81.05\n",
      "[61,    71] loss: 0.50615, train_accuracy: 82.81\n",
      "[61,    81] loss: 0.54831, train_accuracy: 80.47\n",
      "[61,    91] loss: 0.52458, train_accuracy: 80.86\n",
      "duration: 207 s - train loss: 0.54713 - train accuracy: 80.87 - validation loss: 0.42235 - validation accuracy: 85.93 \n",
      "[62,     1] loss: 0.55791, train_accuracy: 80.27\n",
      "[62,    11] loss: 0.57664, train_accuracy: 81.25\n",
      "[62,    21] loss: 0.65923, train_accuracy: 78.52\n",
      "[62,    31] loss: 0.54853, train_accuracy: 80.47\n",
      "[62,    41] loss: 0.51294, train_accuracy: 83.01\n",
      "[62,    51] loss: 0.55903, train_accuracy: 80.66\n",
      "[62,    61] loss: 0.54974, train_accuracy: 80.86\n",
      "[62,    71] loss: 0.48080, train_accuracy: 84.38\n",
      "[62,    81] loss: 0.56114, train_accuracy: 81.05\n",
      "[62,    91] loss: 0.55138, train_accuracy: 80.66\n",
      "duration: 204 s - train loss: 0.54442 - train accuracy: 80.95 - validation loss: 0.41733 - validation accuracy: 86.29 \n",
      "[63,     1] loss: 0.58045, train_accuracy: 79.69\n",
      "[63,    11] loss: 0.50965, train_accuracy: 85.35\n",
      "[63,    21] loss: 0.44915, train_accuracy: 83.20\n",
      "[63,    31] loss: 0.51481, train_accuracy: 82.03\n",
      "[63,    41] loss: 0.55684, train_accuracy: 80.08\n",
      "[63,    51] loss: 0.57925, train_accuracy: 80.86\n",
      "[63,    61] loss: 0.55182, train_accuracy: 81.45\n",
      "[63,    71] loss: 0.47932, train_accuracy: 83.40\n",
      "[63,    81] loss: 0.51287, train_accuracy: 81.84\n",
      "[63,    91] loss: 0.58386, train_accuracy: 79.49\n",
      "duration: 203 s - train loss: 0.53692 - train accuracy: 81.32 - validation loss: 0.43164 - validation accuracy: 86.22 \n",
      "[64,     1] loss: 0.55253, train_accuracy: 81.45\n",
      "[64,    11] loss: 0.53155, train_accuracy: 83.20\n",
      "[64,    21] loss: 0.59223, train_accuracy: 76.37\n",
      "[64,    31] loss: 0.51652, train_accuracy: 81.64\n",
      "[64,    41] loss: 0.55233, train_accuracy: 82.62\n",
      "[64,    51] loss: 0.48685, train_accuracy: 82.03\n",
      "[64,    61] loss: 0.52462, train_accuracy: 83.20\n",
      "[64,    71] loss: 0.49548, train_accuracy: 83.01\n",
      "[64,    81] loss: 0.49593, train_accuracy: 83.79\n",
      "[64,    91] loss: 0.61204, train_accuracy: 79.30\n",
      "duration: 203 s - train loss: 0.53599 - train accuracy: 81.47 - validation loss: 0.43825 - validation accuracy: 86.58 \n",
      "[65,     1] loss: 0.53635, train_accuracy: 80.86\n",
      "[65,    11] loss: 0.60014, train_accuracy: 80.27\n",
      "[65,    21] loss: 0.47798, train_accuracy: 83.59\n",
      "[65,    31] loss: 0.55585, train_accuracy: 80.66\n",
      "[65,    41] loss: 0.52443, train_accuracy: 81.64\n",
      "[65,    51] loss: 0.46987, train_accuracy: 82.03\n",
      "[65,    61] loss: 0.50751, train_accuracy: 83.01\n",
      "[65,    71] loss: 0.52193, train_accuracy: 81.64\n",
      "[65,    81] loss: 0.53139, train_accuracy: 81.64\n",
      "[65,    91] loss: 0.52932, train_accuracy: 81.05\n",
      "duration: 209 s - train loss: 0.52813 - train accuracy: 81.62 - validation loss: 0.40519 - validation accuracy: 86.77 \n",
      "[66,     1] loss: 0.54960, train_accuracy: 82.62\n",
      "[66,    11] loss: 0.58750, train_accuracy: 80.08\n",
      "[66,    21] loss: 0.52175, train_accuracy: 82.42\n",
      "[66,    31] loss: 0.50465, train_accuracy: 83.40\n",
      "[66,    41] loss: 0.51778, train_accuracy: 83.01\n",
      "[66,    51] loss: 0.51720, train_accuracy: 79.10\n",
      "[66,    61] loss: 0.51629, train_accuracy: 81.05\n",
      "[66,    71] loss: 0.53839, train_accuracy: 83.98\n",
      "[66,    81] loss: 0.52571, train_accuracy: 80.86\n",
      "[66,    91] loss: 0.47608, train_accuracy: 83.40\n",
      "duration: 202 s - train loss: 0.52384 - train accuracy: 81.66 - validation loss: 0.39651 - validation accuracy: 86.81 \n",
      "[67,     1] loss: 0.54627, train_accuracy: 81.25\n",
      "[67,    11] loss: 0.44833, train_accuracy: 85.16\n",
      "[67,    21] loss: 0.54407, train_accuracy: 80.08\n",
      "[67,    31] loss: 0.49977, train_accuracy: 82.42\n",
      "[67,    41] loss: 0.49952, train_accuracy: 82.03\n",
      "[67,    51] loss: 0.50573, train_accuracy: 81.25\n",
      "[67,    61] loss: 0.52143, train_accuracy: 81.84\n",
      "[67,    71] loss: 0.48540, train_accuracy: 83.20\n",
      "[67,    81] loss: 0.45697, train_accuracy: 84.57\n",
      "[67,    91] loss: 0.58443, train_accuracy: 78.32\n",
      "duration: 202 s - train loss: 0.51673 - train accuracy: 82.09 - validation loss: 0.40499 - validation accuracy: 86.80 \n",
      "[68,     1] loss: 0.59298, train_accuracy: 80.66\n",
      "[68,    11] loss: 0.50944, train_accuracy: 81.84\n",
      "[68,    21] loss: 0.57766, train_accuracy: 80.27\n",
      "[68,    31] loss: 0.57593, train_accuracy: 78.91\n",
      "[68,    41] loss: 0.55079, train_accuracy: 80.47\n",
      "[68,    51] loss: 0.46524, train_accuracy: 85.74\n",
      "[68,    61] loss: 0.54386, train_accuracy: 80.27\n",
      "[68,    71] loss: 0.45745, train_accuracy: 83.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68,    81] loss: 0.46528, train_accuracy: 84.77\n",
      "[68,    91] loss: 0.61152, train_accuracy: 79.88\n",
      "duration: 208 s - train loss: 0.51968 - train accuracy: 81.92 - validation loss: 0.41543 - validation accuracy: 86.69 \n",
      "[69,     1] loss: 0.56332, train_accuracy: 80.66\n",
      "[69,    11] loss: 0.52380, train_accuracy: 79.49\n",
      "[69,    21] loss: 0.48846, train_accuracy: 82.81\n",
      "[69,    31] loss: 0.48064, train_accuracy: 83.79\n",
      "[69,    41] loss: 0.47840, train_accuracy: 83.20\n",
      "[69,    51] loss: 0.53844, train_accuracy: 82.42\n",
      "[69,    61] loss: 0.42816, train_accuracy: 85.55\n",
      "[69,    71] loss: 0.50031, train_accuracy: 83.98\n",
      "[69,    81] loss: 0.48203, train_accuracy: 82.81\n",
      "[69,    91] loss: 0.42038, train_accuracy: 85.55\n",
      "duration: 202 s - train loss: 0.50964 - train accuracy: 82.10 - validation loss: 0.40720 - validation accuracy: 86.87 \n",
      "[70,     1] loss: 0.45840, train_accuracy: 84.77\n",
      "[70,    11] loss: 0.55968, train_accuracy: 81.25\n",
      "[70,    21] loss: 0.47621, train_accuracy: 82.42\n",
      "[70,    31] loss: 0.50272, train_accuracy: 83.79\n",
      "[70,    41] loss: 0.52576, train_accuracy: 83.01\n",
      "[70,    51] loss: 0.48712, train_accuracy: 82.23\n",
      "[70,    61] loss: 0.53122, train_accuracy: 80.66\n",
      "[70,    71] loss: 0.53987, train_accuracy: 80.86\n",
      "[70,    81] loss: 0.48980, train_accuracy: 83.20\n",
      "[70,    91] loss: 0.50015, train_accuracy: 82.03\n",
      "duration: 203 s - train loss: 0.50317 - train accuracy: 82.37 - validation loss: 0.41865 - validation accuracy: 86.66 \n",
      "[71,     1] loss: 0.49523, train_accuracy: 80.66\n",
      "[71,    11] loss: 0.54844, train_accuracy: 80.08\n",
      "[71,    21] loss: 0.52880, train_accuracy: 81.45\n",
      "[71,    31] loss: 0.48674, train_accuracy: 83.98\n",
      "[71,    41] loss: 0.59302, train_accuracy: 78.91\n",
      "[71,    51] loss: 0.51094, train_accuracy: 82.62\n",
      "[71,    61] loss: 0.48532, train_accuracy: 83.20\n",
      "[71,    71] loss: 0.56709, train_accuracy: 80.66\n",
      "[71,    81] loss: 0.52590, train_accuracy: 81.45\n",
      "[71,    91] loss: 0.50061, train_accuracy: 83.40\n",
      "duration: 205 s - train loss: 0.50911 - train accuracy: 82.18 - validation loss: 0.41574 - validation accuracy: 86.42 \n",
      "[72,     1] loss: 0.52687, train_accuracy: 81.64\n",
      "[72,    11] loss: 0.49818, train_accuracy: 81.05\n",
      "[72,    21] loss: 0.48509, train_accuracy: 83.79\n",
      "[72,    31] loss: 0.43802, train_accuracy: 86.13\n",
      "[72,    41] loss: 0.47775, train_accuracy: 83.79\n",
      "[72,    51] loss: 0.53234, train_accuracy: 83.20\n",
      "[72,    61] loss: 0.46999, train_accuracy: 84.57\n",
      "[72,    71] loss: 0.43434, train_accuracy: 85.35\n",
      "[72,    81] loss: 0.54310, train_accuracy: 80.08\n",
      "[72,    91] loss: 0.54283, train_accuracy: 81.05\n",
      "duration: 208 s - train loss: 0.49915 - train accuracy: 82.56 - validation loss: 0.40238 - validation accuracy: 86.36 \n",
      "[73,     1] loss: 0.47584, train_accuracy: 84.57\n",
      "[73,    11] loss: 0.48467, train_accuracy: 83.98\n",
      "[73,    21] loss: 0.52140, train_accuracy: 81.64\n",
      "[73,    31] loss: 0.49250, train_accuracy: 83.20\n",
      "[73,    41] loss: 0.48394, train_accuracy: 83.40\n",
      "[73,    51] loss: 0.42341, train_accuracy: 85.16\n",
      "[73,    61] loss: 0.42931, train_accuracy: 85.16\n",
      "[73,    71] loss: 0.46740, train_accuracy: 85.74\n",
      "[73,    81] loss: 0.45459, train_accuracy: 83.20\n",
      "[73,    91] loss: 0.51625, train_accuracy: 82.42\n",
      "duration: 203 s - train loss: 0.49039 - train accuracy: 83.01 - validation loss: 0.40514 - validation accuracy: 86.44 \n",
      "[74,     1] loss: 0.47703, train_accuracy: 81.45\n",
      "[74,    11] loss: 0.47993, train_accuracy: 83.79\n",
      "[74,    21] loss: 0.52192, train_accuracy: 81.45\n",
      "[74,    31] loss: 0.47441, train_accuracy: 84.38\n",
      "[74,    41] loss: 0.58858, train_accuracy: 78.91\n",
      "[74,    51] loss: 0.48183, train_accuracy: 83.01\n",
      "[74,    61] loss: 0.51463, train_accuracy: 82.42\n",
      "[74,    71] loss: 0.54706, train_accuracy: 80.27\n",
      "[74,    81] loss: 0.47243, train_accuracy: 83.79\n",
      "[74,    91] loss: 0.52464, train_accuracy: 81.45\n",
      "duration: 204 s - train loss: 0.49437 - train accuracy: 82.60 - validation loss: 0.38389 - validation accuracy: 87.30 \n",
      "[75,     1] loss: 0.48390, train_accuracy: 83.79\n",
      "[75,    11] loss: 0.51704, train_accuracy: 80.86\n",
      "[75,    21] loss: 0.48827, train_accuracy: 82.81\n",
      "[75,    31] loss: 0.52630, train_accuracy: 81.25\n",
      "[75,    41] loss: 0.47733, train_accuracy: 83.59\n",
      "[75,    51] loss: 0.48399, train_accuracy: 83.79\n",
      "[75,    61] loss: 0.52741, train_accuracy: 80.86\n",
      "[75,    71] loss: 0.44364, train_accuracy: 86.33\n",
      "[75,    81] loss: 0.48735, train_accuracy: 82.62\n",
      "[75,    91] loss: 0.50952, train_accuracy: 82.62\n",
      "duration: 207 s - train loss: 0.49139 - train accuracy: 82.76 - validation loss: 0.39628 - validation accuracy: 87.27 \n",
      "[76,     1] loss: 0.50563, train_accuracy: 82.62\n",
      "[76,    11] loss: 0.48015, train_accuracy: 83.98\n",
      "[76,    21] loss: 0.54204, train_accuracy: 81.25\n",
      "[76,    31] loss: 0.46123, train_accuracy: 83.59\n",
      "[76,    41] loss: 0.44635, train_accuracy: 84.96\n",
      "[76,    51] loss: 0.51308, train_accuracy: 81.25\n",
      "[76,    61] loss: 0.51431, train_accuracy: 83.01\n",
      "[76,    71] loss: 0.44501, train_accuracy: 85.55\n",
      "[76,    81] loss: 0.52095, train_accuracy: 82.03\n",
      "[76,    91] loss: 0.47405, train_accuracy: 83.01\n",
      "duration: 205 s - train loss: 0.47999 - train accuracy: 83.37 - validation loss: 0.39770 - validation accuracy: 87.23 \n",
      "[77,     1] loss: 0.41876, train_accuracy: 84.57\n",
      "[77,    11] loss: 0.44028, train_accuracy: 83.20\n",
      "[77,    21] loss: 0.50202, train_accuracy: 82.81\n",
      "[77,    31] loss: 0.49543, train_accuracy: 80.66\n",
      "[77,    41] loss: 0.45055, train_accuracy: 83.79\n",
      "[77,    51] loss: 0.49486, train_accuracy: 82.23\n",
      "[77,    61] loss: 0.50153, train_accuracy: 82.62\n",
      "[77,    71] loss: 0.51662, train_accuracy: 82.03\n",
      "[77,    81] loss: 0.49080, train_accuracy: 82.62\n",
      "[77,    91] loss: 0.49749, train_accuracy: 81.45\n",
      "duration: 205 s - train loss: 0.47729 - train accuracy: 83.24 - validation loss: 0.41562 - validation accuracy: 86.60 \n",
      "[78,     1] loss: 0.47826, train_accuracy: 83.40\n",
      "[78,    11] loss: 0.50024, train_accuracy: 79.88\n",
      "[78,    21] loss: 0.46766, train_accuracy: 81.25\n",
      "[78,    31] loss: 0.43686, train_accuracy: 84.77\n",
      "[78,    41] loss: 0.45972, train_accuracy: 82.62\n",
      "[78,    51] loss: 0.48120, train_accuracy: 84.96\n",
      "[78,    61] loss: 0.56383, train_accuracy: 82.42\n",
      "[78,    71] loss: 0.45431, train_accuracy: 81.25\n",
      "[78,    81] loss: 0.49175, train_accuracy: 83.20\n",
      "[78,    91] loss: 0.56757, train_accuracy: 79.88\n",
      "duration: 202 s - train loss: 0.48517 - train accuracy: 83.10 - validation loss: 0.42979 - validation accuracy: 86.74 \n",
      "[79,     1] loss: 0.42065, train_accuracy: 85.74\n",
      "[79,    11] loss: 0.47720, train_accuracy: 83.20\n",
      "[79,    21] loss: 0.47546, train_accuracy: 82.42\n",
      "[79,    31] loss: 0.56775, train_accuracy: 79.49\n",
      "[79,    41] loss: 0.47161, train_accuracy: 84.18\n",
      "[79,    51] loss: 0.49639, train_accuracy: 83.01\n",
      "[79,    61] loss: 0.48564, train_accuracy: 84.57\n",
      "[79,    71] loss: 0.46452, train_accuracy: 82.42\n",
      "[79,    81] loss: 0.40472, train_accuracy: 86.91\n",
      "[79,    91] loss: 0.47291, train_accuracy: 83.59\n",
      "duration: 207 s - train loss: 0.47896 - train accuracy: 83.21 - validation loss: 0.39945 - validation accuracy: 86.95 \n",
      "[80,     1] loss: 0.50202, train_accuracy: 82.81\n",
      "[80,    11] loss: 0.45246, train_accuracy: 84.57\n",
      "[80,    21] loss: 0.48825, train_accuracy: 82.81\n",
      "[80,    31] loss: 0.43403, train_accuracy: 84.96\n",
      "[80,    41] loss: 0.57422, train_accuracy: 80.47\n",
      "[80,    51] loss: 0.46809, train_accuracy: 82.62\n",
      "[80,    61] loss: 0.54019, train_accuracy: 81.25\n",
      "[80,    71] loss: 0.49539, train_accuracy: 84.57\n",
      "[80,    81] loss: 0.51018, train_accuracy: 82.42\n",
      "[80,    91] loss: 0.57767, train_accuracy: 80.47\n",
      "duration: 203 s - train loss: 0.47618 - train accuracy: 83.42 - validation loss: 0.39828 - validation accuracy: 87.38 \n",
      "[81,     1] loss: 0.44449, train_accuracy: 83.40\n",
      "[81,    11] loss: 0.44560, train_accuracy: 85.55\n",
      "[81,    21] loss: 0.37296, train_accuracy: 87.11\n",
      "[81,    31] loss: 0.45805, train_accuracy: 84.38\n",
      "[81,    41] loss: 0.44995, train_accuracy: 84.96\n",
      "[81,    51] loss: 0.49390, train_accuracy: 82.23\n",
      "[81,    61] loss: 0.44885, train_accuracy: 83.79\n",
      "[81,    71] loss: 0.44396, train_accuracy: 83.20\n",
      "[81,    81] loss: 0.38540, train_accuracy: 86.33\n",
      "[81,    91] loss: 0.45839, train_accuracy: 83.01\n",
      "duration: 202 s - train loss: 0.46852 - train accuracy: 83.54 - validation loss: 0.39590 - validation accuracy: 87.19 \n",
      "[82,     1] loss: 0.44817, train_accuracy: 85.55\n",
      "[82,    11] loss: 0.34547, train_accuracy: 87.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82,    21] loss: 0.49056, train_accuracy: 83.01\n",
      "[82,    31] loss: 0.47792, train_accuracy: 83.98\n",
      "[82,    41] loss: 0.39302, train_accuracy: 86.52\n",
      "[82,    51] loss: 0.45010, train_accuracy: 82.81\n",
      "[82,    61] loss: 0.45318, train_accuracy: 85.16\n",
      "[82,    71] loss: 0.44153, train_accuracy: 85.16\n",
      "[82,    81] loss: 0.50203, train_accuracy: 83.59\n",
      "[82,    91] loss: 0.52620, train_accuracy: 83.40\n",
      "duration: 208 s - train loss: 0.46048 - train accuracy: 83.97 - validation loss: 0.42966 - validation accuracy: 86.98 \n",
      "[83,     1] loss: 0.44215, train_accuracy: 83.79\n",
      "[83,    11] loss: 0.46379, train_accuracy: 84.77\n",
      "[83,    21] loss: 0.41687, train_accuracy: 85.55\n",
      "[83,    31] loss: 0.44630, train_accuracy: 84.38\n",
      "[83,    41] loss: 0.44130, train_accuracy: 84.96\n",
      "[83,    51] loss: 0.41315, train_accuracy: 85.55\n",
      "[83,    61] loss: 0.46764, train_accuracy: 83.98\n",
      "[83,    71] loss: 0.46818, train_accuracy: 83.20\n",
      "[83,    81] loss: 0.40795, train_accuracy: 86.13\n",
      "[83,    91] loss: 0.56759, train_accuracy: 81.25\n",
      "duration: 203 s - train loss: 0.46666 - train accuracy: 83.82 - validation loss: 0.38077 - validation accuracy: 87.35 \n",
      "[84,     1] loss: 0.46984, train_accuracy: 83.79\n",
      "[84,    11] loss: 0.48326, train_accuracy: 83.01\n",
      "[84,    21] loss: 0.54112, train_accuracy: 80.86\n",
      "[84,    31] loss: 0.42064, train_accuracy: 85.74\n",
      "[84,    41] loss: 0.55554, train_accuracy: 79.49\n",
      "[84,    51] loss: 0.47923, train_accuracy: 83.20\n",
      "[84,    61] loss: 0.39920, train_accuracy: 85.35\n",
      "[84,    71] loss: 0.50904, train_accuracy: 83.20\n",
      "[84,    81] loss: 0.40789, train_accuracy: 86.91\n",
      "[84,    91] loss: 0.50191, train_accuracy: 82.81\n",
      "duration: 204 s - train loss: 0.45703 - train accuracy: 84.15 - validation loss: 0.40718 - validation accuracy: 87.13 \n",
      "[85,     1] loss: 0.39731, train_accuracy: 86.52\n",
      "[85,    11] loss: 0.54660, train_accuracy: 82.23\n",
      "[85,    21] loss: 0.40903, train_accuracy: 85.35\n",
      "[85,    31] loss: 0.50696, train_accuracy: 81.64\n",
      "[85,    41] loss: 0.49665, train_accuracy: 80.86\n",
      "[85,    51] loss: 0.46295, train_accuracy: 83.59\n",
      "[85,    61] loss: 0.43132, train_accuracy: 83.20\n",
      "[85,    71] loss: 0.47848, train_accuracy: 83.01\n",
      "[85,    81] loss: 0.48931, train_accuracy: 82.23\n",
      "[85,    91] loss: 0.44781, train_accuracy: 84.18\n",
      "duration: 203 s - train loss: 0.45305 - train accuracy: 84.12 - validation loss: 0.41630 - validation accuracy: 86.75 \n",
      "[86,     1] loss: 0.51066, train_accuracy: 81.84\n",
      "[86,    11] loss: 0.41434, train_accuracy: 85.74\n",
      "[86,    21] loss: 0.37890, train_accuracy: 87.89\n",
      "[86,    31] loss: 0.45692, train_accuracy: 83.79\n",
      "[86,    41] loss: 0.48231, train_accuracy: 84.38\n",
      "[86,    51] loss: 0.51493, train_accuracy: 81.84\n",
      "[86,    61] loss: 0.45821, train_accuracy: 84.57\n",
      "[86,    71] loss: 0.41830, train_accuracy: 83.98\n",
      "[86,    81] loss: 0.48807, train_accuracy: 82.81\n",
      "[86,    91] loss: 0.40002, train_accuracy: 87.30\n",
      "duration: 209 s - train loss: 0.45190 - train accuracy: 84.34 - validation loss: 0.38441 - validation accuracy: 87.46 \n",
      "[87,     1] loss: 0.42936, train_accuracy: 83.79\n",
      "[87,    11] loss: 0.51470, train_accuracy: 83.01\n",
      "[87,    21] loss: 0.44957, train_accuracy: 85.16\n",
      "[87,    31] loss: 0.40671, train_accuracy: 86.91\n",
      "[87,    41] loss: 0.44525, train_accuracy: 84.77\n",
      "[87,    51] loss: 0.46018, train_accuracy: 85.35\n",
      "[87,    61] loss: 0.49425, train_accuracy: 81.84\n",
      "[87,    71] loss: 0.48139, train_accuracy: 83.59\n",
      "[87,    81] loss: 0.47669, train_accuracy: 83.79\n",
      "[87,    91] loss: 0.39835, train_accuracy: 86.72\n",
      "duration: 202 s - train loss: 0.45360 - train accuracy: 84.09 - validation loss: 0.42988 - validation accuracy: 86.76 \n",
      "[88,     1] loss: 0.43200, train_accuracy: 84.57\n",
      "[88,    11] loss: 0.42244, train_accuracy: 83.59\n",
      "[88,    21] loss: 0.40973, train_accuracy: 84.18\n",
      "[88,    31] loss: 0.52963, train_accuracy: 82.81\n",
      "[88,    41] loss: 0.46532, train_accuracy: 81.84\n",
      "[88,    51] loss: 0.53973, train_accuracy: 79.49\n",
      "[88,    61] loss: 0.48030, train_accuracy: 83.01\n",
      "[88,    71] loss: 0.40476, train_accuracy: 85.74\n",
      "[88,    81] loss: 0.51342, train_accuracy: 79.88\n",
      "[88,    91] loss: 0.44897, train_accuracy: 82.23\n",
      "duration: 204 s - train loss: 0.45484 - train accuracy: 84.04 - validation loss: 0.41430 - validation accuracy: 87.00 \n",
      "[89,     1] loss: 0.44237, train_accuracy: 85.16\n",
      "[89,    11] loss: 0.42709, train_accuracy: 86.33\n",
      "[89,    21] loss: 0.42971, train_accuracy: 83.40\n",
      "[89,    31] loss: 0.39907, train_accuracy: 85.16\n",
      "[89,    41] loss: 0.36257, train_accuracy: 86.13\n",
      "[89,    51] loss: 0.47118, train_accuracy: 83.79\n",
      "[89,    61] loss: 0.44279, train_accuracy: 83.59\n",
      "[89,    71] loss: 0.46184, train_accuracy: 85.16\n",
      "[89,    81] loss: 0.43651, train_accuracy: 85.16\n",
      "[89,    91] loss: 0.41047, train_accuracy: 83.79\n",
      "duration: 209 s - train loss: 0.44214 - train accuracy: 84.48 - validation loss: 0.40273 - validation accuracy: 87.35 \n",
      "[90,     1] loss: 0.42318, train_accuracy: 84.38\n",
      "[90,    11] loss: 0.41578, train_accuracy: 85.16\n",
      "[90,    71] loss: 0.51393, train_accuracy: 83.20\n",
      "[90,    81] loss: 0.44107, train_accuracy: 83.98\n",
      "[90,    91] loss: 0.41470, train_accuracy: 84.77\n",
      "duration: 203 s - train loss: 0.44487 - train accuracy: 84.35 - validation loss: 0.39489 - validation accuracy: 86.88 \n",
      "[91,     1] loss: 0.42518, train_accuracy: 83.98\n",
      "[91,    11] loss: 0.41069, train_accuracy: 86.72\n",
      "[91,    21] loss: 0.43597, train_accuracy: 83.98\n",
      "[91,    31] loss: 0.45249, train_accuracy: 84.18\n",
      "[91,    41] loss: 0.45415, train_accuracy: 84.57\n",
      "[91,    51] loss: 0.50045, train_accuracy: 81.84\n",
      "[91,    61] loss: 0.46157, train_accuracy: 85.35\n",
      "[91,    71] loss: 0.46366, train_accuracy: 83.20\n",
      "[91,    81] loss: 0.47655, train_accuracy: 84.18\n",
      "[91,    91] loss: 0.54753, train_accuracy: 80.86\n",
      "duration: 202 s - train loss: 0.43867 - train accuracy: 84.64 - validation loss: 0.43468 - validation accuracy: 86.64 \n",
      "[92,     1] loss: 0.48921, train_accuracy: 82.03\n",
      "[92,    11] loss: 0.46535, train_accuracy: 84.57\n",
      "[92,    21] loss: 0.38507, train_accuracy: 86.13\n",
      "[92,    31] loss: 0.44282, train_accuracy: 83.79\n",
      "[92,    41] loss: 0.47409, train_accuracy: 84.96\n",
      "[92,    51] loss: 0.40958, train_accuracy: 84.18\n",
      "[92,    61] loss: 0.45396, train_accuracy: 84.77\n",
      "[92,    71] loss: 0.40238, train_accuracy: 86.52\n",
      "[92,    81] loss: 0.47318, train_accuracy: 83.40\n",
      "[92,    91] loss: 0.42908, train_accuracy: 84.57\n",
      "duration: 203 s - train loss: 0.43448 - train accuracy: 84.76 - validation loss: 0.42014 - validation accuracy: 87.35 \n",
      "[93,     1] loss: 0.50481, train_accuracy: 81.45\n",
      "[93,    11] loss: 0.44807, train_accuracy: 84.38\n",
      "[93,    21] loss: 0.45816, train_accuracy: 81.84\n",
      "[93,    31] loss: 0.39640, train_accuracy: 86.72\n",
      "[93,    41] loss: 0.53240, train_accuracy: 81.84\n",
      "[93,    51] loss: 0.43468, train_accuracy: 84.57\n",
      "[93,    61] loss: 0.40360, train_accuracy: 85.74\n",
      "[93,    71] loss: 0.40661, train_accuracy: 85.16\n",
      "[93,    81] loss: 0.41422, train_accuracy: 85.74\n",
      "[93,    91] loss: 0.37855, train_accuracy: 87.11\n",
      "duration: 207 s - train loss: 0.43369 - train accuracy: 84.92 - validation loss: 0.39152 - validation accuracy: 87.92 \n",
      "stopped early after 10 epochs without decrease of validation loss\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_stats = model.fit_fast_with_double_update(train_loader, test_loader, 200, device, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='epoch'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_stats.plot(x='epoch', y=['l_inf_robustness', 'l_2_robustness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./saved-models/fast-double-vs-standard-experiment-standard-fast-training.pt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH='./saved-models/fast-double-vs-standard-experiment-standard-fast-training.pt'\n",
    "optimizer = train_stats['optimizer'][0]\n",
    "safe_model(PATH, model, optimizer, description='Comparing fast adversarial training with single and double updates', loss='N/A',epoch='92')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
