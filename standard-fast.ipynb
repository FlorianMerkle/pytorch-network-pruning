{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from src.models  import CifarResNet, MNIST_CNN, CIFAR_CNN\n",
    "from src.helpers import evaluate_rob_accuracy, evaluate_clean_accuracy, load_model, safe_model,_evaluate_model\n",
    "from src.data_loader import load_torchvision_dataset, load_imagenette\n",
    "#from src.pruning import identify_layers, _evaluate_sparsity\n",
    "\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model = CifarResNet()\n",
    "model.to(device)\n",
    "train_loader, test_loader = load_torchvision_dataset('CIFAR10', data_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.86151, train_accuracy: 10.94\n",
      "[1,    11] loss: 5.11607, train_accuracy: 13.67\n",
      "[1,    21] loss: 3.89320, train_accuracy: 17.19\n",
      "[1,    31] loss: 2.59977, train_accuracy: 19.73\n",
      "[1,    41] loss: 2.84274, train_accuracy: 18.55\n",
      "[1,    51] loss: 2.90041, train_accuracy: 22.66\n",
      "[1,    61] loss: 2.23360, train_accuracy: 19.14\n",
      "[1,    71] loss: 2.14534, train_accuracy: 26.56\n",
      "[1,    81] loss: 2.65038, train_accuracy: 25.98\n",
      "[1,    91] loss: 2.30333, train_accuracy: 24.02\n",
      "duration: 191 s - train loss: 4.01494 - train accuracy: 20.41 - validation loss: 2.22422 - validation accuracy: 28.33 \n",
      "[2,     1] loss: 2.13229, train_accuracy: 22.66\n",
      "[2,    11] loss: 2.17772, train_accuracy: 21.48\n",
      "[2,    21] loss: 2.36908, train_accuracy: 25.98\n",
      "[2,    31] loss: 1.93846, train_accuracy: 26.76\n",
      "[2,    41] loss: 2.35091, train_accuracy: 29.30\n",
      "[2,    51] loss: 1.99823, train_accuracy: 29.49\n",
      "[2,    61] loss: 2.15333, train_accuracy: 26.17\n",
      "[2,    71] loss: 1.94948, train_accuracy: 33.20\n",
      "[2,    81] loss: 1.88156, train_accuracy: 28.52\n",
      "[2,    91] loss: 2.09683, train_accuracy: 28.52\n",
      "duration: 198 s - train loss: 2.11798 - train accuracy: 27.77 - validation loss: 1.75627 - validation accuracy: 37.62 \n",
      "[3,     1] loss: 1.94892, train_accuracy: 31.25\n",
      "[3,    11] loss: 2.07015, train_accuracy: 32.03\n",
      "[3,    21] loss: 1.84289, train_accuracy: 33.79\n",
      "[3,    31] loss: 1.92084, train_accuracy: 31.45\n",
      "[3,    41] loss: 1.76276, train_accuracy: 37.50\n",
      "[3,    51] loss: 1.77725, train_accuracy: 38.09\n",
      "[3,    61] loss: 1.71301, train_accuracy: 37.50\n",
      "[3,    71] loss: 1.75004, train_accuracy: 35.35\n",
      "[3,    81] loss: 1.69690, train_accuracy: 37.50\n",
      "[3,    91] loss: 1.70027, train_accuracy: 41.02\n",
      "duration: 203 s - train loss: 1.81750 - train accuracy: 35.02 - validation loss: 1.57431 - validation accuracy: 43.83 \n",
      "[4,     1] loss: 1.74871, train_accuracy: 35.35\n",
      "[4,    11] loss: 1.69342, train_accuracy: 36.52\n",
      "[4,    21] loss: 1.67460, train_accuracy: 39.06\n",
      "[4,    31] loss: 1.77482, train_accuracy: 36.33\n",
      "[4,    41] loss: 1.69310, train_accuracy: 36.33\n",
      "[4,    51] loss: 1.67976, train_accuracy: 37.50\n",
      "[4,    61] loss: 1.68873, train_accuracy: 41.02\n",
      "[4,    71] loss: 1.70244, train_accuracy: 39.65\n",
      "[4,    81] loss: 1.61353, train_accuracy: 40.23\n",
      "[4,    91] loss: 1.62066, train_accuracy: 38.87\n",
      "duration: 193 s - train loss: 1.69919 - train accuracy: 38.85 - validation loss: 1.52557 - validation accuracy: 46.40 \n",
      "[5,     1] loss: 1.66278, train_accuracy: 39.06\n",
      "[5,    11] loss: 1.58205, train_accuracy: 39.45\n",
      "[5,    21] loss: 1.67485, train_accuracy: 42.97\n",
      "[5,    31] loss: 1.69580, train_accuracy: 40.82\n",
      "[5,    41] loss: 1.57602, train_accuracy: 44.34\n",
      "[5,    51] loss: 1.66626, train_accuracy: 41.60\n",
      "[5,    61] loss: 1.50756, train_accuracy: 46.29\n",
      "[5,    71] loss: 1.58645, train_accuracy: 41.60\n",
      "[5,    81] loss: 1.50649, train_accuracy: 44.73\n",
      "[5,    91] loss: 1.56807, train_accuracy: 42.97\n",
      "duration: 194 s - train loss: 1.61418 - train accuracy: 42.09 - validation loss: 1.38552 - validation accuracy: 51.32 \n",
      "[6,     1] loss: 1.58619, train_accuracy: 43.75\n",
      "[6,    11] loss: 1.68250, train_accuracy: 42.38\n",
      "[6,    21] loss: 1.52811, train_accuracy: 45.70\n",
      "[6,    31] loss: 1.60576, train_accuracy: 39.26\n",
      "[6,    41] loss: 1.50721, train_accuracy: 45.31\n",
      "[6,    51] loss: 1.61867, train_accuracy: 41.99\n",
      "[6,    61] loss: 1.52406, train_accuracy: 43.75\n",
      "[6,    71] loss: 1.47760, train_accuracy: 44.53\n",
      "[6,    81] loss: 1.52218, train_accuracy: 47.07\n",
      "[6,    91] loss: 1.48007, train_accuracy: 45.70\n",
      "duration: 193 s - train loss: 1.53006 - train accuracy: 44.85 - validation loss: 1.31372 - validation accuracy: 54.30 \n",
      "[7,     1] loss: 1.62152, train_accuracy: 44.73\n",
      "[7,    11] loss: 1.56035, train_accuracy: 43.75\n",
      "[7,    21] loss: 1.51966, train_accuracy: 47.27\n",
      "[7,    31] loss: 1.50623, train_accuracy: 43.36\n",
      "[7,    41] loss: 1.45752, train_accuracy: 47.66\n",
      "[7,    51] loss: 1.44344, train_accuracy: 47.85\n",
      "[7,    61] loss: 1.47256, train_accuracy: 45.90\n",
      "[7,    71] loss: 1.42504, train_accuracy: 45.51\n",
      "[7,    81] loss: 1.44887, train_accuracy: 47.27\n",
      "[7,    91] loss: 1.34694, train_accuracy: 50.98\n",
      "duration: 197 s - train loss: 1.48611 - train accuracy: 46.87 - validation loss: 1.22416 - validation accuracy: 56.73 \n",
      "[8,     1] loss: 1.38960, train_accuracy: 46.88\n",
      "[8,    11] loss: 1.50158, train_accuracy: 46.48\n",
      "[8,    21] loss: 1.57001, train_accuracy: 47.07\n",
      "[8,    31] loss: 1.44527, train_accuracy: 50.20\n",
      "[8,    41] loss: 1.36702, train_accuracy: 53.32\n",
      "[8,    51] loss: 1.47645, train_accuracy: 47.07\n",
      "[8,    61] loss: 1.45210, train_accuracy: 46.88\n",
      "[8,    71] loss: 1.46112, train_accuracy: 48.83\n",
      "[8,    81] loss: 1.47313, train_accuracy: 48.44\n",
      "[8,    91] loss: 1.41136, train_accuracy: 50.00\n",
      "duration: 193 s - train loss: 1.41528 - train accuracy: 49.30 - validation loss: 1.16012 - validation accuracy: 59.88 \n",
      "[9,     1] loss: 1.39189, train_accuracy: 51.95\n",
      "[9,    11] loss: 1.43312, train_accuracy: 49.02\n",
      "[9,    21] loss: 1.36597, train_accuracy: 51.76\n",
      "[9,    31] loss: 1.34733, train_accuracy: 53.12\n",
      "[9,    41] loss: 1.31347, train_accuracy: 51.95\n",
      "[9,    51] loss: 1.27538, train_accuracy: 55.86\n",
      "[9,    61] loss: 1.49042, train_accuracy: 49.22\n",
      "[9,    71] loss: 1.34446, train_accuracy: 50.20\n",
      "[9,    81] loss: 1.39942, train_accuracy: 49.41\n",
      "[9,    91] loss: 1.34131, train_accuracy: 53.52\n",
      "duration: 193 s - train loss: 1.35780 - train accuracy: 51.98 - validation loss: 1.07468 - validation accuracy: 63.00 \n",
      "[10,     1] loss: 1.23672, train_accuracy: 54.69\n",
      "[10,    11] loss: 1.23727, train_accuracy: 55.47\n",
      "[10,    21] loss: 1.25412, train_accuracy: 52.34\n",
      "[10,    31] loss: 1.32511, train_accuracy: 50.20\n",
      "[10,    41] loss: 1.28813, train_accuracy: 53.91\n",
      "[10,    51] loss: 1.19899, train_accuracy: 57.62\n",
      "[10,    61] loss: 1.20512, train_accuracy: 57.03\n",
      "[10,    71] loss: 1.29315, train_accuracy: 53.71\n",
      "[10,    81] loss: 1.24181, train_accuracy: 55.08\n",
      "[10,    91] loss: 1.30475, train_accuracy: 52.93\n",
      "duration: 194 s - train loss: 1.30255 - train accuracy: 53.92 - validation loss: 1.02306 - validation accuracy: 63.86 \n",
      "[11,     1] loss: 1.25505, train_accuracy: 55.86\n",
      "[11,    11] loss: 1.18788, train_accuracy: 57.81\n",
      "[11,    21] loss: 1.31250, train_accuracy: 54.30\n",
      "[11,    31] loss: 1.23960, train_accuracy: 55.66\n",
      "[11,    41] loss: 1.26778, train_accuracy: 51.95\n",
      "[11,    51] loss: 1.28876, train_accuracy: 55.08\n",
      "[11,    61] loss: 1.16548, train_accuracy: 58.40\n",
      "[11,    71] loss: 1.23116, train_accuracy: 57.23\n",
      "[11,    81] loss: 1.24243, train_accuracy: 54.88\n",
      "[11,    91] loss: 1.32415, train_accuracy: 52.73\n",
      "duration: 196 s - train loss: 1.24872 - train accuracy: 56.13 - validation loss: 0.94799 - validation accuracy: 67.08 \n",
      "[12,     1] loss: 1.24180, train_accuracy: 58.20\n",
      "[12,    11] loss: 1.16870, train_accuracy: 57.42\n",
      "[12,    21] loss: 1.25596, train_accuracy: 57.42\n",
      "[12,    31] loss: 1.27890, train_accuracy: 55.47\n",
      "[12,    41] loss: 1.25377, train_accuracy: 57.03\n",
      "[12,    51] loss: 1.20164, train_accuracy: 60.35\n",
      "[12,    61] loss: 1.22837, train_accuracy: 56.45\n",
      "[12,    71] loss: 1.16778, train_accuracy: 58.01\n",
      "[12,    81] loss: 1.22855, train_accuracy: 55.47\n",
      "[12,    91] loss: 1.27777, train_accuracy: 57.42\n",
      "duration: 192 s - train loss: 1.20644 - train accuracy: 57.60 - validation loss: 0.89784 - validation accuracy: 69.46 \n",
      "[13,     1] loss: 1.06742, train_accuracy: 59.18\n",
      "[13,    11] loss: 1.21410, train_accuracy: 55.27\n",
      "[13,    21] loss: 1.12962, train_accuracy: 60.35\n",
      "[13,    31] loss: 1.14797, train_accuracy: 59.18\n",
      "[13,    41] loss: 1.32223, train_accuracy: 53.91\n",
      "[13,    51] loss: 1.12857, train_accuracy: 59.77\n",
      "[13,    61] loss: 1.15819, train_accuracy: 56.45\n",
      "[13,    71] loss: 1.20415, train_accuracy: 56.84\n",
      "[13,    81] loss: 1.15348, train_accuracy: 58.40\n",
      "[13,    91] loss: 1.19359, train_accuracy: 55.66\n",
      "duration: 192 s - train loss: 1.16939 - train accuracy: 58.94 - validation loss: 0.92269 - validation accuracy: 68.39 \n",
      "[14,     1] loss: 1.20708, train_accuracy: 59.38\n",
      "[14,    11] loss: 1.14181, train_accuracy: 60.55\n",
      "[14,    21] loss: 1.14658, train_accuracy: 60.55\n",
      "[14,    31] loss: 1.15889, train_accuracy: 59.57\n",
      "[14,    41] loss: 1.12932, train_accuracy: 61.33\n",
      "[14,    51] loss: 1.20284, train_accuracy: 57.23\n",
      "[14,    61] loss: 1.09770, train_accuracy: 58.79\n",
      "[14,    71] loss: 1.11240, train_accuracy: 60.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,    81] loss: 1.19001, train_accuracy: 60.55\n",
      "[14,    91] loss: 1.08056, train_accuracy: 59.57\n",
      "duration: 190 s - train loss: 1.13661 - train accuracy: 59.98 - validation loss: 0.82419 - validation accuracy: 70.82 \n",
      "[15,     1] loss: 1.11907, train_accuracy: 61.91\n",
      "[15,    11] loss: 1.12120, train_accuracy: 60.35\n",
      "[15,    21] loss: 1.12845, train_accuracy: 61.33\n",
      "[15,    31] loss: 1.06254, train_accuracy: 64.84\n",
      "[15,    41] loss: 1.01663, train_accuracy: 63.09\n",
      "[15,    51] loss: 1.12115, train_accuracy: 62.11\n",
      "[15,    61] loss: 1.05202, train_accuracy: 61.72\n",
      "[15,    71] loss: 1.08675, train_accuracy: 61.91\n",
      "[15,    81] loss: 1.06812, train_accuracy: 61.72\n",
      "[15,    91] loss: 1.00161, train_accuracy: 65.82\n",
      "duration: 198 s - train loss: 1.08637 - train accuracy: 62.12 - validation loss: 0.78572 - validation accuracy: 72.35 \n",
      "[16,     1] loss: 1.10768, train_accuracy: 62.89\n",
      "[16,    11] loss: 1.05976, train_accuracy: 65.62\n",
      "[16,    21] loss: 1.00837, train_accuracy: 63.87\n",
      "[16,    31] loss: 1.04389, train_accuracy: 63.09\n",
      "[16,    41] loss: 1.08598, train_accuracy: 62.11\n",
      "[16,    51] loss: 1.08395, train_accuracy: 58.59\n",
      "[16,    61] loss: 1.13210, train_accuracy: 62.50\n",
      "[16,    71] loss: 0.98530, train_accuracy: 65.04\n",
      "[16,    81] loss: 1.04244, train_accuracy: 65.82\n",
      "[16,    91] loss: 1.00909, train_accuracy: 63.87\n",
      "duration: 194 s - train loss: 1.06250 - train accuracy: 62.86 - validation loss: 0.80122 - validation accuracy: 72.71 \n",
      "[17,     1] loss: 1.04536, train_accuracy: 61.91\n",
      "[17,    11] loss: 1.06528, train_accuracy: 62.89\n",
      "[17,    21] loss: 1.11032, train_accuracy: 60.16\n",
      "[17,    31] loss: 1.09282, train_accuracy: 60.74\n",
      "[17,    41] loss: 1.16063, train_accuracy: 60.74\n",
      "[17,    51] loss: 0.96727, train_accuracy: 65.23\n",
      "[17,    61] loss: 1.04206, train_accuracy: 61.13\n",
      "[17,    71] loss: 1.10882, train_accuracy: 60.16\n",
      "[17,    81] loss: 1.07815, train_accuracy: 61.91\n",
      "[17,    91] loss: 1.00656, train_accuracy: 63.67\n",
      "duration: 195 s - train loss: 1.05142 - train accuracy: 63.43 - validation loss: 0.73058 - validation accuracy: 74.36 \n",
      "[18,     1] loss: 0.98643, train_accuracy: 67.97\n",
      "[18,    11] loss: 0.91543, train_accuracy: 67.97\n",
      "[18,    21] loss: 1.09400, train_accuracy: 62.30\n",
      "[18,    31] loss: 0.94532, train_accuracy: 66.41\n",
      "[18,    41] loss: 1.08262, train_accuracy: 63.09\n",
      "[18,    51] loss: 1.01501, train_accuracy: 63.48\n",
      "[18,    61] loss: 0.98280, train_accuracy: 64.65\n",
      "[18,    71] loss: 0.96363, train_accuracy: 66.21\n",
      "[18,    81] loss: 1.08938, train_accuracy: 61.91\n",
      "[18,    91] loss: 0.93662, train_accuracy: 66.60\n",
      "duration: 196 s - train loss: 0.99919 - train accuracy: 65.02 - validation loss: 0.72061 - validation accuracy: 75.35 \n",
      "[19,     1] loss: 1.01349, train_accuracy: 65.43\n",
      "[19,    11] loss: 0.94092, train_accuracy: 68.75\n",
      "[19,    21] loss: 0.96776, train_accuracy: 66.41\n",
      "[19,    31] loss: 1.00088, train_accuracy: 65.23\n",
      "[19,    41] loss: 0.90255, train_accuracy: 68.75\n",
      "[19,    51] loss: 0.98268, train_accuracy: 62.70\n",
      "[19,    61] loss: 1.04039, train_accuracy: 67.19\n",
      "[19,    71] loss: 1.08553, train_accuracy: 62.70\n",
      "[19,    81] loss: 1.02189, train_accuracy: 66.02\n",
      "[19,    91] loss: 0.97376, train_accuracy: 65.23\n",
      "duration: 195 s - train loss: 1.00475 - train accuracy: 65.07 - validation loss: 0.67877 - validation accuracy: 76.80 \n",
      "[20,     1] loss: 0.85429, train_accuracy: 71.68\n",
      "[20,    11] loss: 0.97548, train_accuracy: 65.04\n",
      "[20,    21] loss: 1.02298, train_accuracy: 64.84\n",
      "[20,    31] loss: 1.00312, train_accuracy: 64.65\n",
      "[20,    41] loss: 1.01899, train_accuracy: 66.02\n",
      "[20,    51] loss: 0.95703, train_accuracy: 66.21\n",
      "[20,    61] loss: 0.92280, train_accuracy: 67.97\n",
      "[20,    71] loss: 0.89510, train_accuracy: 68.55\n",
      "[20,    81] loss: 0.91080, train_accuracy: 67.58\n",
      "[20,    91] loss: 0.89026, train_accuracy: 67.38\n",
      "duration: 193 s - train loss: 0.96678 - train accuracy: 66.48 - validation loss: 0.70006 - validation accuracy: 76.06 \n",
      "[21,     1] loss: 0.95136, train_accuracy: 67.58\n",
      "[21,    11] loss: 0.89643, train_accuracy: 69.73\n",
      "[21,    21] loss: 0.95864, train_accuracy: 65.62\n",
      "[21,    31] loss: 0.99326, train_accuracy: 66.80\n",
      "[21,    41] loss: 0.94197, train_accuracy: 66.80\n",
      "[21,    51] loss: 0.87295, train_accuracy: 67.58\n",
      "[21,    61] loss: 0.96509, train_accuracy: 64.84\n",
      "[21,    71] loss: 0.88061, train_accuracy: 69.34\n",
      "[21,    81] loss: 0.90582, train_accuracy: 66.21\n",
      "[21,    91] loss: 0.89952, train_accuracy: 69.14\n",
      "duration: 137 s - train loss: 0.92421 - train accuracy: 67.87 - validation loss: 0.64606 - validation accuracy: 77.93 \n",
      "[22,     1] loss: 1.03498, train_accuracy: 65.43\n",
      "[22,    11] loss: 0.91650, train_accuracy: 66.60\n",
      "[22,    21] loss: 0.84399, train_accuracy: 69.14\n",
      "[22,    31] loss: 1.02508, train_accuracy: 65.43\n",
      "[22,    41] loss: 0.88770, train_accuracy: 70.51\n",
      "[22,    51] loss: 0.90179, train_accuracy: 67.58\n",
      "[22,    61] loss: 0.95842, train_accuracy: 66.02\n",
      "[22,    71] loss: 0.85077, train_accuracy: 72.85\n",
      "[22,    81] loss: 1.07835, train_accuracy: 63.28\n",
      "[22,    91] loss: 0.93542, train_accuracy: 68.55\n",
      "duration: 112 s - train loss: 0.91948 - train accuracy: 68.08 - validation loss: 0.65045 - validation accuracy: 77.93 \n",
      "[23,     1] loss: 0.91291, train_accuracy: 68.16\n",
      "[23,    11] loss: 0.94131, train_accuracy: 69.53\n",
      "[23,    21] loss: 0.84116, train_accuracy: 72.85\n",
      "[23,    31] loss: 0.88972, train_accuracy: 69.53\n",
      "[23,    41] loss: 0.89398, train_accuracy: 67.58\n",
      "[23,    51] loss: 0.89530, train_accuracy: 68.16\n",
      "[23,    61] loss: 0.85243, train_accuracy: 67.77\n",
      "[23,    71] loss: 0.91356, train_accuracy: 69.53\n",
      "[23,    81] loss: 0.93894, train_accuracy: 66.80\n",
      "[23,    91] loss: 0.97893, train_accuracy: 67.77\n",
      "duration: 112 s - train loss: 0.89199 - train accuracy: 68.82 - validation loss: 0.62234 - validation accuracy: 78.91 \n",
      "[24,     1] loss: 0.83089, train_accuracy: 70.70\n",
      "[24,    11] loss: 0.87034, train_accuracy: 70.90\n",
      "[24,    21] loss: 0.89601, train_accuracy: 68.95\n",
      "[24,    31] loss: 0.89610, train_accuracy: 69.53\n",
      "[24,    41] loss: 0.90024, train_accuracy: 66.60\n",
      "[24,    51] loss: 0.92615, train_accuracy: 65.62\n",
      "[24,    61] loss: 0.96882, train_accuracy: 67.58\n",
      "[24,    71] loss: 0.89653, train_accuracy: 66.60\n",
      "[24,    81] loss: 0.84719, train_accuracy: 70.90\n",
      "[24,    91] loss: 0.90113, train_accuracy: 68.36\n",
      "duration: 111 s - train loss: 0.88497 - train accuracy: 69.08 - validation loss: 0.63817 - validation accuracy: 78.27 \n",
      "[25,     1] loss: 0.85934, train_accuracy: 70.31\n",
      "[25,    11] loss: 0.81540, train_accuracy: 70.90\n",
      "[25,    21] loss: 0.77910, train_accuracy: 72.46\n",
      "[25,    31] loss: 0.84854, train_accuracy: 70.12\n",
      "[25,    41] loss: 0.91209, train_accuracy: 69.34\n",
      "[25,    51] loss: 0.84994, train_accuracy: 69.34\n",
      "[25,    61] loss: 0.82726, train_accuracy: 68.75\n",
      "[25,    71] loss: 0.96479, train_accuracy: 64.65\n",
      "[25,    81] loss: 0.84049, train_accuracy: 69.73\n",
      "[25,    91] loss: 0.86682, train_accuracy: 69.92\n",
      "duration: 111 s - train loss: 0.86488 - train accuracy: 69.70 - validation loss: 0.61527 - validation accuracy: 79.29 \n",
      "[26,     1] loss: 0.77935, train_accuracy: 71.29\n",
      "[26,    11] loss: 0.77081, train_accuracy: 75.98\n",
      "[26,    21] loss: 0.83942, train_accuracy: 71.29\n",
      "[26,    31] loss: 0.87434, train_accuracy: 71.09\n",
      "[26,    41] loss: 0.77831, train_accuracy: 71.88\n",
      "[26,    51] loss: 0.87567, train_accuracy: 67.97\n",
      "[26,    61] loss: 0.83269, train_accuracy: 70.31\n",
      "[26,    71] loss: 0.87118, train_accuracy: 68.55\n",
      "[26,    81] loss: 0.85577, train_accuracy: 73.05\n",
      "[26,    91] loss: 0.87658, train_accuracy: 69.53\n",
      "duration: 112 s - train loss: 0.84859 - train accuracy: 70.70 - validation loss: 0.57172 - validation accuracy: 80.69 \n",
      "[27,     1] loss: 0.92862, train_accuracy: 68.75\n",
      "[27,    11] loss: 0.86272, train_accuracy: 70.31\n",
      "[27,    21] loss: 0.85100, train_accuracy: 74.02\n",
      "[27,    31] loss: 0.85652, train_accuracy: 72.07\n",
      "[27,    41] loss: 0.85794, train_accuracy: 70.70\n",
      "[27,    51] loss: 1.35450, train_accuracy: 54.69\n",
      "[27,    61] loss: 1.12364, train_accuracy: 62.30\n",
      "[27,    71] loss: 1.09246, train_accuracy: 64.45\n",
      "[27,    81] loss: 1.02270, train_accuracy: 63.67\n",
      "[27,    91] loss: 1.03160, train_accuracy: 66.80\n",
      "duration: 112 s - train loss: 0.99580 - train accuracy: 65.98 - validation loss: 0.63086 - validation accuracy: 79.32 \n",
      "[28,     1] loss: 0.98704, train_accuracy: 67.38\n",
      "[28,    11] loss: 0.86018, train_accuracy: 70.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28,    21] loss: 0.97704, train_accuracy: 66.99\n",
      "[28,    31] loss: 0.92122, train_accuracy: 67.58\n",
      "[28,    41] loss: 0.89232, train_accuracy: 70.51\n",
      "[28,    51] loss: 0.81717, train_accuracy: 72.85\n",
      "[28,    61] loss: 0.94192, train_accuracy: 67.77\n",
      "[28,    71] loss: 0.89083, train_accuracy: 68.36\n",
      "[28,    81] loss: 0.89125, train_accuracy: 67.77\n",
      "[28,    91] loss: 0.79551, train_accuracy: 73.44\n",
      "duration: 112 s - train loss: 0.89705 - train accuracy: 68.87 - validation loss: 0.56953 - validation accuracy: 80.35 \n",
      "[29,     1] loss: 0.77083, train_accuracy: 74.02\n",
      "[29,    11] loss: 0.98906, train_accuracy: 63.28\n",
      "[29,    21] loss: 0.83645, train_accuracy: 71.29\n",
      "[29,    31] loss: 0.92336, train_accuracy: 67.19\n",
      "[29,    41] loss: 0.81758, train_accuracy: 70.12\n",
      "[29,    51] loss: 0.81424, train_accuracy: 71.88\n",
      "[29,    61] loss: 0.84115, train_accuracy: 70.31\n",
      "[29,    71] loss: 0.79535, train_accuracy: 71.68\n",
      "[29,    81] loss: 0.87134, train_accuracy: 68.55\n",
      "[29,    91] loss: 0.84242, train_accuracy: 70.31\n",
      "duration: 112 s - train loss: 0.83944 - train accuracy: 70.82 - validation loss: 0.59280 - validation accuracy: 80.14 \n",
      "[30,     1] loss: 0.78950, train_accuracy: 72.66\n",
      "[30,    11] loss: 0.76189, train_accuracy: 71.88\n",
      "[30,    21] loss: 0.85629, train_accuracy: 69.53\n",
      "[30,    31] loss: 0.81899, train_accuracy: 72.07\n",
      "[30,    41] loss: 0.86946, train_accuracy: 68.75\n",
      "[30,    51] loss: 0.76574, train_accuracy: 72.66\n",
      "[30,    61] loss: 0.81240, train_accuracy: 69.53\n",
      "[30,    71] loss: 0.86238, train_accuracy: 68.16\n",
      "[30,    81] loss: 0.78955, train_accuracy: 74.61\n",
      "[30,    91] loss: 0.81991, train_accuracy: 75.00\n",
      "duration: 111 s - train loss: 0.82267 - train accuracy: 71.39 - validation loss: 0.57147 - validation accuracy: 80.21 \n",
      "[31,     1] loss: 0.80085, train_accuracy: 71.68\n",
      "[31,    11] loss: 0.78518, train_accuracy: 71.09\n",
      "[31,    21] loss: 0.79813, train_accuracy: 71.88\n",
      "[31,    31] loss: 0.82550, train_accuracy: 71.29\n",
      "[31,    41] loss: 0.75392, train_accuracy: 74.41\n",
      "[31,    51] loss: 0.83030, train_accuracy: 73.24\n",
      "[31,    61] loss: 0.80139, train_accuracy: 70.51\n",
      "[31,    71] loss: 0.76203, train_accuracy: 72.66\n",
      "[31,    81] loss: 0.79803, train_accuracy: 72.85\n",
      "[31,    91] loss: 0.76731, train_accuracy: 71.88\n",
      "duration: 173 s - train loss: 0.81343 - train accuracy: 71.76 - validation loss: 0.58798 - validation accuracy: 80.76 \n",
      "[32,     1] loss: 0.79759, train_accuracy: 74.80\n",
      "[32,    11] loss: 0.80601, train_accuracy: 71.88\n",
      "[32,    21] loss: 0.74265, train_accuracy: 74.80\n",
      "[32,    31] loss: 0.79083, train_accuracy: 73.44\n",
      "[32,    41] loss: 0.86469, train_accuracy: 70.31\n",
      "[32,    51] loss: 0.77083, train_accuracy: 73.83\n",
      "[32,    61] loss: 0.80348, train_accuracy: 71.88\n",
      "[32,    71] loss: 0.72721, train_accuracy: 75.59\n",
      "[32,    81] loss: 0.76369, train_accuracy: 72.66\n",
      "[32,    91] loss: 0.73656, train_accuracy: 74.02\n",
      "duration: 216 s - train loss: 0.78318 - train accuracy: 72.87 - validation loss: 0.53182 - validation accuracy: 81.86 \n",
      "[33,     1] loss: 0.76189, train_accuracy: 72.66\n",
      "[33,    11] loss: 0.79392, train_accuracy: 71.48\n",
      "[33,    21] loss: 0.83584, train_accuracy: 72.07\n",
      "[33,    31] loss: 0.77246, train_accuracy: 74.02\n",
      "[33,    41] loss: 0.75790, train_accuracy: 73.83\n",
      "[33,    51] loss: 0.74443, train_accuracy: 73.44\n",
      "[33,    61] loss: 0.72668, train_accuracy: 75.59\n",
      "[33,    71] loss: 0.76572, train_accuracy: 73.83\n",
      "[33,    81] loss: 0.82953, train_accuracy: 69.73\n",
      "[33,    91] loss: 0.73148, train_accuracy: 76.76\n",
      "duration: 213 s - train loss: 0.77467 - train accuracy: 73.09 - validation loss: 0.53625 - validation accuracy: 82.11 \n",
      "[34,     1] loss: 0.81369, train_accuracy: 71.09\n",
      "[34,    11] loss: 0.72274, train_accuracy: 72.27\n",
      "[34,    21] loss: 0.73250, train_accuracy: 74.61\n",
      "[34,    31] loss: 0.80091, train_accuracy: 69.14\n",
      "[34,    41] loss: 0.74219, train_accuracy: 74.80\n",
      "[34,    51] loss: 0.84145, train_accuracy: 70.51\n",
      "[34,    61] loss: 0.67428, train_accuracy: 76.95\n",
      "[34,    71] loss: 0.82180, train_accuracy: 73.24\n",
      "[34,    81] loss: 0.74410, train_accuracy: 75.78\n",
      "[34,    91] loss: 0.85328, train_accuracy: 72.07\n",
      "duration: 213 s - train loss: 0.75510 - train accuracy: 73.69 - validation loss: 0.53147 - validation accuracy: 82.32 \n",
      "[35,     1] loss: 0.78030, train_accuracy: 73.05\n",
      "[35,    11] loss: 0.86043, train_accuracy: 69.73\n",
      "[35,    21] loss: 0.64884, train_accuracy: 77.73\n",
      "[35,    31] loss: 0.79402, train_accuracy: 70.31\n",
      "[35,    41] loss: 0.75570, train_accuracy: 74.80\n",
      "[35,    51] loss: 0.72379, train_accuracy: 73.63\n",
      "[35,    61] loss: 0.70263, train_accuracy: 76.37\n",
      "[35,    71] loss: 0.78984, train_accuracy: 74.41\n",
      "[35,    81] loss: 0.78120, train_accuracy: 70.51\n",
      "[35,    91] loss: 0.72330, train_accuracy: 73.05\n",
      "duration: 111 s - train loss: 0.74949 - train accuracy: 73.70 - validation loss: 0.59928 - validation accuracy: 80.69 \n",
      "[36,     1] loss: 0.76668, train_accuracy: 76.76\n",
      "[36,    11] loss: 0.77328, train_accuracy: 71.68\n",
      "[36,    21] loss: 0.73104, train_accuracy: 74.61\n",
      "[36,    31] loss: 0.76283, train_accuracy: 74.41\n",
      "[36,    41] loss: 0.71629, train_accuracy: 74.80\n",
      "[36,    51] loss: 0.72134, train_accuracy: 74.80\n",
      "[36,    61] loss: 0.78888, train_accuracy: 71.48\n",
      "[36,    71] loss: 0.87350, train_accuracy: 72.07\n",
      "[36,    81] loss: 0.74856, train_accuracy: 74.02\n",
      "[36,    91] loss: 0.69574, train_accuracy: 77.34\n",
      "duration: 111 s - train loss: 0.75722 - train accuracy: 73.64 - validation loss: 0.48710 - validation accuracy: 83.47 \n",
      "[37,     1] loss: 0.73025, train_accuracy: 75.78\n",
      "[37,    11] loss: 0.71499, train_accuracy: 75.59\n",
      "[37,    21] loss: 0.67976, train_accuracy: 77.15\n",
      "[37,    31] loss: 0.72781, train_accuracy: 74.61\n",
      "[37,    41] loss: 0.74880, train_accuracy: 74.22\n",
      "[37,    51] loss: 0.72640, train_accuracy: 74.41\n",
      "[37,    61] loss: 0.71610, train_accuracy: 76.17\n",
      "[37,    71] loss: 0.79151, train_accuracy: 72.07\n",
      "[37,    81] loss: 0.74447, train_accuracy: 73.44\n",
      "[37,    91] loss: 0.69111, train_accuracy: 73.44\n",
      "duration: 112 s - train loss: 0.73968 - train accuracy: 74.23 - validation loss: 0.48068 - validation accuracy: 83.97 \n",
      "[38,     1] loss: 0.71245, train_accuracy: 73.83\n",
      "[38,    11] loss: 0.67295, train_accuracy: 75.78\n",
      "[38,    21] loss: 0.75831, train_accuracy: 72.66\n",
      "[38,    31] loss: 0.76445, train_accuracy: 72.27\n",
      "[38,    41] loss: 0.81550, train_accuracy: 72.07\n",
      "[38,    51] loss: 0.72981, train_accuracy: 74.61\n",
      "[38,    61] loss: 0.74796, train_accuracy: 74.02\n",
      "[38,    71] loss: 0.64306, train_accuracy: 77.93\n",
      "[38,    81] loss: 0.82237, train_accuracy: 71.09\n",
      "[38,    91] loss: 0.77640, train_accuracy: 71.88\n",
      "duration: 112 s - train loss: 0.72230 - train accuracy: 74.78 - validation loss: 0.48879 - validation accuracy: 83.18 \n",
      "[39,     1] loss: 0.72950, train_accuracy: 74.02\n",
      "[39,    11] loss: 0.65188, train_accuracy: 79.49\n",
      "[39,    21] loss: 0.63773, train_accuracy: 77.73\n",
      "[39,    31] loss: 0.74071, train_accuracy: 74.22\n",
      "[39,    41] loss: 0.64800, train_accuracy: 75.98\n",
      "[39,    51] loss: 0.64309, train_accuracy: 78.32\n",
      "[39,    61] loss: 0.68174, train_accuracy: 76.17\n",
      "[39,    71] loss: 0.68961, train_accuracy: 75.00\n",
      "[39,    81] loss: 0.75958, train_accuracy: 73.63\n",
      "[39,    91] loss: 0.72412, train_accuracy: 74.61\n",
      "duration: 111 s - train loss: 0.71410 - train accuracy: 75.34 - validation loss: 0.48470 - validation accuracy: 83.88 \n",
      "[40,     1] loss: 0.72449, train_accuracy: 75.98\n",
      "[40,    11] loss: 0.73195, train_accuracy: 74.02\n",
      "[40,    21] loss: 0.76799, train_accuracy: 72.46\n",
      "[40,    31] loss: 0.72279, train_accuracy: 75.59\n",
      "[40,    41] loss: 0.56114, train_accuracy: 81.25\n",
      "[40,    51] loss: 0.70518, train_accuracy: 77.73\n",
      "[40,    61] loss: 0.70476, train_accuracy: 76.37\n",
      "[40,    71] loss: 0.76718, train_accuracy: 74.80\n",
      "[40,    81] loss: 0.72891, train_accuracy: 74.02\n",
      "[40,    91] loss: 0.70045, train_accuracy: 74.22\n",
      "duration: 159 s - train loss: 0.69786 - train accuracy: 75.74 - validation loss: 0.47492 - validation accuracy: 83.89 \n",
      "[41,     1] loss: 0.70050, train_accuracy: 76.37\n",
      "[41,    11] loss: 0.64502, train_accuracy: 76.95\n",
      "[41,    21] loss: 0.64203, train_accuracy: 77.15\n",
      "[41,    31] loss: 0.78987, train_accuracy: 72.85\n",
      "[41,    41] loss: 0.71593, train_accuracy: 75.78\n",
      "[41,    51] loss: 0.70654, train_accuracy: 74.61\n",
      "[41,    61] loss: 0.71298, train_accuracy: 74.41\n",
      "[41,    71] loss: 0.65005, train_accuracy: 79.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41,    81] loss: 0.66850, train_accuracy: 77.54\n",
      "[41,    91] loss: 0.60663, train_accuracy: 80.27\n",
      "duration: 216 s - train loss: 0.69818 - train accuracy: 75.78 - validation loss: 0.48014 - validation accuracy: 83.42 \n",
      "[42,     1] loss: 0.66767, train_accuracy: 78.12\n",
      "[42,    11] loss: 0.75834, train_accuracy: 72.46\n",
      "[42,    21] loss: 0.72143, train_accuracy: 75.20\n",
      "[42,    31] loss: 0.63240, train_accuracy: 79.69\n",
      "[42,    41] loss: 0.66273, train_accuracy: 75.98\n",
      "[42,    51] loss: 0.66702, train_accuracy: 75.20\n",
      "[42,    61] loss: 0.66512, train_accuracy: 75.20\n",
      "[42,    71] loss: 0.73327, train_accuracy: 76.76\n",
      "[42,    81] loss: 0.70746, train_accuracy: 76.95\n",
      "[42,    91] loss: 0.66920, train_accuracy: 76.17\n",
      "duration: 214 s - train loss: 0.68652 - train accuracy: 75.96 - validation loss: 0.47199 - validation accuracy: 84.01 \n",
      "[43,     1] loss: 0.59145, train_accuracy: 78.12\n",
      "[43,    11] loss: 0.72304, train_accuracy: 77.15\n",
      "[43,    21] loss: 0.64328, train_accuracy: 76.17\n",
      "[43,    31] loss: 0.65439, train_accuracy: 78.32\n",
      "[43,    41] loss: 0.71260, train_accuracy: 74.80\n",
      "[43,    51] loss: 0.66784, train_accuracy: 77.15\n",
      "[43,    61] loss: 0.63197, train_accuracy: 78.52\n",
      "[43,    71] loss: 0.68089, train_accuracy: 76.95\n",
      "[43,    81] loss: 0.65740, train_accuracy: 76.37\n",
      "[43,    91] loss: 0.67406, train_accuracy: 75.59\n",
      "duration: 214 s - train loss: 0.67433 - train accuracy: 76.24 - validation loss: 0.44937 - validation accuracy: 84.52 \n",
      "[44,     1] loss: 0.64266, train_accuracy: 77.15\n",
      "[44,    11] loss: 0.64709, train_accuracy: 75.78\n",
      "[44,    21] loss: 0.66433, train_accuracy: 75.78\n",
      "[44,    31] loss: 0.77158, train_accuracy: 73.83\n",
      "[44,    41] loss: 0.80356, train_accuracy: 70.70\n",
      "[44,    51] loss: 0.57077, train_accuracy: 79.88\n",
      "[44,    61] loss: 0.72340, train_accuracy: 75.98\n",
      "[44,    71] loss: 0.70972, train_accuracy: 76.37\n",
      "[44,    81] loss: 0.67345, train_accuracy: 75.78\n",
      "[44,    91] loss: 0.67096, train_accuracy: 76.56\n",
      "duration: 215 s - train loss: 0.67362 - train accuracy: 76.78 - validation loss: 0.46296 - validation accuracy: 84.25 \n",
      "[45,     1] loss: 0.61823, train_accuracy: 77.15\n",
      "[45,    11] loss: 0.63767, train_accuracy: 77.93\n",
      "[45,    21] loss: 0.69510, train_accuracy: 76.37\n",
      "[45,    31] loss: 0.66459, train_accuracy: 75.98\n",
      "[45,    41] loss: 0.64609, train_accuracy: 76.17\n",
      "[45,    51] loss: 0.67650, train_accuracy: 75.59\n",
      "[45,    61] loss: 0.63483, train_accuracy: 77.15\n",
      "[45,    71] loss: 0.74299, train_accuracy: 73.63\n",
      "[45,    81] loss: 0.64482, train_accuracy: 79.49\n",
      "[45,    91] loss: 0.62060, train_accuracy: 78.71\n",
      "duration: 214 s - train loss: 0.65803 - train accuracy: 76.87 - validation loss: 0.44740 - validation accuracy: 84.62 \n",
      "[46,     1] loss: 0.65909, train_accuracy: 77.15\n",
      "[46,    11] loss: 0.64125, train_accuracy: 76.56\n",
      "[46,    21] loss: 0.75067, train_accuracy: 73.05\n",
      "[46,    31] loss: 0.67298, train_accuracy: 74.02\n",
      "[46,    41] loss: 0.62173, train_accuracy: 79.49\n",
      "[46,    51] loss: 0.66296, train_accuracy: 77.54\n",
      "[46,    61] loss: 0.64943, train_accuracy: 75.78\n",
      "[46,    71] loss: 0.68142, train_accuracy: 76.56\n",
      "[46,    81] loss: 0.65488, train_accuracy: 76.76\n",
      "[46,    91] loss: 0.65920, train_accuracy: 76.76\n",
      "duration: 214 s - train loss: 0.65983 - train accuracy: 76.94 - validation loss: 0.44027 - validation accuracy: 85.37 \n",
      "[47,     1] loss: 0.59108, train_accuracy: 78.91\n",
      "[47,    11] loss: 0.60543, train_accuracy: 77.54\n",
      "[47,    21] loss: 0.66010, train_accuracy: 76.76\n",
      "[47,    31] loss: 0.63743, train_accuracy: 77.34\n",
      "[47,    41] loss: 0.61987, train_accuracy: 76.95\n",
      "[47,    51] loss: 0.64175, train_accuracy: 78.91\n",
      "[47,    61] loss: 0.59804, train_accuracy: 78.52\n",
      "[47,    71] loss: 0.67876, train_accuracy: 76.37\n",
      "[47,    81] loss: 0.59391, train_accuracy: 80.66\n",
      "[47,    91] loss: 0.62341, train_accuracy: 80.27\n",
      "duration: 169 s - train loss: 0.64250 - train accuracy: 77.53 - validation loss: 0.47255 - validation accuracy: 84.02 \n",
      "[48,     1] loss: 0.68459, train_accuracy: 74.61\n",
      "[48,    11] loss: 0.61566, train_accuracy: 78.32\n",
      "[48,    21] loss: 0.65881, train_accuracy: 75.98\n",
      "[48,    31] loss: 0.69840, train_accuracy: 75.20\n",
      "[48,    41] loss: 0.66855, train_accuracy: 76.37\n",
      "[48,    51] loss: 0.63010, train_accuracy: 78.32\n",
      "[48,    61] loss: 0.58479, train_accuracy: 78.32\n",
      "[48,    71] loss: 0.64991, train_accuracy: 78.91\n",
      "[48,    81] loss: 0.73725, train_accuracy: 75.20\n",
      "[48,    91] loss: 0.63199, train_accuracy: 77.34\n",
      "duration: 111 s - train loss: 0.64515 - train accuracy: 77.43 - validation loss: 0.44269 - validation accuracy: 85.08 \n",
      "[49,     1] loss: 0.64823, train_accuracy: 77.15\n",
      "[49,    11] loss: 0.67482, train_accuracy: 77.15\n",
      "[49,    21] loss: 0.61155, train_accuracy: 78.32\n",
      "[49,    31] loss: 0.57354, train_accuracy: 79.30\n",
      "[49,    41] loss: 0.68741, train_accuracy: 74.61\n",
      "[49,    51] loss: 0.58542, train_accuracy: 81.64\n",
      "[49,    61] loss: 0.65512, train_accuracy: 77.34\n",
      "[49,    71] loss: 0.64373, train_accuracy: 78.12\n",
      "[49,    81] loss: 0.61660, train_accuracy: 77.54\n",
      "[49,    91] loss: 0.60918, train_accuracy: 79.10\n",
      "duration: 111 s - train loss: 0.63714 - train accuracy: 77.90 - validation loss: 0.44760 - validation accuracy: 85.07 \n",
      "[50,     1] loss: 0.56829, train_accuracy: 79.69\n",
      "[50,    11] loss: 0.63039, train_accuracy: 78.32\n",
      "[50,    21] loss: 0.65681, train_accuracy: 76.56\n",
      "[50,    31] loss: 0.61731, train_accuracy: 79.10\n",
      "[50,    41] loss: 0.59747, train_accuracy: 79.10\n",
      "[50,    51] loss: 0.56517, train_accuracy: 80.08\n",
      "[50,    61] loss: 0.63486, train_accuracy: 78.12\n",
      "[50,    71] loss: 0.65670, train_accuracy: 77.34\n",
      "[50,    81] loss: 0.58461, train_accuracy: 78.91\n",
      "[50,    91] loss: 0.62583, train_accuracy: 78.71\n",
      "duration: 140 s - train loss: 0.63597 - train accuracy: 77.85 - validation loss: 0.43904 - validation accuracy: 85.59 \n",
      "[51,     1] loss: 0.71588, train_accuracy: 74.80\n",
      "[51,    11] loss: 0.73587, train_accuracy: 75.00\n",
      "[51,    21] loss: 0.68406, train_accuracy: 76.76\n",
      "[51,    31] loss: 0.57686, train_accuracy: 80.66\n",
      "[51,    41] loss: 0.60145, train_accuracy: 77.73\n",
      "[51,    51] loss: 0.69646, train_accuracy: 75.39\n",
      "[51,    61] loss: 0.63457, train_accuracy: 76.56\n",
      "[51,    71] loss: 0.58741, train_accuracy: 79.69\n",
      "[51,    81] loss: 0.73176, train_accuracy: 75.00\n",
      "[51,    91] loss: 0.58080, train_accuracy: 81.64\n",
      "duration: 140 s - train loss: 0.62899 - train accuracy: 78.11 - validation loss: 0.43138 - validation accuracy: 85.32 \n",
      "[52,     1] loss: 0.60020, train_accuracy: 80.08\n",
      "[52,    11] loss: 0.65267, train_accuracy: 75.39\n",
      "[52,    21] loss: 0.64900, train_accuracy: 75.98\n",
      "[52,    31] loss: 0.57730, train_accuracy: 79.88\n",
      "[52,    41] loss: 0.72242, train_accuracy: 75.20\n",
      "[52,    51] loss: 0.63993, train_accuracy: 79.10\n",
      "[52,    61] loss: 0.59068, train_accuracy: 80.08\n",
      "[52,    71] loss: 0.56855, train_accuracy: 80.66\n",
      "[52,    81] loss: 0.60754, train_accuracy: 77.54\n",
      "[52,    91] loss: 0.58441, train_accuracy: 78.71\n",
      "duration: 111 s - train loss: 0.61674 - train accuracy: 78.41 - validation loss: 0.46227 - validation accuracy: 84.91 \n",
      "[53,     1] loss: 0.61907, train_accuracy: 76.37\n",
      "[53,    11] loss: 0.67450, train_accuracy: 76.37\n",
      "[53,    21] loss: 0.67332, train_accuracy: 75.78\n",
      "[53,    31] loss: 0.68337, train_accuracy: 77.93\n",
      "[53,    41] loss: 0.56770, train_accuracy: 78.91\n",
      "[53,    51] loss: 0.71138, train_accuracy: 75.39\n",
      "[53,    61] loss: 0.60887, train_accuracy: 80.27\n",
      "[53,    71] loss: 0.64957, train_accuracy: 76.76\n",
      "[53,    81] loss: 0.58366, train_accuracy: 77.34\n",
      "[53,    91] loss: 0.55932, train_accuracy: 81.05\n",
      "duration: 112 s - train loss: 0.61221 - train accuracy: 78.54 - validation loss: 0.41850 - validation accuracy: 86.05 \n",
      "[54,     1] loss: 0.62388, train_accuracy: 78.91\n",
      "[54,    11] loss: 0.65334, train_accuracy: 77.54\n",
      "[54,    21] loss: 0.62665, train_accuracy: 78.32\n",
      "[54,    31] loss: 0.64841, train_accuracy: 76.56\n",
      "[54,    41] loss: 0.57511, train_accuracy: 80.66\n",
      "[54,    51] loss: 0.69484, train_accuracy: 74.80\n",
      "[54,    61] loss: 0.57277, train_accuracy: 78.91\n",
      "[54,    71] loss: 0.63846, train_accuracy: 77.54\n",
      "[54,    81] loss: 0.54544, train_accuracy: 82.23\n",
      "[54,    91] loss: 0.57128, train_accuracy: 79.88\n",
      "duration: 112 s - train loss: 0.61325 - train accuracy: 78.56 - validation loss: 0.39873 - validation accuracy: 86.54 \n",
      "[55,     1] loss: 0.58420, train_accuracy: 78.32\n",
      "[55,    11] loss: 0.62269, train_accuracy: 81.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55,    21] loss: 0.51613, train_accuracy: 81.84\n",
      "[55,    31] loss: 0.57834, train_accuracy: 80.08\n",
      "[55,    41] loss: 0.49685, train_accuracy: 83.59\n",
      "[55,    51] loss: 0.62625, train_accuracy: 78.32\n",
      "[55,    61] loss: 0.50139, train_accuracy: 81.45\n",
      "[55,    71] loss: 0.59293, train_accuracy: 78.12\n",
      "[55,    81] loss: 0.67078, train_accuracy: 75.59\n",
      "[55,    91] loss: 0.59281, train_accuracy: 78.32\n",
      "duration: 111 s - train loss: 0.59523 - train accuracy: 79.27 - validation loss: 0.39251 - validation accuracy: 87.01 \n",
      "[56,     1] loss: 0.59268, train_accuracy: 78.12\n",
      "[56,    11] loss: 0.54397, train_accuracy: 78.91\n",
      "[56,    21] loss: 0.57059, train_accuracy: 82.23\n",
      "[56,    31] loss: 0.52470, train_accuracy: 81.84\n",
      "[56,    41] loss: 0.58947, train_accuracy: 79.30\n",
      "[56,    51] loss: 0.68067, train_accuracy: 74.61\n",
      "[56,    61] loss: 0.58225, train_accuracy: 80.66\n",
      "[56,    71] loss: 0.58904, train_accuracy: 80.86\n",
      "[56,    81] loss: 0.57746, train_accuracy: 78.71\n",
      "[56,    91] loss: 0.67945, train_accuracy: 75.78\n",
      "duration: 111 s - train loss: 0.59859 - train accuracy: 79.11 - validation loss: 0.41909 - validation accuracy: 86.16 \n",
      "[57,     1] loss: 0.61120, train_accuracy: 77.93\n",
      "[57,    11] loss: 0.69536, train_accuracy: 75.39\n",
      "[57,    21] loss: 0.54104, train_accuracy: 81.64\n",
      "[57,    31] loss: 0.58872, train_accuracy: 79.30\n",
      "[57,    41] loss: 0.63772, train_accuracy: 76.76\n",
      "[57,    51] loss: 0.64021, train_accuracy: 78.52\n",
      "[57,    61] loss: 0.67317, train_accuracy: 77.54\n",
      "[57,    71] loss: 0.65103, train_accuracy: 76.95\n",
      "[57,    81] loss: 0.58123, train_accuracy: 78.12\n",
      "[57,    91] loss: 0.59467, train_accuracy: 78.32\n",
      "duration: 112 s - train loss: 0.60152 - train accuracy: 79.08 - validation loss: 0.41872 - validation accuracy: 85.99 \n",
      "[58,     1] loss: 0.58848, train_accuracy: 79.88\n",
      "[58,    11] loss: 0.56866, train_accuracy: 78.91\n",
      "[58,    21] loss: 0.60135, train_accuracy: 79.10\n",
      "[58,    31] loss: 0.62497, train_accuracy: 77.73\n",
      "[58,    41] loss: 0.61468, train_accuracy: 79.10\n",
      "[58,    51] loss: 0.56909, train_accuracy: 81.64\n",
      "[58,    61] loss: 0.57934, train_accuracy: 78.71\n",
      "[58,    71] loss: 0.62299, train_accuracy: 75.59\n",
      "[58,    81] loss: 0.71801, train_accuracy: 72.27\n",
      "[58,    91] loss: 0.54117, train_accuracy: 80.86\n",
      "duration: 111 s - train loss: 0.59350 - train accuracy: 79.21 - validation loss: 0.41467 - validation accuracy: 86.05 \n",
      "[59,     1] loss: 0.60954, train_accuracy: 75.78\n",
      "[59,    11] loss: 0.58378, train_accuracy: 80.66\n",
      "[59,    21] loss: 0.57350, train_accuracy: 79.10\n",
      "[59,    31] loss: 0.51726, train_accuracy: 81.45\n",
      "[59,    41] loss: 0.62369, train_accuracy: 77.15\n",
      "[59,    51] loss: 0.58480, train_accuracy: 77.34\n",
      "[59,    61] loss: 0.49530, train_accuracy: 82.23\n",
      "[59,    71] loss: 0.50381, train_accuracy: 83.01\n",
      "[59,    81] loss: 0.60017, train_accuracy: 78.52\n",
      "[59,    91] loss: 0.75547, train_accuracy: 77.93\n",
      "duration: 112 s - train loss: 0.58345 - train accuracy: 79.62 - validation loss: 0.40794 - validation accuracy: 86.46 \n",
      "[60,     1] loss: 0.56758, train_accuracy: 79.49\n",
      "[60,    11] loss: 0.58841, train_accuracy: 78.71\n",
      "[60,    21] loss: 0.52677, train_accuracy: 81.25\n",
      "[60,    31] loss: 0.51263, train_accuracy: 83.01\n",
      "[60,    41] loss: 0.55074, train_accuracy: 79.69\n",
      "[60,    51] loss: 0.60496, train_accuracy: 78.71\n",
      "[60,    61] loss: 0.56278, train_accuracy: 81.25\n",
      "[60,    71] loss: 0.60570, train_accuracy: 77.73\n",
      "[60,    81] loss: 0.57234, train_accuracy: 79.10\n",
      "[60,    91] loss: 0.59084, train_accuracy: 79.10\n",
      "duration: 111 s - train loss: 0.58166 - train accuracy: 79.94 - validation loss: 0.38731 - validation accuracy: 87.12 \n",
      "[61,     1] loss: 0.66052, train_accuracy: 78.12\n",
      "[61,    11] loss: 0.56375, train_accuracy: 81.64\n",
      "[61,    21] loss: 0.61841, train_accuracy: 76.95\n",
      "[61,    31] loss: 0.57941, train_accuracy: 83.20\n",
      "[61,    41] loss: 0.52646, train_accuracy: 81.05\n",
      "[61,    51] loss: 0.55935, train_accuracy: 79.69\n",
      "[61,    61] loss: 0.61881, train_accuracy: 78.32\n",
      "[61,    71] loss: 0.61018, train_accuracy: 79.10\n",
      "[61,    81] loss: 0.56495, train_accuracy: 78.71\n",
      "[61,    91] loss: 0.50209, train_accuracy: 80.86\n",
      "duration: 111 s - train loss: 0.58008 - train accuracy: 79.80 - validation loss: 0.41366 - validation accuracy: 86.12 \n",
      "[62,     1] loss: 0.54266, train_accuracy: 79.49\n",
      "[62,    11] loss: 0.64108, train_accuracy: 78.32\n",
      "[63,    31] loss: 0.55809, train_accuracy: 81.45\n",
      "[63,    41] loss: 0.55132, train_accuracy: 80.27\n",
      "[63,    51] loss: 0.51925, train_accuracy: 82.42\n",
      "[63,    61] loss: 0.56024, train_accuracy: 80.86\n",
      "[63,    71] loss: 0.57147, train_accuracy: 78.12\n",
      "[63,    81] loss: 0.47361, train_accuracy: 84.18\n",
      "[63,    91] loss: 0.59184, train_accuracy: 78.91\n",
      "duration: 111 s - train loss: 0.55808 - train accuracy: 80.45 - validation loss: 0.38845 - validation accuracy: 87.16 \n",
      "[64,     1] loss: 0.49331, train_accuracy: 82.03\n",
      "[64,    11] loss: 0.53576, train_accuracy: 82.03\n",
      "[64,    21] loss: 0.59227, train_accuracy: 77.93\n",
      "[64,    31] loss: 0.56824, train_accuracy: 79.49\n",
      "[64,    41] loss: 0.51286, train_accuracy: 82.81\n",
      "[64,    51] loss: 0.52889, train_accuracy: 80.66\n",
      "[64,    61] loss: 0.55757, train_accuracy: 78.71\n",
      "[64,    71] loss: 0.57443, train_accuracy: 80.66\n",
      "[64,    81] loss: 0.58915, train_accuracy: 78.91\n",
      "[64,    91] loss: 0.56492, train_accuracy: 78.12\n",
      "duration: 111 s - train loss: 0.56601 - train accuracy: 80.19 - validation loss: 0.42023 - validation accuracy: 86.96 \n",
      "[65,     1] loss: 0.52747, train_accuracy: 81.05\n",
      "[65,    11] loss: 0.57563, train_accuracy: 79.49\n",
      "[65,    21] loss: 0.56492, train_accuracy: 79.49\n",
      "[65,    31] loss: 0.52044, train_accuracy: 83.01\n",
      "[65,    41] loss: 0.59947, train_accuracy: 78.12\n",
      "[65,    51] loss: 0.52195, train_accuracy: 81.64\n",
      "[65,    61] loss: 0.59593, train_accuracy: 79.69\n",
      "[65,    71] loss: 0.52506, train_accuracy: 81.25\n",
      "[65,    81] loss: 0.55656, train_accuracy: 80.47\n",
      "[65,    91] loss: 0.56548, train_accuracy: 81.05\n",
      "duration: 111 s - train loss: 0.56073 - train accuracy: 80.51 - validation loss: 0.39652 - validation accuracy: 87.14 \n",
      "[66,     1] loss: 0.60410, train_accuracy: 78.91\n",
      "[66,    11] loss: 0.54878, train_accuracy: 82.03\n",
      "[66,    21] loss: 0.47174, train_accuracy: 84.38\n",
      "[66,    31] loss: 0.53946, train_accuracy: 82.42\n",
      "[66,    41] loss: 0.51414, train_accuracy: 81.45\n",
      "[66,    51] loss: 0.56160, train_accuracy: 79.88\n",
      "[66,    61] loss: 0.51401, train_accuracy: 81.25\n",
      "[66,    71] loss: 0.52821, train_accuracy: 81.45\n",
      "[66,    81] loss: 0.64112, train_accuracy: 79.30\n",
      "[66,    91] loss: 0.44713, train_accuracy: 83.59\n",
      "duration: 111 s - train loss: 0.55672 - train accuracy: 80.61 - validation loss: 0.39074 - validation accuracy: 86.92 \n",
      "[67,     1] loss: 0.46892, train_accuracy: 83.79\n",
      "[67,    11] loss: 0.53222, train_accuracy: 82.23\n",
      "[67,    21] loss: 0.48865, train_accuracy: 81.84\n",
      "[67,    31] loss: 0.57279, train_accuracy: 79.88\n",
      "[67,    41] loss: 0.51251, train_accuracy: 80.47\n",
      "[67,    51] loss: 0.57815, train_accuracy: 81.84\n",
      "[67,    61] loss: 0.55856, train_accuracy: 80.27\n",
      "[67,    71] loss: 0.54294, train_accuracy: 81.64\n",
      "[67,    81] loss: 0.54766, train_accuracy: 82.23\n",
      "[67,    91] loss: 0.51978, train_accuracy: 81.84\n",
      "duration: 111 s - train loss: 0.54348 - train accuracy: 81.12 - validation loss: 0.38332 - validation accuracy: 87.14 \n",
      "[68,     1] loss: 0.51998, train_accuracy: 82.23\n",
      "[68,    11] loss: 0.58659, train_accuracy: 77.73\n",
      "[68,    21] loss: 0.57735, train_accuracy: 79.30\n",
      "[68,    31] loss: 0.60296, train_accuracy: 79.10\n",
      "[68,    41] loss: 0.57376, train_accuracy: 79.10\n",
      "[68,    51] loss: 0.52149, train_accuracy: 80.86\n",
      "[68,    61] loss: 0.58251, train_accuracy: 77.54\n",
      "[68,    71] loss: 0.55377, train_accuracy: 80.27\n",
      "[68,    81] loss: 0.54297, train_accuracy: 81.25\n",
      "[68,    91] loss: 0.46751, train_accuracy: 82.42\n",
      "duration: 112 s - train loss: 0.54862 - train accuracy: 80.80 - validation loss: 0.43082 - validation accuracy: 86.23 \n",
      "[69,     1] loss: 0.53788, train_accuracy: 81.25\n",
      "[69,    11] loss: 0.51238, train_accuracy: 81.64\n",
      "[69,    21] loss: 0.58522, train_accuracy: 81.05\n",
      "[69,    31] loss: 0.54109, train_accuracy: 79.69\n",
      "[69,    41] loss: 0.52972, train_accuracy: 80.47\n",
      "[69,    51] loss: 0.46411, train_accuracy: 83.01\n",
      "[69,    61] loss: 0.58907, train_accuracy: 78.32\n",
      "[69,    71] loss: 0.59328, train_accuracy: 78.91\n",
      "[69,    81] loss: 0.49346, train_accuracy: 82.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69,    91] loss: 0.56655, train_accuracy: 79.69\n",
      "duration: 112 s - train loss: 0.53814 - train accuracy: 81.10 - validation loss: 0.37678 - validation accuracy: 88.17 \n",
      "[70,     1] loss: 0.54585, train_accuracy: 81.64\n",
      "[70,    11] loss: 0.50609, train_accuracy: 82.42\n",
      "[70,    21] loss: 0.52353, train_accuracy: 82.23\n",
      "[70,    31] loss: 0.54402, train_accuracy: 80.66\n",
      "[70,    41] loss: 0.61317, train_accuracy: 78.91\n",
      "[70,    51] loss: 0.54993, train_accuracy: 80.47\n",
      "[70,    61] loss: 0.53117, train_accuracy: 82.42\n",
      "[70,    71] loss: 0.55402, train_accuracy: 80.86\n",
      "[70,    81] loss: 0.56727, train_accuracy: 78.52\n",
      "[70,    91] loss: 0.59130, train_accuracy: 77.73\n",
      "duration: 111 s - train loss: 0.54052 - train accuracy: 81.11 - validation loss: 0.41397 - validation accuracy: 86.88 \n",
      "[71,     1] loss: 0.43406, train_accuracy: 85.35\n",
      "[71,    11] loss: 0.56734, train_accuracy: 81.25\n",
      "[71,    21] loss: 0.58946, train_accuracy: 80.47\n",
      "[71,    31] loss: 0.56712, train_accuracy: 80.66\n",
      "[71,    41] loss: 0.55704, train_accuracy: 79.69\n",
      "[71,    51] loss: 0.51187, train_accuracy: 82.42\n",
      "[71,    61] loss: 0.54380, train_accuracy: 81.45\n",
      "[71,    71] loss: 0.50191, train_accuracy: 82.23\n",
      "[71,    81] loss: 0.58949, train_accuracy: 81.45\n",
      "[71,    91] loss: 0.60455, train_accuracy: 79.10\n",
      "duration: 112 s - train loss: 0.53689 - train accuracy: 81.25 - validation loss: 0.37784 - validation accuracy: 87.55 \n",
      "[72,     1] loss: 0.52654, train_accuracy: 80.27\n",
      "[72,    11] loss: 0.50060, train_accuracy: 82.42\n",
      "[72,    21] loss: 0.47906, train_accuracy: 82.03\n",
      "[72,    31] loss: 0.54408, train_accuracy: 80.47\n",
      "[72,    41] loss: 0.59002, train_accuracy: 81.05\n",
      "[72,    51] loss: 0.47236, train_accuracy: 83.59\n",
      "[72,    61] loss: 0.55331, train_accuracy: 80.08\n",
      "[72,    71] loss: 0.54490, train_accuracy: 79.69\n",
      "[72,    81] loss: 0.50523, train_accuracy: 84.38\n",
      "[72,    91] loss: 0.52630, train_accuracy: 82.03\n",
      "duration: 112 s - train loss: 0.52395 - train accuracy: 81.79 - validation loss: 0.37741 - validation accuracy: 87.43 \n",
      "[73,     1] loss: 0.49159, train_accuracy: 82.23\n",
      "[73,    11] loss: 0.53724, train_accuracy: 81.25\n",
      "[73,    21] loss: 0.53916, train_accuracy: 81.25\n",
      "[73,    31] loss: 0.51579, train_accuracy: 81.84\n",
      "[73,    41] loss: 0.54773, train_accuracy: 80.08\n",
      "[73,    51] loss: 0.58405, train_accuracy: 80.08\n",
      "[73,    61] loss: 0.48349, train_accuracy: 82.81\n",
      "[73,    71] loss: 0.53901, train_accuracy: 80.66\n",
      "[73,    81] loss: 0.57393, train_accuracy: 79.69\n",
      "[73,    91] loss: 0.52442, train_accuracy: 83.98\n",
      "duration: 111 s - train loss: 0.52603 - train accuracy: 81.63 - validation loss: 0.39847 - validation accuracy: 87.39 \n",
      "[74,     1] loss: 0.48346, train_accuracy: 82.81\n",
      "[74,    11] loss: 0.52879, train_accuracy: 81.45\n",
      "[74,    21] loss: 0.52640, train_accuracy: 82.03\n",
      "[74,    31] loss: 0.59957, train_accuracy: 80.86\n",
      "[74,    41] loss: 0.48133, train_accuracy: 83.59\n",
      "[74,    51] loss: 0.55822, train_accuracy: 81.84\n",
      "[74,    61] loss: 0.60178, train_accuracy: 79.49\n",
      "[74,    71] loss: 0.52516, train_accuracy: 81.84\n",
      "[74,    81] loss: 0.47178, train_accuracy: 83.20\n",
      "[74,    91] loss: 0.55352, train_accuracy: 80.86\n",
      "duration: 111 s - train loss: 0.52670 - train accuracy: 81.69 - validation loss: 0.40036 - validation accuracy: 87.08 \n",
      "[75,     1] loss: 0.52570, train_accuracy: 82.03\n",
      "[75,    11] loss: 0.52563, train_accuracy: 83.01\n",
      "[75,    21] loss: 0.52265, train_accuracy: 80.27\n",
      "[75,    31] loss: 0.53728, train_accuracy: 81.25\n",
      "[75,    41] loss: 0.51019, train_accuracy: 81.64\n",
      "[75,    51] loss: 0.48073, train_accuracy: 81.84\n",
      "[75,    61] loss: 0.54820, train_accuracy: 81.25\n",
      "[75,    71] loss: 0.53780, train_accuracy: 80.86\n",
      "[75,    81] loss: 0.60801, train_accuracy: 79.69\n",
      "[75,    91] loss: 0.49245, train_accuracy: 84.57\n",
      "duration: 111 s - train loss: 0.52624 - train accuracy: 81.60 - validation loss: 0.38282 - validation accuracy: 87.24 \n",
      "[76,     1] loss: 0.47772, train_accuracy: 82.81\n",
      "[76,    11] loss: 0.48832, train_accuracy: 84.96\n",
      "[76,    21] loss: 0.50542, train_accuracy: 80.08\n",
      "[76,    31] loss: 0.52143, train_accuracy: 82.81\n",
      "[76,    41] loss: 0.45300, train_accuracy: 83.79\n",
      "[76,    51] loss: 0.52153, train_accuracy: 82.03\n",
      "[76,    61] loss: 0.45354, train_accuracy: 85.94\n",
      "[76,    71] loss: 0.54127, train_accuracy: 80.27\n",
      "[76,    81] loss: 0.51693, train_accuracy: 80.66\n",
      "[76,    91] loss: 0.63182, train_accuracy: 77.93\n",
      "duration: 111 s - train loss: 0.52423 - train accuracy: 81.73 - validation loss: 0.35910 - validation accuracy: 87.82 \n",
      "[77,     1] loss: 0.54547, train_accuracy: 83.01\n",
      "[77,    11] loss: 0.53895, train_accuracy: 80.86\n",
      "[77,    21] loss: 0.57133, train_accuracy: 80.27\n",
      "[77,    31] loss: 0.53977, train_accuracy: 79.69\n",
      "[77,    41] loss: 0.52685, train_accuracy: 82.03\n",
      "[77,    51] loss: 0.54255, train_accuracy: 82.03\n",
      "[77,    61] loss: 0.51350, train_accuracy: 81.64\n",
      "[77,    71] loss: 0.53755, train_accuracy: 81.25\n",
      "[77,    81] loss: 0.53067, train_accuracy: 82.62\n",
      "[77,    91] loss: 0.54170, train_accuracy: 80.47\n",
      "duration: 112 s - train loss: 0.51873 - train accuracy: 82.08 - validation loss: 0.38290 - validation accuracy: 87.73 \n",
      "[78,     1] loss: 0.56705, train_accuracy: 79.49\n",
      "[78,    11] loss: 0.51144, train_accuracy: 81.45\n",
      "[78,    21] loss: 0.49743, train_accuracy: 83.01\n",
      "[78,    31] loss: 0.51554, train_accuracy: 80.66\n",
      "[78,    41] loss: 0.50944, train_accuracy: 80.66\n",
      "[78,    51] loss: 0.51402, train_accuracy: 81.25\n",
      "[78,    61] loss: 0.59791, train_accuracy: 79.10\n",
      "[78,    71] loss: 0.55024, train_accuracy: 81.05\n",
      "[78,    81] loss: 0.52061, train_accuracy: 82.23\n",
      "[78,    91] loss: 0.49701, train_accuracy: 82.62\n",
      "duration: 111 s - train loss: 0.52082 - train accuracy: 81.89 - validation loss: 0.35859 - validation accuracy: 87.89 \n",
      "[79,     1] loss: 0.52140, train_accuracy: 82.62\n",
      "[79,    11] loss: 0.51747, train_accuracy: 83.40\n",
      "[79,    21] loss: 0.54095, train_accuracy: 80.66\n",
      "[79,    31] loss: 0.55112, train_accuracy: 82.81\n",
      "[79,    41] loss: 0.54849, train_accuracy: 81.84\n",
      "[79,    51] loss: 0.48448, train_accuracy: 82.62\n",
      "[79,    61] loss: 0.47213, train_accuracy: 83.79\n",
      "[79,    71] loss: 0.40915, train_accuracy: 85.94\n",
      "[79,    81] loss: 0.49676, train_accuracy: 80.66\n",
      "[79,    91] loss: 0.51284, train_accuracy: 81.45\n",
      "duration: 111 s - train loss: 0.50967 - train accuracy: 82.20 - validation loss: 0.37633 - validation accuracy: 87.88 \n",
      "[80,     1] loss: 0.53001, train_accuracy: 78.91\n",
      "[80,    11] loss: 0.51285, train_accuracy: 82.42\n",
      "[80,    21] loss: 0.55316, train_accuracy: 80.08\n",
      "[80,    31] loss: 0.50463, train_accuracy: 81.05\n",
      "[80,    41] loss: 0.47236, train_accuracy: 83.98\n",
      "[80,    51] loss: 0.45379, train_accuracy: 82.81\n",
      "[80,    61] loss: 0.55001, train_accuracy: 80.47\n",
      "[80,    71] loss: 0.53436, train_accuracy: 82.03\n",
      "[80,    81] loss: 0.56115, train_accuracy: 81.45\n",
      "[80,    91] loss: 0.49930, train_accuracy: 80.66\n",
      "duration: 111 s - train loss: 0.50779 - train accuracy: 82.06 - validation loss: 0.37260 - validation accuracy: 88.33 \n",
      "[81,     1] loss: 0.52089, train_accuracy: 80.86\n",
      "[81,    11] loss: 0.55133, train_accuracy: 79.10\n",
      "[81,    21] loss: 0.47556, train_accuracy: 82.81\n",
      "[81,    31] loss: 0.43507, train_accuracy: 85.16\n",
      "[81,    41] loss: 0.52436, train_accuracy: 82.81\n",
      "[81,    51] loss: 0.49537, train_accuracy: 83.98\n",
      "[81,    61] loss: 0.47920, train_accuracy: 83.98\n",
      "[81,    71] loss: 0.52401, train_accuracy: 80.66\n",
      "[81,    81] loss: 0.43845, train_accuracy: 84.38\n",
      "[81,    91] loss: 0.47356, train_accuracy: 82.62\n",
      "duration: 111 s - train loss: 0.50253 - train accuracy: 82.37 - validation loss: 0.36247 - validation accuracy: 88.46 \n",
      "[82,     1] loss: 0.47438, train_accuracy: 82.03\n",
      "[82,    11] loss: 0.44191, train_accuracy: 83.79\n",
      "[82,    21] loss: 0.43456, train_accuracy: 84.18\n",
      "[82,    31] loss: 0.52772, train_accuracy: 80.86\n",
      "[82,    41] loss: 0.41825, train_accuracy: 86.13\n",
      "[82,    51] loss: 0.50593, train_accuracy: 81.84\n",
      "[82,    61] loss: 0.50263, train_accuracy: 82.81\n",
      "[82,    71] loss: 0.61790, train_accuracy: 79.88\n",
      "[82,    81] loss: 0.53955, train_accuracy: 80.86\n",
      "[82,    91] loss: 0.52714, train_accuracy: 80.86\n",
      "duration: 111 s - train loss: 0.49505 - train accuracy: 82.64 - validation loss: 0.36521 - validation accuracy: 88.24 \n",
      "[83,     1] loss: 0.45447, train_accuracy: 83.98\n",
      "[83,    11] loss: 0.46098, train_accuracy: 83.59\n",
      "[83,    21] loss: 0.48986, train_accuracy: 81.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83,    31] loss: 0.52041, train_accuracy: 82.03\n",
      "[83,    41] loss: 0.44227, train_accuracy: 83.40\n",
      "[83,    51] loss: 0.49156, train_accuracy: 82.81\n",
      "[83,    61] loss: 0.52230, train_accuracy: 80.66\n",
      "[83,    71] loss: 0.44784, train_accuracy: 84.96\n",
      "[83,    81] loss: 0.51786, train_accuracy: 81.45\n",
      "[83,    91] loss: 0.45939, train_accuracy: 84.57\n",
      "duration: 111 s - train loss: 0.49330 - train accuracy: 82.74 - validation loss: 0.39903 - validation accuracy: 87.56 \n",
      "[84,     1] loss: 0.44424, train_accuracy: 84.57\n",
      "[84,    11] loss: 0.53706, train_accuracy: 79.49\n",
      "[84,    21] loss: 0.39877, train_accuracy: 84.77\n",
      "[84,    31] loss: 0.47520, train_accuracy: 83.01\n",
      "[84,    41] loss: 0.53676, train_accuracy: 80.27\n",
      "[84,    51] loss: 0.48146, train_accuracy: 83.20\n",
      "[84,    61] loss: 0.42953, train_accuracy: 83.59\n",
      "[84,    71] loss: 0.44260, train_accuracy: 84.96\n",
      "[84,    81] loss: 0.55856, train_accuracy: 79.49\n",
      "[84,    91] loss: 0.43549, train_accuracy: 85.74\n",
      "duration: 111 s - train loss: 0.48530 - train accuracy: 83.05 - validation loss: 0.36634 - validation accuracy: 88.24 \n",
      "[85,     1] loss: 0.43445, train_accuracy: 84.96\n",
      "[85,    11] loss: 0.44945, train_accuracy: 83.20\n",
      "[85,    21] loss: 0.50098, train_accuracy: 82.42\n",
      "[85,    31] loss: 0.50947, train_accuracy: 81.64\n",
      "[85,    41] loss: 0.50096, train_accuracy: 81.84\n",
      "[85,    51] loss: 0.47820, train_accuracy: 83.01\n",
      "[85,    61] loss: 0.54024, train_accuracy: 80.66\n",
      "[85,    71] loss: 0.56257, train_accuracy: 79.30\n",
      "[85,    81] loss: 0.50087, train_accuracy: 82.81\n",
      "[85,    91] loss: 0.54602, train_accuracy: 79.30\n",
      "duration: 112 s - train loss: 0.48749 - train accuracy: 83.01 - validation loss: 0.38211 - validation accuracy: 88.05 \n",
      "[86,     1] loss: 0.51485, train_accuracy: 83.20\n",
      "[86,    11] loss: 0.49426, train_accuracy: 82.81\n",
      "[86,    21] loss: 0.47619, train_accuracy: 83.20\n",
      "[86,    31] loss: 0.50780, train_accuracy: 82.62\n",
      "[86,    41] loss: 0.51238, train_accuracy: 81.45\n",
      "[86,    51] loss: 0.49335, train_accuracy: 83.01\n",
      "[86,    61] loss: 0.39619, train_accuracy: 85.94\n",
      "[86,    71] loss: 0.48718, train_accuracy: 83.20\n",
      "[86,    81] loss: 0.40925, train_accuracy: 86.33\n",
      "[86,    91] loss: 0.48217, train_accuracy: 84.18\n",
      "duration: 111 s - train loss: 0.48152 - train accuracy: 83.11 - validation loss: 0.36868 - validation accuracy: 87.99 \n",
      "[87,     1] loss: 0.38907, train_accuracy: 86.91\n",
      "[87,    11] loss: 0.45395, train_accuracy: 83.20\n",
      "[87,    21] loss: 0.46076, train_accuracy: 83.98\n",
      "[87,    31] loss: 0.49922, train_accuracy: 83.79\n",
      "[87,    41] loss: 0.54131, train_accuracy: 80.66\n",
      "[87,    51] loss: 0.51938, train_accuracy: 80.27\n",
      "[87,    61] loss: 0.64532, train_accuracy: 79.88\n",
      "[87,    71] loss: 0.51255, train_accuracy: 83.20\n",
      "[87,    81] loss: 0.50266, train_accuracy: 81.45\n",
      "[87,    91] loss: 0.49873, train_accuracy: 83.20\n",
      "duration: 111 s - train loss: 0.48402 - train accuracy: 82.99 - validation loss: 0.38955 - validation accuracy: 87.13 \n",
      "[88,     1] loss: 0.53136, train_accuracy: 83.40\n",
      "[88,    11] loss: 0.44365, train_accuracy: 84.96\n",
      "[88,    21] loss: 0.41621, train_accuracy: 84.96\n",
      "[88,    31] loss: 0.50947, train_accuracy: 80.86\n",
      "[88,    41] loss: 0.53266, train_accuracy: 82.42\n",
      "[88,    51] loss: 0.48403, train_accuracy: 84.18\n",
      "[88,    61] loss: 0.46744, train_accuracy: 82.42\n",
      "[88,    71] loss: 0.45900, train_accuracy: 83.20\n",
      "[88,    81] loss: 0.45356, train_accuracy: 82.62\n",
      "[88,    91] loss: 0.55770, train_accuracy: 81.05\n",
      "duration: 111 s - train loss: 0.48897 - train accuracy: 82.92 - validation loss: 0.36570 - validation accuracy: 87.74 \n",
      "stopped early after 10 epochs without decrease of validation loss\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_stats = model.fit_fast(train_loader, test_loader, 200, device, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.014938</td>\n",
       "      <td>20.412719</td>\n",
       "      <td>2.224216</td>\n",
       "      <td>tensor(0.2441, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.2598, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.33</td>\n",
       "      <td>191.826580</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.117979</td>\n",
       "      <td>27.771293</td>\n",
       "      <td>1.756267</td>\n",
       "      <td>tensor(0.2441, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.2598, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.62</td>\n",
       "      <td>390.593966</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.817503</td>\n",
       "      <td>35.018544</td>\n",
       "      <td>1.574313</td>\n",
       "      <td>tensor(0.2441, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.2598, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.83</td>\n",
       "      <td>594.097908</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.699194</td>\n",
       "      <td>38.853521</td>\n",
       "      <td>1.525570</td>\n",
       "      <td>tensor(0.4629, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.4766, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.40</td>\n",
       "      <td>787.746843</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.614181</td>\n",
       "      <td>42.089369</td>\n",
       "      <td>1.385516</td>\n",
       "      <td>tensor(0.4629, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.4766, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.32</td>\n",
       "      <td>982.720916</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>0.485299</td>\n",
       "      <td>83.054410</td>\n",
       "      <td>0.366336</td>\n",
       "      <td>tensor(0.8301, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.8867, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.24</td>\n",
       "      <td>12240.489929</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>0.487485</td>\n",
       "      <td>83.009805</td>\n",
       "      <td>0.382107</td>\n",
       "      <td>tensor(0.8555, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.8906, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.05</td>\n",
       "      <td>12352.496004</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>0.481521</td>\n",
       "      <td>83.107557</td>\n",
       "      <td>0.368679</td>\n",
       "      <td>tensor(0.8555, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.8906, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.99</td>\n",
       "      <td>12464.494867</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>0.484023</td>\n",
       "      <td>82.987029</td>\n",
       "      <td>0.389550</td>\n",
       "      <td>tensor(0.8555, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.8906, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.13</td>\n",
       "      <td>12576.488944</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>0.488967</td>\n",
       "      <td>82.924012</td>\n",
       "      <td>0.365702</td>\n",
       "      <td>tensor(0.8418, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.8789, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.74</td>\n",
       "      <td>12688.213916</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  train_accuracy  validation_loss  \\\n",
       "0      1    4.014938       20.412719         2.224216   \n",
       "1      2    2.117979       27.771293         1.756267   \n",
       "2      3    1.817503       35.018544         1.574313   \n",
       "3      4    1.699194       38.853521         1.525570   \n",
       "4      5    1.614181       42.089369         1.385516   \n",
       "..   ...         ...             ...              ...   \n",
       "83    84    0.485299       83.054410         0.366336   \n",
       "84    85    0.487485       83.009805         0.382107   \n",
       "85    86    0.481521       83.107557         0.368679   \n",
       "86    87    0.484023       82.987029         0.389550   \n",
       "87    88    0.488967       82.924012         0.365702   \n",
       "\n",
       "                   l_inf_robustness  l_inf_loss  \\\n",
       "0   tensor(0.2441, device='cuda:0')         NaN   \n",
       "1   tensor(0.2441, device='cuda:0')         NaN   \n",
       "2   tensor(0.2441, device='cuda:0')         NaN   \n",
       "3   tensor(0.4629, device='cuda:0')         NaN   \n",
       "4   tensor(0.4629, device='cuda:0')         NaN   \n",
       "..                              ...         ...   \n",
       "83  tensor(0.8301, device='cuda:0')         NaN   \n",
       "84  tensor(0.8555, device='cuda:0')         NaN   \n",
       "85  tensor(0.8555, device='cuda:0')         NaN   \n",
       "86  tensor(0.8555, device='cuda:0')         NaN   \n",
       "87  tensor(0.8418, device='cuda:0')         NaN   \n",
       "\n",
       "                     l_2_robustness  l_2_loss l_0_robustness  l_0_loss  \\\n",
       "0   tensor(0.2598, device='cuda:0')       NaN              0       NaN   \n",
       "1   tensor(0.2598, device='cuda:0')       NaN              0       NaN   \n",
       "2   tensor(0.2598, device='cuda:0')       NaN              0       NaN   \n",
       "3   tensor(0.4766, device='cuda:0')       NaN              0       NaN   \n",
       "4   tensor(0.4766, device='cuda:0')       NaN              0       NaN   \n",
       "..                              ...       ...            ...       ...   \n",
       "83  tensor(0.8867, device='cuda:0')       NaN              0       NaN   \n",
       "84  tensor(0.8906, device='cuda:0')       NaN              0       NaN   \n",
       "85  tensor(0.8906, device='cuda:0')       NaN              0       NaN   \n",
       "86  tensor(0.8906, device='cuda:0')       NaN              0       NaN   \n",
       "87  tensor(0.8789, device='cuda:0')       NaN              0       NaN   \n",
       "\n",
       "    validation_accuracy      duration           criterion  \\\n",
       "0                 28.33    191.826580  CrossEntropyLoss()   \n",
       "1                 37.62    390.593966  CrossEntropyLoss()   \n",
       "2                 43.83    594.097908  CrossEntropyLoss()   \n",
       "3                 46.40    787.746843  CrossEntropyLoss()   \n",
       "4                 51.32    982.720916  CrossEntropyLoss()   \n",
       "..                  ...           ...                 ...   \n",
       "83                88.24  12240.489929  CrossEntropyLoss()   \n",
       "84                88.05  12352.496004  CrossEntropyLoss()   \n",
       "85                87.99  12464.494867  CrossEntropyLoss()   \n",
       "86                87.13  12576.488944  CrossEntropyLoss()   \n",
       "87                87.74  12688.213916  CrossEntropyLoss()   \n",
       "\n",
       "                                            optimizer    method  \\\n",
       "0   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                ...       ...   \n",
       "83  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "84  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "85  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "86  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "87  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "    learning_rate batchsize  \n",
       "0             NaN       512  \n",
       "1             NaN       512  \n",
       "2             NaN       512  \n",
       "3             NaN       512  \n",
       "4             NaN       512  \n",
       "..            ...       ...  \n",
       "83            NaN       512  \n",
       "84            NaN       512  \n",
       "85            NaN       512  \n",
       "86            NaN       512  \n",
       "87            NaN       512  \n",
       "\n",
       "[88 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./saved-models/fast-double-vs-standard-experiment-standard-fast-training.pt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH='./saved-models/fast-double-vs-standard-experiment-standard-fast-training.pt'\n",
    "optimizer = train_stats['optimizer'][0]\n",
    "safe_model(PATH, model, optimizer, description='Comparing fast adversarial training with single and double updates', loss='N/A',epoch='94')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n"
     ]
    }
   ],
   "source": [
    "model = CifarResNet()\n",
    "model = load_model(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>l_inf_robustness</th>\n",
       "      <th>l_inf_loss</th>\n",
       "      <th>l_2_robustness</th>\n",
       "      <th>l_2_loss</th>\n",
       "      <th>l_0_robustness</th>\n",
       "      <th>l_0_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.014938</td>\n",
       "      <td>20.412719</td>\n",
       "      <td>2.224216</td>\n",
       "      <td>tensor(0.2441, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.2598, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.33</td>\n",
       "      <td>191.826580</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.117979</td>\n",
       "      <td>27.771293</td>\n",
       "      <td>1.756267</td>\n",
       "      <td>tensor(0.2441, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.2598, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.62</td>\n",
       "      <td>390.593966</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.817503</td>\n",
       "      <td>35.018544</td>\n",
       "      <td>1.574313</td>\n",
       "      <td>tensor(0.2441, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.2598, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.83</td>\n",
       "      <td>594.097908</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.699194</td>\n",
       "      <td>38.853521</td>\n",
       "      <td>1.525570</td>\n",
       "      <td>tensor(0.4629, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.4766, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.40</td>\n",
       "      <td>787.746843</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.614181</td>\n",
       "      <td>42.089369</td>\n",
       "      <td>1.385516</td>\n",
       "      <td>tensor(0.4629, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.4766, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.32</td>\n",
       "      <td>982.720916</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>0.485299</td>\n",
       "      <td>83.054410</td>\n",
       "      <td>0.366336</td>\n",
       "      <td>tensor(0.8301, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.8867, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.24</td>\n",
       "      <td>12240.489929</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>0.487485</td>\n",
       "      <td>83.009805</td>\n",
       "      <td>0.382107</td>\n",
       "      <td>tensor(0.8555, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.8906, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.05</td>\n",
       "      <td>12352.496004</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>0.481521</td>\n",
       "      <td>83.107557</td>\n",
       "      <td>0.368679</td>\n",
       "      <td>tensor(0.8555, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.8906, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.99</td>\n",
       "      <td>12464.494867</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>0.484023</td>\n",
       "      <td>82.987029</td>\n",
       "      <td>0.389550</td>\n",
       "      <td>tensor(0.8555, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.8906, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.13</td>\n",
       "      <td>12576.488944</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>0.488967</td>\n",
       "      <td>82.924012</td>\n",
       "      <td>0.365702</td>\n",
       "      <td>tensor(0.8418, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensor(0.8789, device='cuda:0')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.74</td>\n",
       "      <td>12688.213916</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  train_accuracy  validation_loss  \\\n",
       "0      1    4.014938       20.412719         2.224216   \n",
       "1      2    2.117979       27.771293         1.756267   \n",
       "2      3    1.817503       35.018544         1.574313   \n",
       "3      4    1.699194       38.853521         1.525570   \n",
       "4      5    1.614181       42.089369         1.385516   \n",
       "..   ...         ...             ...              ...   \n",
       "83    84    0.485299       83.054410         0.366336   \n",
       "84    85    0.487485       83.009805         0.382107   \n",
       "85    86    0.481521       83.107557         0.368679   \n",
       "86    87    0.484023       82.987029         0.389550   \n",
       "87    88    0.488967       82.924012         0.365702   \n",
       "\n",
       "                   l_inf_robustness  l_inf_loss  \\\n",
       "0   tensor(0.2441, device='cuda:0')         NaN   \n",
       "1   tensor(0.2441, device='cuda:0')         NaN   \n",
       "2   tensor(0.2441, device='cuda:0')         NaN   \n",
       "3   tensor(0.4629, device='cuda:0')         NaN   \n",
       "4   tensor(0.4629, device='cuda:0')         NaN   \n",
       "..                              ...         ...   \n",
       "83  tensor(0.8301, device='cuda:0')         NaN   \n",
       "84  tensor(0.8555, device='cuda:0')         NaN   \n",
       "85  tensor(0.8555, device='cuda:0')         NaN   \n",
       "86  tensor(0.8555, device='cuda:0')         NaN   \n",
       "87  tensor(0.8418, device='cuda:0')         NaN   \n",
       "\n",
       "                     l_2_robustness  l_2_loss l_0_robustness  l_0_loss  \\\n",
       "0   tensor(0.2598, device='cuda:0')       NaN              0       NaN   \n",
       "1   tensor(0.2598, device='cuda:0')       NaN              0       NaN   \n",
       "2   tensor(0.2598, device='cuda:0')       NaN              0       NaN   \n",
       "3   tensor(0.4766, device='cuda:0')       NaN              0       NaN   \n",
       "4   tensor(0.4766, device='cuda:0')       NaN              0       NaN   \n",
       "..                              ...       ...            ...       ...   \n",
       "83  tensor(0.8867, device='cuda:0')       NaN              0       NaN   \n",
       "84  tensor(0.8906, device='cuda:0')       NaN              0       NaN   \n",
       "85  tensor(0.8906, device='cuda:0')       NaN              0       NaN   \n",
       "86  tensor(0.8906, device='cuda:0')       NaN              0       NaN   \n",
       "87  tensor(0.8789, device='cuda:0')       NaN              0       NaN   \n",
       "\n",
       "    validation_accuracy      duration           criterion  \\\n",
       "0                 28.33    191.826580  CrossEntropyLoss()   \n",
       "1                 37.62    390.593966  CrossEntropyLoss()   \n",
       "2                 43.83    594.097908  CrossEntropyLoss()   \n",
       "3                 46.40    787.746843  CrossEntropyLoss()   \n",
       "4                 51.32    982.720916  CrossEntropyLoss()   \n",
       "..                  ...           ...                 ...   \n",
       "83                88.24  12240.489929  CrossEntropyLoss()   \n",
       "84                88.05  12352.496004  CrossEntropyLoss()   \n",
       "85                87.99  12464.494867  CrossEntropyLoss()   \n",
       "86                87.13  12576.488944  CrossEntropyLoss()   \n",
       "87                87.74  12688.213916  CrossEntropyLoss()   \n",
       "\n",
       "                                            optimizer    method  \\\n",
       "0   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "1   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "2   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "3   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "4   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "..                                                ...       ...   \n",
       "83  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "84  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "85  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "86  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "87  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard   \n",
       "\n",
       "    learning_rate batchsize  \n",
       "0             NaN       512  \n",
       "1             NaN       512  \n",
       "2             NaN       512  \n",
       "3             NaN       512  \n",
       "4             NaN       512  \n",
       "..            ...       ...  \n",
       "83            NaN       512  \n",
       "84            NaN       512  \n",
       "85            NaN       512  \n",
       "86            NaN       512  \n",
       "87            NaN       512  \n",
       "\n",
       "[88 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
