{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.models import CifarResNet, MNIST_CNN, CIFAR_CNN\n",
    "from src.helpers import evaluate_rob_accuracy, evaluate_clean_accuracy, load_model, safe_model,_evaluate_model\n",
    "from src.data_loader import load_torchvision_dataset, load_imagenette\n",
    "#from src.pruning import identify_layers, _evaluate_sparsity\n",
    "\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def load_torchvision_dataset(dataset, batchsize=512, data_augmentation=False):\n",
    "    if data_augmentation == True:\n",
    "        train_transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.RandomRotation(20),\n",
    "            torchvision.transforms.Resize(40),\n",
    "            torchvision.transforms.RandomResizedCrop(32),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),        \n",
    "        ])\n",
    "    if data_augmentation == False:\n",
    "        train_transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),        \n",
    "        ])\n",
    "    val_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    if dataset == 'MNIST':\n",
    "        train = torchvision.datasets.MNIST('./data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "        test = torchvision.datasets.MNIST('./data', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    if dataset == 'CIFAR10':\n",
    "        train = torchvision.datasets.CIFAR10('./data', train=True, transform=train_transforms, download=True)\n",
    "        test = torchvision.datasets.CIFAR10('./data', train=False, transform=val_transforms, download=True)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train,\n",
    "        batch_size=batchsize,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test,\n",
    "        batch_size=batchsize,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = load_torchvision_dataset('CIFAR10', batchsize=128, data_augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Augmentation - 108 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.87525, train_accuracy: 71.09\n",
      "[1,     2] loss: 1.81754, train_accuracy: 53.12\n",
      "[1,     3] loss: 2.90354, train_accuracy: 48.44\n",
      "[1,     4] loss: 2.27259, train_accuracy: 40.62\n",
      "[1,     5] loss: 1.57684, train_accuracy: 51.56\n",
      "[1,     6] loss: 1.88914, train_accuracy: 49.22\n",
      "[1,     7] loss: 2.06021, train_accuracy: 40.62\n",
      "[1,     8] loss: 1.46237, train_accuracy: 57.81\n",
      "[1,     9] loss: 1.31716, train_accuracy: 60.94\n",
      "[1,    10] loss: 2.11844, train_accuracy: 54.69\n",
      "[1,    11] loss: 1.64806, train_accuracy: 53.12\n",
      "[1,    12] loss: 1.81902, train_accuracy: 57.03\n",
      "[1,    13] loss: 1.64876, train_accuracy: 57.81\n",
      "[1,    14] loss: 1.52725, train_accuracy: 55.47\n",
      "[1,    15] loss: 1.52262, train_accuracy: 53.91\n",
      "[1,    16] loss: 1.74966, train_accuracy: 43.75\n",
      "[1,    17] loss: 1.17733, train_accuracy: 57.03\n",
      "[1,    18] loss: 1.78217, train_accuracy: 46.09\n",
      "[1,    19] loss: 2.01632, train_accuracy: 48.44\n",
      "[1,    20] loss: 1.36680, train_accuracy: 58.59\n",
      "[1,    21] loss: 1.29572, train_accuracy: 53.91\n",
      "[1,    22] loss: 1.46552, train_accuracy: 55.47\n",
      "[1,    23] loss: 1.20288, train_accuracy: 60.94\n",
      "[1,    24] loss: 1.90578, train_accuracy: 67.19\n",
      "[1,    25] loss: 1.19704, train_accuracy: 65.62\n",
      "[1,    26] loss: 2.07090, train_accuracy: 50.78\n",
      "[1,    27] loss: 1.55773, train_accuracy: 51.56\n",
      "[1,    28] loss: 1.28410, train_accuracy: 60.16\n",
      "[1,    29] loss: 1.08339, train_accuracy: 65.62\n",
      "[1,    30] loss: 1.39560, train_accuracy: 60.94\n",
      "[1,    31] loss: 1.25901, train_accuracy: 64.06\n",
      "[1,    32] loss: 1.16551, train_accuracy: 62.50\n",
      "[1,    33] loss: 0.87841, train_accuracy: 67.97\n",
      "[1,    34] loss: 1.12465, train_accuracy: 60.16\n",
      "[1,    35] loss: 1.38258, train_accuracy: 61.72\n",
      "[1,    36] loss: 1.09661, train_accuracy: 64.06\n",
      "[1,    37] loss: 0.99923, train_accuracy: 69.53\n",
      "[1,    38] loss: 0.89706, train_accuracy: 66.41\n",
      "[1,    39] loss: 1.10285, train_accuracy: 64.06\n",
      "[1,    40] loss: 1.13520, train_accuracy: 61.72\n",
      "[1,    41] loss: 1.46067, train_accuracy: 60.16\n",
      "[1,    42] loss: 1.17529, train_accuracy: 62.50\n",
      "[1,    43] loss: 1.06318, train_accuracy: 61.72\n",
      "[1,    44] loss: 1.40589, train_accuracy: 58.59\n",
      "[1,    45] loss: 1.19049, train_accuracy: 60.16\n",
      "[1,    46] loss: 0.93323, train_accuracy: 66.41\n",
      "[1,    47] loss: 1.22360, train_accuracy: 57.03\n",
      "[1,    48] loss: 1.00527, train_accuracy: 63.28\n",
      "[1,    49] loss: 0.89470, train_accuracy: 73.44\n",
      "[1,    50] loss: 1.00495, train_accuracy: 67.97\n",
      "[1,    51] loss: 0.98369, train_accuracy: 67.19\n",
      "[1,    52] loss: 1.01835, train_accuracy: 64.84\n",
      "[1,    53] loss: 1.14439, train_accuracy: 57.03\n",
      "[1,    54] loss: 1.27393, train_accuracy: 60.94\n",
      "[1,    55] loss: 1.10846, train_accuracy: 73.44\n",
      "[1,    56] loss: 0.97708, train_accuracy: 68.75\n",
      "[1,    57] loss: 0.94002, train_accuracy: 75.00\n",
      "[1,    58] loss: 1.02294, train_accuracy: 65.62\n",
      "[1,    59] loss: 0.83258, train_accuracy: 75.78\n",
      "[1,    60] loss: 0.86055, train_accuracy: 72.66\n",
      "[1,    61] loss: 0.80704, train_accuracy: 71.09\n",
      "[1,    62] loss: 0.86111, train_accuracy: 70.31\n",
      "[1,    63] loss: 0.94448, train_accuracy: 73.44\n",
      "[1,    64] loss: 1.01822, train_accuracy: 65.62\n",
      "[1,    65] loss: 0.88724, train_accuracy: 70.31\n",
      "[1,    66] loss: 0.86101, train_accuracy: 67.19\n",
      "[1,    67] loss: 0.87836, train_accuracy: 71.09\n",
      "[1,    68] loss: 0.89916, train_accuracy: 71.09\n",
      "[1,    69] loss: 1.17250, train_accuracy: 64.84\n",
      "[1,    70] loss: 0.82293, train_accuracy: 71.09\n",
      "[1,    71] loss: 0.98504, train_accuracy: 72.66\n",
      "[1,    72] loss: 0.68212, train_accuracy: 75.78\n",
      "[1,    73] loss: 0.96765, train_accuracy: 72.66\n",
      "[1,    74] loss: 1.00206, train_accuracy: 68.75\n",
      "[1,    75] loss: 0.94274, train_accuracy: 69.53\n",
      "[1,    76] loss: 0.92811, train_accuracy: 69.53\n",
      "[1,    77] loss: 0.87762, train_accuracy: 70.31\n",
      "[1,    78] loss: 1.10190, train_accuracy: 65.62\n",
      "[1,    79] loss: 0.89032, train_accuracy: 67.19\n",
      "[1,    80] loss: 1.03176, train_accuracy: 65.62\n",
      "[1,    81] loss: 0.64968, train_accuracy: 80.47\n",
      "[1,    82] loss: 0.83393, train_accuracy: 71.88\n",
      "[1,    83] loss: 0.84722, train_accuracy: 68.75\n",
      "[1,    84] loss: 0.88645, train_accuracy: 69.53\n",
      "[1,    85] loss: 0.72445, train_accuracy: 74.22\n",
      "[1,    86] loss: 0.63872, train_accuracy: 79.69\n",
      "[1,    87] loss: 0.76334, train_accuracy: 71.88\n",
      "[1,    88] loss: 0.82728, train_accuracy: 73.44\n",
      "[1,    89] loss: 0.76983, train_accuracy: 73.44\n",
      "[1,    90] loss: 0.68307, train_accuracy: 71.88\n",
      "[1,    91] loss: 0.84086, train_accuracy: 75.78\n",
      "[1,    92] loss: 0.72853, train_accuracy: 74.22\n",
      "[1,    93] loss: 0.78415, train_accuracy: 71.88\n",
      "[1,    94] loss: 0.85838, train_accuracy: 71.09\n",
      "[1,    95] loss: 0.74094, train_accuracy: 77.34\n",
      "[1,    96] loss: 0.82373, train_accuracy: 68.75\n",
      "[1,    97] loss: 0.79934, train_accuracy: 71.09\n",
      "[1,    98] loss: 0.75838, train_accuracy: 70.31\n",
      "[1,    99] loss: 0.63273, train_accuracy: 77.34\n",
      "[1,   100] loss: 0.95930, train_accuracy: 65.62\n",
      "[1,   101] loss: 1.09349, train_accuracy: 68.75\n",
      "[1,   102] loss: 0.66342, train_accuracy: 75.78\n",
      "[1,   103] loss: 0.68103, train_accuracy: 78.12\n",
      "[1,   104] loss: 0.78976, train_accuracy: 70.31\n",
      "[1,   105] loss: 1.00498, train_accuracy: 69.53\n",
      "[1,   106] loss: 1.00109, train_accuracy: 68.75\n",
      "[1,   107] loss: 0.79250, train_accuracy: 67.97\n",
      "[1,   108] loss: 0.69409, train_accuracy: 80.47\n",
      "[1,   109] loss: 0.83713, train_accuracy: 73.44\n",
      "[1,   110] loss: 0.73277, train_accuracy: 76.56\n",
      "[1,   111] loss: 0.89409, train_accuracy: 72.66\n",
      "[1,   112] loss: 0.89312, train_accuracy: 69.53\n",
      "[1,   113] loss: 0.81171, train_accuracy: 68.75\n",
      "[1,   114] loss: 0.76765, train_accuracy: 71.88\n",
      "[1,   115] loss: 0.81036, train_accuracy: 74.22\n",
      "[1,   116] loss: 0.80987, train_accuracy: 72.66\n",
      "[1,   117] loss: 0.90646, train_accuracy: 68.75\n",
      "[1,   118] loss: 0.76755, train_accuracy: 70.31\n",
      "[1,   119] loss: 0.71712, train_accuracy: 76.56\n",
      "[1,   120] loss: 1.09588, train_accuracy: 65.62\n",
      "[1,   121] loss: 0.63770, train_accuracy: 78.12\n",
      "[1,   122] loss: 0.72388, train_accuracy: 80.47\n",
      "[1,   123] loss: 0.80250, train_accuracy: 71.88\n",
      "[1,   124] loss: 0.82972, train_accuracy: 68.75\n",
      "[1,   125] loss: 0.80502, train_accuracy: 67.97\n",
      "[1,   126] loss: 0.69644, train_accuracy: 74.22\n",
      "[1,   127] loss: 0.89891, train_accuracy: 67.19\n",
      "[1,   128] loss: 0.67811, train_accuracy: 75.78\n",
      "[1,   129] loss: 1.00259, train_accuracy: 69.53\n",
      "[1,   130] loss: 0.72565, train_accuracy: 77.34\n",
      "[1,   131] loss: 0.83698, train_accuracy: 74.22\n",
      "[1,   132] loss: 0.90703, train_accuracy: 71.88\n",
      "[1,   133] loss: 1.07831, train_accuracy: 64.84\n",
      "[1,   134] loss: 0.95033, train_accuracy: 62.50\n",
      "[1,   135] loss: 0.68546, train_accuracy: 75.00\n",
      "[1,   136] loss: 1.11247, train_accuracy: 59.38\n",
      "[1,   137] loss: 0.85470, train_accuracy: 71.09\n",
      "[1,   138] loss: 0.94894, train_accuracy: 66.41\n",
      "[1,   139] loss: 0.63654, train_accuracy: 77.34\n",
      "[1,   140] loss: 0.79070, train_accuracy: 71.09\n",
      "[1,   141] loss: 0.80115, train_accuracy: 75.00\n",
      "[1,   142] loss: 0.85080, train_accuracy: 70.31\n",
      "[1,   143] loss: 0.65732, train_accuracy: 70.31\n",
      "[1,   144] loss: 0.75171, train_accuracy: 76.56\n",
      "[1,   145] loss: 0.65095, train_accuracy: 77.34\n",
      "[1,   146] loss: 0.57840, train_accuracy: 78.91\n",
      "[1,   147] loss: 0.99946, train_accuracy: 69.53\n",
      "[1,   148] loss: 0.88630, train_accuracy: 72.66\n",
      "[1,   149] loss: 0.83897, train_accuracy: 73.44\n",
      "[1,   150] loss: 1.04731, train_accuracy: 67.19\n",
      "[1,   151] loss: 0.71615, train_accuracy: 77.34\n",
      "[1,   152] loss: 0.79311, train_accuracy: 73.44\n",
      "[1,   153] loss: 0.65867, train_accuracy: 75.00\n",
      "[1,   154] loss: 0.82801, train_accuracy: 69.53\n",
      "[1,   155] loss: 0.71836, train_accuracy: 73.44\n",
      "[1,   156] loss: 0.64182, train_accuracy: 77.34\n",
      "[1,   157] loss: 0.91596, train_accuracy: 67.19\n",
      "[1,   158] loss: 0.87611, train_accuracy: 70.31\n",
      "[1,   159] loss: 0.70116, train_accuracy: 73.44\n",
      "[1,   160] loss: 0.76345, train_accuracy: 71.88\n",
      "[1,   161] loss: 0.90775, train_accuracy: 66.41\n",
      "[1,   162] loss: 1.07738, train_accuracy: 68.75\n",
      "[1,   163] loss: 0.66527, train_accuracy: 80.47\n",
      "[1,   164] loss: 0.64138, train_accuracy: 78.12\n",
      "[1,   165] loss: 0.76561, train_accuracy: 71.09\n",
      "[1,   166] loss: 0.82498, train_accuracy: 70.31\n",
      "[1,   167] loss: 0.97039, train_accuracy: 70.31\n",
      "[1,   168] loss: 0.88308, train_accuracy: 71.09\n",
      "[1,   169] loss: 0.86257, train_accuracy: 75.00\n",
      "[1,   170] loss: 0.85616, train_accuracy: 72.66\n",
      "[1,   171] loss: 0.84625, train_accuracy: 71.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   172] loss: 1.02279, train_accuracy: 64.84\n",
      "[1,   173] loss: 0.97144, train_accuracy: 71.09\n",
      "[1,   174] loss: 0.63283, train_accuracy: 80.47\n",
      "[1,   175] loss: 0.59900, train_accuracy: 77.34\n",
      "[1,   176] loss: 0.96610, train_accuracy: 67.97\n",
      "[1,   177] loss: 0.87859, train_accuracy: 72.66\n",
      "[1,   178] loss: 0.95553, train_accuracy: 65.62\n",
      "[1,   179] loss: 0.69874, train_accuracy: 76.56\n",
      "[1,   180] loss: 0.80651, train_accuracy: 72.66\n",
      "[1,   181] loss: 0.96836, train_accuracy: 63.28\n",
      "[1,   182] loss: 0.75550, train_accuracy: 72.66\n",
      "[1,   183] loss: 1.05013, train_accuracy: 67.97\n",
      "[1,   184] loss: 0.81823, train_accuracy: 70.31\n",
      "[1,   185] loss: 0.88716, train_accuracy: 70.31\n",
      "[1,   186] loss: 0.92622, train_accuracy: 70.31\n",
      "[1,   187] loss: 0.97265, train_accuracy: 66.41\n",
      "[1,   188] loss: 0.54613, train_accuracy: 79.69\n",
      "[1,   189] loss: 0.84934, train_accuracy: 73.44\n",
      "[1,   190] loss: 0.80076, train_accuracy: 71.88\n",
      "[1,   191] loss: 0.94644, train_accuracy: 67.97\n",
      "[1,   192] loss: 0.94544, train_accuracy: 69.53\n",
      "[1,   193] loss: 0.67047, train_accuracy: 75.78\n",
      "[1,   194] loss: 0.91449, train_accuracy: 66.41\n",
      "[1,   195] loss: 0.69184, train_accuracy: 78.12\n",
      "[1,   196] loss: 1.04648, train_accuracy: 67.19\n",
      "[1,   197] loss: 0.78440, train_accuracy: 76.56\n",
      "[1,   198] loss: 0.75122, train_accuracy: 74.22\n",
      "[1,   199] loss: 1.02825, train_accuracy: 64.84\n",
      "[1,   200] loss: 0.90833, train_accuracy: 69.53\n",
      "[1,   201] loss: 0.68081, train_accuracy: 75.78\n",
      "[1,   202] loss: 0.61272, train_accuracy: 83.59\n",
      "[1,   203] loss: 0.76579, train_accuracy: 78.12\n",
      "[1,   204] loss: 0.65507, train_accuracy: 78.91\n",
      "[1,   205] loss: 0.64114, train_accuracy: 75.00\n",
      "[1,   206] loss: 0.84482, train_accuracy: 71.88\n",
      "[1,   207] loss: 0.73393, train_accuracy: 78.12\n",
      "[1,   208] loss: 0.96233, train_accuracy: 69.53\n",
      "[1,   209] loss: 0.87941, train_accuracy: 76.56\n",
      "[1,   210] loss: 0.90113, train_accuracy: 67.97\n",
      "[1,   211] loss: 0.68381, train_accuracy: 78.91\n",
      "[1,   212] loss: 0.86990, train_accuracy: 73.44\n",
      "[1,   213] loss: 0.70751, train_accuracy: 76.56\n",
      "[1,   214] loss: 0.88183, train_accuracy: 70.31\n",
      "[1,   215] loss: 0.94029, train_accuracy: 67.19\n",
      "[1,   216] loss: 0.77667, train_accuracy: 76.56\n",
      "[1,   217] loss: 0.94738, train_accuracy: 70.31\n",
      "[1,   218] loss: 0.63795, train_accuracy: 75.00\n",
      "[1,   219] loss: 0.81017, train_accuracy: 71.09\n",
      "[1,   220] loss: 0.93027, train_accuracy: 67.97\n",
      "[1,   221] loss: 0.80503, train_accuracy: 71.88\n",
      "[1,   222] loss: 0.74286, train_accuracy: 72.66\n",
      "[1,   223] loss: 0.77184, train_accuracy: 75.00\n",
      "[1,   224] loss: 0.70114, train_accuracy: 75.78\n",
      "[1,   225] loss: 0.81049, train_accuracy: 71.09\n",
      "[1,   226] loss: 0.63118, train_accuracy: 79.69\n",
      "[1,   227] loss: 0.68885, train_accuracy: 77.34\n",
      "[1,   228] loss: 1.06502, train_accuracy: 67.19\n",
      "[1,   229] loss: 0.75264, train_accuracy: 75.78\n",
      "[1,   230] loss: 0.61260, train_accuracy: 78.12\n",
      "[1,   231] loss: 0.84004, train_accuracy: 71.09\n",
      "[1,   232] loss: 0.75659, train_accuracy: 79.69\n",
      "[1,   233] loss: 0.81985, train_accuracy: 71.88\n",
      "[1,   234] loss: 0.67503, train_accuracy: 77.34\n",
      "[1,   235] loss: 0.92462, train_accuracy: 68.75\n",
      "[1,   236] loss: 0.67599, train_accuracy: 71.09\n",
      "[1,   237] loss: 0.71136, train_accuracy: 77.34\n",
      "[1,   238] loss: 0.67870, train_accuracy: 78.12\n",
      "[1,   239] loss: 0.70861, train_accuracy: 74.22\n",
      "[1,   240] loss: 0.80382, train_accuracy: 78.12\n",
      "[1,   241] loss: 0.70406, train_accuracy: 80.47\n",
      "[1,   242] loss: 0.67119, train_accuracy: 75.00\n",
      "[1,   243] loss: 0.65292, train_accuracy: 79.69\n",
      "[1,   244] loss: 0.56140, train_accuracy: 78.91\n",
      "[1,   245] loss: 0.78281, train_accuracy: 69.53\n",
      "[1,   246] loss: 0.72368, train_accuracy: 73.44\n",
      "[1,   247] loss: 0.65927, train_accuracy: 74.22\n",
      "[1,   248] loss: 0.57264, train_accuracy: 79.69\n",
      "[1,   249] loss: 0.67228, train_accuracy: 76.56\n",
      "[1,   250] loss: 0.78964, train_accuracy: 71.88\n",
      "[1,   251] loss: 0.77852, train_accuracy: 77.34\n",
      "[1,   252] loss: 0.66299, train_accuracy: 72.66\n",
      "[1,   253] loss: 0.95403, train_accuracy: 65.62\n",
      "[1,   254] loss: 0.71981, train_accuracy: 79.69\n",
      "[1,   255] loss: 0.68675, train_accuracy: 75.78\n",
      "[1,   256] loss: 0.66840, train_accuracy: 77.34\n",
      "[1,   257] loss: 0.46918, train_accuracy: 82.81\n",
      "[1,   258] loss: 0.64813, train_accuracy: 73.44\n",
      "[1,   259] loss: 0.83613, train_accuracy: 70.31\n",
      "[1,   260] loss: 0.87305, train_accuracy: 73.44\n",
      "[1,   261] loss: 0.66662, train_accuracy: 69.53\n",
      "[1,   262] loss: 1.04918, train_accuracy: 66.41\n",
      "[1,   263] loss: 0.90748, train_accuracy: 69.53\n",
      "[1,   264] loss: 0.69633, train_accuracy: 75.78\n",
      "[1,   265] loss: 0.76078, train_accuracy: 77.34\n",
      "[1,   266] loss: 0.71319, train_accuracy: 75.78\n",
      "[1,   267] loss: 0.91544, train_accuracy: 67.97\n",
      "[1,   268] loss: 0.85838, train_accuracy: 73.44\n",
      "[1,   269] loss: 0.84367, train_accuracy: 73.44\n",
      "[1,   270] loss: 0.86043, train_accuracy: 68.75\n",
      "[1,   271] loss: 0.89779, train_accuracy: 71.88\n",
      "[1,   272] loss: 0.65415, train_accuracy: 78.91\n",
      "[1,   273] loss: 0.79772, train_accuracy: 75.00\n",
      "[1,   274] loss: 0.62036, train_accuracy: 81.25\n",
      "[1,   275] loss: 0.64868, train_accuracy: 75.78\n",
      "[1,   276] loss: 0.71786, train_accuracy: 75.78\n",
      "[1,   277] loss: 0.79619, train_accuracy: 66.41\n",
      "[1,   278] loss: 0.60404, train_accuracy: 82.03\n",
      "[1,   279] loss: 0.68260, train_accuracy: 79.69\n",
      "[1,   280] loss: 0.69759, train_accuracy: 72.66\n",
      "[1,   281] loss: 0.76279, train_accuracy: 76.56\n",
      "[1,   282] loss: 0.51610, train_accuracy: 78.91\n",
      "[1,   283] loss: 0.72676, train_accuracy: 78.91\n",
      "[1,   284] loss: 0.95810, train_accuracy: 65.62\n",
      "[1,   285] loss: 0.74105, train_accuracy: 78.91\n",
      "[1,   286] loss: 0.79373, train_accuracy: 78.91\n",
      "[1,   287] loss: 0.79917, train_accuracy: 69.53\n",
      "[1,   288] loss: 0.95766, train_accuracy: 66.41\n",
      "[1,   289] loss: 0.65336, train_accuracy: 74.22\n",
      "[1,   290] loss: 0.75920, train_accuracy: 75.78\n",
      "[1,   291] loss: 0.75856, train_accuracy: 78.91\n",
      "[1,   292] loss: 0.59283, train_accuracy: 78.12\n",
      "[1,   293] loss: 0.76099, train_accuracy: 73.44\n",
      "[1,   294] loss: 0.77850, train_accuracy: 75.00\n",
      "[1,   295] loss: 0.75281, train_accuracy: 73.44\n",
      "[1,   296] loss: 0.58873, train_accuracy: 79.69\n",
      "[1,   297] loss: 0.64678, train_accuracy: 78.12\n",
      "[1,   298] loss: 1.14149, train_accuracy: 68.75\n",
      "[1,   299] loss: 0.67163, train_accuracy: 75.00\n",
      "[1,   300] loss: 0.76460, train_accuracy: 68.75\n",
      "[1,   301] loss: 0.73578, train_accuracy: 77.34\n",
      "[1,   302] loss: 0.61680, train_accuracy: 76.56\n",
      "[1,   303] loss: 0.60335, train_accuracy: 80.47\n",
      "[1,   304] loss: 0.77659, train_accuracy: 75.78\n",
      "[1,   305] loss: 0.65819, train_accuracy: 78.12\n",
      "[1,   306] loss: 0.90007, train_accuracy: 65.62\n",
      "[1,   307] loss: 0.74206, train_accuracy: 73.44\n",
      "[1,   308] loss: 0.63217, train_accuracy: 81.25\n",
      "[1,   309] loss: 0.85137, train_accuracy: 73.44\n",
      "[1,   310] loss: 0.89054, train_accuracy: 71.88\n",
      "[1,   311] loss: 0.77322, train_accuracy: 73.44\n",
      "[1,   312] loss: 0.59801, train_accuracy: 79.69\n",
      "[1,   313] loss: 0.51881, train_accuracy: 77.34\n",
      "[1,   314] loss: 0.62422, train_accuracy: 79.69\n",
      "[1,   315] loss: 0.73588, train_accuracy: 77.34\n",
      "[1,   316] loss: 0.75907, train_accuracy: 75.78\n",
      "[1,   317] loss: 0.44177, train_accuracy: 85.94\n",
      "[1,   318] loss: 0.92400, train_accuracy: 69.53\n",
      "[1,   319] loss: 0.67526, train_accuracy: 81.25\n",
      "[1,   320] loss: 0.76867, train_accuracy: 77.34\n",
      "[1,   321] loss: 0.73311, train_accuracy: 75.78\n",
      "[1,   322] loss: 0.61791, train_accuracy: 76.56\n",
      "[1,   323] loss: 0.77153, train_accuracy: 72.66\n",
      "[1,   324] loss: 0.53683, train_accuracy: 84.38\n",
      "[1,   325] loss: 0.61827, train_accuracy: 79.69\n",
      "[1,   326] loss: 0.72534, train_accuracy: 73.44\n",
      "[1,   327] loss: 0.60667, train_accuracy: 79.69\n",
      "[1,   328] loss: 0.74876, train_accuracy: 74.22\n",
      "[1,   329] loss: 0.77974, train_accuracy: 72.66\n",
      "[1,   330] loss: 0.66425, train_accuracy: 78.91\n",
      "[1,   331] loss: 0.75908, train_accuracy: 76.56\n",
      "[1,   332] loss: 0.84679, train_accuracy: 74.22\n",
      "[1,   333] loss: 0.87621, train_accuracy: 72.66\n",
      "[1,   334] loss: 0.86145, train_accuracy: 71.09\n",
      "[1,   335] loss: 0.62748, train_accuracy: 77.34\n",
      "[1,   336] loss: 0.71785, train_accuracy: 71.88\n",
      "[1,   337] loss: 0.73053, train_accuracy: 73.44\n",
      "[1,   338] loss: 0.71835, train_accuracy: 76.56\n",
      "[1,   339] loss: 0.68547, train_accuracy: 75.00\n",
      "[1,   340] loss: 0.87974, train_accuracy: 71.88\n",
      "[1,   341] loss: 0.82051, train_accuracy: 71.88\n",
      "[1,   342] loss: 0.59436, train_accuracy: 78.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   343] loss: 0.58122, train_accuracy: 79.69\n",
      "[1,   344] loss: 0.59925, train_accuracy: 82.03\n",
      "[1,   345] loss: 0.74389, train_accuracy: 72.66\n",
      "[1,   346] loss: 0.73941, train_accuracy: 73.44\n",
      "[1,   347] loss: 0.64701, train_accuracy: 79.69\n",
      "[1,   348] loss: 0.64721, train_accuracy: 77.34\n",
      "[1,   349] loss: 0.67092, train_accuracy: 77.34\n",
      "[1,   350] loss: 0.68900, train_accuracy: 75.00\n",
      "[1,   351] loss: 0.70238, train_accuracy: 78.91\n",
      "[1,   352] loss: 0.83198, train_accuracy: 75.00\n",
      "[1,   353] loss: 0.77339, train_accuracy: 75.00\n",
      "[1,   354] loss: 0.69830, train_accuracy: 75.78\n",
      "[1,   355] loss: 0.68953, train_accuracy: 75.00\n",
      "[1,   356] loss: 0.94624, train_accuracy: 67.97\n",
      "[1,   357] loss: 0.95821, train_accuracy: 65.62\n",
      "[1,   358] loss: 0.85500, train_accuracy: 72.66\n",
      "[1,   359] loss: 0.63542, train_accuracy: 83.59\n",
      "[1,   360] loss: 0.69774, train_accuracy: 72.66\n",
      "[1,   361] loss: 0.80361, train_accuracy: 73.44\n",
      "[1,   362] loss: 0.80438, train_accuracy: 72.66\n",
      "[1,   363] loss: 0.66535, train_accuracy: 76.56\n",
      "[1,   364] loss: 0.64451, train_accuracy: 75.00\n",
      "[1,   365] loss: 0.54855, train_accuracy: 82.81\n",
      "[1,   366] loss: 0.82001, train_accuracy: 74.22\n",
      "[1,   367] loss: 0.66617, train_accuracy: 74.22\n",
      "[1,   368] loss: 0.84392, train_accuracy: 67.19\n",
      "[1,   369] loss: 0.77693, train_accuracy: 73.44\n",
      "[1,   370] loss: 0.54638, train_accuracy: 82.03\n",
      "[1,   371] loss: 0.67877, train_accuracy: 77.34\n",
      "[1,   372] loss: 0.62081, train_accuracy: 80.47\n",
      "[1,   373] loss: 0.77711, train_accuracy: 71.88\n",
      "[1,   374] loss: 0.60551, train_accuracy: 80.47\n",
      "[1,   375] loss: 0.68321, train_accuracy: 77.34\n",
      "[1,   376] loss: 0.56413, train_accuracy: 79.69\n",
      "[1,   377] loss: 0.51578, train_accuracy: 80.47\n",
      "[1,   378] loss: 0.80329, train_accuracy: 68.75\n",
      "[1,   379] loss: 0.58684, train_accuracy: 78.91\n",
      "[1,   380] loss: 0.65435, train_accuracy: 74.22\n",
      "[1,   381] loss: 0.72904, train_accuracy: 77.34\n",
      "[1,   382] loss: 0.72696, train_accuracy: 75.00\n",
      "[1,   383] loss: 0.64278, train_accuracy: 76.56\n",
      "[1,   384] loss: 0.66271, train_accuracy: 75.78\n",
      "[1,   385] loss: 0.67436, train_accuracy: 75.00\n",
      "[1,   386] loss: 0.76096, train_accuracy: 74.22\n",
      "[1,   387] loss: 0.65403, train_accuracy: 81.25\n",
      "[1,   388] loss: 0.66861, train_accuracy: 78.91\n",
      "[1,   389] loss: 0.68110, train_accuracy: 80.47\n",
      "[1,   390] loss: 0.53279, train_accuracy: 85.94\n",
      "[1,   391] loss: 0.60671, train_accuracy: 81.25\n",
      "duration: 108 s - train loss: 0.86613 - train accuracy: 71.69 - validation loss: 0.76 - validation accuracy: 74.04 \n",
      "[2,     1] loss: 0.69307, train_accuracy: 75.00\n",
      "[2,     2] loss: 0.59236, train_accuracy: 81.25\n",
      "[2,     3] loss: 0.67098, train_accuracy: 76.56\n",
      "[2,     4] loss: 0.58042, train_accuracy: 79.69\n",
      "[2,     5] loss: 0.63354, train_accuracy: 78.12\n",
      "[2,     6] loss: 0.58203, train_accuracy: 78.91\n",
      "[2,     7] loss: 0.68643, train_accuracy: 77.34\n",
      "[2,     8] loss: 0.54579, train_accuracy: 83.59\n",
      "[2,     9] loss: 0.71776, train_accuracy: 74.22\n",
      "[2,    10] loss: 0.65056, train_accuracy: 80.47\n",
      "[2,    11] loss: 0.62655, train_accuracy: 78.12\n",
      "[2,    12] loss: 0.58637, train_accuracy: 78.12\n",
      "[2,    13] loss: 0.60510, train_accuracy: 76.56\n",
      "[2,    14] loss: 0.55952, train_accuracy: 79.69\n",
      "[2,    15] loss: 0.67538, train_accuracy: 76.56\n",
      "[2,    16] loss: 0.67001, train_accuracy: 76.56\n",
      "[2,    17] loss: 0.48416, train_accuracy: 78.91\n",
      "[2,    18] loss: 0.63365, train_accuracy: 82.03\n",
      "[2,    19] loss: 0.52371, train_accuracy: 79.69\n",
      "[2,    20] loss: 0.60802, train_accuracy: 81.25\n",
      "[2,    21] loss: 0.65763, train_accuracy: 77.34\n",
      "[2,    22] loss: 0.59163, train_accuracy: 80.47\n",
      "[2,    23] loss: 0.91797, train_accuracy: 71.09\n",
      "[2,    24] loss: 0.50442, train_accuracy: 82.81\n",
      "[2,    25] loss: 0.84655, train_accuracy: 80.47\n",
      "[2,    26] loss: 0.57785, train_accuracy: 78.91\n",
      "[2,    27] loss: 0.66309, train_accuracy: 75.00\n",
      "[2,    28] loss: 0.67479, train_accuracy: 75.78\n",
      "[2,    29] loss: 0.68309, train_accuracy: 78.12\n",
      "[2,    30] loss: 0.76252, train_accuracy: 71.09\n",
      "[2,    31] loss: 0.66327, train_accuracy: 71.88\n",
      "[2,    32] loss: 0.49767, train_accuracy: 79.69\n",
      "[2,    33] loss: 0.53756, train_accuracy: 81.25\n",
      "[2,    34] loss: 0.67388, train_accuracy: 80.47\n",
      "[2,    35] loss: 0.54410, train_accuracy: 78.91\n",
      "[2,    36] loss: 0.52631, train_accuracy: 82.81\n",
      "[2,    37] loss: 0.65128, train_accuracy: 80.47\n",
      "[2,    38] loss: 0.75343, train_accuracy: 75.00\n",
      "[2,    39] loss: 0.59869, train_accuracy: 79.69\n",
      "[2,    40] loss: 0.66740, train_accuracy: 78.12\n",
      "[2,    41] loss: 0.69751, train_accuracy: 72.66\n",
      "[2,    42] loss: 0.69523, train_accuracy: 75.00\n",
      "[2,    43] loss: 0.75777, train_accuracy: 75.78\n",
      "[2,    44] loss: 0.71922, train_accuracy: 77.34\n",
      "[2,    45] loss: 0.72225, train_accuracy: 77.34\n",
      "[2,    46] loss: 0.65065, train_accuracy: 75.78\n",
      "[2,    47] loss: 0.66311, train_accuracy: 75.78\n",
      "[2,    48] loss: 0.68418, train_accuracy: 75.00\n",
      "[2,    49] loss: 0.69385, train_accuracy: 74.22\n",
      "[2,    50] loss: 0.63490, train_accuracy: 79.69\n",
      "[2,    51] loss: 0.79269, train_accuracy: 69.53\n",
      "[2,    52] loss: 0.67049, train_accuracy: 78.91\n",
      "[2,    53] loss: 0.58986, train_accuracy: 79.69\n",
      "[2,    54] loss: 0.63122, train_accuracy: 76.56\n",
      "[2,    55] loss: 0.85784, train_accuracy: 75.78\n",
      "[2,    56] loss: 0.79317, train_accuracy: 73.44\n",
      "[2,    57] loss: 0.50985, train_accuracy: 81.25\n",
      "[2,    58] loss: 0.60174, train_accuracy: 77.34\n",
      "[2,    59] loss: 0.72730, train_accuracy: 76.56\n",
      "[2,    60] loss: 0.88787, train_accuracy: 71.09\n",
      "[2,    61] loss: 0.65721, train_accuracy: 75.00\n",
      "[2,    62] loss: 0.72375, train_accuracy: 74.22\n",
      "[2,    63] loss: 0.81579, train_accuracy: 69.53\n",
      "[2,    64] loss: 0.59010, train_accuracy: 81.25\n",
      "[2,    65] loss: 0.47438, train_accuracy: 80.47\n",
      "[2,    66] loss: 0.69422, train_accuracy: 76.56\n",
      "[2,    67] loss: 0.69909, train_accuracy: 79.69\n",
      "[2,    68] loss: 0.52215, train_accuracy: 80.47\n",
      "[2,    69] loss: 0.64371, train_accuracy: 77.34\n",
      "[2,    70] loss: 0.40091, train_accuracy: 83.59\n",
      "[2,    71] loss: 0.82426, train_accuracy: 73.44\n",
      "[2,    72] loss: 0.73215, train_accuracy: 71.09\n",
      "[2,    73] loss: 0.67963, train_accuracy: 76.56\n",
      "[2,    74] loss: 0.63346, train_accuracy: 78.91\n",
      "[2,    75] loss: 0.51177, train_accuracy: 82.03\n",
      "[2,    76] loss: 0.70492, train_accuracy: 77.34\n",
      "[2,    77] loss: 0.88975, train_accuracy: 74.22\n",
      "[2,    78] loss: 0.90853, train_accuracy: 71.88\n",
      "[2,    79] loss: 0.80153, train_accuracy: 75.00\n",
      "[2,    80] loss: 0.72942, train_accuracy: 74.22\n",
      "[2,    81] loss: 0.71749, train_accuracy: 77.34\n",
      "[2,    82] loss: 0.67530, train_accuracy: 78.12\n",
      "[2,    83] loss: 0.58599, train_accuracy: 78.91\n",
      "[2,    84] loss: 0.75643, train_accuracy: 73.44\n",
      "[2,    85] loss: 0.75930, train_accuracy: 73.44\n",
      "[2,    86] loss: 0.71722, train_accuracy: 75.00\n",
      "[2,    87] loss: 0.77901, train_accuracy: 77.34\n",
      "[2,    88] loss: 0.63639, train_accuracy: 82.03\n",
      "[2,    89] loss: 0.61286, train_accuracy: 77.34\n",
      "[2,    90] loss: 0.56492, train_accuracy: 81.25\n",
      "[2,    91] loss: 0.56553, train_accuracy: 79.69\n",
      "[2,    92] loss: 0.61609, train_accuracy: 77.34\n",
      "[2,    93] loss: 0.59926, train_accuracy: 78.91\n",
      "[2,    94] loss: 0.60804, train_accuracy: 76.56\n",
      "[2,    95] loss: 0.55443, train_accuracy: 82.81\n",
      "[2,    96] loss: 0.70684, train_accuracy: 78.12\n",
      "[2,    97] loss: 0.62450, train_accuracy: 78.91\n",
      "[2,    98] loss: 0.55631, train_accuracy: 83.59\n",
      "[2,    99] loss: 0.64888, train_accuracy: 73.44\n",
      "[2,   100] loss: 0.62930, train_accuracy: 76.56\n",
      "[2,   101] loss: 0.64587, train_accuracy: 74.22\n",
      "[2,   102] loss: 0.80052, train_accuracy: 71.09\n",
      "[2,   103] loss: 0.73747, train_accuracy: 71.88\n",
      "[2,   104] loss: 0.76078, train_accuracy: 73.44\n",
      "[2,   105] loss: 0.54240, train_accuracy: 82.03\n",
      "[2,   106] loss: 0.77450, train_accuracy: 79.69\n",
      "[2,   107] loss: 0.68568, train_accuracy: 77.34\n",
      "[2,   108] loss: 0.62960, train_accuracy: 75.00\n",
      "[2,   109] loss: 0.66745, train_accuracy: 75.78\n",
      "[2,   110] loss: 0.47256, train_accuracy: 83.59\n",
      "[2,   111] loss: 0.62163, train_accuracy: 75.78\n",
      "[2,   112] loss: 0.67301, train_accuracy: 76.56\n",
      "[2,   113] loss: 0.56220, train_accuracy: 79.69\n",
      "[2,   114] loss: 0.75519, train_accuracy: 74.22\n",
      "[2,   115] loss: 0.71127, train_accuracy: 78.12\n",
      "[2,   116] loss: 0.60017, train_accuracy: 83.59\n",
      "[2,   117] loss: 0.87051, train_accuracy: 72.66\n",
      "[2,   118] loss: 0.69681, train_accuracy: 77.34\n",
      "[2,   119] loss: 0.57829, train_accuracy: 78.12\n",
      "[2,   120] loss: 0.56953, train_accuracy: 78.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   121] loss: 0.73784, train_accuracy: 75.78\n",
      "[2,   122] loss: 0.74558, train_accuracy: 75.78\n",
      "[2,   123] loss: 0.51246, train_accuracy: 85.16\n",
      "[2,   124] loss: 0.61427, train_accuracy: 71.88\n",
      "[2,   125] loss: 0.45424, train_accuracy: 85.16\n",
      "[2,   126] loss: 0.54579, train_accuracy: 80.47\n",
      "[2,   127] loss: 0.68289, train_accuracy: 77.34\n",
      "[2,   128] loss: 0.43115, train_accuracy: 85.94\n",
      "[2,   129] loss: 0.43546, train_accuracy: 82.81\n",
      "[2,   130] loss: 0.68373, train_accuracy: 75.00\n",
      "[2,   131] loss: 0.66353, train_accuracy: 80.47\n",
      "[2,   132] loss: 0.64222, train_accuracy: 78.12\n",
      "[2,   133] loss: 0.67675, train_accuracy: 82.81\n",
      "[2,   134] loss: 0.54615, train_accuracy: 81.25\n",
      "[2,   135] loss: 0.80153, train_accuracy: 79.69\n",
      "[2,   136] loss: 0.87810, train_accuracy: 67.19\n",
      "[2,   137] loss: 0.52501, train_accuracy: 81.25\n",
      "[2,   138] loss: 0.48927, train_accuracy: 80.47\n",
      "[2,   139] loss: 0.70933, train_accuracy: 68.75\n",
      "[2,   140] loss: 0.76757, train_accuracy: 75.00\n",
      "[2,   141] loss: 0.66439, train_accuracy: 76.56\n",
      "[2,   142] loss: 0.73734, train_accuracy: 68.75\n",
      "[2,   143] loss: 0.36147, train_accuracy: 89.84\n",
      "[2,   144] loss: 0.51587, train_accuracy: 82.03\n",
      "[2,   145] loss: 0.71503, train_accuracy: 80.47\n",
      "[2,   146] loss: 0.73564, train_accuracy: 71.88\n",
      "[2,   147] loss: 0.58607, train_accuracy: 78.91\n",
      "[2,   148] loss: 0.52142, train_accuracy: 79.69\n",
      "[2,   149] loss: 0.63933, train_accuracy: 77.34\n",
      "[2,   150] loss: 0.72711, train_accuracy: 77.34\n",
      "[2,   151] loss: 0.61688, train_accuracy: 76.56\n",
      "[2,   152] loss: 0.73616, train_accuracy: 72.66\n",
      "[2,   153] loss: 0.60996, train_accuracy: 79.69\n",
      "[2,   154] loss: 0.53057, train_accuracy: 81.25\n",
      "[2,   155] loss: 0.62264, train_accuracy: 80.47\n",
      "[2,   156] loss: 0.63785, train_accuracy: 73.44\n",
      "[2,   157] loss: 0.79113, train_accuracy: 76.56\n",
      "[2,   158] loss: 0.44689, train_accuracy: 81.25\n",
      "[2,   159] loss: 0.68794, train_accuracy: 77.34\n",
      "[2,   160] loss: 0.53980, train_accuracy: 78.12\n",
      "[2,   161] loss: 0.48184, train_accuracy: 82.81\n",
      "[2,   162] loss: 0.60849, train_accuracy: 75.00\n",
      "[2,   163] loss: 0.47437, train_accuracy: 80.47\n",
      "[2,   164] loss: 0.57655, train_accuracy: 81.25\n",
      "[2,   165] loss: 0.49473, train_accuracy: 82.81\n",
      "[2,   166] loss: 0.69307, train_accuracy: 73.44\n",
      "[2,   167] loss: 0.60982, train_accuracy: 81.25\n",
      "[2,   168] loss: 0.58257, train_accuracy: 82.03\n",
      "[2,   169] loss: 0.54075, train_accuracy: 80.47\n",
      "[2,   170] loss: 0.55140, train_accuracy: 81.25\n",
      "[2,   171] loss: 0.53658, train_accuracy: 78.12\n",
      "[2,   172] loss: 0.52278, train_accuracy: 81.25\n",
      "[2,   173] loss: 0.56874, train_accuracy: 75.00\n",
      "[2,   174] loss: 0.52866, train_accuracy: 79.69\n",
      "[2,   175] loss: 0.48069, train_accuracy: 82.81\n",
      "[2,   176] loss: 0.63870, train_accuracy: 82.03\n",
      "[2,   177] loss: 0.62281, train_accuracy: 80.47\n",
      "[2,   178] loss: 0.65491, train_accuracy: 77.34\n",
      "[2,   179] loss: 0.74622, train_accuracy: 76.56\n",
      "[2,   180] loss: 0.56817, train_accuracy: 75.78\n",
      "[2,   181] loss: 0.53715, train_accuracy: 83.59\n",
      "[2,   182] loss: 0.50171, train_accuracy: 82.81\n",
      "[2,   183] loss: 0.81289, train_accuracy: 71.88\n",
      "[2,   184] loss: 0.53782, train_accuracy: 81.25\n",
      "[2,   185] loss: 0.54676, train_accuracy: 82.81\n",
      "[2,   186] loss: 0.57430, train_accuracy: 79.69\n",
      "[2,   187] loss: 0.68065, train_accuracy: 74.22\n",
      "[2,   188] loss: 0.64234, train_accuracy: 75.78\n",
      "[2,   189] loss: 0.54353, train_accuracy: 77.34\n",
      "[2,   190] loss: 0.82319, train_accuracy: 72.66\n",
      "[2,   191] loss: 0.58546, train_accuracy: 75.78\n",
      "[2,   192] loss: 0.59696, train_accuracy: 80.47\n",
      "[2,   193] loss: 0.68289, train_accuracy: 78.91\n",
      "[2,   194] loss: 0.71719, train_accuracy: 78.12\n",
      "[2,   195] loss: 0.58296, train_accuracy: 77.34\n",
      "[2,   196] loss: 0.62405, train_accuracy: 81.25\n",
      "[2,   197] loss: 0.61085, train_accuracy: 81.25\n",
      "[2,   198] loss: 0.51522, train_accuracy: 84.38\n",
      "[2,   199] loss: 0.53256, train_accuracy: 82.81\n",
      "[2,   200] loss: 0.70335, train_accuracy: 75.00\n",
      "[2,   201] loss: 0.55298, train_accuracy: 81.25\n",
      "[2,   202] loss: 0.45823, train_accuracy: 85.16\n",
      "[2,   203] loss: 0.92109, train_accuracy: 75.78\n",
      "[2,   204] loss: 0.60822, train_accuracy: 75.00\n",
      "[2,   205] loss: 0.51078, train_accuracy: 78.91\n",
      "[2,   206] loss: 0.71167, train_accuracy: 75.78\n",
      "[2,   207] loss: 0.57580, train_accuracy: 82.03\n",
      "[2,   208] loss: 0.77265, train_accuracy: 71.09\n",
      "[2,   209] loss: 0.66869, train_accuracy: 80.47\n",
      "[2,   210] loss: 0.61743, train_accuracy: 78.12\n",
      "[2,   211] loss: 0.48887, train_accuracy: 79.69\n",
      "[2,   212] loss: 0.53153, train_accuracy: 80.47\n",
      "[2,   213] loss: 0.71663, train_accuracy: 74.22\n",
      "[2,   214] loss: 0.56156, train_accuracy: 80.47\n",
      "[2,   215] loss: 0.44356, train_accuracy: 85.16\n",
      "[2,   216] loss: 0.48379, train_accuracy: 81.25\n",
      "[2,   217] loss: 0.82241, train_accuracy: 71.88\n",
      "[2,   218] loss: 0.63750, train_accuracy: 75.00\n",
      "[2,   219] loss: 0.69745, train_accuracy: 75.78\n",
      "[2,   220] loss: 0.46661, train_accuracy: 82.81\n",
      "[2,   221] loss: 0.84566, train_accuracy: 78.12\n",
      "[2,   222] loss: 0.60844, train_accuracy: 78.91\n",
      "[2,   223] loss: 0.43746, train_accuracy: 84.38\n",
      "[2,   224] loss: 0.68260, train_accuracy: 78.91\n",
      "[2,   225] loss: 0.52077, train_accuracy: 82.81\n",
      "[2,   226] loss: 0.47566, train_accuracy: 84.38\n",
      "[2,   227] loss: 0.67244, train_accuracy: 71.88\n",
      "[2,   228] loss: 0.52287, train_accuracy: 81.25\n",
      "[2,   229] loss: 0.61508, train_accuracy: 81.25\n",
      "[2,   230] loss: 0.80117, train_accuracy: 73.44\n",
      "[2,   231] loss: 0.77545, train_accuracy: 75.78\n",
      "[2,   232] loss: 0.53960, train_accuracy: 77.34\n",
      "[2,   233] loss: 0.50042, train_accuracy: 82.81\n",
      "[2,   234] loss: 0.67911, train_accuracy: 76.56\n",
      "[2,   235] loss: 0.67668, train_accuracy: 72.66\n",
      "[2,   236] loss: 0.54701, train_accuracy: 80.47\n",
      "[2,   237] loss: 0.73032, train_accuracy: 74.22\n",
      "[2,   238] loss: 0.51759, train_accuracy: 80.47\n",
      "[2,   239] loss: 0.61347, train_accuracy: 78.91\n",
      "[2,   240] loss: 0.71271, train_accuracy: 77.34\n",
      "[2,   241] loss: 0.53600, train_accuracy: 76.56\n",
      "[2,   242] loss: 0.71669, train_accuracy: 74.22\n",
      "[2,   243] loss: 0.55043, train_accuracy: 79.69\n",
      "[2,   244] loss: 0.53577, train_accuracy: 80.47\n",
      "[2,   245] loss: 0.56375, train_accuracy: 78.91\n",
      "[2,   246] loss: 0.61971, train_accuracy: 75.78\n",
      "[2,   247] loss: 0.69965, train_accuracy: 76.56\n",
      "[2,   248] loss: 0.56535, train_accuracy: 78.12\n",
      "[2,   249] loss: 0.50270, train_accuracy: 81.25\n",
      "[2,   250] loss: 0.46446, train_accuracy: 85.16\n",
      "[2,   251] loss: 0.55879, train_accuracy: 78.12\n",
      "[2,   252] loss: 0.90437, train_accuracy: 72.66\n",
      "[2,   253] loss: 0.66799, train_accuracy: 78.12\n",
      "[2,   254] loss: 0.59847, train_accuracy: 79.69\n",
      "[2,   255] loss: 0.59278, train_accuracy: 78.12\n",
      "[2,   256] loss: 0.45219, train_accuracy: 86.72\n",
      "[2,   257] loss: 0.65625, train_accuracy: 74.22\n",
      "[2,   258] loss: 0.51255, train_accuracy: 82.81\n",
      "[2,   259] loss: 0.70846, train_accuracy: 73.44\n",
      "[2,   260] loss: 0.61528, train_accuracy: 77.34\n",
      "[2,   261] loss: 0.55079, train_accuracy: 79.69\n",
      "[2,   262] loss: 0.61391, train_accuracy: 78.91\n",
      "[2,   263] loss: 0.75594, train_accuracy: 75.78\n",
      "[2,   264] loss: 0.59321, train_accuracy: 84.38\n",
      "[2,   265] loss: 0.60736, train_accuracy: 82.03\n",
      "[2,   266] loss: 0.55196, train_accuracy: 82.03\n",
      "[2,   267] loss: 0.41884, train_accuracy: 86.72\n",
      "[2,   268] loss: 0.56949, train_accuracy: 83.59\n",
      "[2,   269] loss: 0.40355, train_accuracy: 85.16\n",
      "[2,   270] loss: 0.42374, train_accuracy: 84.38\n",
      "[2,   271] loss: 0.66990, train_accuracy: 79.69\n",
      "[2,   272] loss: 0.69072, train_accuracy: 73.44\n",
      "[2,   273] loss: 0.59872, train_accuracy: 72.66\n",
      "[2,   274] loss: 0.60209, train_accuracy: 81.25\n",
      "[2,   275] loss: 0.64622, train_accuracy: 78.12\n",
      "[2,   276] loss: 0.89457, train_accuracy: 67.97\n",
      "[2,   277] loss: 0.56588, train_accuracy: 79.69\n",
      "[2,   278] loss: 0.58852, train_accuracy: 78.12\n",
      "[2,   279] loss: 0.56291, train_accuracy: 83.59\n",
      "[2,   280] loss: 0.75962, train_accuracy: 71.88\n",
      "[2,   281] loss: 0.57821, train_accuracy: 77.34\n",
      "[2,   282] loss: 0.58164, train_accuracy: 80.47\n",
      "[2,   283] loss: 0.60796, train_accuracy: 78.91\n",
      "[2,   284] loss: 0.64532, train_accuracy: 78.12\n",
      "[2,   285] loss: 0.58909, train_accuracy: 80.47\n",
      "[2,   286] loss: 0.61912, train_accuracy: 78.91\n",
      "[2,   287] loss: 0.81716, train_accuracy: 67.97\n",
      "[2,   288] loss: 0.59807, train_accuracy: 79.69\n",
      "[2,   289] loss: 0.60357, train_accuracy: 78.91\n",
      "[2,   290] loss: 0.70603, train_accuracy: 75.78\n",
      "[2,   291] loss: 0.65679, train_accuracy: 78.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   292] loss: 0.52257, train_accuracy: 82.81\n",
      "[2,   293] loss: 0.72770, train_accuracy: 76.56\n",
      "[2,   294] loss: 0.49523, train_accuracy: 81.25\n",
      "[2,   295] loss: 0.54752, train_accuracy: 80.47\n",
      "[2,   296] loss: 0.55750, train_accuracy: 79.69\n",
      "[2,   297] loss: 0.62624, train_accuracy: 75.78\n",
      "[2,   298] loss: 0.39854, train_accuracy: 88.28\n",
      "[2,   299] loss: 0.48476, train_accuracy: 83.59\n",
      "[2,   300] loss: 0.70649, train_accuracy: 77.34\n",
      "[2,   301] loss: 0.57118, train_accuracy: 80.47\n",
      "[2,   302] loss: 0.51269, train_accuracy: 81.25\n",
      "[2,   303] loss: 0.54638, train_accuracy: 81.25\n",
      "[2,   304] loss: 0.65902, train_accuracy: 75.78\n",
      "[2,   305] loss: 0.57479, train_accuracy: 80.47\n",
      "[2,   306] loss: 0.62878, train_accuracy: 78.12\n",
      "[2,   307] loss: 0.81359, train_accuracy: 72.66\n",
      "[2,   308] loss: 0.55606, train_accuracy: 81.25\n",
      "[2,   309] loss: 0.70758, train_accuracy: 78.91\n",
      "[2,   310] loss: 0.63437, train_accuracy: 82.03\n",
      "[2,   311] loss: 0.76427, train_accuracy: 74.22\n",
      "[2,   312] loss: 0.64867, train_accuracy: 78.91\n",
      "[2,   313] loss: 0.47446, train_accuracy: 82.81\n",
      "[2,   314] loss: 0.56076, train_accuracy: 78.91\n",
      "[2,   315] loss: 0.60239, train_accuracy: 77.34\n",
      "[2,   316] loss: 0.77901, train_accuracy: 75.78\n",
      "[2,   317] loss: 0.72019, train_accuracy: 75.78\n",
      "[2,   318] loss: 0.56161, train_accuracy: 76.56\n",
      "[2,   319] loss: 0.54123, train_accuracy: 79.69\n",
      "[2,   320] loss: 0.49480, train_accuracy: 81.25\n",
      "[2,   321] loss: 0.59860, train_accuracy: 75.00\n",
      "[2,   322] loss: 0.62004, train_accuracy: 80.47\n",
      "[2,   323] loss: 0.66402, train_accuracy: 75.00\n",
      "[2,   324] loss: 0.37986, train_accuracy: 85.16\n",
      "[2,   325] loss: 0.56412, train_accuracy: 75.00\n",
      "[2,   326] loss: 0.69062, train_accuracy: 77.34\n",
      "[2,   327] loss: 0.48186, train_accuracy: 82.81\n",
      "[2,   328] loss: 0.72166, train_accuracy: 76.56\n",
      "[2,   329] loss: 0.57668, train_accuracy: 78.91\n",
      "[2,   330] loss: 0.50962, train_accuracy: 83.59\n",
      "[2,   331] loss: 0.56033, train_accuracy: 78.12\n",
      "[2,   332] loss: 0.51944, train_accuracy: 82.81\n",
      "[2,   333] loss: 0.46332, train_accuracy: 85.16\n",
      "[2,   334] loss: 0.59048, train_accuracy: 77.34\n",
      "[2,   335] loss: 0.58419, train_accuracy: 82.03\n",
      "[2,   336] loss: 0.55293, train_accuracy: 76.56\n",
      "[2,   337] loss: 0.78396, train_accuracy: 74.22\n",
      "[2,   338] loss: 0.72221, train_accuracy: 71.88\n",
      "[2,   339] loss: 0.69856, train_accuracy: 71.09\n",
      "[2,   340] loss: 0.65552, train_accuracy: 79.69\n",
      "[2,   341] loss: 0.49939, train_accuracy: 85.16\n",
      "[2,   342] loss: 0.54335, train_accuracy: 78.91\n",
      "[2,   343] loss: 0.64432, train_accuracy: 79.69\n",
      "[2,   344] loss: 0.47317, train_accuracy: 83.59\n",
      "[2,   345] loss: 0.65803, train_accuracy: 78.12\n",
      "[2,   346] loss: 0.39061, train_accuracy: 87.50\n",
      "[2,   347] loss: 0.64027, train_accuracy: 78.12\n",
      "[2,   348] loss: 0.78848, train_accuracy: 76.56\n",
      "[2,   349] loss: 0.57459, train_accuracy: 78.91\n",
      "[2,   350] loss: 0.53078, train_accuracy: 79.69\n",
      "[2,   351] loss: 0.64057, train_accuracy: 78.12\n",
      "[2,   352] loss: 0.60044, train_accuracy: 80.47\n",
      "[2,   353] loss: 0.61839, train_accuracy: 79.69\n",
      "[2,   354] loss: 0.63405, train_accuracy: 75.00\n",
      "[2,   355] loss: 0.44543, train_accuracy: 82.03\n",
      "[2,   356] loss: 0.54206, train_accuracy: 79.69\n",
      "[2,   357] loss: 0.57419, train_accuracy: 78.91\n",
      "[2,   358] loss: 0.53174, train_accuracy: 78.91\n",
      "[2,   359] loss: 0.64176, train_accuracy: 75.78\n",
      "[2,   360] loss: 0.56909, train_accuracy: 78.12\n",
      "[2,   361] loss: 0.47622, train_accuracy: 85.16\n",
      "[2,   362] loss: 0.61899, train_accuracy: 82.03\n",
      "[2,   363] loss: 0.61808, train_accuracy: 80.47\n",
      "[2,   364] loss: 0.61427, train_accuracy: 77.34\n",
      "[2,   365] loss: 0.46412, train_accuracy: 82.81\n",
      "[2,   366] loss: 0.41923, train_accuracy: 85.94\n",
      "[2,   367] loss: 0.66904, train_accuracy: 78.12\n",
      "[2,   368] loss: 0.49427, train_accuracy: 83.59\n",
      "[2,   369] loss: 0.64307, train_accuracy: 79.69\n",
      "[2,   370] loss: 0.60006, train_accuracy: 82.03\n",
      "[2,   371] loss: 0.53772, train_accuracy: 79.69\n",
      "[2,   372] loss: 0.51346, train_accuracy: 83.59\n",
      "[2,   373] loss: 0.47749, train_accuracy: 85.94\n",
      "[2,   374] loss: 0.47450, train_accuracy: 84.38\n",
      "[2,   375] loss: 0.61468, train_accuracy: 78.91\n",
      "[2,   376] loss: 0.62711, train_accuracy: 75.78\n",
      "[2,   377] loss: 0.71801, train_accuracy: 79.69\n",
      "[2,   378] loss: 0.71333, train_accuracy: 76.56\n",
      "[2,   379] loss: 0.64093, train_accuracy: 76.56\n",
      "[2,   380] loss: 0.65249, train_accuracy: 77.34\n",
      "[2,   381] loss: 0.48664, train_accuracy: 79.69\n",
      "[2,   382] loss: 0.81486, train_accuracy: 74.22\n",
      "[2,   383] loss: 0.84738, train_accuracy: 71.09\n",
      "[2,   384] loss: 0.59047, train_accuracy: 79.69\n",
      "[2,   385] loss: 0.67627, train_accuracy: 78.12\n",
      "[2,   386] loss: 0.63609, train_accuracy: 75.78\n",
      "[2,   387] loss: 0.54850, train_accuracy: 79.69\n",
      "[2,   388] loss: 0.50889, train_accuracy: 82.03\n",
      "[2,   389] loss: 0.55936, train_accuracy: 82.03\n",
      "[2,   390] loss: 0.62091, train_accuracy: 76.56\n",
      "[2,   391] loss: 0.85767, train_accuracy: 62.50\n",
      "duration: 108 s - train loss: 0.62264 - train accuracy: 78.39 - validation loss: 0.74 - validation accuracy: 75.15 \n",
      "[3,     1] loss: 0.56985, train_accuracy: 84.38\n",
      "[3,     2] loss: 0.53403, train_accuracy: 82.81\n",
      "[3,     3] loss: 0.46513, train_accuracy: 82.81\n",
      "[3,     4] loss: 0.41504, train_accuracy: 85.16\n",
      "[3,     5] loss: 0.52148, train_accuracy: 83.59\n",
      "[3,     6] loss: 0.57606, train_accuracy: 78.12\n",
      "[3,     7] loss: 0.56296, train_accuracy: 79.69\n",
      "[3,     8] loss: 0.40677, train_accuracy: 83.59\n",
      "[3,     9] loss: 0.52098, train_accuracy: 78.91\n",
      "[3,    10] loss: 0.53461, train_accuracy: 77.34\n",
      "[3,    11] loss: 0.70596, train_accuracy: 75.00\n",
      "[3,    12] loss: 0.47977, train_accuracy: 85.16\n",
      "[3,    13] loss: 0.48767, train_accuracy: 76.56\n",
      "[3,    14] loss: 0.52913, train_accuracy: 82.81\n",
      "[3,    15] loss: 0.35971, train_accuracy: 89.06\n",
      "[3,    16] loss: 0.45232, train_accuracy: 84.38\n",
      "[3,    17] loss: 0.66478, train_accuracy: 79.69\n",
      "[3,    18] loss: 0.40480, train_accuracy: 88.28\n",
      "[3,    19] loss: 0.51611, train_accuracy: 78.91\n",
      "[3,    20] loss: 0.58065, train_accuracy: 82.81\n",
      "[3,    21] loss: 0.49924, train_accuracy: 82.81\n",
      "[3,    22] loss: 0.50541, train_accuracy: 84.38\n",
      "[3,    23] loss: 0.46770, train_accuracy: 85.16\n",
      "[3,    24] loss: 0.52300, train_accuracy: 85.16\n",
      "[3,    25] loss: 0.51364, train_accuracy: 82.03\n",
      "[3,    26] loss: 0.43535, train_accuracy: 85.16\n",
      "[3,    27] loss: 0.52549, train_accuracy: 82.81\n",
      "[3,    28] loss: 0.42147, train_accuracy: 85.94\n",
      "[3,    29] loss: 0.56597, train_accuracy: 83.59\n",
      "[3,    30] loss: 0.48657, train_accuracy: 85.16\n",
      "[3,    31] loss: 0.36467, train_accuracy: 89.06\n",
      "[3,    32] loss: 0.44856, train_accuracy: 86.72\n",
      "[3,    33] loss: 0.45510, train_accuracy: 84.38\n",
      "[3,    34] loss: 0.39386, train_accuracy: 85.94\n",
      "[3,    35] loss: 0.60719, train_accuracy: 81.25\n",
      "[3,    36] loss: 0.44996, train_accuracy: 83.59\n",
      "[3,    37] loss: 0.64492, train_accuracy: 77.34\n",
      "[3,    38] loss: 0.56715, train_accuracy: 83.59\n",
      "[3,    39] loss: 0.39569, train_accuracy: 85.94\n",
      "[3,    40] loss: 0.50561, train_accuracy: 83.59\n",
      "[3,    41] loss: 0.47130, train_accuracy: 80.47\n",
      "[3,    42] loss: 0.60139, train_accuracy: 78.12\n",
      "[3,    43] loss: 0.38299, train_accuracy: 86.72\n",
      "[3,    44] loss: 0.43526, train_accuracy: 85.16\n",
      "[3,    45] loss: 0.48078, train_accuracy: 84.38\n",
      "[3,    46] loss: 0.48242, train_accuracy: 82.03\n",
      "[3,    47] loss: 0.50429, train_accuracy: 84.38\n",
      "[3,    48] loss: 0.59081, train_accuracy: 79.69\n",
      "[3,    49] loss: 0.44251, train_accuracy: 85.94\n",
      "[3,    50] loss: 0.40347, train_accuracy: 85.16\n",
      "[3,    51] loss: 0.50147, train_accuracy: 79.69\n",
      "[3,    52] loss: 0.39727, train_accuracy: 87.50\n",
      "[3,    53] loss: 0.47569, train_accuracy: 80.47\n",
      "[3,    54] loss: 0.52338, train_accuracy: 83.59\n",
      "[3,    55] loss: 0.57567, train_accuracy: 80.47\n",
      "[3,    56] loss: 0.49514, train_accuracy: 83.59\n",
      "[3,    57] loss: 0.44145, train_accuracy: 86.72\n",
      "[3,    58] loss: 0.39946, train_accuracy: 89.06\n",
      "[3,    59] loss: 0.55929, train_accuracy: 78.91\n",
      "[3,    60] loss: 0.62852, train_accuracy: 77.34\n",
      "[3,    61] loss: 0.39752, train_accuracy: 85.94\n",
      "[3,    62] loss: 0.56313, train_accuracy: 80.47\n",
      "[3,    63] loss: 0.33932, train_accuracy: 89.06\n",
      "[3,    64] loss: 0.32708, train_accuracy: 89.84\n",
      "[3,    65] loss: 0.56756, train_accuracy: 83.59\n",
      "[3,    66] loss: 0.43440, train_accuracy: 89.06\n",
      "[3,    67] loss: 0.46649, train_accuracy: 83.59\n",
      "[3,    68] loss: 0.52232, train_accuracy: 79.69\n",
      "[3,    69] loss: 0.55811, train_accuracy: 80.47\n",
      "[3,    70] loss: 0.41918, train_accuracy: 86.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    71] loss: 0.56791, train_accuracy: 77.34\n",
      "[3,    72] loss: 0.54192, train_accuracy: 82.03\n",
      "[3,    73] loss: 0.49290, train_accuracy: 82.81\n",
      "[3,    74] loss: 0.45257, train_accuracy: 86.72\n",
      "[3,    75] loss: 0.27665, train_accuracy: 89.06\n",
      "[3,    76] loss: 0.50973, train_accuracy: 82.03\n",
      "[3,    77] loss: 0.57263, train_accuracy: 81.25\n",
      "[3,    78] loss: 0.45637, train_accuracy: 85.94\n",
      "[3,    79] loss: 0.44540, train_accuracy: 81.25\n",
      "[3,    80] loss: 0.46824, train_accuracy: 83.59\n",
      "[3,    81] loss: 0.45887, train_accuracy: 80.47\n",
      "[3,    82] loss: 0.45769, train_accuracy: 85.16\n",
      "[3,    83] loss: 0.41601, train_accuracy: 83.59\n",
      "[3,    84] loss: 0.51086, train_accuracy: 82.81\n",
      "[3,    85] loss: 0.41166, train_accuracy: 84.38\n",
      "[3,    86] loss: 0.47988, train_accuracy: 86.72\n",
      "[3,    87] loss: 0.54083, train_accuracy: 78.91\n",
      "[3,    88] loss: 0.57408, train_accuracy: 82.81\n",
      "[3,    89] loss: 0.39518, train_accuracy: 86.72\n",
      "[3,    90] loss: 0.48227, train_accuracy: 80.47\n",
      "[3,    91] loss: 0.37219, train_accuracy: 84.38\n",
      "[3,    92] loss: 0.53481, train_accuracy: 82.81\n",
      "[3,    93] loss: 0.45427, train_accuracy: 85.16\n",
      "[3,    94] loss: 0.59281, train_accuracy: 78.91\n",
      "[3,    95] loss: 0.56376, train_accuracy: 80.47\n",
      "[3,    96] loss: 0.53001, train_accuracy: 79.69\n",
      "[3,    97] loss: 0.48837, train_accuracy: 80.47\n",
      "[3,    98] loss: 0.39097, train_accuracy: 83.59\n",
      "[3,    99] loss: 0.43580, train_accuracy: 86.72\n",
      "[3,   100] loss: 0.53426, train_accuracy: 84.38\n",
      "[3,   101] loss: 0.60949, train_accuracy: 81.25\n",
      "[3,   102] loss: 0.45758, train_accuracy: 84.38\n",
      "[3,   103] loss: 0.58871, train_accuracy: 75.78\n",
      "[3,   104] loss: 0.55215, train_accuracy: 78.91\n",
      "[3,   105] loss: 0.27355, train_accuracy: 91.41\n",
      "[3,   106] loss: 0.50527, train_accuracy: 82.03\n",
      "[3,   107] loss: 0.52715, train_accuracy: 85.16\n",
      "[3,   108] loss: 0.51103, train_accuracy: 83.59\n",
      "[3,   109] loss: 0.38652, train_accuracy: 84.38\n",
      "[3,   110] loss: 0.54780, train_accuracy: 78.12\n",
      "[3,   111] loss: 0.45120, train_accuracy: 82.81\n",
      "[3,   112] loss: 0.58047, train_accuracy: 77.34\n",
      "[3,   113] loss: 0.47338, train_accuracy: 81.25\n",
      "[3,   114] loss: 0.36563, train_accuracy: 84.38\n",
      "[3,   115] loss: 0.59616, train_accuracy: 79.69\n",
      "[3,   116] loss: 0.40812, train_accuracy: 82.81\n",
      "[3,   117] loss: 0.60196, train_accuracy: 78.12\n",
      "[3,   118] loss: 0.46341, train_accuracy: 82.81\n",
      "[3,   119] loss: 0.33764, train_accuracy: 88.28\n",
      "[3,   120] loss: 0.74344, train_accuracy: 73.44\n",
      "[3,   121] loss: 0.36618, train_accuracy: 84.38\n",
      "[3,   122] loss: 0.60746, train_accuracy: 82.03\n",
      "[3,   123] loss: 0.55047, train_accuracy: 83.59\n",
      "[3,   124] loss: 0.67201, train_accuracy: 75.00\n",
      "[3,   125] loss: 0.38132, train_accuracy: 85.94\n",
      "[3,   126] loss: 0.41009, train_accuracy: 86.72\n",
      "[3,   127] loss: 0.45656, train_accuracy: 88.28\n",
      "[3,   128] loss: 0.55611, train_accuracy: 84.38\n",
      "[3,   129] loss: 0.54466, train_accuracy: 80.47\n",
      "[3,   130] loss: 0.50070, train_accuracy: 85.94\n",
      "[3,   131] loss: 0.51067, train_accuracy: 82.81\n",
      "[3,   132] loss: 0.43979, train_accuracy: 84.38\n",
      "[3,   133] loss: 0.57480, train_accuracy: 81.25\n",
      "[3,   134] loss: 0.42658, train_accuracy: 82.81\n",
      "[3,   135] loss: 0.53544, train_accuracy: 82.81\n",
      "[3,   136] loss: 0.49569, train_accuracy: 82.81\n",
      "[3,   137] loss: 0.54252, train_accuracy: 82.81\n",
      "[3,   138] loss: 0.57384, train_accuracy: 82.03\n",
      "[3,   139] loss: 0.44061, train_accuracy: 84.38\n",
      "[3,   140] loss: 0.61921, train_accuracy: 77.34\n",
      "[3,   141] loss: 0.44710, train_accuracy: 87.50\n",
      "[3,   142] loss: 0.55349, train_accuracy: 81.25\n",
      "[3,   143] loss: 0.45929, train_accuracy: 82.81\n",
      "[3,   144] loss: 0.46425, train_accuracy: 83.59\n",
      "[3,   145] loss: 0.41697, train_accuracy: 85.16\n",
      "[3,   146] loss: 0.53116, train_accuracy: 81.25\n",
      "[3,   147] loss: 0.48025, train_accuracy: 84.38\n",
      "[3,   148] loss: 0.46427, train_accuracy: 83.59\n",
      "[3,   149] loss: 0.42592, train_accuracy: 85.94\n",
      "[3,   150] loss: 0.51398, train_accuracy: 80.47\n",
      "[3,   151] loss: 0.65762, train_accuracy: 75.78\n",
      "[3,   152] loss: 0.34022, train_accuracy: 89.06\n",
      "[3,   153] loss: 0.36108, train_accuracy: 87.50\n",
      "[3,   154] loss: 0.35544, train_accuracy: 86.72\n",
      "[3,   155] loss: 0.60770, train_accuracy: 78.12\n",
      "[3,   156] loss: 0.37466, train_accuracy: 85.94\n",
      "[3,   157] loss: 0.54572, train_accuracy: 80.47\n",
      "[3,   158] loss: 0.62392, train_accuracy: 82.03\n",
      "[3,   159] loss: 0.53647, train_accuracy: 82.81\n",
      "[3,   160] loss: 0.65165, train_accuracy: 82.81\n",
      "[3,   161] loss: 0.34127, train_accuracy: 85.16\n",
      "[3,   162] loss: 0.44669, train_accuracy: 84.38\n",
      "[3,   163] loss: 0.61031, train_accuracy: 79.69\n",
      "[3,   164] loss: 0.54157, train_accuracy: 77.34\n",
      "[3,   165] loss: 0.65583, train_accuracy: 79.69\n",
      "[3,   166] loss: 0.55808, train_accuracy: 79.69\n",
      "[3,   167] loss: 0.56092, train_accuracy: 80.47\n",
      "[3,   168] loss: 0.58253, train_accuracy: 82.03\n",
      "[3,   169] loss: 0.41338, train_accuracy: 84.38\n",
      "[3,   170] loss: 0.38635, train_accuracy: 86.72\n",
      "[3,   171] loss: 0.51310, train_accuracy: 82.81\n",
      "[3,   172] loss: 0.50044, train_accuracy: 85.16\n",
      "[3,   173] loss: 0.56955, train_accuracy: 83.59\n",
      "[3,   174] loss: 0.61584, train_accuracy: 76.56\n",
      "[3,   175] loss: 0.39435, train_accuracy: 83.59\n",
      "[3,   176] loss: 0.38436, train_accuracy: 86.72\n",
      "[3,   177] loss: 0.56742, train_accuracy: 81.25\n",
      "[3,   178] loss: 0.59976, train_accuracy: 81.25\n",
      "[3,   179] loss: 0.60221, train_accuracy: 80.47\n",
      "[3,   180] loss: 0.49840, train_accuracy: 84.38\n",
      "[3,   181] loss: 0.49067, train_accuracy: 85.94\n",
      "[3,   182] loss: 0.46093, train_accuracy: 85.94\n",
      "[3,   183] loss: 0.59252, train_accuracy: 78.91\n",
      "[3,   184] loss: 0.58956, train_accuracy: 79.69\n",
      "[3,   185] loss: 0.53410, train_accuracy: 81.25\n",
      "[3,   186] loss: 0.52793, train_accuracy: 82.03\n",
      "[3,   187] loss: 0.61440, train_accuracy: 78.91\n",
      "[3,   188] loss: 0.56246, train_accuracy: 73.44\n",
      "[3,   189] loss: 0.44074, train_accuracy: 85.16\n",
      "[3,   190] loss: 0.60059, train_accuracy: 78.91\n",
      "[3,   191] loss: 0.50866, train_accuracy: 82.03\n",
      "[3,   192] loss: 0.52688, train_accuracy: 84.38\n",
      "[3,   193] loss: 0.48259, train_accuracy: 85.16\n",
      "[3,   194] loss: 0.53897, train_accuracy: 81.25\n",
      "[3,   195] loss: 0.58132, train_accuracy: 80.47\n",
      "[3,   196] loss: 0.53760, train_accuracy: 81.25\n",
      "[3,   197] loss: 0.44391, train_accuracy: 82.03\n",
      "[3,   198] loss: 0.45102, train_accuracy: 85.16\n",
      "[3,   199] loss: 0.44118, train_accuracy: 84.38\n",
      "[3,   200] loss: 0.51883, train_accuracy: 82.03\n",
      "[3,   201] loss: 0.59868, train_accuracy: 80.47\n",
      "[3,   202] loss: 0.55050, train_accuracy: 85.16\n",
      "[3,   203] loss: 0.47754, train_accuracy: 85.94\n",
      "[3,   204] loss: 0.59339, train_accuracy: 81.25\n",
      "[3,   205] loss: 0.73746, train_accuracy: 78.12\n",
      "[3,   206] loss: 0.55036, train_accuracy: 79.69\n",
      "[3,   207] loss: 0.57887, train_accuracy: 82.03\n",
      "[3,   208] loss: 0.57831, train_accuracy: 79.69\n",
      "[3,   209] loss: 0.53158, train_accuracy: 82.81\n",
      "[3,   210] loss: 0.61642, train_accuracy: 78.12\n",
      "[3,   211] loss: 0.60092, train_accuracy: 78.91\n",
      "[3,   212] loss: 0.45756, train_accuracy: 83.59\n",
      "[3,   213] loss: 0.52685, train_accuracy: 82.03\n",
      "[3,   214] loss: 0.63287, train_accuracy: 75.78\n",
      "[3,   215] loss: 0.52394, train_accuracy: 80.47\n",
      "[3,   216] loss: 0.57018, train_accuracy: 78.12\n",
      "[3,   217] loss: 0.56990, train_accuracy: 81.25\n",
      "[3,   218] loss: 0.33228, train_accuracy: 90.62\n",
      "[3,   219] loss: 0.44054, train_accuracy: 84.38\n",
      "[3,   220] loss: 0.56817, train_accuracy: 79.69\n",
      "[3,   221] loss: 0.80364, train_accuracy: 75.00\n",
      "[3,   222] loss: 0.63859, train_accuracy: 77.34\n",
      "[3,   223] loss: 0.42923, train_accuracy: 89.06\n",
      "[3,   224] loss: 0.44451, train_accuracy: 86.72\n",
      "[3,   225] loss: 0.48023, train_accuracy: 80.47\n",
      "[3,   226] loss: 0.50458, train_accuracy: 82.03\n",
      "[3,   227] loss: 0.44810, train_accuracy: 83.59\n",
      "[3,   228] loss: 0.38429, train_accuracy: 86.72\n",
      "[3,   229] loss: 0.57515, train_accuracy: 83.59\n",
      "[3,   230] loss: 0.41594, train_accuracy: 86.72\n",
      "[3,   231] loss: 0.60049, train_accuracy: 82.81\n",
      "[3,   232] loss: 0.53097, train_accuracy: 82.03\n",
      "[3,   233] loss: 0.55737, train_accuracy: 81.25\n",
      "[3,   234] loss: 0.60329, train_accuracy: 80.47\n",
      "[3,   235] loss: 0.55126, train_accuracy: 79.69\n",
      "[3,   236] loss: 0.50267, train_accuracy: 81.25\n",
      "[3,   237] loss: 0.46740, train_accuracy: 88.28\n",
      "[3,   238] loss: 0.50216, train_accuracy: 82.81\n",
      "[3,   239] loss: 0.50591, train_accuracy: 83.59\n",
      "[3,   240] loss: 0.53038, train_accuracy: 82.03\n",
      "[3,   241] loss: 0.46505, train_accuracy: 84.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   242] loss: 0.48183, train_accuracy: 83.59\n",
      "[3,   243] loss: 0.41562, train_accuracy: 85.94\n",
      "[3,   244] loss: 0.45297, train_accuracy: 86.72\n",
      "[3,   245] loss: 0.34392, train_accuracy: 87.50\n",
      "[3,   246] loss: 0.58279, train_accuracy: 78.91\n",
      "[3,   247] loss: 0.37382, train_accuracy: 89.06\n",
      "[3,   248] loss: 0.26941, train_accuracy: 89.06\n",
      "[3,   249] loss: 0.37677, train_accuracy: 89.06\n",
      "[3,   250] loss: 0.57498, train_accuracy: 85.16\n",
      "[3,   251] loss: 0.54554, train_accuracy: 82.03\n",
      "[3,   252] loss: 0.55200, train_accuracy: 82.03\n",
      "[3,   253] loss: 0.53162, train_accuracy: 82.81\n",
      "[3,   254] loss: 0.24473, train_accuracy: 92.97\n",
      "[3,   255] loss: 0.67899, train_accuracy: 79.69\n",
      "[3,   256] loss: 0.59410, train_accuracy: 79.69\n",
      "[3,   257] loss: 0.63307, train_accuracy: 76.56\n",
      "[3,   258] loss: 0.45097, train_accuracy: 84.38\n",
      "[3,   259] loss: 0.47619, train_accuracy: 82.81\n",
      "[3,   260] loss: 0.61511, train_accuracy: 78.12\n",
      "[3,   261] loss: 0.63656, train_accuracy: 75.78\n",
      "[3,   262] loss: 0.48871, train_accuracy: 79.69\n",
      "[3,   263] loss: 0.45587, train_accuracy: 84.38\n",
      "[3,   264] loss: 0.44478, train_accuracy: 80.47\n",
      "[3,   265] loss: 0.40638, train_accuracy: 88.28\n",
      "[3,   266] loss: 0.42676, train_accuracy: 82.81\n",
      "[3,   267] loss: 0.47752, train_accuracy: 82.03\n",
      "[3,   268] loss: 0.37896, train_accuracy: 83.59\n",
      "[3,   269] loss: 0.47829, train_accuracy: 85.16\n",
      "[3,   270] loss: 0.53966, train_accuracy: 78.91\n",
      "[3,   271] loss: 0.47723, train_accuracy: 82.81\n",
      "[3,   272] loss: 0.33567, train_accuracy: 88.28\n",
      "[3,   273] loss: 0.56851, train_accuracy: 84.38\n",
      "[3,   274] loss: 0.63479, train_accuracy: 75.78\n",
      "[3,   275] loss: 0.39861, train_accuracy: 87.50\n",
      "[3,   276] loss: 0.46962, train_accuracy: 85.16\n",
      "[3,   277] loss: 0.55131, train_accuracy: 77.34\n",
      "[3,   278] loss: 0.47023, train_accuracy: 85.94\n",
      "[3,   279] loss: 0.42575, train_accuracy: 84.38\n",
      "[3,   280] loss: 0.60414, train_accuracy: 79.69\n",
      "[3,   281] loss: 0.41584, train_accuracy: 85.16\n",
      "[3,   282] loss: 0.59970, train_accuracy: 79.69\n",
      "[3,   283] loss: 0.48661, train_accuracy: 85.16\n",
      "[3,   284] loss: 0.55298, train_accuracy: 84.38\n",
      "[3,   285] loss: 0.73731, train_accuracy: 82.81\n",
      "[3,   286] loss: 0.55049, train_accuracy: 81.25\n",
      "[3,   287] loss: 0.43640, train_accuracy: 89.84\n",
      "[3,   288] loss: 0.57858, train_accuracy: 82.03\n",
      "[3,   289] loss: 0.41753, train_accuracy: 88.28\n",
      "[3,   290] loss: 0.50018, train_accuracy: 84.38\n",
      "[3,   291] loss: 0.60899, train_accuracy: 79.69\n",
      "[3,   292] loss: 0.51259, train_accuracy: 85.94\n",
      "[3,   293] loss: 0.55322, train_accuracy: 78.91\n",
      "[3,   294] loss: 0.45259, train_accuracy: 81.25\n",
      "[3,   295] loss: 0.52970, train_accuracy: 78.91\n",
      "[3,   296] loss: 0.55469, train_accuracy: 79.69\n",
      "[3,   297] loss: 0.53935, train_accuracy: 80.47\n",
      "[3,   298] loss: 0.42092, train_accuracy: 84.38\n",
      "[3,   299] loss: 0.57887, train_accuracy: 83.59\n",
      "[3,   300] loss: 0.40846, train_accuracy: 88.28\n",
      "[3,   301] loss: 0.66818, train_accuracy: 84.38\n",
      "[3,   302] loss: 0.37747, train_accuracy: 86.72\n",
      "[3,   303] loss: 0.47937, train_accuracy: 84.38\n",
      "[3,   304] loss: 0.43940, train_accuracy: 87.50\n",
      "[3,   305] loss: 0.38785, train_accuracy: 85.94\n",
      "[3,   306] loss: 0.58279, train_accuracy: 79.69\n",
      "[3,   307] loss: 0.58539, train_accuracy: 79.69\n",
      "[3,   308] loss: 0.55458, train_accuracy: 81.25\n",
      "[3,   309] loss: 0.68062, train_accuracy: 81.25\n",
      "[3,   310] loss: 0.39796, train_accuracy: 85.16\n",
      "[3,   311] loss: 0.50710, train_accuracy: 77.34\n",
      "[3,   312] loss: 0.50944, train_accuracy: 81.25\n",
      "[3,   313] loss: 0.54993, train_accuracy: 81.25\n",
      "[3,   314] loss: 0.39019, train_accuracy: 85.16\n",
      "[3,   315] loss: 0.40038, train_accuracy: 85.94\n",
      "[3,   316] loss: 0.52974, train_accuracy: 81.25\n",
      "[3,   317] loss: 0.50684, train_accuracy: 83.59\n",
      "[3,   318] loss: 0.47190, train_accuracy: 78.91\n",
      "[3,   319] loss: 0.43079, train_accuracy: 83.59\n",
      "[3,   320] loss: 0.56491, train_accuracy: 80.47\n",
      "[3,   321] loss: 0.53464, train_accuracy: 82.03\n",
      "[3,   322] loss: 0.42007, train_accuracy: 86.72\n",
      "[3,   323] loss: 0.49394, train_accuracy: 82.81\n",
      "[3,   324] loss: 0.57323, train_accuracy: 82.03\n",
      "[3,   325] loss: 0.47067, train_accuracy: 79.69\n",
      "[3,   326] loss: 0.62075, train_accuracy: 80.47\n",
      "[3,   327] loss: 0.39856, train_accuracy: 85.94\n",
      "[3,   328] loss: 0.44705, train_accuracy: 84.38\n",
      "[3,   329] loss: 0.62576, train_accuracy: 78.12\n",
      "[3,   330] loss: 0.51301, train_accuracy: 82.81\n",
      "[3,   331] loss: 0.40947, train_accuracy: 81.25\n",
      "[3,   332] loss: 0.48153, train_accuracy: 80.47\n",
      "[3,   333] loss: 0.52683, train_accuracy: 80.47\n",
      "[3,   334] loss: 0.58262, train_accuracy: 81.25\n",
      "[3,   335] loss: 0.44786, train_accuracy: 82.03\n",
      "[3,   336] loss: 0.59606, train_accuracy: 84.38\n",
      "[3,   337] loss: 0.57466, train_accuracy: 81.25\n",
      "[3,   338] loss: 0.30676, train_accuracy: 92.19\n",
      "[3,   339] loss: 0.46414, train_accuracy: 86.72\n",
      "[3,   340] loss: 0.39821, train_accuracy: 86.72\n",
      "[3,   341] loss: 0.44531, train_accuracy: 84.38\n",
      "[3,   342] loss: 0.57196, train_accuracy: 79.69\n",
      "[3,   343] loss: 0.55710, train_accuracy: 79.69\n",
      "[3,   344] loss: 0.64717, train_accuracy: 83.59\n",
      "[3,   345] loss: 0.53306, train_accuracy: 82.03\n",
      "[3,   346] loss: 0.36372, train_accuracy: 87.50\n",
      "[3,   347] loss: 0.54548, train_accuracy: 80.47\n",
      "[3,   348] loss: 0.66489, train_accuracy: 79.69\n",
      "[3,   349] loss: 0.47969, train_accuracy: 82.03\n",
      "[3,   350] loss: 0.58869, train_accuracy: 80.47\n",
      "[3,   351] loss: 0.42535, train_accuracy: 87.50\n",
      "[3,   352] loss: 0.46114, train_accuracy: 80.47\n",
      "[3,   353] loss: 0.42051, train_accuracy: 82.03\n",
      "[3,   354] loss: 0.60311, train_accuracy: 80.47\n",
      "[3,   355] loss: 0.48813, train_accuracy: 83.59\n",
      "[3,   356] loss: 0.51126, train_accuracy: 81.25\n",
      "[3,   357] loss: 0.49060, train_accuracy: 85.16\n",
      "[3,   358] loss: 0.51849, train_accuracy: 82.03\n",
      "[3,   359] loss: 0.55249, train_accuracy: 80.47\n",
      "[3,   360] loss: 0.53860, train_accuracy: 78.12\n",
      "[3,   361] loss: 0.51989, train_accuracy: 84.38\n",
      "[3,   362] loss: 0.36517, train_accuracy: 85.94\n",
      "[3,   363] loss: 0.53064, train_accuracy: 81.25\n",
      "[3,   364] loss: 0.50381, train_accuracy: 80.47\n",
      "[3,   365] loss: 0.53901, train_accuracy: 79.69\n",
      "[3,   366] loss: 0.53534, train_accuracy: 82.03\n",
      "[3,   367] loss: 0.45779, train_accuracy: 83.59\n",
      "[3,   368] loss: 0.53011, train_accuracy: 82.81\n",
      "[3,   369] loss: 0.46956, train_accuracy: 80.47\n",
      "[3,   370] loss: 0.49453, train_accuracy: 84.38\n",
      "[3,   371] loss: 0.68962, train_accuracy: 80.47\n",
      "[3,   372] loss: 0.58511, train_accuracy: 77.34\n",
      "[3,   373] loss: 0.59842, train_accuracy: 77.34\n",
      "[3,   374] loss: 0.58456, train_accuracy: 75.78\n",
      "[3,   375] loss: 0.56729, train_accuracy: 78.12\n",
      "[3,   376] loss: 0.44978, train_accuracy: 83.59\n",
      "[3,   377] loss: 0.59429, train_accuracy: 78.91\n",
      "[3,   378] loss: 0.47410, train_accuracy: 82.03\n",
      "[3,   379] loss: 0.49624, train_accuracy: 84.38\n",
      "[3,   380] loss: 0.58053, train_accuracy: 80.47\n",
      "[3,   381] loss: 0.49164, train_accuracy: 80.47\n",
      "[3,   382] loss: 0.59447, train_accuracy: 78.12\n",
      "[3,   383] loss: 0.49500, train_accuracy: 82.81\n",
      "[3,   384] loss: 0.51324, train_accuracy: 84.38\n",
      "[3,   385] loss: 0.59456, train_accuracy: 83.59\n",
      "[3,   386] loss: 0.44125, train_accuracy: 83.59\n",
      "[3,   387] loss: 0.70485, train_accuracy: 78.91\n",
      "[3,   388] loss: 0.49253, train_accuracy: 82.03\n",
      "[3,   389] loss: 0.44363, train_accuracy: 78.12\n",
      "[3,   390] loss: 0.47808, train_accuracy: 85.16\n",
      "[3,   391] loss: 0.43659, train_accuracy: 85.00\n",
      "duration: 108 s - train loss: 0.50506 - train accuracy: 82.69 - validation loss: 0.68 - validation accuracy: 77.92 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.413389</td>\n",
       "      <td>38.807545</td>\n",
       "      <td>1.304850</td>\n",
       "      <td>54.43</td>\n",
       "      <td>108.108993</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.134127</td>\n",
       "      <td>60.045556</td>\n",
       "      <td>0.990263</td>\n",
       "      <td>64.52</td>\n",
       "      <td>216.399744</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.865272</td>\n",
       "      <td>69.462916</td>\n",
       "      <td>0.899868</td>\n",
       "      <td>69.36</td>\n",
       "      <td>324.463973</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.866134</td>\n",
       "      <td>71.691176</td>\n",
       "      <td>0.764294</td>\n",
       "      <td>74.04</td>\n",
       "      <td>108.423787</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.622638</td>\n",
       "      <td>78.392743</td>\n",
       "      <td>0.738648</td>\n",
       "      <td>75.15</td>\n",
       "      <td>216.943161</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.505064</td>\n",
       "      <td>82.688219</td>\n",
       "      <td>0.676020</td>\n",
       "      <td>77.92</td>\n",
       "      <td>325.141385</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch  train_loss  train_accuracy  validation_loss  validation_accuracy  \\\n",
       "0     1    2.413389       38.807545         1.304850                54.43   \n",
       "1     2    1.134127       60.045556         0.990263                64.52   \n",
       "2     3    0.865272       69.462916         0.899868                69.36   \n",
       "3     1    0.866134       71.691176         0.764294                74.04   \n",
       "4     2    0.622638       78.392743         0.738648                75.15   \n",
       "5     3    0.505064       82.688219         0.676020                77.92   \n",
       "\n",
       "     duration           criterion  \\\n",
       "0  108.108993  CrossEntropyLoss()   \n",
       "1  216.399744  CrossEntropyLoss()   \n",
       "2  324.463973  CrossEntropyLoss()   \n",
       "3  108.423787  CrossEntropyLoss()   \n",
       "4  216.943161  CrossEntropyLoss()   \n",
       "5  325.141385  CrossEntropyLoss()   \n",
       "\n",
       "                                           optimizer    method  learning_rate  \\\n",
       "0  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard            NaN   \n",
       "1  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard            NaN   \n",
       "2  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard            NaN   \n",
       "3  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard            NaN   \n",
       "4  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard            NaN   \n",
       "5  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard            NaN   \n",
       "\n",
       "  batchsize  \n",
       "0        80  \n",
       "1        80  \n",
       "2        80  \n",
       "3        80  \n",
       "4        80  \n",
       "5        80  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = CifarResNet().to(device)\n",
    "model.fit(train_loader, test_loader, 3, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_stats['optimizer'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pipeline - 152s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "[1,     1] loss: 2.78745, train_accuracy: 10.16\n",
      "[1,     2] loss: 34.23767, train_accuracy: 9.38\n",
      "[1,     3] loss: 23.95284, train_accuracy: 18.75\n",
      "[1,     4] loss: 30.55729, train_accuracy: 13.28\n",
      "[1,     5] loss: 36.58367, train_accuracy: 10.94\n",
      "[1,     6] loss: 26.28638, train_accuracy: 6.25\n",
      "[1,     7] loss: 13.82383, train_accuracy: 10.16\n",
      "[1,     8] loss: 15.66329, train_accuracy: 14.06\n",
      "[1,     9] loss: 12.64819, train_accuracy: 8.59\n",
      "[1,    10] loss: 15.36391, train_accuracy: 7.81\n",
      "[1,    11] loss: 7.47738, train_accuracy: 10.16\n",
      "[1,    12] loss: 17.23159, train_accuracy: 9.38\n",
      "[1,    13] loss: 14.77475, train_accuracy: 7.03\n",
      "[1,    14] loss: 9.23299, train_accuracy: 7.03\n",
      "[1,    15] loss: 9.45286, train_accuracy: 13.28\n",
      "[1,    16] loss: 6.93368, train_accuracy: 13.28\n",
      "[1,    17] loss: 6.41030, train_accuracy: 10.16\n",
      "[1,    18] loss: 8.64443, train_accuracy: 10.94\n",
      "[1,    19] loss: 3.52179, train_accuracy: 10.16\n",
      "[1,    20] loss: 5.16632, train_accuracy: 17.19\n",
      "[1,    21] loss: 6.64420, train_accuracy: 12.50\n",
      "[1,    22] loss: 4.60088, train_accuracy: 10.94\n",
      "[1,    23] loss: 3.70901, train_accuracy: 14.06\n",
      "[1,    24] loss: 5.51887, train_accuracy: 14.06\n",
      "[1,    25] loss: 4.16165, train_accuracy: 14.84\n",
      "[1,    26] loss: 3.10675, train_accuracy: 14.84\n",
      "[1,    27] loss: 3.56272, train_accuracy: 14.06\n",
      "[1,    28] loss: 3.32372, train_accuracy: 18.75\n",
      "[1,    29] loss: 2.81550, train_accuracy: 17.19\n",
      "[1,    30] loss: 3.38791, train_accuracy: 18.75\n",
      "[1,    31] loss: 5.20483, train_accuracy: 16.41\n",
      "[1,    32] loss: 4.92925, train_accuracy: 21.88\n",
      "[1,    33] loss: 5.29606, train_accuracy: 14.84\n",
      "[1,    34] loss: 8.39919, train_accuracy: 14.84\n",
      "[1,    35] loss: 2.62127, train_accuracy: 14.84\n",
      "[1,    36] loss: 6.85231, train_accuracy: 18.75\n",
      "[1,    37] loss: 3.47506, train_accuracy: 20.31\n",
      "[1,    38] loss: 5.89118, train_accuracy: 19.53\n",
      "[1,    39] loss: 5.08634, train_accuracy: 15.62\n",
      "[1,    40] loss: 3.89039, train_accuracy: 16.41\n",
      "[1,    41] loss: 3.47617, train_accuracy: 21.09\n",
      "[1,    42] loss: 3.21907, train_accuracy: 9.38\n",
      "[1,    43] loss: 3.26662, train_accuracy: 16.41\n",
      "[1,    44] loss: 3.71223, train_accuracy: 17.19\n",
      "[1,    45] loss: 2.44602, train_accuracy: 17.97\n",
      "[1,    46] loss: 2.48889, train_accuracy: 16.41\n",
      "[1,    47] loss: 4.33761, train_accuracy: 15.62\n",
      "[1,    48] loss: 4.24951, train_accuracy: 16.41\n",
      "[1,    49] loss: 6.10761, train_accuracy: 17.97\n",
      "[1,    50] loss: 3.68054, train_accuracy: 24.22\n",
      "[1,    51] loss: 3.84263, train_accuracy: 20.31\n",
      "[1,    52] loss: 2.82055, train_accuracy: 17.97\n",
      "[1,    53] loss: 5.62278, train_accuracy: 17.19\n",
      "[1,    54] loss: 6.08256, train_accuracy: 14.84\n",
      "[1,    55] loss: 2.84465, train_accuracy: 14.84\n",
      "[1,    56] loss: 4.76352, train_accuracy: 10.94\n",
      "[1,    57] loss: 3.04015, train_accuracy: 14.06\n",
      "[1,    58] loss: 3.27966, train_accuracy: 21.09\n",
      "[1,    59] loss: 2.60228, train_accuracy: 20.31\n",
      "[1,    60] loss: 4.44363, train_accuracy: 17.97\n",
      "[1,    61] loss: 2.94604, train_accuracy: 20.31\n",
      "[1,    62] loss: 3.13361, train_accuracy: 13.28\n",
      "[1,    63] loss: 2.96189, train_accuracy: 15.62\n",
      "[1,    64] loss: 2.78947, train_accuracy: 21.88\n",
      "[1,    65] loss: 2.32507, train_accuracy: 23.44\n",
      "[1,    66] loss: 2.65508, train_accuracy: 19.53\n",
      "[1,    67] loss: 2.41103, train_accuracy: 18.75\n",
      "[1,    68] loss: 2.45981, train_accuracy: 21.09\n",
      "[1,    69] loss: 5.12264, train_accuracy: 21.09\n",
      "[1,    70] loss: 2.70214, train_accuracy: 15.62\n",
      "[1,    71] loss: 3.23162, train_accuracy: 19.53\n",
      "[1,    72] loss: 2.82983, train_accuracy: 14.84\n",
      "[1,    73] loss: 4.65642, train_accuracy: 24.22\n",
      "[1,    74] loss: 3.06562, train_accuracy: 15.62\n",
      "[1,    75] loss: 2.62362, train_accuracy: 17.97\n",
      "[1,    76] loss: 2.48927, train_accuracy: 21.88\n",
      "[1,    77] loss: 2.90036, train_accuracy: 21.09\n",
      "[1,    78] loss: 3.83427, train_accuracy: 25.00\n",
      "[1,    79] loss: 3.82826, train_accuracy: 20.31\n",
      "[1,    80] loss: 3.99170, train_accuracy: 21.88\n",
      "[1,    81] loss: 2.89740, train_accuracy: 17.97\n",
      "[1,    82] loss: 4.06004, train_accuracy: 14.06\n",
      "[1,    83] loss: 2.40971, train_accuracy: 23.44\n",
      "[1,    84] loss: 3.51612, train_accuracy: 24.22\n",
      "[1,    85] loss: 2.84454, train_accuracy: 14.84\n",
      "[1,    86] loss: 2.68618, train_accuracy: 18.75\n",
      "[1,    87] loss: 2.22890, train_accuracy: 20.31\n",
      "[1,    88] loss: 2.38998, train_accuracy: 17.97\n",
      "[1,    89] loss: 3.07022, train_accuracy: 14.06\n",
      "[1,    90] loss: 2.69884, train_accuracy: 23.44\n",
      "[1,    91] loss: 2.66685, train_accuracy: 23.44\n",
      "[1,    92] loss: 2.94553, train_accuracy: 17.19\n",
      "[1,    93] loss: 2.85165, train_accuracy: 17.19\n",
      "[1,    94] loss: 2.16247, train_accuracy: 18.75\n",
      "[1,    95] loss: 2.62699, train_accuracy: 14.84\n",
      "[1,    96] loss: 2.24401, train_accuracy: 22.66\n",
      "[1,    97] loss: 2.55322, train_accuracy: 19.53\n",
      "[1,    98] loss: 2.37941, train_accuracy: 23.44\n",
      "[1,    99] loss: 2.47411, train_accuracy: 21.09\n",
      "[1,   100] loss: 2.43081, train_accuracy: 20.31\n",
      "[1,   101] loss: 2.26038, train_accuracy: 17.97\n",
      "[1,   102] loss: 2.24728, train_accuracy: 21.09\n",
      "[1,   103] loss: 2.96000, train_accuracy: 19.53\n",
      "[1,   104] loss: 2.44949, train_accuracy: 20.31\n",
      "[1,   105] loss: 2.11788, train_accuracy: 19.53\n",
      "[1,   106] loss: 2.36887, train_accuracy: 21.09\n",
      "[1,   107] loss: 3.77126, train_accuracy: 17.97\n",
      "[1,   108] loss: 2.19082, train_accuracy: 23.44\n",
      "[1,   109] loss: 2.78941, train_accuracy: 20.31\n",
      "[1,   110] loss: 2.57811, train_accuracy: 17.19\n",
      "[1,   111] loss: 2.55662, train_accuracy: 17.19\n",
      "[1,   112] loss: 2.69125, train_accuracy: 18.75\n",
      "[1,   113] loss: 2.17158, train_accuracy: 21.09\n",
      "[1,   114] loss: 2.24136, train_accuracy: 24.22\n",
      "[1,   115] loss: 2.44821, train_accuracy: 22.66\n",
      "[1,   116] loss: 2.49735, train_accuracy: 21.09\n",
      "[1,   117] loss: 2.72921, train_accuracy: 14.84\n",
      "[1,   118] loss: 2.03779, train_accuracy: 21.88\n",
      "[1,   119] loss: 3.09378, train_accuracy: 20.31\n",
      "[1,   120] loss: 2.88409, train_accuracy: 29.69\n",
      "[1,   121] loss: 2.60965, train_accuracy: 21.88\n",
      "[1,   122] loss: 3.26628, train_accuracy: 17.19\n",
      "[1,   123] loss: 3.08149, train_accuracy: 14.84\n",
      "[1,   124] loss: 2.92165, train_accuracy: 20.31\n",
      "[1,   125] loss: 2.86876, train_accuracy: 17.19\n",
      "[1,   126] loss: 2.18962, train_accuracy: 23.44\n",
      "[1,   127] loss: 2.77140, train_accuracy: 28.12\n",
      "[1,   128] loss: 2.16034, train_accuracy: 31.25\n",
      "[1,   129] loss: 2.51285, train_accuracy: 25.00\n",
      "[1,   130] loss: 2.68399, train_accuracy: 21.09\n",
      "[1,   131] loss: 2.14045, train_accuracy: 28.91\n",
      "[1,   132] loss: 2.41902, train_accuracy: 20.31\n",
      "[1,   133] loss: 2.69960, train_accuracy: 16.41\n",
      "[1,   134] loss: 2.50551, train_accuracy: 17.19\n",
      "[1,   135] loss: 2.42051, train_accuracy: 19.53\n",
      "[1,   136] loss: 2.50706, train_accuracy: 17.19\n",
      "[1,   137] loss: 2.50606, train_accuracy: 28.12\n",
      "[1,   138] loss: 2.52412, train_accuracy: 30.47\n",
      "[1,   139] loss: 2.18912, train_accuracy: 21.09\n",
      "[1,   140] loss: 2.85793, train_accuracy: 24.22\n",
      "[1,   141] loss: 2.38743, train_accuracy: 28.91\n",
      "[1,   142] loss: 2.13546, train_accuracy: 29.69\n",
      "[1,   143] loss: 2.13252, train_accuracy: 23.44\n",
      "[1,   144] loss: 2.37435, train_accuracy: 21.09\n",
      "[1,   145] loss: 2.40583, train_accuracy: 21.09\n",
      "[1,   146] loss: 2.14640, train_accuracy: 21.88\n",
      "[1,   147] loss: 2.41512, train_accuracy: 23.44\n",
      "[1,   148] loss: 2.21557, train_accuracy: 17.97\n",
      "[1,   149] loss: 3.29576, train_accuracy: 15.62\n",
      "[1,   150] loss: 2.50485, train_accuracy: 17.97\n",
      "[1,   151] loss: 2.50820, train_accuracy: 30.47\n",
      "[1,   152] loss: 3.52602, train_accuracy: 11.72\n",
      "[1,   153] loss: 2.31061, train_accuracy: 17.97\n",
      "[1,   154] loss: 2.30256, train_accuracy: 22.66\n",
      "[1,   155] loss: 2.68047, train_accuracy: 17.19\n",
      "[1,   156] loss: 2.56950, train_accuracy: 29.69\n",
      "[1,   157] loss: 2.39091, train_accuracy: 20.31\n",
      "[1,   158] loss: 2.47588, train_accuracy: 24.22\n",
      "[1,   159] loss: 2.36430, train_accuracy: 18.75\n",
      "[1,   160] loss: 3.08577, train_accuracy: 16.41\n",
      "[1,   161] loss: 2.80754, train_accuracy: 17.97\n",
      "[1,   162] loss: 2.14345, train_accuracy: 28.91\n",
      "[1,   163] loss: 2.42210, train_accuracy: 21.09\n",
      "[1,   164] loss: 2.00569, train_accuracy: 23.44\n",
      "[1,   165] loss: 1.89467, train_accuracy: 27.34\n",
      "[1,   166] loss: 2.10167, train_accuracy: 23.44\n",
      "[1,   167] loss: 2.94032, train_accuracy: 24.22\n",
      "[1,   168] loss: 3.58411, train_accuracy: 19.53\n",
      "[1,   169] loss: 2.74760, train_accuracy: 18.75\n",
      "[1,   170] loss: 2.32044, train_accuracy: 17.97\n",
      "[1,   171] loss: 2.27581, train_accuracy: 14.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   172] loss: 2.44553, train_accuracy: 22.66\n",
      "[1,   173] loss: 2.74980, train_accuracy: 21.88\n",
      "[1,   174] loss: 2.65715, train_accuracy: 21.88\n",
      "[1,   175] loss: 2.53540, train_accuracy: 27.34\n",
      "[1,   176] loss: 2.64625, train_accuracy: 21.88\n",
      "[1,   177] loss: 2.26340, train_accuracy: 17.97\n",
      "[1,   178] loss: 2.17109, train_accuracy: 17.19\n",
      "[1,   179] loss: 2.14707, train_accuracy: 22.66\n",
      "[1,   180] loss: 2.48100, train_accuracy: 20.31\n",
      "[1,   181] loss: 2.62162, train_accuracy: 19.53\n",
      "[1,   182] loss: 2.33696, train_accuracy: 25.78\n",
      "[1,   183] loss: 2.10156, train_accuracy: 18.75\n",
      "[1,   184] loss: 2.27609, train_accuracy: 21.09\n",
      "[1,   185] loss: 2.40949, train_accuracy: 15.62\n",
      "[1,   186] loss: 2.09517, train_accuracy: 23.44\n",
      "[1,   187] loss: 2.39182, train_accuracy: 16.41\n",
      "[1,   188] loss: 2.20529, train_accuracy: 18.75\n",
      "[1,   189] loss: 2.35630, train_accuracy: 16.41\n",
      "[1,   190] loss: 2.15628, train_accuracy: 28.12\n",
      "[1,   191] loss: 1.94121, train_accuracy: 26.56\n",
      "[1,   192] loss: 2.54936, train_accuracy: 21.88\n",
      "[1,   193] loss: 2.29987, train_accuracy: 20.31\n",
      "[1,   194] loss: 2.18173, train_accuracy: 20.31\n",
      "[1,   195] loss: 2.32252, train_accuracy: 24.22\n",
      "[1,   196] loss: 1.98081, train_accuracy: 25.78\n",
      "[1,   197] loss: 2.03222, train_accuracy: 18.75\n",
      "[1,   198] loss: 2.11276, train_accuracy: 23.44\n",
      "[1,   199] loss: 2.14268, train_accuracy: 21.09\n",
      "[1,   200] loss: 2.14227, train_accuracy: 25.00\n",
      "[1,   201] loss: 1.94526, train_accuracy: 25.00\n",
      "[1,   202] loss: 2.01577, train_accuracy: 28.12\n",
      "[1,   203] loss: 2.05284, train_accuracy: 28.91\n",
      "[1,   204] loss: 2.45270, train_accuracy: 26.56\n",
      "[1,   205] loss: 2.08827, train_accuracy: 23.44\n",
      "[1,   206] loss: 2.29262, train_accuracy: 32.81\n",
      "[1,   207] loss: 2.01392, train_accuracy: 24.22\n",
      "[1,   208] loss: 2.01302, train_accuracy: 25.00\n",
      "[1,   209] loss: 2.31530, train_accuracy: 17.19\n",
      "[1,   210] loss: 2.05438, train_accuracy: 28.12\n",
      "[1,   211] loss: 2.32135, train_accuracy: 26.56\n",
      "[1,   212] loss: 1.92007, train_accuracy: 24.22\n",
      "[1,   213] loss: 1.99058, train_accuracy: 28.91\n",
      "[1,   214] loss: 2.43108, train_accuracy: 23.44\n",
      "[1,   215] loss: 1.96790, train_accuracy: 25.78\n",
      "[1,   216] loss: 2.04652, train_accuracy: 24.22\n",
      "[1,   217] loss: 2.22953, train_accuracy: 27.34\n",
      "[1,   218] loss: 2.04127, train_accuracy: 23.44\n",
      "[1,   219] loss: 2.13757, train_accuracy: 21.09\n",
      "[1,   220] loss: 2.23494, train_accuracy: 24.22\n",
      "[1,   221] loss: 1.83652, train_accuracy: 29.69\n",
      "[1,   222] loss: 2.10981, train_accuracy: 21.88\n",
      "[1,   223] loss: 2.42617, train_accuracy: 28.12\n",
      "[1,   224] loss: 2.26267, train_accuracy: 19.53\n",
      "[1,   225] loss: 1.96035, train_accuracy: 19.53\n",
      "[1,   226] loss: 1.87969, train_accuracy: 26.56\n",
      "[1,   227] loss: 2.14561, train_accuracy: 29.69\n",
      "[1,   228] loss: 2.28735, train_accuracy: 19.53\n",
      "[1,   229] loss: 2.18912, train_accuracy: 22.66\n",
      "[1,   230] loss: 2.16246, train_accuracy: 28.12\n",
      "[1,   231] loss: 2.17066, train_accuracy: 27.34\n",
      "[1,   232] loss: 2.49638, train_accuracy: 18.75\n",
      "[1,   233] loss: 1.97551, train_accuracy: 29.69\n",
      "[1,   234] loss: 2.47761, train_accuracy: 23.44\n",
      "[1,   235] loss: 2.10186, train_accuracy: 26.56\n",
      "[1,   236] loss: 1.97488, train_accuracy: 30.47\n",
      "[1,   237] loss: 2.06023, train_accuracy: 25.00\n",
      "[1,   238] loss: 2.06819, train_accuracy: 19.53\n",
      "[1,   239] loss: 2.23074, train_accuracy: 17.19\n",
      "[1,   240] loss: 2.17947, train_accuracy: 25.78\n",
      "[1,   241] loss: 2.12313, train_accuracy: 24.22\n",
      "[1,   242] loss: 2.15144, train_accuracy: 25.00\n",
      "[1,   243] loss: 2.06176, train_accuracy: 25.00\n",
      "[1,   244] loss: 2.16325, train_accuracy: 28.91\n",
      "[1,   245] loss: 2.23511, train_accuracy: 21.09\n",
      "[1,   246] loss: 2.21181, train_accuracy: 32.81\n",
      "[1,   247] loss: 2.17803, train_accuracy: 27.34\n",
      "[1,   248] loss: 2.38541, train_accuracy: 21.88\n",
      "[1,   249] loss: 2.04770, train_accuracy: 32.03\n",
      "[1,   250] loss: 2.32946, train_accuracy: 20.31\n",
      "[1,   251] loss: 2.05187, train_accuracy: 25.00\n",
      "[1,   252] loss: 2.16250, train_accuracy: 23.44\n",
      "[1,   253] loss: 2.25243, train_accuracy: 32.03\n",
      "[1,   254] loss: 2.28831, train_accuracy: 30.47\n",
      "[1,   255] loss: 1.97486, train_accuracy: 34.38\n",
      "[1,   256] loss: 2.12751, train_accuracy: 19.53\n",
      "[1,   257] loss: 2.36750, train_accuracy: 29.69\n",
      "[1,   258] loss: 2.02686, train_accuracy: 25.00\n",
      "[1,   259] loss: 1.89926, train_accuracy: 27.34\n",
      "[1,   260] loss: 2.25426, train_accuracy: 23.44\n",
      "[1,   261] loss: 2.12332, train_accuracy: 17.97\n",
      "[1,   262] loss: 2.47453, train_accuracy: 17.97\n",
      "[1,   263] loss: 2.15705, train_accuracy: 23.44\n",
      "[1,   264] loss: 2.16002, train_accuracy: 20.31\n",
      "[1,   265] loss: 2.25242, train_accuracy: 21.88\n",
      "[1,   266] loss: 2.23036, train_accuracy: 17.97\n",
      "[1,   267] loss: 2.30821, train_accuracy: 25.78\n",
      "[1,   268] loss: 2.26874, train_accuracy: 23.44\n",
      "[1,   269] loss: 2.20610, train_accuracy: 25.00\n",
      "[1,   270] loss: 1.99399, train_accuracy: 27.34\n",
      "[1,   271] loss: 2.21840, train_accuracy: 14.06\n",
      "[1,   272] loss: 2.25850, train_accuracy: 27.34\n",
      "[1,   273] loss: 2.43356, train_accuracy: 25.00\n",
      "[1,   274] loss: 2.62870, train_accuracy: 15.62\n",
      "[1,   275] loss: 2.40460, train_accuracy: 16.41\n",
      "[1,   276] loss: 2.50618, train_accuracy: 18.75\n",
      "[1,   277] loss: 1.86810, train_accuracy: 42.19\n",
      "[1,   278] loss: 2.42198, train_accuracy: 21.88\n",
      "[1,   279] loss: 2.10861, train_accuracy: 33.59\n",
      "[1,   280] loss: 1.98969, train_accuracy: 21.88\n",
      "[1,   281] loss: 2.40551, train_accuracy: 21.09\n",
      "[1,   282] loss: 1.89284, train_accuracy: 37.50\n",
      "[1,   283] loss: 2.02013, train_accuracy: 28.91\n",
      "[1,   284] loss: 2.26437, train_accuracy: 26.56\n",
      "[1,   285] loss: 2.20672, train_accuracy: 19.53\n",
      "[1,   286] loss: 2.09374, train_accuracy: 25.00\n",
      "[1,   287] loss: 2.09244, train_accuracy: 21.88\n",
      "[1,   288] loss: 2.05308, train_accuracy: 24.22\n",
      "[1,   289] loss: 2.17247, train_accuracy: 25.00\n",
      "[1,   290] loss: 2.04223, train_accuracy: 28.12\n",
      "[1,   291] loss: 2.11774, train_accuracy: 25.78\n",
      "[1,   292] loss: 1.98173, train_accuracy: 31.25\n",
      "[1,   293] loss: 2.09084, train_accuracy: 23.44\n",
      "[1,   294] loss: 2.29662, train_accuracy: 28.91\n",
      "[1,   295] loss: 1.97334, train_accuracy: 24.22\n",
      "[1,   296] loss: 2.13684, train_accuracy: 21.09\n",
      "[1,   297] loss: 2.19965, train_accuracy: 19.53\n",
      "[1,   298] loss: 2.10945, train_accuracy: 17.97\n",
      "[1,   299] loss: 2.19270, train_accuracy: 29.69\n",
      "[1,   300] loss: 2.02889, train_accuracy: 25.00\n",
      "[1,   301] loss: 1.87402, train_accuracy: 25.78\n",
      "[1,   302] loss: 1.94714, train_accuracy: 27.34\n",
      "[1,   303] loss: 2.08592, train_accuracy: 31.25\n",
      "[1,   304] loss: 2.01069, train_accuracy: 34.38\n",
      "[1,   305] loss: 2.26445, train_accuracy: 23.44\n",
      "[1,   306] loss: 2.09335, train_accuracy: 23.44\n",
      "[1,   307] loss: 2.10564, train_accuracy: 27.34\n",
      "[1,   308] loss: 1.86642, train_accuracy: 30.47\n",
      "[1,   309] loss: 1.95932, train_accuracy: 32.03\n",
      "[1,   310] loss: 2.08228, train_accuracy: 22.66\n",
      "[1,   311] loss: 1.88474, train_accuracy: 28.91\n",
      "[1,   312] loss: 2.16613, train_accuracy: 23.44\n",
      "[1,   313] loss: 1.83529, train_accuracy: 29.69\n",
      "[1,   314] loss: 1.98837, train_accuracy: 28.91\n",
      "[1,   315] loss: 1.97638, train_accuracy: 32.81\n",
      "[1,   316] loss: 2.17437, train_accuracy: 26.56\n",
      "[1,   317] loss: 1.96368, train_accuracy: 22.66\n",
      "[1,   318] loss: 1.99322, train_accuracy: 31.25\n",
      "[1,   319] loss: 1.87708, train_accuracy: 21.88\n",
      "[1,   320] loss: 2.06762, train_accuracy: 21.09\n",
      "[1,   321] loss: 1.83054, train_accuracy: 35.16\n",
      "[1,   322] loss: 2.42748, train_accuracy: 29.69\n",
      "[1,   323] loss: 2.06381, train_accuracy: 25.78\n",
      "[1,   324] loss: 1.91170, train_accuracy: 33.59\n",
      "[1,   325] loss: 2.09930, train_accuracy: 25.00\n",
      "[1,   326] loss: 2.30653, train_accuracy: 21.88\n",
      "[1,   327] loss: 2.00870, train_accuracy: 25.78\n",
      "[1,   328] loss: 2.11813, train_accuracy: 32.03\n",
      "[1,   329] loss: 1.96284, train_accuracy: 32.81\n",
      "[1,   330] loss: 2.01284, train_accuracy: 23.44\n",
      "[1,   331] loss: 1.94133, train_accuracy: 26.56\n",
      "[1,   332] loss: 1.88988, train_accuracy: 28.12\n",
      "[1,   333] loss: 2.03383, train_accuracy: 26.56\n",
      "[1,   334] loss: 1.92290, train_accuracy: 24.22\n",
      "[1,   335] loss: 1.89256, train_accuracy: 25.00\n",
      "[1,   336] loss: 1.82973, train_accuracy: 24.22\n",
      "[1,   337] loss: 1.97949, train_accuracy: 25.78\n",
      "[1,   338] loss: 2.14356, train_accuracy: 30.47\n",
      "[1,   339] loss: 1.84565, train_accuracy: 29.69\n",
      "[1,   340] loss: 1.89106, train_accuracy: 26.56\n",
      "[1,   341] loss: 2.02139, train_accuracy: 28.12\n",
      "[1,   342] loss: 1.80536, train_accuracy: 33.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   343] loss: 1.87129, train_accuracy: 36.72\n",
      "[1,   344] loss: 1.88244, train_accuracy: 26.56\n",
      "[1,   345] loss: 1.94002, train_accuracy: 31.25\n",
      "[1,   346] loss: 1.81500, train_accuracy: 26.56\n",
      "[1,   347] loss: 1.95406, train_accuracy: 21.09\n",
      "[1,   348] loss: 1.88064, train_accuracy: 36.72\n",
      "[1,   349] loss: 1.80671, train_accuracy: 35.16\n",
      "[1,   350] loss: 2.00401, train_accuracy: 28.91\n",
      "[1,   351] loss: 1.87571, train_accuracy: 34.38\n",
      "[1,   352] loss: 1.92065, train_accuracy: 29.69\n",
      "[1,   353] loss: 1.94781, train_accuracy: 28.12\n",
      "[1,   354] loss: 1.99935, train_accuracy: 32.03\n",
      "[1,   355] loss: 1.99637, train_accuracy: 28.12\n",
      "[1,   356] loss: 1.88664, train_accuracy: 27.34\n",
      "[1,   357] loss: 1.93833, train_accuracy: 27.34\n",
      "[1,   358] loss: 1.91061, train_accuracy: 30.47\n",
      "[1,   359] loss: 1.92077, train_accuracy: 26.56\n",
      "[1,   360] loss: 1.80987, train_accuracy: 32.03\n",
      "[1,   361] loss: 1.99050, train_accuracy: 27.34\n",
      "[1,   362] loss: 1.82531, train_accuracy: 35.94\n",
      "[1,   363] loss: 1.86083, train_accuracy: 32.81\n",
      "[1,   364] loss: 2.00610, train_accuracy: 25.00\n",
      "[1,   365] loss: 1.92929, train_accuracy: 35.94\n",
      "[1,   366] loss: 1.79386, train_accuracy: 35.16\n",
      "[1,   367] loss: 1.84001, train_accuracy: 28.12\n",
      "[1,   368] loss: 1.89231, train_accuracy: 30.47\n",
      "[1,   369] loss: 1.93453, train_accuracy: 34.38\n",
      "[1,   370] loss: 1.94032, train_accuracy: 24.22\n",
      "[1,   371] loss: 1.79888, train_accuracy: 28.91\n",
      "[1,   372] loss: 1.83488, train_accuracy: 35.94\n",
      "[1,   373] loss: 2.10442, train_accuracy: 25.78\n",
      "[1,   374] loss: 2.01054, train_accuracy: 23.44\n",
      "[1,   375] loss: 1.88537, train_accuracy: 38.28\n",
      "[1,   376] loss: 1.83077, train_accuracy: 34.38\n",
      "[1,   377] loss: 1.83017, train_accuracy: 28.12\n",
      "[1,   378] loss: 1.73500, train_accuracy: 39.84\n",
      "[1,   379] loss: 1.70586, train_accuracy: 39.84\n",
      "[1,   380] loss: 2.06677, train_accuracy: 28.12\n",
      "[1,   381] loss: 1.85143, train_accuracy: 29.69\n",
      "[1,   382] loss: 1.81769, train_accuracy: 30.47\n",
      "[1,   383] loss: 1.93089, train_accuracy: 34.38\n",
      "[1,   384] loss: 1.91887, train_accuracy: 29.69\n",
      "[1,   385] loss: 1.86424, train_accuracy: 29.69\n",
      "[1,   386] loss: 1.89198, train_accuracy: 31.25\n",
      "[1,   387] loss: 1.78844, train_accuracy: 33.59\n",
      "[1,   388] loss: 1.75421, train_accuracy: 39.84\n",
      "[1,   389] loss: 1.95803, train_accuracy: 33.59\n",
      "[1,   390] loss: 1.91307, train_accuracy: 25.78\n",
      "[1,   391] loss: 1.80888, train_accuracy: 26.25\n",
      "duration: 154 s - train loss: 3.13775 - train accuracy: 22.95 - validation loss: 1.73 - validation accuracy: 37.50 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs_trained': 0,\n",
       " 'avg_time_per_epoch': 154.96460223197937,\n",
       " 'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'hist': {'train_loss': [3.137745145641629],\n",
       "  'train_accuracy': [22.95316496163683],\n",
       "  'validation_loss': [1.734822559960281],\n",
       "  'validation_accuracy': [37.5]},\n",
       " 'val_accuracy': 37.5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CifarResNet().to(device)\n",
    "model.fit(train_loader, test_loader, 1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss_history': [2.8527273421397297],\n",
       " 'train_accuracy_history': [33.750399616368284],\n",
       " 'validation_loss_history': [1.5421439137639879],\n",
       " 'validation_accuracy_history': [43.53],\n",
       " 'epochs_trained': 1,\n",
       " 'total_training_time': 108.13442301750183,\n",
       " 'criterion': [CrossEntropyLoss()],\n",
       " 'optimizer': [Adam (\n",
       "  Parameter Group 0\n",
       "      amsgrad: False\n",
       "      betas: (0.9, 0.999)\n",
       "      eps: 1e-08\n",
       "      lr: 0.001\n",
       "      weight_decay: 0\n",
       "  )]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w/o color jitter - 127 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "[1,     1] loss: 2.71906, train_accuracy: 10.94\n",
      "[1,     2] loss: 31.83177, train_accuracy: 6.25\n",
      "[1,     3] loss: 40.89853, train_accuracy: 5.47\n",
      "[1,     4] loss: 38.26459, train_accuracy: 8.59\n",
      "[1,     5] loss: 29.79355, train_accuracy: 13.28\n",
      "[1,     6] loss: 29.99668, train_accuracy: 9.38\n",
      "[1,     7] loss: 19.14003, train_accuracy: 13.28\n",
      "[1,     8] loss: 24.36173, train_accuracy: 13.28\n",
      "[1,     9] loss: 11.03250, train_accuracy: 8.59\n",
      "[1,    10] loss: 13.41577, train_accuracy: 14.06\n",
      "[1,    11] loss: 14.73741, train_accuracy: 8.59\n",
      "[1,    12] loss: 11.69197, train_accuracy: 7.81\n",
      "[1,    13] loss: 9.41380, train_accuracy: 10.94\n",
      "[1,    14] loss: 9.56711, train_accuracy: 15.62\n",
      "[1,    15] loss: 6.92797, train_accuracy: 17.19\n",
      "[1,    16] loss: 4.90577, train_accuracy: 13.28\n",
      "[1,    17] loss: 4.59638, train_accuracy: 17.97\n",
      "[1,    18] loss: 6.84164, train_accuracy: 6.25\n",
      "[1,    19] loss: 5.30594, train_accuracy: 18.75\n",
      "[1,    20] loss: 5.90743, train_accuracy: 15.62\n",
      "[1,    21] loss: 8.00086, train_accuracy: 24.22\n",
      "[1,    22] loss: 4.63866, train_accuracy: 14.84\n",
      "[1,    23] loss: 6.64213, train_accuracy: 20.31\n",
      "[1,    24] loss: 4.92617, train_accuracy: 15.62\n",
      "[1,    25] loss: 4.23593, train_accuracy: 17.97\n",
      "[1,    26] loss: 3.63057, train_accuracy: 14.84\n",
      "[1,    27] loss: 5.08188, train_accuracy: 12.50\n",
      "[1,    28] loss: 5.14567, train_accuracy: 7.03\n",
      "[1,    29] loss: 4.24832, train_accuracy: 10.16\n",
      "[1,    30] loss: 3.69415, train_accuracy: 14.84\n",
      "[1,    31] loss: 3.66081, train_accuracy: 16.41\n",
      "[1,    32] loss: 3.56759, train_accuracy: 10.94\n",
      "[1,    33] loss: 3.21939, train_accuracy: 15.62\n",
      "[1,    34] loss: 2.89996, train_accuracy: 17.97\n",
      "[1,    35] loss: 3.11924, train_accuracy: 12.50\n",
      "[1,    36] loss: 4.69710, train_accuracy: 15.62\n",
      "[1,    37] loss: 3.80210, train_accuracy: 16.41\n",
      "[1,    38] loss: 3.69737, train_accuracy: 15.62\n",
      "[1,    39] loss: 4.59716, train_accuracy: 18.75\n",
      "[1,    40] loss: 4.07984, train_accuracy: 22.66\n",
      "[1,    41] loss: 3.53656, train_accuracy: 18.75\n",
      "[1,    42] loss: 2.92965, train_accuracy: 19.53\n",
      "[1,    43] loss: 3.45352, train_accuracy: 14.06\n",
      "[1,    44] loss: 3.76298, train_accuracy: 13.28\n",
      "[1,    45] loss: 3.24962, train_accuracy: 17.19\n",
      "[1,    46] loss: 3.22195, train_accuracy: 14.84\n",
      "[1,    47] loss: 3.30452, train_accuracy: 16.41\n",
      "[1,    48] loss: 4.21460, train_accuracy: 16.41\n",
      "[1,    49] loss: 3.42676, train_accuracy: 17.19\n",
      "[1,    50] loss: 2.83721, train_accuracy: 17.97\n",
      "[1,    51] loss: 3.21253, train_accuracy: 18.75\n",
      "[1,    52] loss: 3.37005, train_accuracy: 14.06\n",
      "[1,    53] loss: 3.80757, train_accuracy: 15.62\n",
      "[1,    54] loss: 3.44789, train_accuracy: 20.31\n",
      "[1,    55] loss: 2.98799, train_accuracy: 22.66\n",
      "[1,    56] loss: 2.87436, train_accuracy: 14.84\n",
      "[1,    57] loss: 3.17228, train_accuracy: 18.75\n",
      "[1,    58] loss: 2.98068, train_accuracy: 18.75\n",
      "[1,    59] loss: 2.73380, train_accuracy: 17.97\n",
      "[1,    60] loss: 2.90682, train_accuracy: 22.66\n",
      "[1,    61] loss: 3.60445, train_accuracy: 16.41\n",
      "[1,    62] loss: 3.11106, train_accuracy: 17.19\n",
      "[1,    63] loss: 2.81112, train_accuracy: 14.06\n",
      "[1,    64] loss: 2.40241, train_accuracy: 23.44\n",
      "[1,    65] loss: 2.50423, train_accuracy: 16.41\n",
      "[1,    66] loss: 2.69458, train_accuracy: 17.97\n",
      "[1,    67] loss: 2.38201, train_accuracy: 14.06\n",
      "[1,    68] loss: 2.08859, train_accuracy: 21.88\n",
      "[1,    69] loss: 2.39875, train_accuracy: 25.00\n",
      "[1,    70] loss: 2.62970, train_accuracy: 15.62\n",
      "[1,    71] loss: 2.33212, train_accuracy: 20.31\n",
      "[1,    72] loss: 2.38292, train_accuracy: 25.78\n",
      "[1,    73] loss: 2.19658, train_accuracy: 21.09\n",
      "[1,    74] loss: 2.15154, train_accuracy: 20.31\n",
      "[1,    75] loss: 2.41901, train_accuracy: 16.41\n",
      "[1,    76] loss: 2.78614, train_accuracy: 22.66\n",
      "[1,    77] loss: 2.66066, train_accuracy: 22.66\n",
      "[1,    78] loss: 2.26934, train_accuracy: 29.69\n",
      "[1,    79] loss: 2.51758, train_accuracy: 26.56\n",
      "[1,    80] loss: 2.19473, train_accuracy: 15.62\n",
      "[1,    81] loss: 2.25469, train_accuracy: 25.78\n",
      "[1,    82] loss: 2.15457, train_accuracy: 28.12\n",
      "[1,    83] loss: 2.42827, train_accuracy: 18.75\n",
      "[1,    84] loss: 2.22122, train_accuracy: 26.56\n",
      "[1,    85] loss: 2.19727, train_accuracy: 25.78\n",
      "[1,    86] loss: 2.16106, train_accuracy: 22.66\n",
      "[1,    87] loss: 2.18630, train_accuracy: 29.69\n",
      "[1,    88] loss: 2.16403, train_accuracy: 17.19\n",
      "[1,    89] loss: 2.13525, train_accuracy: 26.56\n",
      "[1,    90] loss: 2.52814, train_accuracy: 17.97\n",
      "[1,    91] loss: 2.31826, train_accuracy: 21.88\n",
      "[1,    92] loss: 2.17869, train_accuracy: 16.41\n",
      "[1,    93] loss: 2.08798, train_accuracy: 22.66\n",
      "[1,    94] loss: 2.19158, train_accuracy: 18.75\n",
      "[1,    95] loss: 2.30917, train_accuracy: 24.22\n",
      "[1,    96] loss: 2.33704, train_accuracy: 27.34\n",
      "[1,    97] loss: 2.07674, train_accuracy: 23.44\n",
      "[1,    98] loss: 2.44100, train_accuracy: 23.44\n",
      "[1,    99] loss: 2.00005, train_accuracy: 27.34\n",
      "[1,   100] loss: 2.37126, train_accuracy: 24.22\n",
      "[1,   101] loss: 2.30205, train_accuracy: 20.31\n",
      "[1,   102] loss: 2.14392, train_accuracy: 22.66\n",
      "[1,   103] loss: 2.29129, train_accuracy: 28.12\n",
      "[1,   104] loss: 2.47185, train_accuracy: 24.22\n",
      "[1,   105] loss: 2.50971, train_accuracy: 15.62\n",
      "[1,   106] loss: 2.16395, train_accuracy: 21.88\n",
      "[1,   107] loss: 2.08994, train_accuracy: 26.56\n",
      "[1,   108] loss: 2.25110, train_accuracy: 21.09\n",
      "[1,   109] loss: 2.03482, train_accuracy: 25.00\n",
      "[1,   110] loss: 2.19285, train_accuracy: 20.31\n",
      "[1,   111] loss: 2.10347, train_accuracy: 23.44\n",
      "[1,   112] loss: 2.16557, train_accuracy: 25.00\n",
      "[1,   113] loss: 1.94622, train_accuracy: 28.91\n",
      "[1,   114] loss: 2.12189, train_accuracy: 24.22\n",
      "[1,   115] loss: 2.07493, train_accuracy: 25.78\n",
      "[1,   116] loss: 2.12258, train_accuracy: 27.34\n",
      "[1,   117] loss: 2.11838, train_accuracy: 24.22\n",
      "[1,   118] loss: 2.00284, train_accuracy: 22.66\n",
      "[1,   119] loss: 2.32450, train_accuracy: 17.19\n",
      "[1,   120] loss: 2.00380, train_accuracy: 26.56\n",
      "[1,   121] loss: 2.05340, train_accuracy: 32.81\n",
      "[1,   122] loss: 1.92549, train_accuracy: 31.25\n",
      "[1,   123] loss: 1.95294, train_accuracy: 28.91\n",
      "[1,   124] loss: 2.03393, train_accuracy: 21.88\n",
      "[1,   125] loss: 2.41367, train_accuracy: 23.44\n",
      "[1,   126] loss: 2.28708, train_accuracy: 27.34\n",
      "[1,   127] loss: 2.00865, train_accuracy: 23.44\n",
      "[1,   128] loss: 2.09061, train_accuracy: 30.47\n",
      "[1,   129] loss: 1.88995, train_accuracy: 29.69\n",
      "[1,   130] loss: 2.17505, train_accuracy: 24.22\n",
      "[1,   131] loss: 2.20735, train_accuracy: 25.78\n",
      "[1,   132] loss: 2.06893, train_accuracy: 32.03\n",
      "[1,   133] loss: 2.09206, train_accuracy: 27.34\n",
      "[1,   134] loss: 2.15607, train_accuracy: 21.09\n",
      "[1,   135] loss: 2.08662, train_accuracy: 22.66\n",
      "[1,   136] loss: 2.04344, train_accuracy: 26.56\n",
      "[1,   137] loss: 2.17199, train_accuracy: 25.78\n",
      "[1,   138] loss: 2.09546, train_accuracy: 20.31\n",
      "[1,   139] loss: 2.30017, train_accuracy: 30.47\n",
      "[1,   140] loss: 2.11586, train_accuracy: 21.09\n",
      "[1,   141] loss: 2.00477, train_accuracy: 23.44\n",
      "[1,   142] loss: 2.33973, train_accuracy: 21.88\n",
      "[1,   143] loss: 2.21590, train_accuracy: 18.75\n",
      "[1,   144] loss: 2.04304, train_accuracy: 21.88\n",
      "[1,   145] loss: 1.89036, train_accuracy: 26.56\n",
      "[1,   146] loss: 2.15857, train_accuracy: 14.84\n",
      "[1,   147] loss: 2.30043, train_accuracy: 25.78\n",
      "[1,   148] loss: 2.15493, train_accuracy: 22.66\n",
      "[1,   149] loss: 2.19028, train_accuracy: 17.97\n",
      "[1,   150] loss: 2.17770, train_accuracy: 21.09\n",
      "[1,   151] loss: 1.97630, train_accuracy: 24.22\n",
      "[1,   152] loss: 2.11988, train_accuracy: 21.88\n",
      "[1,   153] loss: 2.05947, train_accuracy: 21.88\n",
      "[1,   154] loss: 1.92554, train_accuracy: 28.91\n",
      "[1,   155] loss: 2.16970, train_accuracy: 27.34\n",
      "[1,   156] loss: 1.96616, train_accuracy: 26.56\n",
      "[1,   157] loss: 2.09675, train_accuracy: 27.34\n",
      "[1,   158] loss: 2.08424, train_accuracy: 23.44\n",
      "[1,   159] loss: 1.99914, train_accuracy: 27.34\n",
      "[1,   160] loss: 1.99695, train_accuracy: 32.81\n",
      "[1,   161] loss: 1.99832, train_accuracy: 20.31\n",
      "[1,   162] loss: 1.93157, train_accuracy: 27.34\n",
      "[1,   163] loss: 2.05638, train_accuracy: 25.00\n",
      "[1,   164] loss: 2.17627, train_accuracy: 25.78\n",
      "[1,   165] loss: 2.02310, train_accuracy: 29.69\n",
      "[1,   166] loss: 2.00646, train_accuracy: 29.69\n",
      "[1,   167] loss: 2.03629, train_accuracy: 28.91\n",
      "[1,   168] loss: 1.85151, train_accuracy: 29.69\n",
      "[1,   169] loss: 2.13006, train_accuracy: 23.44\n",
      "[1,   170] loss: 2.03211, train_accuracy: 20.31\n",
      "[1,   171] loss: 2.07469, train_accuracy: 21.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   172] loss: 2.01363, train_accuracy: 28.91\n",
      "[1,   173] loss: 2.10887, train_accuracy: 28.12\n",
      "[1,   174] loss: 2.03718, train_accuracy: 28.91\n",
      "[1,   175] loss: 2.05474, train_accuracy: 29.69\n",
      "[1,   176] loss: 2.12229, train_accuracy: 26.56\n",
      "[1,   177] loss: 2.06592, train_accuracy: 27.34\n",
      "[1,   178] loss: 2.04574, train_accuracy: 28.12\n",
      "[1,   179] loss: 1.99611, train_accuracy: 28.12\n",
      "[1,   180] loss: 1.97262, train_accuracy: 31.25\n",
      "[1,   181] loss: 2.09172, train_accuracy: 30.47\n",
      "[1,   182] loss: 2.04191, train_accuracy: 30.47\n",
      "[1,   183] loss: 1.96241, train_accuracy: 32.03\n",
      "[1,   184] loss: 2.30822, train_accuracy: 21.88\n",
      "[1,   185] loss: 2.15116, train_accuracy: 26.56\n",
      "[1,   186] loss: 2.18135, train_accuracy: 26.56\n",
      "[1,   187] loss: 1.98889, train_accuracy: 28.91\n",
      "[1,   188] loss: 1.92764, train_accuracy: 31.25\n",
      "[1,   189] loss: 1.83186, train_accuracy: 38.28\n",
      "[1,   190] loss: 2.00745, train_accuracy: 21.09\n",
      "[1,   191] loss: 1.91047, train_accuracy: 25.78\n",
      "[1,   192] loss: 1.96792, train_accuracy: 28.91\n",
      "[1,   193] loss: 1.96988, train_accuracy: 28.91\n",
      "[1,   194] loss: 2.15873, train_accuracy: 23.44\n",
      "[1,   195] loss: 1.88323, train_accuracy: 32.03\n",
      "[1,   196] loss: 1.90764, train_accuracy: 33.59\n",
      "[1,   197] loss: 1.85565, train_accuracy: 32.03\n",
      "[1,   198] loss: 1.92570, train_accuracy: 29.69\n",
      "[1,   199] loss: 1.88344, train_accuracy: 32.81\n",
      "[1,   200] loss: 2.07713, train_accuracy: 35.16\n",
      "[1,   201] loss: 1.85293, train_accuracy: 38.28\n",
      "[1,   202] loss: 1.90371, train_accuracy: 36.72\n",
      "[1,   203] loss: 1.91045, train_accuracy: 31.25\n",
      "[1,   204] loss: 2.08696, train_accuracy: 24.22\n",
      "[1,   205] loss: 1.97420, train_accuracy: 28.91\n",
      "[1,   206] loss: 2.01107, train_accuracy: 21.09\n",
      "[1,   207] loss: 2.06383, train_accuracy: 27.34\n",
      "[1,   208] loss: 1.89143, train_accuracy: 32.81\n",
      "[1,   209] loss: 1.80928, train_accuracy: 34.38\n",
      "[1,   210] loss: 1.92045, train_accuracy: 31.25\n",
      "[1,   211] loss: 1.94358, train_accuracy: 32.03\n",
      "[1,   212] loss: 2.05179, train_accuracy: 25.00\n",
      "[1,   213] loss: 2.14543, train_accuracy: 23.44\n",
      "[1,   214] loss: 1.89291, train_accuracy: 28.91\n",
      "[1,   215] loss: 1.98985, train_accuracy: 30.47\n",
      "[1,   216] loss: 1.93459, train_accuracy: 33.59\n",
      "[1,   217] loss: 2.00020, train_accuracy: 22.66\n",
      "[1,   218] loss: 2.05442, train_accuracy: 34.38\n",
      "[1,   219] loss: 1.99393, train_accuracy: 23.44\n",
      "[1,   220] loss: 1.88885, train_accuracy: 28.12\n",
      "[1,   221] loss: 2.05911, train_accuracy: 26.56\n",
      "[1,   222] loss: 1.84346, train_accuracy: 33.59\n",
      "[1,   223] loss: 2.15288, train_accuracy: 29.69\n",
      "[1,   224] loss: 2.20389, train_accuracy: 20.31\n",
      "[1,   225] loss: 1.86284, train_accuracy: 25.78\n",
      "[1,   226] loss: 2.01889, train_accuracy: 26.56\n",
      "[1,   227] loss: 2.31136, train_accuracy: 19.53\n",
      "[1,   228] loss: 2.20672, train_accuracy: 22.66\n",
      "[1,   229] loss: 2.23427, train_accuracy: 28.12\n",
      "[1,   230] loss: 2.17614, train_accuracy: 26.56\n",
      "[1,   231] loss: 2.12105, train_accuracy: 27.34\n",
      "[1,   232] loss: 2.35819, train_accuracy: 20.31\n",
      "[1,   233] loss: 2.07300, train_accuracy: 28.12\n",
      "[1,   234] loss: 1.96435, train_accuracy: 28.12\n",
      "[1,   235] loss: 2.15127, train_accuracy: 28.12\n",
      "[1,   236] loss: 2.14739, train_accuracy: 23.44\n",
      "[1,   237] loss: 2.16899, train_accuracy: 26.56\n",
      "[1,   238] loss: 1.82826, train_accuracy: 26.56\n",
      "[1,   239] loss: 1.91625, train_accuracy: 21.88\n",
      "[1,   240] loss: 1.87593, train_accuracy: 33.59\n",
      "[1,   241] loss: 2.31455, train_accuracy: 26.56\n",
      "[1,   242] loss: 2.15479, train_accuracy: 25.00\n",
      "[1,   243] loss: 2.33021, train_accuracy: 27.34\n",
      "[1,   244] loss: 2.24226, train_accuracy: 23.44\n",
      "[1,   245] loss: 2.31841, train_accuracy: 28.91\n",
      "[1,   246] loss: 1.96640, train_accuracy: 28.12\n",
      "[1,   247] loss: 2.03688, train_accuracy: 29.69\n",
      "[1,   248] loss: 1.93331, train_accuracy: 30.47\n",
      "[1,   249] loss: 1.91403, train_accuracy: 32.03\n",
      "[1,   250] loss: 2.16699, train_accuracy: 30.47\n",
      "[1,   251] loss: 2.15372, train_accuracy: 19.53\n",
      "[1,   252] loss: 2.20872, train_accuracy: 25.00\n",
      "[1,   253] loss: 2.13812, train_accuracy: 25.00\n",
      "[1,   254] loss: 2.13645, train_accuracy: 28.12\n",
      "[1,   255] loss: 2.00122, train_accuracy: 34.38\n",
      "[1,   256] loss: 2.53530, train_accuracy: 29.69\n",
      "[1,   257] loss: 2.10961, train_accuracy: 31.25\n",
      "[1,   258] loss: 2.38358, train_accuracy: 25.00\n",
      "[1,   259] loss: 2.11059, train_accuracy: 30.47\n",
      "[1,   260] loss: 1.90691, train_accuracy: 36.72\n",
      "[1,   261] loss: 1.89891, train_accuracy: 37.50\n",
      "[1,   262] loss: 2.07370, train_accuracy: 26.56\n",
      "[1,   263] loss: 2.00074, train_accuracy: 34.38\n",
      "[1,   264] loss: 2.21829, train_accuracy: 27.34\n",
      "[1,   265] loss: 1.91630, train_accuracy: 25.00\n",
      "[1,   266] loss: 2.18625, train_accuracy: 27.34\n",
      "[1,   267] loss: 1.91032, train_accuracy: 32.03\n",
      "[1,   268] loss: 1.79653, train_accuracy: 28.12\n",
      "[1,   269] loss: 2.12851, train_accuracy: 18.75\n",
      "[1,   270] loss: 2.01911, train_accuracy: 30.47\n",
      "[1,   271] loss: 1.94561, train_accuracy: 29.69\n",
      "[1,   272] loss: 1.96032, train_accuracy: 29.69\n",
      "[1,   273] loss: 1.84325, train_accuracy: 31.25\n",
      "[1,   274] loss: 1.89378, train_accuracy: 32.03\n",
      "[1,   275] loss: 2.05284, train_accuracy: 32.03\n",
      "[1,   276] loss: 1.94263, train_accuracy: 33.59\n",
      "[1,   277] loss: 2.02170, train_accuracy: 24.22\n",
      "[1,   278] loss: 2.06993, train_accuracy: 28.12\n",
      "[1,   279] loss: 1.96061, train_accuracy: 27.34\n",
      "[1,   280] loss: 1.83209, train_accuracy: 32.03\n",
      "[1,   281] loss: 1.96778, train_accuracy: 26.56\n",
      "[1,   282] loss: 2.05562, train_accuracy: 29.69\n",
      "[1,   283] loss: 1.99381, train_accuracy: 24.22\n",
      "[1,   284] loss: 1.91308, train_accuracy: 28.91\n",
      "[1,   285] loss: 1.83540, train_accuracy: 28.12\n",
      "[1,   286] loss: 1.77929, train_accuracy: 43.75\n",
      "[1,   287] loss: 1.84666, train_accuracy: 32.03\n",
      "[1,   288] loss: 1.81971, train_accuracy: 28.12\n",
      "[1,   289] loss: 1.97667, train_accuracy: 26.56\n",
      "[1,   290] loss: 2.09076, train_accuracy: 26.56\n",
      "[1,   291] loss: 1.95467, train_accuracy: 35.94\n",
      "[1,   292] loss: 1.83077, train_accuracy: 28.91\n",
      "[1,   293] loss: 2.14026, train_accuracy: 27.34\n",
      "[1,   294] loss: 2.00486, train_accuracy: 25.78\n",
      "[1,   295] loss: 1.90731, train_accuracy: 31.25\n",
      "[1,   296] loss: 1.93832, train_accuracy: 23.44\n",
      "[1,   297] loss: 2.00128, train_accuracy: 31.25\n",
      "[1,   298] loss: 1.97355, train_accuracy: 33.59\n",
      "[1,   299] loss: 1.96206, train_accuracy: 26.56\n",
      "[1,   300] loss: 1.89938, train_accuracy: 31.25\n",
      "[1,   301] loss: 2.12299, train_accuracy: 23.44\n",
      "[1,   302] loss: 1.95975, train_accuracy: 24.22\n",
      "[1,   303] loss: 1.78358, train_accuracy: 31.25\n",
      "[1,   304] loss: 2.07445, train_accuracy: 29.69\n",
      "[1,   305] loss: 1.90679, train_accuracy: 25.78\n",
      "[1,   306] loss: 2.01991, train_accuracy: 28.12\n",
      "[1,   307] loss: 1.94501, train_accuracy: 32.81\n",
      "[1,   308] loss: 1.85223, train_accuracy: 30.47\n",
      "[1,   309] loss: 1.82585, train_accuracy: 28.12\n",
      "[1,   310] loss: 1.90915, train_accuracy: 27.34\n",
      "[1,   311] loss: 1.99373, train_accuracy: 21.88\n",
      "[1,   312] loss: 1.80111, train_accuracy: 34.38\n",
      "[1,   313] loss: 2.00688, train_accuracy: 20.31\n",
      "[1,   314] loss: 1.96072, train_accuracy: 25.00\n",
      "[1,   315] loss: 1.81485, train_accuracy: 30.47\n",
      "[1,   316] loss: 1.97029, train_accuracy: 35.16\n",
      "[1,   317] loss: 1.84395, train_accuracy: 29.69\n",
      "[1,   318] loss: 1.86703, train_accuracy: 31.25\n",
      "[1,   319] loss: 1.89500, train_accuracy: 28.91\n",
      "[1,   320] loss: 1.82478, train_accuracy: 30.47\n",
      "[1,   321] loss: 1.81901, train_accuracy: 36.72\n",
      "[1,   322] loss: 1.96383, train_accuracy: 32.81\n",
      "[1,   323] loss: 2.01955, train_accuracy: 22.66\n",
      "[1,   324] loss: 1.84283, train_accuracy: 38.28\n",
      "[1,   325] loss: 1.92637, train_accuracy: 32.03\n",
      "[1,   326] loss: 1.86925, train_accuracy: 29.69\n",
      "[1,   327] loss: 1.85699, train_accuracy: 33.59\n",
      "[1,   328] loss: 1.81283, train_accuracy: 32.81\n",
      "[1,   329] loss: 1.82756, train_accuracy: 32.81\n",
      "[1,   330] loss: 1.98757, train_accuracy: 26.56\n",
      "[1,   331] loss: 1.78736, train_accuracy: 35.94\n",
      "[1,   332] loss: 1.91136, train_accuracy: 28.91\n",
      "[1,   333] loss: 1.88244, train_accuracy: 24.22\n",
      "[1,   334] loss: 1.96425, train_accuracy: 33.59\n",
      "[1,   335] loss: 1.78994, train_accuracy: 36.72\n",
      "[1,   336] loss: 1.84816, train_accuracy: 34.38\n",
      "[1,   337] loss: 1.88575, train_accuracy: 32.81\n",
      "[1,   338] loss: 1.90699, train_accuracy: 30.47\n",
      "[1,   339] loss: 1.77455, train_accuracy: 34.38\n",
      "[1,   340] loss: 1.90113, train_accuracy: 32.03\n",
      "[1,   341] loss: 1.87910, train_accuracy: 31.25\n",
      "[1,   342] loss: 1.93749, train_accuracy: 39.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   343] loss: 1.77375, train_accuracy: 39.06\n",
      "[1,   344] loss: 1.69919, train_accuracy: 38.28\n",
      "[1,   345] loss: 1.99508, train_accuracy: 29.69\n",
      "[1,   346] loss: 1.82078, train_accuracy: 34.38\n",
      "[1,   347] loss: 1.81249, train_accuracy: 32.81\n",
      "[1,   348] loss: 1.94072, train_accuracy: 29.69\n",
      "[1,   349] loss: 1.83569, train_accuracy: 39.06\n",
      "[1,   350] loss: 2.00946, train_accuracy: 27.34\n",
      "[1,   351] loss: 1.99693, train_accuracy: 27.34\n",
      "[1,   352] loss: 1.86889, train_accuracy: 32.81\n",
      "[1,   353] loss: 1.76471, train_accuracy: 34.38\n",
      "[1,   354] loss: 1.68774, train_accuracy: 36.72\n",
      "[1,   355] loss: 2.06402, train_accuracy: 25.78\n",
      "[1,   356] loss: 1.96217, train_accuracy: 31.25\n",
      "[1,   357] loss: 1.97939, train_accuracy: 25.78\n",
      "[1,   358] loss: 1.87406, train_accuracy: 30.47\n",
      "[1,   359] loss: 1.75787, train_accuracy: 41.41\n",
      "[1,   360] loss: 1.62473, train_accuracy: 42.97\n",
      "[1,   361] loss: 1.82472, train_accuracy: 33.59\n",
      "[1,   362] loss: 1.87716, train_accuracy: 28.91\n",
      "[1,   363] loss: 1.79778, train_accuracy: 30.47\n",
      "[1,   364] loss: 1.77321, train_accuracy: 33.59\n",
      "[1,   365] loss: 1.66541, train_accuracy: 42.19\n",
      "[1,   366] loss: 1.88000, train_accuracy: 34.38\n",
      "[1,   367] loss: 1.90797, train_accuracy: 39.06\n",
      "[1,   368] loss: 1.89998, train_accuracy: 29.69\n",
      "[1,   369] loss: 1.86154, train_accuracy: 29.69\n",
      "[1,   370] loss: 1.88955, train_accuracy: 32.81\n",
      "[1,   371] loss: 1.86618, train_accuracy: 34.38\n",
      "[1,   372] loss: 1.80918, train_accuracy: 35.16\n",
      "[1,   373] loss: 1.75700, train_accuracy: 36.72\n",
      "[1,   374] loss: 2.12545, train_accuracy: 26.56\n",
      "[1,   375] loss: 1.89199, train_accuracy: 24.22\n",
      "[1,   376] loss: 1.97939, train_accuracy: 27.34\n",
      "[1,   377] loss: 1.98422, train_accuracy: 30.47\n",
      "[1,   378] loss: 1.72451, train_accuracy: 39.06\n",
      "[1,   379] loss: 1.81920, train_accuracy: 35.16\n",
      "[1,   380] loss: 1.87048, train_accuracy: 32.81\n",
      "[1,   381] loss: 2.00681, train_accuracy: 32.81\n",
      "[1,   382] loss: 1.96846, train_accuracy: 29.69\n",
      "[1,   383] loss: 1.89544, train_accuracy: 31.25\n",
      "[1,   384] loss: 1.85948, train_accuracy: 26.56\n",
      "[1,   385] loss: 1.69683, train_accuracy: 34.38\n",
      "[1,   386] loss: 1.87283, train_accuracy: 31.25\n",
      "[1,   387] loss: 1.72974, train_accuracy: 36.72\n",
      "[1,   388] loss: 1.80744, train_accuracy: 35.16\n",
      "[1,   389] loss: 1.87791, train_accuracy: 29.69\n",
      "[1,   390] loss: 1.76421, train_accuracy: 32.81\n",
      "[1,   391] loss: 2.03591, train_accuracy: 28.75\n",
      "duration: 127 s - train loss: 2.94492 - train accuracy: 25.87 - validation loss: 1.66 - validation accuracy: 40.51 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs_trained': 0,\n",
       " 'avg_time_per_epoch': 127.58919072151184,\n",
       " 'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'hist': {'train_loss': [2.944924154549913],\n",
       "  'train_accuracy': [25.872762148337596],\n",
       "  'validation_loss': [1.6564999366108375],\n",
       "  'validation_accuracy': [40.51]},\n",
       " 'val_accuracy': 40.51}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CifarResNet().to(device)\n",
    "model.fit(train_loader, test_loader, 1, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w/o random horizontal flip - 148 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "[1,     1] loss: 2.73089, train_accuracy: 7.81\n",
      "[1,     2] loss: 33.70625, train_accuracy: 6.25\n",
      "[1,     3] loss: 37.72399, train_accuracy: 5.47\n",
      "[1,     4] loss: 39.64744, train_accuracy: 13.28\n",
      "[1,     5] loss: 23.97301, train_accuracy: 17.97\n",
      "[1,     6] loss: 20.02452, train_accuracy: 17.19\n",
      "[1,     7] loss: 13.37092, train_accuracy: 7.03\n",
      "[1,     8] loss: 17.59218, train_accuracy: 14.06\n",
      "[1,     9] loss: 16.38407, train_accuracy: 14.06\n",
      "[1,    10] loss: 12.62568, train_accuracy: 14.06\n",
      "[1,    11] loss: 9.25568, train_accuracy: 9.38\n",
      "[1,    12] loss: 9.94829, train_accuracy: 14.06\n",
      "[1,    13] loss: 9.08403, train_accuracy: 9.38\n",
      "[1,    14] loss: 11.07196, train_accuracy: 12.50\n",
      "[1,    15] loss: 11.03835, train_accuracy: 16.41\n",
      "[1,    16] loss: 8.93029, train_accuracy: 12.50\n",
      "[1,    17] loss: 7.73774, train_accuracy: 10.94\n",
      "[1,    18] loss: 5.02678, train_accuracy: 17.97\n",
      "[1,    19] loss: 5.41755, train_accuracy: 13.28\n",
      "[1,    20] loss: 9.17142, train_accuracy: 10.16\n",
      "[1,    21] loss: 6.79408, train_accuracy: 14.84\n",
      "[1,    22] loss: 7.16221, train_accuracy: 8.59\n",
      "[1,    23] loss: 5.83333, train_accuracy: 12.50\n",
      "[1,    24] loss: 4.62456, train_accuracy: 11.72\n",
      "[1,    25] loss: 4.50736, train_accuracy: 15.62\n",
      "[1,    26] loss: 4.90291, train_accuracy: 14.06\n",
      "[1,    27] loss: 6.16039, train_accuracy: 5.47\n",
      "[1,    28] loss: 8.54701, train_accuracy: 15.62\n",
      "[1,    29] loss: 4.27762, train_accuracy: 12.50\n",
      "[1,    30] loss: 4.04544, train_accuracy: 18.75\n",
      "[1,    31] loss: 4.83137, train_accuracy: 12.50\n",
      "[1,    32] loss: 3.76248, train_accuracy: 16.41\n",
      "[1,    33] loss: 4.18002, train_accuracy: 17.19\n",
      "[1,    34] loss: 5.70251, train_accuracy: 17.97\n",
      "[1,    35] loss: 4.27317, train_accuracy: 10.94\n",
      "[1,    36] loss: 3.33067, train_accuracy: 22.66\n",
      "[1,    37] loss: 3.70751, train_accuracy: 17.19\n",
      "[1,    38] loss: 4.74400, train_accuracy: 17.19\n",
      "[1,    39] loss: 2.67330, train_accuracy: 17.97\n",
      "[1,    40] loss: 3.22421, train_accuracy: 8.59\n",
      "[1,    41] loss: 2.88526, train_accuracy: 16.41\n",
      "[1,    42] loss: 3.29792, train_accuracy: 10.94\n",
      "[1,    43] loss: 3.85736, train_accuracy: 10.94\n",
      "[1,    44] loss: 2.44775, train_accuracy: 21.88\n",
      "[1,    45] loss: 2.56277, train_accuracy: 14.06\n",
      "[1,    46] loss: 2.44867, train_accuracy: 15.62\n",
      "[1,    47] loss: 5.71920, train_accuracy: 13.28\n",
      "[1,    48] loss: 2.47752, train_accuracy: 25.00\n",
      "[1,    49] loss: 5.06485, train_accuracy: 14.06\n",
      "[1,    50] loss: 2.85560, train_accuracy: 23.44\n",
      "[1,    51] loss: 5.99154, train_accuracy: 23.44\n",
      "[1,    52] loss: 2.80243, train_accuracy: 17.97\n",
      "[1,    53] loss: 2.38343, train_accuracy: 20.31\n",
      "[1,    54] loss: 4.13450, train_accuracy: 17.97\n",
      "[1,    55] loss: 4.53329, train_accuracy: 24.22\n",
      "[1,    56] loss: 3.83676, train_accuracy: 17.19\n",
      "[1,    57] loss: 4.07831, train_accuracy: 13.28\n",
      "[1,    58] loss: 3.15532, train_accuracy: 18.75\n",
      "[1,    59] loss: 2.99849, train_accuracy: 17.97\n",
      "[1,    60] loss: 2.83913, train_accuracy: 17.19\n",
      "[1,    61] loss: 2.35961, train_accuracy: 17.97\n",
      "[1,    62] loss: 2.86001, train_accuracy: 14.06\n",
      "[1,    63] loss: 3.16333, train_accuracy: 17.97\n",
      "[1,    64] loss: 2.58807, train_accuracy: 28.91\n",
      "[1,    65] loss: 2.34629, train_accuracy: 14.06\n",
      "[1,    66] loss: 4.70243, train_accuracy: 16.41\n",
      "[1,    67] loss: 4.02560, train_accuracy: 21.09\n",
      "[1,    68] loss: 5.22608, train_accuracy: 23.44\n",
      "[1,    69] loss: 3.03460, train_accuracy: 9.38\n",
      "[1,    70] loss: 2.81632, train_accuracy: 11.72\n",
      "[1,    71] loss: 2.81930, train_accuracy: 17.19\n",
      "[1,    72] loss: 3.67177, train_accuracy: 12.50\n",
      "[1,    73] loss: 2.81064, train_accuracy: 20.31\n",
      "[1,    74] loss: 2.66150, train_accuracy: 26.56\n",
      "[1,    75] loss: 4.13136, train_accuracy: 14.84\n",
      "[1,    76] loss: 2.26173, train_accuracy: 21.09\n",
      "[1,    77] loss: 4.18693, train_accuracy: 11.72\n",
      "[1,    78] loss: 3.09662, train_accuracy: 10.16\n",
      "[1,    79] loss: 3.68429, train_accuracy: 17.97\n",
      "[1,    80] loss: 4.32906, train_accuracy: 16.41\n",
      "[1,    81] loss: 3.12394, train_accuracy: 14.84\n",
      "[1,    82] loss: 2.35208, train_accuracy: 23.44\n",
      "[1,    83] loss: 2.79581, train_accuracy: 28.12\n",
      "[1,    84] loss: 3.25027, train_accuracy: 14.84\n",
      "[1,    85] loss: 3.69566, train_accuracy: 16.41\n",
      "[1,    86] loss: 2.62604, train_accuracy: 22.66\n",
      "[1,    87] loss: 3.82402, train_accuracy: 21.88\n",
      "[1,    88] loss: 3.40952, train_accuracy: 18.75\n",
      "[1,    89] loss: 4.14205, train_accuracy: 20.31\n",
      "[1,    90] loss: 2.29735, train_accuracy: 20.31\n",
      "[1,    91] loss: 3.15495, train_accuracy: 28.12\n",
      "[1,    92] loss: 4.54325, train_accuracy: 17.19\n",
      "[1,    93] loss: 3.51082, train_accuracy: 17.97\n",
      "[1,    94] loss: 3.01704, train_accuracy: 18.75\n",
      "[1,    95] loss: 3.07982, train_accuracy: 18.75\n",
      "[1,    96] loss: 3.83403, train_accuracy: 17.19\n",
      "[1,    97] loss: 3.62644, train_accuracy: 15.62\n",
      "[1,    98] loss: 3.40002, train_accuracy: 22.66\n",
      "[1,    99] loss: 2.96836, train_accuracy: 22.66\n",
      "[1,   100] loss: 2.70140, train_accuracy: 19.53\n",
      "[1,   101] loss: 2.48652, train_accuracy: 15.62\n",
      "[1,   102] loss: 3.69709, train_accuracy: 10.16\n",
      "[1,   103] loss: 2.94695, train_accuracy: 19.53\n",
      "[1,   104] loss: 2.26010, train_accuracy: 17.97\n",
      "[1,   105] loss: 3.64050, train_accuracy: 27.34\n",
      "[1,   106] loss: 3.27749, train_accuracy: 13.28\n",
      "[1,   107] loss: 2.73093, train_accuracy: 19.53\n",
      "[1,   108] loss: 3.08679, train_accuracy: 11.72\n",
      "[1,   109] loss: 2.31761, train_accuracy: 21.09\n",
      "[1,   110] loss: 2.37310, train_accuracy: 20.31\n",
      "[1,   111] loss: 3.51670, train_accuracy: 17.97\n",
      "[1,   112] loss: 2.47331, train_accuracy: 20.31\n",
      "[1,   113] loss: 2.15750, train_accuracy: 19.53\n",
      "[1,   114] loss: 2.75196, train_accuracy: 16.41\n",
      "[1,   115] loss: 2.77541, train_accuracy: 32.03\n",
      "[1,   116] loss: 2.58725, train_accuracy: 15.62\n",
      "[1,   117] loss: 2.88639, train_accuracy: 17.97\n",
      "[1,   118] loss: 2.87612, train_accuracy: 19.53\n",
      "[1,   119] loss: 2.81316, train_accuracy: 21.88\n",
      "[1,   120] loss: 2.55141, train_accuracy: 19.53\n",
      "[1,   121] loss: 3.53531, train_accuracy: 15.62\n",
      "[1,   122] loss: 2.55979, train_accuracy: 19.53\n",
      "[1,   123] loss: 2.28381, train_accuracy: 28.12\n",
      "[1,   124] loss: 2.56824, train_accuracy: 17.19\n",
      "[1,   125] loss: 2.84225, train_accuracy: 21.88\n",
      "[1,   126] loss: 2.55073, train_accuracy: 19.53\n",
      "[1,   127] loss: 2.35071, train_accuracy: 17.97\n",
      "[1,   128] loss: 2.90793, train_accuracy: 17.97\n",
      "[1,   129] loss: 2.46292, train_accuracy: 14.06\n",
      "[1,   130] loss: 3.30205, train_accuracy: 11.72\n",
      "[1,   131] loss: 2.17637, train_accuracy: 18.75\n",
      "[1,   132] loss: 2.06263, train_accuracy: 25.78\n",
      "[1,   133] loss: 3.20596, train_accuracy: 17.97\n",
      "[1,   134] loss: 2.05641, train_accuracy: 25.78\n",
      "[1,   135] loss: 2.29519, train_accuracy: 32.03\n",
      "[1,   136] loss: 2.32844, train_accuracy: 26.56\n",
      "[1,   137] loss: 2.15659, train_accuracy: 18.75\n",
      "[1,   138] loss: 2.25385, train_accuracy: 24.22\n",
      "[1,   139] loss: 2.62596, train_accuracy: 21.09\n",
      "[1,   140] loss: 2.65250, train_accuracy: 20.31\n",
      "[1,   141] loss: 2.56084, train_accuracy: 32.03\n",
      "[1,   142] loss: 2.59810, train_accuracy: 21.09\n",
      "[1,   143] loss: 2.59289, train_accuracy: 15.62\n",
      "[1,   144] loss: 2.27358, train_accuracy: 25.00\n",
      "[1,   145] loss: 2.24501, train_accuracy: 17.97\n",
      "[1,   146] loss: 2.22142, train_accuracy: 30.47\n",
      "[1,   147] loss: 2.60667, train_accuracy: 26.56\n",
      "[1,   148] loss: 2.45152, train_accuracy: 18.75\n",
      "[1,   149] loss: 2.95724, train_accuracy: 17.19\n",
      "[1,   150] loss: 2.08202, train_accuracy: 25.00\n",
      "[1,   151] loss: 2.12050, train_accuracy: 20.31\n",
      "[1,   152] loss: 2.18706, train_accuracy: 28.91\n",
      "[1,   153] loss: 2.09741, train_accuracy: 27.34\n",
      "[1,   154] loss: 2.11264, train_accuracy: 22.66\n",
      "[1,   155] loss: 2.00550, train_accuracy: 22.66\n",
      "[1,   156] loss: 2.12202, train_accuracy: 19.53\n",
      "[1,   157] loss: 2.37158, train_accuracy: 24.22\n",
      "[1,   158] loss: 2.82104, train_accuracy: 23.44\n",
      "[1,   159] loss: 2.13546, train_accuracy: 31.25\n",
      "[1,   160] loss: 2.20702, train_accuracy: 25.00\n",
      "[1,   161] loss: 2.18887, train_accuracy: 22.66\n",
      "[1,   162] loss: 2.30029, train_accuracy: 25.78\n",
      "[1,   163] loss: 2.13762, train_accuracy: 19.53\n",
      "[1,   164] loss: 2.09385, train_accuracy: 21.88\n",
      "[1,   165] loss: 2.15251, train_accuracy: 28.12\n",
      "[1,   166] loss: 2.18038, train_accuracy: 21.09\n",
      "[1,   167] loss: 2.00427, train_accuracy: 32.81\n",
      "[1,   168] loss: 2.13063, train_accuracy: 25.78\n",
      "[1,   169] loss: 2.15990, train_accuracy: 28.12\n",
      "[1,   170] loss: 1.96528, train_accuracy: 33.59\n",
      "[1,   171] loss: 2.05137, train_accuracy: 28.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   172] loss: 1.85165, train_accuracy: 32.81\n",
      "[1,   173] loss: 2.24087, train_accuracy: 28.12\n",
      "[1,   174] loss: 2.27824, train_accuracy: 26.56\n",
      "[1,   175] loss: 2.13371, train_accuracy: 28.12\n",
      "[1,   176] loss: 1.97337, train_accuracy: 30.47\n",
      "[1,   177] loss: 2.45703, train_accuracy: 20.31\n",
      "[1,   178] loss: 2.11995, train_accuracy: 17.97\n",
      "[1,   179] loss: 1.88462, train_accuracy: 30.47\n",
      "[1,   180] loss: 2.17834, train_accuracy: 23.44\n",
      "[1,   181] loss: 2.31661, train_accuracy: 20.31\n",
      "[1,   182] loss: 1.97295, train_accuracy: 19.53\n",
      "[1,   183] loss: 1.88052, train_accuracy: 27.34\n",
      "[1,   184] loss: 1.97934, train_accuracy: 29.69\n",
      "[1,   185] loss: 1.99207, train_accuracy: 30.47\n",
      "[1,   186] loss: 2.10996, train_accuracy: 25.00\n",
      "[1,   187] loss: 2.13081, train_accuracy: 28.91\n",
      "[1,   188] loss: 1.80777, train_accuracy: 32.03\n",
      "[1,   189] loss: 1.97322, train_accuracy: 29.69\n",
      "[1,   190] loss: 2.19852, train_accuracy: 25.00\n",
      "[1,   191] loss: 2.27146, train_accuracy: 30.47\n",
      "[1,   192] loss: 2.19726, train_accuracy: 28.91\n",
      "[1,   193] loss: 1.99502, train_accuracy: 22.66\n",
      "[1,   194] loss: 2.11850, train_accuracy: 21.09\n",
      "[1,   195] loss: 2.05208, train_accuracy: 25.00\n",
      "[1,   196] loss: 2.11832, train_accuracy: 28.12\n",
      "[1,   197] loss: 2.11638, train_accuracy: 23.44\n",
      "[1,   198] loss: 2.09531, train_accuracy: 21.88\n",
      "[1,   199] loss: 1.99560, train_accuracy: 28.12\n",
      "[1,   200] loss: 2.29327, train_accuracy: 19.53\n",
      "[1,   201] loss: 2.04647, train_accuracy: 30.47\n",
      "[1,   202] loss: 1.96406, train_accuracy: 27.34\n",
      "[1,   203] loss: 1.99636, train_accuracy: 28.91\n",
      "[1,   204] loss: 2.02876, train_accuracy: 33.59\n",
      "[1,   205] loss: 2.05387, train_accuracy: 31.25\n",
      "[1,   206] loss: 2.09323, train_accuracy: 28.91\n",
      "[1,   207] loss: 2.02305, train_accuracy: 28.12\n",
      "[1,   208] loss: 2.05086, train_accuracy: 24.22\n",
      "[1,   209] loss: 1.87628, train_accuracy: 29.69\n",
      "[1,   210] loss: 2.03547, train_accuracy: 21.88\n",
      "[1,   211] loss: 2.03271, train_accuracy: 28.12\n",
      "[1,   212] loss: 1.88485, train_accuracy: 28.91\n",
      "[1,   213] loss: 1.97991, train_accuracy: 37.50\n",
      "[1,   214] loss: 2.01296, train_accuracy: 27.34\n",
      "[1,   215] loss: 1.94265, train_accuracy: 24.22\n",
      "[1,   216] loss: 1.96913, train_accuracy: 25.00\n",
      "[1,   217] loss: 1.95424, train_accuracy: 27.34\n",
      "[1,   218] loss: 1.90644, train_accuracy: 27.34\n",
      "[1,   219] loss: 2.32031, train_accuracy: 29.69\n",
      "[1,   220] loss: 1.91156, train_accuracy: 31.25\n",
      "[1,   221] loss: 1.92531, train_accuracy: 29.69\n",
      "[1,   222] loss: 2.08235, train_accuracy: 28.12\n",
      "[1,   223] loss: 1.99499, train_accuracy: 32.03\n",
      "[1,   224] loss: 1.91899, train_accuracy: 24.22\n",
      "[1,   225] loss: 1.96117, train_accuracy: 35.16\n",
      "[1,   226] loss: 1.92430, train_accuracy: 25.00\n",
      "[1,   227] loss: 2.04416, train_accuracy: 29.69\n",
      "[1,   228] loss: 2.41733, train_accuracy: 21.88\n",
      "[1,   229] loss: 2.13672, train_accuracy: 28.91\n",
      "[1,   230] loss: 1.92487, train_accuracy: 29.69\n",
      "[1,   231] loss: 2.07904, train_accuracy: 30.47\n",
      "[1,   232] loss: 2.26512, train_accuracy: 32.81\n",
      "[1,   233] loss: 2.11762, train_accuracy: 30.47\n",
      "[1,   234] loss: 2.08280, train_accuracy: 25.78\n",
      "[1,   235] loss: 2.16708, train_accuracy: 21.09\n",
      "[1,   236] loss: 1.98182, train_accuracy: 32.03\n",
      "[1,   237] loss: 2.05448, train_accuracy: 31.25\n",
      "[1,   238] loss: 1.91870, train_accuracy: 32.03\n",
      "[1,   239] loss: 1.92412, train_accuracy: 33.59\n",
      "[1,   240] loss: 1.97897, train_accuracy: 39.84\n",
      "[1,   241] loss: 2.12539, train_accuracy: 28.12\n",
      "[1,   242] loss: 1.83547, train_accuracy: 37.50\n",
      "[1,   243] loss: 2.06969, train_accuracy: 33.59\n",
      "[1,   244] loss: 2.05384, train_accuracy: 23.44\n",
      "[1,   245] loss: 1.85839, train_accuracy: 31.25\n",
      "[1,   246] loss: 1.84211, train_accuracy: 36.72\n",
      "[1,   247] loss: 1.99942, train_accuracy: 24.22\n",
      "[1,   248] loss: 1.85518, train_accuracy: 28.91\n",
      "[1,   249] loss: 1.80929, train_accuracy: 33.59\n",
      "[1,   250] loss: 2.46868, train_accuracy: 28.12\n",
      "[1,   251] loss: 2.35807, train_accuracy: 28.12\n",
      "[1,   252] loss: 1.80207, train_accuracy: 28.91\n",
      "[1,   253] loss: 1.83277, train_accuracy: 33.59\n",
      "[1,   254] loss: 2.00099, train_accuracy: 27.34\n",
      "[1,   255] loss: 1.84176, train_accuracy: 34.38\n",
      "[1,   256] loss: 1.96143, train_accuracy: 30.47\n",
      "[1,   257] loss: 2.04807, train_accuracy: 25.78\n",
      "[1,   258] loss: 1.80295, train_accuracy: 32.81\n",
      "[1,   259] loss: 1.87514, train_accuracy: 41.41\n",
      "[1,   260] loss: 1.82449, train_accuracy: 35.94\n",
      "[1,   261] loss: 2.05573, train_accuracy: 29.69\n",
      "[1,   262] loss: 1.93623, train_accuracy: 35.16\n",
      "[1,   263] loss: 2.16682, train_accuracy: 25.78\n",
      "[1,   264] loss: 2.06672, train_accuracy: 25.78\n",
      "[1,   265] loss: 1.88813, train_accuracy: 34.38\n",
      "[1,   266] loss: 1.91346, train_accuracy: 28.12\n",
      "[1,   267] loss: 1.90109, train_accuracy: 28.91\n",
      "[1,   268] loss: 2.01700, train_accuracy: 24.22\n",
      "[1,   269] loss: 2.00004, train_accuracy: 36.72\n",
      "[1,   270] loss: 1.97421, train_accuracy: 28.91\n",
      "[1,   271] loss: 2.18721, train_accuracy: 22.66\n",
      "[1,   272] loss: 1.92434, train_accuracy: 26.56\n",
      "[1,   273] loss: 1.78226, train_accuracy: 29.69\n",
      "[1,   274] loss: 1.97986, train_accuracy: 29.69\n",
      "[1,   275] loss: 2.18860, train_accuracy: 25.78\n",
      "[1,   276] loss: 1.92188, train_accuracy: 28.12\n",
      "[1,   277] loss: 1.96184, train_accuracy: 32.81\n",
      "[1,   278] loss: 1.96063, train_accuracy: 30.47\n",
      "[1,   279] loss: 1.90733, train_accuracy: 26.56\n",
      "[1,   280] loss: 1.92137, train_accuracy: 27.34\n",
      "[1,   281] loss: 2.06146, train_accuracy: 26.56\n",
      "[1,   282] loss: 2.01081, train_accuracy: 25.00\n",
      "[1,   283] loss: 1.94745, train_accuracy: 28.12\n",
      "[1,   284] loss: 2.14244, train_accuracy: 28.12\n",
      "[1,   285] loss: 1.89799, train_accuracy: 32.03\n",
      "[1,   286] loss: 1.88559, train_accuracy: 28.91\n",
      "[1,   287] loss: 1.87658, train_accuracy: 35.94\n",
      "[1,   288] loss: 1.86659, train_accuracy: 28.12\n",
      "[1,   289] loss: 2.03356, train_accuracy: 26.56\n",
      "[1,   290] loss: 2.10788, train_accuracy: 33.59\n",
      "[1,   291] loss: 1.81199, train_accuracy: 30.47\n",
      "[1,   292] loss: 1.88694, train_accuracy: 32.03\n",
      "[1,   293] loss: 1.86274, train_accuracy: 33.59\n",
      "[1,   294] loss: 1.93491, train_accuracy: 33.59\n",
      "[1,   295] loss: 2.03048, train_accuracy: 29.69\n",
      "[1,   296] loss: 1.98777, train_accuracy: 25.78\n",
      "[1,   297] loss: 1.99392, train_accuracy: 31.25\n",
      "[1,   298] loss: 2.09516, train_accuracy: 27.34\n",
      "[1,   299] loss: 1.82345, train_accuracy: 33.59\n",
      "[1,   300] loss: 1.92791, train_accuracy: 32.81\n",
      "[1,   301] loss: 1.74304, train_accuracy: 32.03\n",
      "[1,   302] loss: 1.87188, train_accuracy: 28.12\n",
      "[1,   303] loss: 2.06540, train_accuracy: 31.25\n",
      "[1,   304] loss: 2.05222, train_accuracy: 21.88\n",
      "[1,   305] loss: 1.76313, train_accuracy: 39.06\n",
      "[1,   306] loss: 1.82382, train_accuracy: 39.06\n",
      "[1,   307] loss: 2.00213, train_accuracy: 31.25\n",
      "[1,   308] loss: 1.82970, train_accuracy: 33.59\n",
      "[1,   309] loss: 1.83602, train_accuracy: 35.94\n",
      "[1,   310] loss: 1.89705, train_accuracy: 28.91\n",
      "[1,   311] loss: 1.83283, train_accuracy: 32.03\n",
      "[1,   312] loss: 1.87431, train_accuracy: 26.56\n",
      "[1,   313] loss: 1.82754, train_accuracy: 32.81\n",
      "[1,   314] loss: 1.89972, train_accuracy: 27.34\n",
      "[1,   315] loss: 1.94302, train_accuracy: 30.47\n",
      "[1,   316] loss: 1.80694, train_accuracy: 35.94\n",
      "[1,   317] loss: 1.89115, train_accuracy: 34.38\n",
      "[1,   318] loss: 1.87610, train_accuracy: 32.81\n",
      "[1,   319] loss: 1.94003, train_accuracy: 28.91\n",
      "[1,   320] loss: 1.83186, train_accuracy: 32.81\n",
      "[1,   321] loss: 1.96053, train_accuracy: 34.38\n",
      "[1,   322] loss: 1.86250, train_accuracy: 27.34\n",
      "[1,   323] loss: 1.74886, train_accuracy: 36.72\n",
      "[1,   324] loss: 1.86044, train_accuracy: 31.25\n",
      "[1,   325] loss: 1.99148, train_accuracy: 32.03\n",
      "[1,   326] loss: 1.91151, train_accuracy: 33.59\n",
      "[1,   327] loss: 1.91861, train_accuracy: 35.16\n",
      "[1,   328] loss: 1.90414, train_accuracy: 33.59\n",
      "[1,   329] loss: 1.78632, train_accuracy: 31.25\n",
      "[1,   330] loss: 2.00866, train_accuracy: 33.59\n",
      "[1,   331] loss: 1.92302, train_accuracy: 28.91\n",
      "[1,   332] loss: 1.92441, train_accuracy: 28.91\n",
      "[1,   333] loss: 1.86335, train_accuracy: 24.22\n",
      "[1,   334] loss: 2.02884, train_accuracy: 32.81\n",
      "[1,   335] loss: 2.04100, train_accuracy: 25.78\n",
      "[1,   336] loss: 2.03478, train_accuracy: 29.69\n",
      "[1,   337] loss: 1.67601, train_accuracy: 40.62\n",
      "[1,   338] loss: 1.90650, train_accuracy: 34.38\n",
      "[1,   339] loss: 1.89190, train_accuracy: 25.00\n",
      "[1,   340] loss: 1.96075, train_accuracy: 25.78\n",
      "[1,   341] loss: 1.74184, train_accuracy: 42.19\n",
      "[1,   342] loss: 1.83888, train_accuracy: 30.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   343] loss: 1.89575, train_accuracy: 33.59\n",
      "[1,   344] loss: 1.77417, train_accuracy: 41.41\n",
      "[1,   345] loss: 1.89497, train_accuracy: 29.69\n",
      "[1,   346] loss: 1.90319, train_accuracy: 28.91\n",
      "[1,   347] loss: 1.90949, train_accuracy: 28.91\n",
      "[1,   348] loss: 2.04251, train_accuracy: 36.72\n",
      "[1,   349] loss: 2.00208, train_accuracy: 31.25\n",
      "[1,   350] loss: 1.93692, train_accuracy: 28.12\n",
      "[1,   351] loss: 1.95633, train_accuracy: 29.69\n",
      "[1,   352] loss: 1.68713, train_accuracy: 34.38\n",
      "[1,   353] loss: 1.94206, train_accuracy: 29.69\n",
      "[1,   354] loss: 1.89232, train_accuracy: 35.16\n",
      "[1,   355] loss: 2.07786, train_accuracy: 28.91\n",
      "[1,   356] loss: 1.79529, train_accuracy: 36.72\n",
      "[1,   357] loss: 1.72653, train_accuracy: 33.59\n",
      "[1,   358] loss: 1.90266, train_accuracy: 35.94\n",
      "[1,   359] loss: 2.05230, train_accuracy: 28.91\n",
      "[1,   360] loss: 1.89385, train_accuracy: 29.69\n",
      "[1,   361] loss: 1.93209, train_accuracy: 29.69\n",
      "[1,   362] loss: 1.86382, train_accuracy: 32.03\n",
      "[1,   363] loss: 1.90629, train_accuracy: 35.94\n",
      "[1,   364] loss: 2.07224, train_accuracy: 26.56\n",
      "[1,   365] loss: 1.99167, train_accuracy: 30.47\n",
      "[1,   366] loss: 2.00342, train_accuracy: 33.59\n",
      "[1,   367] loss: 1.94440, train_accuracy: 37.50\n",
      "[1,   368] loss: 2.02385, train_accuracy: 24.22\n",
      "[1,   369] loss: 2.00358, train_accuracy: 27.34\n",
      "[1,   370] loss: 1.80069, train_accuracy: 35.94\n",
      "[1,   371] loss: 1.82452, train_accuracy: 35.16\n",
      "[1,   372] loss: 1.80509, train_accuracy: 35.16\n",
      "[1,   373] loss: 1.96547, train_accuracy: 25.00\n",
      "[1,   374] loss: 1.91612, train_accuracy: 28.12\n",
      "[1,   375] loss: 1.82693, train_accuracy: 37.50\n",
      "[1,   376] loss: 1.85665, train_accuracy: 32.03\n",
      "[1,   377] loss: 1.81193, train_accuracy: 37.50\n",
      "[1,   378] loss: 1.80435, train_accuracy: 36.72\n",
      "[1,   379] loss: 2.12170, train_accuracy: 24.22\n",
      "[1,   380] loss: 2.06638, train_accuracy: 34.38\n",
      "[1,   381] loss: 1.99941, train_accuracy: 28.12\n",
      "[1,   382] loss: 1.85551, train_accuracy: 32.03\n",
      "[1,   383] loss: 1.84539, train_accuracy: 39.84\n",
      "[1,   384] loss: 1.67865, train_accuracy: 37.50\n",
      "[1,   385] loss: 2.21802, train_accuracy: 25.00\n",
      "[1,   386] loss: 1.78480, train_accuracy: 35.16\n",
      "[1,   387] loss: 1.87867, train_accuracy: 35.94\n",
      "[1,   388] loss: 1.96872, train_accuracy: 32.03\n",
      "[1,   389] loss: 1.87157, train_accuracy: 35.94\n",
      "[1,   390] loss: 1.85106, train_accuracy: 39.06\n",
      "[1,   391] loss: 2.29977, train_accuracy: 22.50\n",
      "duration: 148 s - train loss: 3.10755 - train accuracy: 25.13 - validation loss: 1.71 - validation accuracy: 39.74 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs_trained': 0,\n",
       " 'avg_time_per_epoch': 148.91602849960327,\n",
       " 'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'hist': {'train_loss': [3.107554952201941],\n",
       "  'train_accuracy': [25.129475703324808],\n",
       "  'validation_loss': [1.7050109467928922],\n",
       "  'validation_accuracy': [39.74]},\n",
       " 'val_accuracy': 39.74}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CifarResNet().to(device)\n",
    "model.fit(train_loader, test_loader, 1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w/o random rotation - 148 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "[1,     1] loss: 2.59091, train_accuracy: 9.38\n",
      "[1,     2] loss: 27.52983, train_accuracy: 7.81\n",
      "[1,     3] loss: 35.05844, train_accuracy: 9.38\n",
      "[1,     4] loss: 23.72497, train_accuracy: 18.75\n",
      "[1,     5] loss: 20.20100, train_accuracy: 10.94\n",
      "[1,     6] loss: 24.16389, train_accuracy: 9.38\n",
      "[1,     7] loss: 28.31976, train_accuracy: 11.72\n",
      "[1,     8] loss: 11.39920, train_accuracy: 8.59\n",
      "[1,     9] loss: 8.72260, train_accuracy: 16.41\n",
      "[1,    10] loss: 8.80157, train_accuracy: 14.84\n",
      "[1,    11] loss: 13.42351, train_accuracy: 10.16\n",
      "[1,    12] loss: 8.73238, train_accuracy: 11.72\n",
      "[1,    13] loss: 7.69056, train_accuracy: 8.59\n",
      "[1,    14] loss: 8.93891, train_accuracy: 12.50\n",
      "[1,    15] loss: 7.53752, train_accuracy: 10.16\n",
      "[1,    16] loss: 5.24707, train_accuracy: 7.81\n",
      "[1,    17] loss: 4.76543, train_accuracy: 14.06\n",
      "[1,    18] loss: 7.94311, train_accuracy: 12.50\n",
      "[1,    19] loss: 5.75391, train_accuracy: 13.28\n",
      "[1,    20] loss: 3.98639, train_accuracy: 19.53\n",
      "[1,    21] loss: 4.87581, train_accuracy: 13.28\n",
      "[1,    22] loss: 3.27984, train_accuracy: 18.75\n",
      "[1,    23] loss: 4.61535, train_accuracy: 16.41\n",
      "[1,    24] loss: 3.39892, train_accuracy: 15.62\n",
      "[1,    25] loss: 4.01853, train_accuracy: 17.97\n",
      "[1,    26] loss: 5.63836, train_accuracy: 16.41\n",
      "[1,    27] loss: 4.76517, train_accuracy: 15.62\n",
      "[1,    28] loss: 2.89108, train_accuracy: 18.75\n",
      "[1,    29] loss: 2.76995, train_accuracy: 14.84\n",
      "[1,    30] loss: 4.15881, train_accuracy: 15.62\n",
      "[1,    31] loss: 3.14075, train_accuracy: 18.75\n",
      "[1,    32] loss: 4.92743, train_accuracy: 10.94\n",
      "[1,    33] loss: 3.12226, train_accuracy: 14.84\n",
      "[1,    34] loss: 3.49852, train_accuracy: 16.41\n",
      "[1,    35] loss: 3.57342, train_accuracy: 14.84\n",
      "[1,    36] loss: 3.36718, train_accuracy: 9.38\n",
      "[1,    37] loss: 2.98551, train_accuracy: 19.53\n",
      "[1,    38] loss: 3.87435, train_accuracy: 15.62\n",
      "[1,    39] loss: 3.35663, train_accuracy: 16.41\n",
      "[1,    40] loss: 3.15050, train_accuracy: 9.38\n",
      "[1,    41] loss: 2.41097, train_accuracy: 15.62\n",
      "[1,    42] loss: 3.40968, train_accuracy: 12.50\n",
      "[1,    43] loss: 3.19721, train_accuracy: 17.97\n",
      "[1,    44] loss: 2.20326, train_accuracy: 16.41\n",
      "[1,    45] loss: 2.35990, train_accuracy: 21.09\n",
      "[1,    46] loss: 5.07016, train_accuracy: 14.84\n",
      "[1,    47] loss: 3.12175, train_accuracy: 20.31\n",
      "[1,    48] loss: 2.23214, train_accuracy: 18.75\n",
      "[1,    49] loss: 2.60288, train_accuracy: 16.41\n",
      "[1,    50] loss: 3.57855, train_accuracy: 17.97\n",
      "[1,    51] loss: 3.06007, train_accuracy: 22.66\n",
      "[1,    52] loss: 3.39348, train_accuracy: 24.22\n",
      "[1,    53] loss: 3.33903, train_accuracy: 17.97\n",
      "[1,    54] loss: 3.32130, train_accuracy: 25.78\n",
      "[1,    55] loss: 2.51402, train_accuracy: 20.31\n",
      "[1,    56] loss: 4.08283, train_accuracy: 21.88\n",
      "[1,    57] loss: 3.15810, train_accuracy: 19.53\n",
      "[1,    58] loss: 2.41830, train_accuracy: 21.09\n",
      "[1,    59] loss: 3.00038, train_accuracy: 15.62\n",
      "[1,    60] loss: 2.60593, train_accuracy: 21.88\n",
      "[1,    61] loss: 2.16076, train_accuracy: 26.56\n",
      "[1,    62] loss: 3.32389, train_accuracy: 20.31\n",
      "[1,    63] loss: 2.37925, train_accuracy: 24.22\n",
      "[1,    64] loss: 2.47611, train_accuracy: 21.09\n",
      "[1,    65] loss: 4.23018, train_accuracy: 15.62\n",
      "[1,    66] loss: 4.24780, train_accuracy: 17.97\n",
      "[1,    67] loss: 2.79010, train_accuracy: 17.97\n",
      "[1,    68] loss: 2.75244, train_accuracy: 18.75\n",
      "[1,    69] loss: 3.47001, train_accuracy: 24.22\n",
      "[1,    70] loss: 3.08107, train_accuracy: 26.56\n",
      "[1,    71] loss: 2.82499, train_accuracy: 14.84\n",
      "[1,    72] loss: 2.60703, train_accuracy: 18.75\n",
      "[1,    73] loss: 2.60294, train_accuracy: 18.75\n",
      "[1,    74] loss: 2.39556, train_accuracy: 22.66\n",
      "[1,    75] loss: 2.12987, train_accuracy: 26.56\n",
      "[1,    76] loss: 2.39947, train_accuracy: 14.84\n",
      "[1,    77] loss: 2.46738, train_accuracy: 23.44\n",
      "[1,    78] loss: 2.59942, train_accuracy: 17.97\n",
      "[1,    79] loss: 3.34717, train_accuracy: 17.97\n",
      "[1,    80] loss: 3.22666, train_accuracy: 16.41\n",
      "[1,    81] loss: 2.23908, train_accuracy: 15.62\n",
      "[1,    82] loss: 2.87448, train_accuracy: 22.66\n",
      "[1,    83] loss: 3.18551, train_accuracy: 16.41\n",
      "[1,    84] loss: 2.72109, train_accuracy: 20.31\n",
      "[1,    85] loss: 3.23254, train_accuracy: 13.28\n",
      "[1,    86] loss: 2.41041, train_accuracy: 17.19\n",
      "[1,    87] loss: 3.45980, train_accuracy: 14.06\n",
      "[1,    88] loss: 2.66942, train_accuracy: 26.56\n",
      "[1,    89] loss: 2.26804, train_accuracy: 23.44\n",
      "[1,    90] loss: 2.79742, train_accuracy: 17.97\n",
      "[1,    91] loss: 2.35480, train_accuracy: 23.44\n",
      "[1,    92] loss: 2.76358, train_accuracy: 20.31\n",
      "[1,    93] loss: 2.94269, train_accuracy: 17.19\n",
      "[1,    94] loss: 2.20846, train_accuracy: 21.09\n",
      "[1,    95] loss: 2.38590, train_accuracy: 20.31\n",
      "[1,    96] loss: 2.35661, train_accuracy: 16.41\n",
      "[1,    97] loss: 2.46449, train_accuracy: 17.97\n",
      "[1,    98] loss: 2.20073, train_accuracy: 25.78\n",
      "[1,    99] loss: 2.70282, train_accuracy: 18.75\n",
      "[1,   100] loss: 2.27405, train_accuracy: 19.53\n",
      "[1,   101] loss: 2.31334, train_accuracy: 21.88\n",
      "[1,   102] loss: 2.85906, train_accuracy: 22.66\n",
      "[1,   103] loss: 2.84169, train_accuracy: 18.75\n",
      "[1,   104] loss: 2.80832, train_accuracy: 17.19\n",
      "[1,   105] loss: 2.07617, train_accuracy: 24.22\n",
      "[1,   106] loss: 3.24722, train_accuracy: 17.97\n",
      "[1,   107] loss: 2.66031, train_accuracy: 23.44\n",
      "[1,   108] loss: 2.86117, train_accuracy: 25.00\n",
      "[1,   109] loss: 2.73276, train_accuracy: 23.44\n",
      "[1,   110] loss: 2.25974, train_accuracy: 15.62\n",
      "[1,   111] loss: 2.18942, train_accuracy: 25.00\n",
      "[1,   112] loss: 2.48288, train_accuracy: 17.19\n",
      "[1,   113] loss: 2.87021, train_accuracy: 16.41\n",
      "[1,   114] loss: 2.11997, train_accuracy: 22.66\n",
      "[1,   115] loss: 2.56650, train_accuracy: 21.88\n",
      "[1,   116] loss: 2.35000, train_accuracy: 23.44\n",
      "[1,   117] loss: 2.32263, train_accuracy: 15.62\n",
      "[1,   118] loss: 2.44260, train_accuracy: 22.66\n",
      "[1,   119] loss: 2.44881, train_accuracy: 23.44\n",
      "[1,   120] loss: 2.54048, train_accuracy: 26.56\n",
      "[1,   121] loss: 2.60432, train_accuracy: 21.88\n",
      "[1,   122] loss: 2.46072, train_accuracy: 27.34\n",
      "[1,   123] loss: 2.61199, train_accuracy: 24.22\n",
      "[1,   124] loss: 2.24439, train_accuracy: 31.25\n",
      "[1,   125] loss: 2.04185, train_accuracy: 21.88\n",
      "[1,   126] loss: 2.63626, train_accuracy: 27.34\n",
      "[1,   127] loss: 2.51221, train_accuracy: 22.66\n",
      "[1,   128] loss: 2.65839, train_accuracy: 24.22\n",
      "[1,   129] loss: 2.13417, train_accuracy: 29.69\n",
      "[1,   130] loss: 2.43907, train_accuracy: 20.31\n",
      "[1,   131] loss: 2.31000, train_accuracy: 21.88\n",
      "[1,   132] loss: 2.03235, train_accuracy: 25.00\n",
      "[1,   133] loss: 2.33229, train_accuracy: 28.91\n",
      "[1,   134] loss: 2.43219, train_accuracy: 19.53\n",
      "[1,   135] loss: 2.24222, train_accuracy: 21.09\n",
      "[1,   136] loss: 2.50102, train_accuracy: 24.22\n",
      "[1,   137] loss: 2.23180, train_accuracy: 21.88\n",
      "[1,   138] loss: 1.98992, train_accuracy: 31.25\n",
      "[1,   139] loss: 2.59076, train_accuracy: 23.44\n",
      "[1,   140] loss: 2.37814, train_accuracy: 18.75\n",
      "[1,   141] loss: 2.60640, train_accuracy: 20.31\n",
      "[1,   142] loss: 2.40056, train_accuracy: 21.88\n",
      "[1,   143] loss: 2.43906, train_accuracy: 29.69\n",
      "[1,   144] loss: 2.56759, train_accuracy: 21.09\n",
      "[1,   145] loss: 2.11934, train_accuracy: 23.44\n",
      "[1,   146] loss: 1.98630, train_accuracy: 25.00\n",
      "[1,   147] loss: 2.03424, train_accuracy: 20.31\n",
      "[1,   148] loss: 2.49418, train_accuracy: 19.53\n",
      "[1,   149] loss: 2.22444, train_accuracy: 23.44\n",
      "[1,   150] loss: 2.00314, train_accuracy: 28.12\n",
      "[1,   151] loss: 2.09845, train_accuracy: 18.75\n",
      "[1,   152] loss: 2.08858, train_accuracy: 17.19\n",
      "[1,   153] loss: 2.01931, train_accuracy: 22.66\n",
      "[1,   154] loss: 2.09060, train_accuracy: 30.47\n",
      "[1,   155] loss: 2.46473, train_accuracy: 26.56\n",
      "[1,   156] loss: 2.45924, train_accuracy: 22.66\n",
      "[1,   157] loss: 1.95380, train_accuracy: 25.78\n",
      "[1,   158] loss: 2.04308, train_accuracy: 21.88\n",
      "[1,   159] loss: 1.98515, train_accuracy: 25.00\n",
      "[1,   160] loss: 2.14013, train_accuracy: 20.31\n",
      "[1,   161] loss: 2.15150, train_accuracy: 21.09\n",
      "[1,   162] loss: 2.36226, train_accuracy: 28.91\n",
      "[1,   163] loss: 2.20298, train_accuracy: 25.00\n",
      "[1,   164] loss: 2.25738, train_accuracy: 24.22\n",
      "[1,   165] loss: 2.14239, train_accuracy: 23.44\n",
      "[1,   166] loss: 1.97590, train_accuracy: 21.09\n",
      "[1,   167] loss: 2.16562, train_accuracy: 24.22\n",
      "[1,   168] loss: 2.20313, train_accuracy: 23.44\n",
      "[1,   169] loss: 2.16567, train_accuracy: 32.81\n",
      "[1,   170] loss: 2.27696, train_accuracy: 28.12\n",
      "[1,   171] loss: 2.11189, train_accuracy: 21.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   172] loss: 2.35078, train_accuracy: 17.97\n",
      "[1,   173] loss: 2.07586, train_accuracy: 25.78\n",
      "[1,   174] loss: 1.88815, train_accuracy: 31.25\n",
      "[1,   175] loss: 2.06590, train_accuracy: 31.25\n",
      "[1,   176] loss: 2.06548, train_accuracy: 31.25\n",
      "[1,   177] loss: 1.93422, train_accuracy: 30.47\n",
      "[1,   178] loss: 2.03168, train_accuracy: 25.78\n",
      "[1,   179] loss: 2.00081, train_accuracy: 25.00\n",
      "[1,   180] loss: 1.90612, train_accuracy: 28.91\n",
      "[1,   181] loss: 1.99527, train_accuracy: 28.91\n",
      "[1,   182] loss: 2.04399, train_accuracy: 30.47\n",
      "[1,   183] loss: 2.05088, train_accuracy: 23.44\n",
      "[1,   184] loss: 2.12243, train_accuracy: 25.78\n",
      "[1,   185] loss: 2.06697, train_accuracy: 26.56\n",
      "[1,   186] loss: 1.92959, train_accuracy: 28.12\n",
      "[1,   187] loss: 2.07570, train_accuracy: 25.00\n",
      "[1,   188] loss: 2.33274, train_accuracy: 26.56\n",
      "[1,   189] loss: 2.16263, train_accuracy: 25.78\n",
      "[1,   190] loss: 1.90182, train_accuracy: 29.69\n",
      "[1,   191] loss: 2.00371, train_accuracy: 21.09\n",
      "[1,   192] loss: 2.03149, train_accuracy: 31.25\n",
      "[1,   193] loss: 2.20835, train_accuracy: 26.56\n",
      "[1,   194] loss: 1.96997, train_accuracy: 26.56\n",
      "[1,   195] loss: 1.99759, train_accuracy: 32.03\n",
      "[1,   196] loss: 1.72934, train_accuracy: 35.16\n",
      "[1,   197] loss: 1.93680, train_accuracy: 30.47\n",
      "[1,   198] loss: 2.00627, train_accuracy: 21.09\n",
      "[1,   199] loss: 2.05603, train_accuracy: 25.78\n",
      "[1,   200] loss: 2.13887, train_accuracy: 25.78\n",
      "[1,   201] loss: 2.09679, train_accuracy: 28.91\n",
      "[1,   202] loss: 1.83952, train_accuracy: 30.47\n",
      "[1,   203] loss: 2.03697, train_accuracy: 24.22\n",
      "[1,   204] loss: 2.02679, train_accuracy: 29.69\n",
      "[1,   205] loss: 1.99913, train_accuracy: 27.34\n",
      "[1,   206] loss: 2.00949, train_accuracy: 25.00\n",
      "[1,   207] loss: 2.31914, train_accuracy: 26.56\n",
      "[1,   208] loss: 2.07292, train_accuracy: 21.88\n",
      "[1,   209] loss: 2.19186, train_accuracy: 22.66\n",
      "[1,   210] loss: 1.99283, train_accuracy: 27.34\n",
      "[1,   211] loss: 1.92392, train_accuracy: 30.47\n",
      "[1,   212] loss: 2.06152, train_accuracy: 25.78\n",
      "[1,   213] loss: 2.01472, train_accuracy: 25.00\n",
      "[1,   214] loss: 2.12140, train_accuracy: 21.09\n",
      "[1,   215] loss: 1.99442, train_accuracy: 27.34\n",
      "[1,   216] loss: 2.06834, train_accuracy: 26.56\n",
      "[1,   217] loss: 2.04246, train_accuracy: 23.44\n",
      "[1,   218] loss: 2.01402, train_accuracy: 21.09\n",
      "[1,   219] loss: 1.91758, train_accuracy: 20.31\n",
      "[1,   220] loss: 1.92474, train_accuracy: 25.78\n",
      "[1,   221] loss: 1.98872, train_accuracy: 24.22\n",
      "[1,   222] loss: 2.10936, train_accuracy: 30.47\n",
      "[1,   223] loss: 2.00073, train_accuracy: 26.56\n",
      "[1,   224] loss: 1.85796, train_accuracy: 30.47\n",
      "[1,   225] loss: 2.24351, train_accuracy: 28.91\n",
      "[1,   226] loss: 1.93128, train_accuracy: 28.91\n",
      "[1,   227] loss: 2.00246, train_accuracy: 24.22\n",
      "[1,   228] loss: 1.97136, train_accuracy: 33.59\n",
      "[1,   229] loss: 1.78956, train_accuracy: 35.94\n",
      "[1,   230] loss: 2.01472, train_accuracy: 26.56\n",
      "[1,   231] loss: 1.89653, train_accuracy: 30.47\n",
      "[1,   232] loss: 2.00727, train_accuracy: 25.00\n",
      "[1,   233] loss: 1.96933, train_accuracy: 28.91\n",
      "[1,   234] loss: 2.00786, train_accuracy: 26.56\n",
      "[1,   235] loss: 2.18309, train_accuracy: 26.56\n",
      "[1,   236] loss: 2.32173, train_accuracy: 32.03\n",
      "[1,   237] loss: 2.12938, train_accuracy: 29.69\n",
      "[1,   238] loss: 1.87397, train_accuracy: 32.03\n",
      "[1,   239] loss: 2.05184, train_accuracy: 32.81\n",
      "[1,   240] loss: 1.91428, train_accuracy: 33.59\n",
      "[1,   241] loss: 2.00669, train_accuracy: 33.59\n",
      "[1,   242] loss: 1.85942, train_accuracy: 28.91\n",
      "[1,   243] loss: 2.19259, train_accuracy: 20.31\n",
      "[1,   244] loss: 2.02949, train_accuracy: 25.78\n",
      "[1,   245] loss: 1.87277, train_accuracy: 32.03\n",
      "[1,   246] loss: 1.97341, train_accuracy: 25.78\n",
      "[1,   247] loss: 1.94893, train_accuracy: 26.56\n",
      "[1,   248] loss: 1.94863, train_accuracy: 26.56\n",
      "[1,   249] loss: 1.89441, train_accuracy: 32.81\n",
      "[1,   250] loss: 2.06300, train_accuracy: 21.88\n",
      "[1,   251] loss: 1.88099, train_accuracy: 26.56\n",
      "[1,   252] loss: 1.99953, train_accuracy: 29.69\n",
      "[1,   253] loss: 1.95462, train_accuracy: 27.34\n",
      "[1,   254] loss: 2.08672, train_accuracy: 24.22\n",
      "[1,   255] loss: 2.02980, train_accuracy: 27.34\n",
      "[1,   256] loss: 2.00874, train_accuracy: 28.91\n",
      "[1,   257] loss: 1.92386, train_accuracy: 29.69\n",
      "[1,   258] loss: 2.57225, train_accuracy: 25.00\n",
      "[1,   259] loss: 2.22489, train_accuracy: 25.00\n",
      "[1,   260] loss: 1.99343, train_accuracy: 23.44\n",
      "[1,   261] loss: 1.94322, train_accuracy: 26.56\n",
      "[1,   262] loss: 1.95798, train_accuracy: 22.66\n",
      "[1,   263] loss: 1.78663, train_accuracy: 37.50\n",
      "[1,   264] loss: 2.00119, train_accuracy: 32.81\n",
      "[1,   265] loss: 2.00852, train_accuracy: 28.12\n",
      "[1,   266] loss: 1.91692, train_accuracy: 31.25\n",
      "[1,   267] loss: 1.79082, train_accuracy: 30.47\n",
      "[1,   268] loss: 1.94408, train_accuracy: 39.06\n",
      "[1,   269] loss: 2.05892, train_accuracy: 32.03\n",
      "[1,   270] loss: 2.04817, train_accuracy: 25.78\n",
      "[1,   271] loss: 2.05497, train_accuracy: 32.81\n",
      "[1,   272] loss: 1.96096, train_accuracy: 29.69\n",
      "[1,   273] loss: 1.91716, train_accuracy: 22.66\n",
      "[1,   274] loss: 1.95767, train_accuracy: 31.25\n",
      "[1,   275] loss: 1.96653, train_accuracy: 28.91\n",
      "[1,   276] loss: 2.01779, train_accuracy: 27.34\n",
      "[1,   277] loss: 1.86688, train_accuracy: 39.84\n",
      "[1,   278] loss: 1.86313, train_accuracy: 34.38\n",
      "[1,   279] loss: 1.96623, train_accuracy: 32.81\n",
      "[1,   280] loss: 1.90093, train_accuracy: 35.16\n",
      "[1,   281] loss: 1.91743, train_accuracy: 28.12\n",
      "[1,   282] loss: 1.85721, train_accuracy: 28.12\n",
      "[1,   283] loss: 2.00214, train_accuracy: 31.25\n",
      "[1,   284] loss: 1.92815, train_accuracy: 28.91\n",
      "[1,   285] loss: 1.97100, train_accuracy: 28.91\n",
      "[1,   286] loss: 1.99946, train_accuracy: 29.69\n",
      "[1,   287] loss: 2.10545, train_accuracy: 27.34\n",
      "[1,   288] loss: 1.86446, train_accuracy: 36.72\n",
      "[1,   289] loss: 1.97288, train_accuracy: 29.69\n",
      "[1,   290] loss: 1.89804, train_accuracy: 33.59\n",
      "[1,   291] loss: 1.96737, train_accuracy: 23.44\n",
      "[1,   292] loss: 1.96210, train_accuracy: 28.91\n",
      "[1,   293] loss: 1.84592, train_accuracy: 32.03\n",
      "[1,   294] loss: 1.89474, train_accuracy: 32.81\n",
      "[1,   295] loss: 1.83116, train_accuracy: 34.38\n",
      "[1,   296] loss: 1.76663, train_accuracy: 36.72\n",
      "[1,   297] loss: 1.90363, train_accuracy: 30.47\n",
      "[1,   298] loss: 1.90653, train_accuracy: 32.03\n",
      "[1,   299] loss: 1.86050, train_accuracy: 34.38\n",
      "[1,   300] loss: 1.97121, train_accuracy: 32.81\n",
      "[1,   301] loss: 2.02165, train_accuracy: 29.69\n",
      "[1,   302] loss: 2.03425, train_accuracy: 28.12\n",
      "[1,   303] loss: 1.75870, train_accuracy: 32.03\n",
      "[1,   304] loss: 1.98847, train_accuracy: 31.25\n",
      "[1,   305] loss: 1.78063, train_accuracy: 39.06\n",
      "[1,   306] loss: 1.82374, train_accuracy: 31.25\n",
      "[1,   307] loss: 1.70764, train_accuracy: 39.84\n",
      "[1,   308] loss: 1.95793, train_accuracy: 32.81\n",
      "[1,   309] loss: 1.87782, train_accuracy: 35.94\n",
      "[1,   310] loss: 1.83682, train_accuracy: 33.59\n",
      "[1,   311] loss: 2.01654, train_accuracy: 28.12\n",
      "[1,   312] loss: 1.79888, train_accuracy: 35.16\n",
      "[1,   313] loss: 1.91320, train_accuracy: 35.94\n",
      "[1,   314] loss: 1.86902, train_accuracy: 30.47\n",
      "[1,   315] loss: 1.89428, train_accuracy: 30.47\n",
      "[1,   316] loss: 1.88900, train_accuracy: 27.34\n",
      "[1,   317] loss: 1.86552, train_accuracy: 26.56\n",
      "[1,   318] loss: 1.87271, train_accuracy: 28.12\n",
      "[1,   319] loss: 1.74336, train_accuracy: 33.59\n",
      "[1,   320] loss: 1.77033, train_accuracy: 35.94\n",
      "[1,   321] loss: 1.85615, train_accuracy: 36.72\n",
      "[1,   322] loss: 1.71399, train_accuracy: 34.38\n",
      "[1,   323] loss: 1.78020, train_accuracy: 32.03\n",
      "[1,   324] loss: 1.80152, train_accuracy: 33.59\n",
      "[1,   325] loss: 1.88474, train_accuracy: 31.25\n",
      "[1,   326] loss: 1.85334, train_accuracy: 33.59\n",
      "[1,   327] loss: 2.05526, train_accuracy: 25.00\n",
      "[1,   328] loss: 1.93206, train_accuracy: 29.69\n",
      "[1,   329] loss: 2.02069, train_accuracy: 26.56\n",
      "[1,   330] loss: 1.81351, train_accuracy: 33.59\n",
      "[1,   331] loss: 1.81105, train_accuracy: 33.59\n",
      "[1,   332] loss: 1.83852, train_accuracy: 27.34\n",
      "[1,   333] loss: 1.98090, train_accuracy: 26.56\n",
      "[1,   334] loss: 1.90816, train_accuracy: 26.56\n",
      "[1,   335] loss: 1.87466, train_accuracy: 28.12\n",
      "[1,   336] loss: 1.84698, train_accuracy: 28.91\n",
      "[1,   337] loss: 1.93373, train_accuracy: 33.59\n",
      "[1,   338] loss: 1.82636, train_accuracy: 32.81\n",
      "[1,   339] loss: 1.83034, train_accuracy: 32.03\n",
      "[1,   340] loss: 1.85816, train_accuracy: 37.50\n",
      "[1,   341] loss: 2.01517, train_accuracy: 25.78\n",
      "[1,   342] loss: 1.80777, train_accuracy: 32.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   343] loss: 2.12886, train_accuracy: 26.56\n",
      "[1,   344] loss: 1.79190, train_accuracy: 28.91\n",
      "[1,   345] loss: 1.92370, train_accuracy: 27.34\n",
      "[1,   346] loss: 1.84822, train_accuracy: 39.06\n",
      "[1,   347] loss: 1.98468, train_accuracy: 25.00\n",
      "[1,   348] loss: 1.75195, train_accuracy: 38.28\n",
      "[1,   349] loss: 1.91630, train_accuracy: 34.38\n",
      "[1,   350] loss: 1.90386, train_accuracy: 25.00\n",
      "[1,   351] loss: 1.81721, train_accuracy: 33.59\n",
      "[1,   352] loss: 1.88080, train_accuracy: 34.38\n",
      "[1,   353] loss: 2.06307, train_accuracy: 25.78\n",
      "[1,   354] loss: 1.92496, train_accuracy: 25.78\n",
      "[1,   355] loss: 1.68671, train_accuracy: 39.06\n",
      "[1,   356] loss: 1.91359, train_accuracy: 28.91\n",
      "[1,   357] loss: 1.86076, train_accuracy: 36.72\n",
      "[1,   358] loss: 1.77974, train_accuracy: 40.62\n",
      "[1,   359] loss: 1.88117, train_accuracy: 29.69\n",
      "[1,   360] loss: 1.82426, train_accuracy: 34.38\n",
      "[1,   361] loss: 1.98927, train_accuracy: 28.12\n",
      "[1,   362] loss: 1.75256, train_accuracy: 40.62\n",
      "[1,   363] loss: 1.87360, train_accuracy: 32.03\n",
      "[1,   364] loss: 1.70566, train_accuracy: 29.69\n",
      "[1,   365] loss: 1.83019, train_accuracy: 30.47\n",
      "[1,   366] loss: 1.76871, train_accuracy: 32.81\n",
      "[1,   367] loss: 1.84017, train_accuracy: 33.59\n",
      "[1,   368] loss: 1.76425, train_accuracy: 32.03\n",
      "[1,   369] loss: 1.91877, train_accuracy: 28.91\n",
      "[1,   370] loss: 1.82408, train_accuracy: 30.47\n",
      "[1,   371] loss: 1.85277, train_accuracy: 35.16\n",
      "[1,   372] loss: 1.74121, train_accuracy: 29.69\n",
      "[1,   373] loss: 1.81683, train_accuracy: 32.81\n",
      "[1,   374] loss: 1.76331, train_accuracy: 36.72\n",
      "[1,   375] loss: 1.79572, train_accuracy: 26.56\n",
      "[1,   376] loss: 1.71149, train_accuracy: 33.59\n",
      "[1,   377] loss: 1.61195, train_accuracy: 38.28\n",
      "[1,   378] loss: 1.85689, train_accuracy: 33.59\n",
      "[1,   379] loss: 1.76067, train_accuracy: 37.50\n",
      "[1,   380] loss: 1.82534, train_accuracy: 32.03\n",
      "[1,   381] loss: 1.72507, train_accuracy: 32.81\n",
      "[1,   382] loss: 1.94779, train_accuracy: 30.47\n",
      "[1,   383] loss: 1.85900, train_accuracy: 32.81\n",
      "[1,   384] loss: 1.76423, train_accuracy: 42.19\n",
      "[1,   385] loss: 1.96511, train_accuracy: 28.91\n",
      "[1,   386] loss: 1.76280, train_accuracy: 31.25\n",
      "[1,   387] loss: 1.81049, train_accuracy: 33.59\n",
      "[1,   388] loss: 1.65006, train_accuracy: 39.06\n",
      "[1,   389] loss: 1.58789, train_accuracy: 45.31\n",
      "[1,   390] loss: 1.88996, train_accuracy: 31.25\n",
      "[1,   391] loss: 1.81846, train_accuracy: 37.50\n",
      "duration: 148 s - train loss: 2.82306 - train accuracy: 25.54 - validation loss: 1.62 - validation accuracy: 42.76 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs_trained': 0,\n",
       " 'avg_time_per_epoch': 148.66814661026,\n",
       " 'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'hist': {'train_loss': [2.8230593899631744],\n",
       "  'train_accuracy': [25.543478260869566],\n",
       "  'validation_loss': [1.6168042074275921],\n",
       "  'validation_accuracy': [42.76]},\n",
       " 'val_accuracy': 42.76}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CifarResNet().to(device)\n",
    "model.fit(train_loader, test_loader, 1, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w/o resizing - 142 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "[1,     1] loss: 2.81770, train_accuracy: 7.81\n",
      "[1,     2] loss: 35.36283, train_accuracy: 11.72\n",
      "[1,     3] loss: 26.17254, train_accuracy: 21.09\n",
      "[1,     4] loss: 20.82720, train_accuracy: 10.94\n",
      "[1,     5] loss: 24.54180, train_accuracy: 8.59\n",
      "[1,     6] loss: 15.62462, train_accuracy: 18.75\n",
      "[1,     7] loss: 12.95870, train_accuracy: 7.03\n",
      "[1,     8] loss: 13.69677, train_accuracy: 7.03\n",
      "[1,     9] loss: 11.40793, train_accuracy: 7.81\n",
      "[1,    10] loss: 9.86576, train_accuracy: 10.94\n",
      "[1,    11] loss: 5.70351, train_accuracy: 13.28\n",
      "[1,    12] loss: 7.70698, train_accuracy: 15.62\n",
      "[1,    13] loss: 8.56297, train_accuracy: 14.06\n",
      "[1,    14] loss: 10.54087, train_accuracy: 17.97\n",
      "[1,    15] loss: 8.81648, train_accuracy: 12.50\n",
      "[1,    16] loss: 4.83721, train_accuracy: 14.84\n",
      "[1,    17] loss: 4.05362, train_accuracy: 11.72\n",
      "[1,    18] loss: 4.59992, train_accuracy: 14.06\n",
      "[1,    19] loss: 3.82780, train_accuracy: 10.94\n",
      "[1,    20] loss: 5.90464, train_accuracy: 8.59\n",
      "[1,    21] loss: 6.03958, train_accuracy: 16.41\n",
      "[1,    22] loss: 3.54280, train_accuracy: 26.56\n",
      "[1,    23] loss: 4.22344, train_accuracy: 14.06\n",
      "[1,    24] loss: 3.41914, train_accuracy: 15.62\n",
      "[1,    25] loss: 4.19025, train_accuracy: 16.41\n",
      "[1,    26] loss: 4.02544, train_accuracy: 12.50\n",
      "[1,    27] loss: 3.71064, train_accuracy: 20.31\n",
      "[1,    28] loss: 3.94093, train_accuracy: 19.53\n",
      "[1,    29] loss: 4.63736, train_accuracy: 14.84\n",
      "[1,    30] loss: 4.63036, train_accuracy: 19.53\n",
      "[1,    31] loss: 4.89923, train_accuracy: 18.75\n",
      "[1,    32] loss: 4.47256, train_accuracy: 21.09\n",
      "[1,    33] loss: 3.48006, train_accuracy: 16.41\n",
      "[1,    34] loss: 2.95432, train_accuracy: 17.19\n",
      "[1,    35] loss: 2.53030, train_accuracy: 18.75\n",
      "[1,    36] loss: 2.88754, train_accuracy: 16.41\n",
      "[1,    37] loss: 3.75079, train_accuracy: 16.41\n",
      "[1,    38] loss: 3.48132, train_accuracy: 18.75\n",
      "[1,    39] loss: 2.98904, train_accuracy: 17.97\n",
      "[1,    40] loss: 2.61960, train_accuracy: 18.75\n",
      "[1,    41] loss: 2.57321, train_accuracy: 17.97\n",
      "[1,    42] loss: 2.70209, train_accuracy: 17.19\n",
      "[1,    43] loss: 2.46530, train_accuracy: 21.88\n",
      "[1,    44] loss: 2.91508, train_accuracy: 22.66\n",
      "[1,    45] loss: 2.40963, train_accuracy: 24.22\n",
      "[1,    46] loss: 2.18625, train_accuracy: 31.25\n",
      "[1,    47] loss: 4.05436, train_accuracy: 22.66\n",
      "[1,    48] loss: 2.32907, train_accuracy: 14.06\n",
      "[1,    49] loss: 4.32877, train_accuracy: 22.66\n",
      "[1,    50] loss: 2.09792, train_accuracy: 25.78\n",
      "[1,    51] loss: 2.23172, train_accuracy: 25.00\n",
      "[1,    52] loss: 2.19786, train_accuracy: 18.75\n",
      "[1,    53] loss: 2.29702, train_accuracy: 15.62\n",
      "[1,    54] loss: 3.92381, train_accuracy: 24.22\n",
      "[1,    55] loss: 2.05922, train_accuracy: 26.56\n",
      "[1,    56] loss: 2.65775, train_accuracy: 28.12\n",
      "[1,    57] loss: 2.02971, train_accuracy: 26.56\n",
      "[1,    58] loss: 3.23775, train_accuracy: 18.75\n",
      "[1,    59] loss: 2.39992, train_accuracy: 21.09\n",
      "[1,    60] loss: 2.56014, train_accuracy: 20.31\n",
      "[1,    61] loss: 2.62720, train_accuracy: 22.66\n",
      "[1,    62] loss: 2.25477, train_accuracy: 27.34\n",
      "[1,    63] loss: 2.32885, train_accuracy: 21.88\n",
      "[1,    64] loss: 2.45833, train_accuracy: 22.66\n",
      "[1,    65] loss: 2.21757, train_accuracy: 20.31\n",
      "[1,    66] loss: 1.97584, train_accuracy: 27.34\n",
      "[1,    67] loss: 2.21967, train_accuracy: 25.00\n",
      "[1,    68] loss: 2.08481, train_accuracy: 28.12\n",
      "[1,    69] loss: 2.14357, train_accuracy: 23.44\n",
      "[1,    70] loss: 2.21071, train_accuracy: 28.12\n",
      "[1,    71] loss: 2.07436, train_accuracy: 27.34\n",
      "[1,    72] loss: 2.00829, train_accuracy: 27.34\n",
      "[1,    73] loss: 2.17954, train_accuracy: 30.47\n",
      "[1,    74] loss: 1.99601, train_accuracy: 24.22\n",
      "[1,    75] loss: 2.36206, train_accuracy: 21.09\n",
      "[1,    76] loss: 2.17771, train_accuracy: 21.09\n",
      "[1,    77] loss: 2.05816, train_accuracy: 23.44\n",
      "[1,    78] loss: 2.79102, train_accuracy: 17.97\n",
      "[1,    79] loss: 2.17723, train_accuracy: 27.34\n",
      "[1,    80] loss: 2.59465, train_accuracy: 31.25\n",
      "[1,    81] loss: 2.44315, train_accuracy: 30.47\n",
      "[1,    82] loss: 3.33401, train_accuracy: 25.00\n",
      "[1,    83] loss: 2.01191, train_accuracy: 32.03\n",
      "[1,    84] loss: 2.27470, train_accuracy: 28.91\n",
      "[1,    85] loss: 2.44444, train_accuracy: 29.69\n",
      "[1,    86] loss: 2.57375, train_accuracy: 28.91\n",
      "[1,    87] loss: 2.65307, train_accuracy: 26.56\n",
      "[1,    88] loss: 2.32539, train_accuracy: 21.09\n",
      "[1,    89] loss: 2.44292, train_accuracy: 32.81\n",
      "[1,    90] loss: 2.13320, train_accuracy: 24.22\n",
      "[1,    91] loss: 2.29931, train_accuracy: 21.09\n",
      "[1,    92] loss: 2.02327, train_accuracy: 26.56\n",
      "[1,    93] loss: 2.18000, train_accuracy: 28.91\n",
      "[1,    94] loss: 2.12854, train_accuracy: 25.78\n",
      "[1,    95] loss: 2.45435, train_accuracy: 39.84\n",
      "[1,    96] loss: 1.96799, train_accuracy: 23.44\n",
      "[1,    97] loss: 2.16390, train_accuracy: 32.03\n",
      "[1,    98] loss: 2.33173, train_accuracy: 34.38\n",
      "[1,    99] loss: 2.25772, train_accuracy: 22.66\n",
      "[1,   100] loss: 2.71952, train_accuracy: 25.00\n",
      "[1,   101] loss: 2.15841, train_accuracy: 39.84\n",
      "[1,   102] loss: 2.41625, train_accuracy: 27.34\n",
      "[1,   103] loss: 2.22129, train_accuracy: 30.47\n",
      "[1,   104] loss: 2.60705, train_accuracy: 25.00\n",
      "[1,   105] loss: 2.39464, train_accuracy: 19.53\n",
      "[1,   106] loss: 1.90915, train_accuracy: 25.78\n",
      "[1,   107] loss: 2.32323, train_accuracy: 28.12\n",
      "[1,   108] loss: 2.02530, train_accuracy: 20.31\n",
      "[1,   109] loss: 2.21217, train_accuracy: 28.91\n",
      "[1,   110] loss: 2.14548, train_accuracy: 25.78\n",
      "[1,   111] loss: 2.11111, train_accuracy: 18.75\n",
      "[1,   112] loss: 2.10541, train_accuracy: 27.34\n",
      "[1,   113] loss: 2.71210, train_accuracy: 26.56\n",
      "[1,   114] loss: 2.19021, train_accuracy: 22.66\n",
      "[1,   115] loss: 2.00886, train_accuracy: 22.66\n",
      "[1,   116] loss: 2.88280, train_accuracy: 28.12\n",
      "[1,   117] loss: 2.20969, train_accuracy: 26.56\n",
      "[1,   118] loss: 2.24392, train_accuracy: 32.81\n",
      "[1,   119] loss: 2.26864, train_accuracy: 27.34\n",
      "[1,   120] loss: 1.87320, train_accuracy: 33.59\n",
      "[1,   121] loss: 1.97355, train_accuracy: 21.88\n",
      "[1,   122] loss: 1.91280, train_accuracy: 25.78\n",
      "[1,   123] loss: 1.92823, train_accuracy: 32.81\n",
      "[1,   124] loss: 1.82627, train_accuracy: 32.81\n",
      "[1,   125] loss: 1.85967, train_accuracy: 32.03\n",
      "[1,   126] loss: 1.73675, train_accuracy: 30.47\n",
      "[1,   127] loss: 2.05103, train_accuracy: 23.44\n",
      "[1,   128] loss: 1.92761, train_accuracy: 22.66\n",
      "[1,   129] loss: 1.91292, train_accuracy: 35.16\n",
      "[1,   130] loss: 1.92498, train_accuracy: 25.78\n",
      "[1,   131] loss: 1.98945, train_accuracy: 25.78\n",
      "[1,   132] loss: 1.87912, train_accuracy: 29.69\n",
      "[1,   133] loss: 1.82058, train_accuracy: 32.03\n",
      "[1,   134] loss: 1.73847, train_accuracy: 38.28\n",
      "[1,   135] loss: 1.77018, train_accuracy: 30.47\n",
      "[1,   136] loss: 1.97460, train_accuracy: 28.12\n",
      "[1,   137] loss: 2.09370, train_accuracy: 29.69\n",
      "[1,   138] loss: 1.96970, train_accuracy: 29.69\n",
      "[1,   139] loss: 1.84211, train_accuracy: 34.38\n",
      "[1,   140] loss: 1.95637, train_accuracy: 31.25\n",
      "[1,   141] loss: 1.71669, train_accuracy: 40.62\n",
      "[1,   142] loss: 2.05841, train_accuracy: 27.34\n",
      "[1,   143] loss: 1.78928, train_accuracy: 43.75\n",
      "[1,   144] loss: 2.17450, train_accuracy: 32.81\n",
      "[1,   145] loss: 1.83093, train_accuracy: 39.84\n",
      "[1,   146] loss: 1.83366, train_accuracy: 31.25\n",
      "[1,   147] loss: 1.92331, train_accuracy: 30.47\n",
      "[1,   148] loss: 1.94147, train_accuracy: 33.59\n",
      "[1,   149] loss: 1.63165, train_accuracy: 32.03\n",
      "[1,   150] loss: 1.87345, train_accuracy: 37.50\n",
      "[1,   151] loss: 2.11843, train_accuracy: 39.06\n",
      "[1,   152] loss: 1.80054, train_accuracy: 33.59\n",
      "[1,   153] loss: 1.89790, train_accuracy: 24.22\n",
      "[1,   154] loss: 1.69380, train_accuracy: 37.50\n",
      "[1,   155] loss: 1.82472, train_accuracy: 35.16\n",
      "[1,   156] loss: 1.91761, train_accuracy: 37.50\n",
      "[1,   157] loss: 1.80984, train_accuracy: 30.47\n",
      "[1,   158] loss: 2.00412, train_accuracy: 25.78\n",
      "[1,   159] loss: 1.86225, train_accuracy: 35.16\n",
      "[1,   160] loss: 1.73031, train_accuracy: 38.28\n",
      "[1,   161] loss: 1.61884, train_accuracy: 35.16\n",
      "[1,   162] loss: 1.63887, train_accuracy: 36.72\n",
      "[1,   163] loss: 1.94127, train_accuracy: 36.72\n",
      "[1,   164] loss: 1.75384, train_accuracy: 32.81\n",
      "[1,   165] loss: 1.65064, train_accuracy: 34.38\n",
      "[1,   166] loss: 2.45041, train_accuracy: 23.44\n",
      "[1,   167] loss: 1.60910, train_accuracy: 36.72\n",
      "[1,   168] loss: 1.78948, train_accuracy: 34.38\n",
      "[1,   169] loss: 1.93713, train_accuracy: 25.78\n",
      "[1,   170] loss: 2.02882, train_accuracy: 28.91\n",
      "[1,   171] loss: 1.76030, train_accuracy: 32.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   172] loss: 1.87000, train_accuracy: 32.81\n",
      "[1,   173] loss: 1.69370, train_accuracy: 39.84\n",
      "[1,   174] loss: 1.79453, train_accuracy: 30.47\n",
      "[1,   175] loss: 1.94114, train_accuracy: 28.91\n",
      "[1,   176] loss: 1.84333, train_accuracy: 29.69\n",
      "[1,   177] loss: 1.81316, train_accuracy: 35.16\n",
      "[1,   178] loss: 1.79244, train_accuracy: 33.59\n",
      "[1,   179] loss: 1.49503, train_accuracy: 42.97\n",
      "[1,   180] loss: 1.56331, train_accuracy: 40.62\n",
      "[1,   181] loss: 1.77229, train_accuracy: 37.50\n",
      "[1,   182] loss: 1.62251, train_accuracy: 39.06\n",
      "[1,   183] loss: 2.12049, train_accuracy: 35.16\n",
      "[1,   184] loss: 1.52983, train_accuracy: 45.31\n",
      "[1,   185] loss: 1.85622, train_accuracy: 29.69\n",
      "[1,   186] loss: 1.75090, train_accuracy: 34.38\n",
      "[1,   187] loss: 1.84776, train_accuracy: 32.81\n",
      "[1,   188] loss: 1.88282, train_accuracy: 33.59\n",
      "[1,   189] loss: 1.53692, train_accuracy: 42.19\n",
      "[1,   190] loss: 1.66074, train_accuracy: 42.97\n",
      "[1,   191] loss: 1.71650, train_accuracy: 34.38\n",
      "[1,   192] loss: 1.90489, train_accuracy: 33.59\n",
      "[1,   193] loss: 1.77011, train_accuracy: 35.94\n",
      "[1,   194] loss: 1.57465, train_accuracy: 39.84\n",
      "[1,   195] loss: 1.66190, train_accuracy: 33.59\n",
      "[1,   196] loss: 1.78331, train_accuracy: 39.84\n",
      "[1,   197] loss: 1.79719, train_accuracy: 34.38\n",
      "[1,   198] loss: 1.53856, train_accuracy: 41.41\n",
      "[1,   199] loss: 1.61393, train_accuracy: 40.62\n",
      "[1,   200] loss: 1.65206, train_accuracy: 39.84\n",
      "[1,   201] loss: 1.68508, train_accuracy: 39.84\n",
      "[1,   202] loss: 1.91097, train_accuracy: 32.03\n",
      "[1,   203] loss: 1.74235, train_accuracy: 47.66\n",
      "[1,   204] loss: 1.90331, train_accuracy: 32.03\n",
      "[1,   205] loss: 1.62642, train_accuracy: 36.72\n",
      "[1,   206] loss: 1.85264, train_accuracy: 35.94\n",
      "[1,   207] loss: 1.85042, train_accuracy: 36.72\n",
      "[1,   208] loss: 1.65620, train_accuracy: 39.06\n",
      "[1,   209] loss: 1.52838, train_accuracy: 41.41\n",
      "[1,   210] loss: 1.74875, train_accuracy: 42.97\n",
      "[1,   211] loss: 1.74032, train_accuracy: 35.16\n",
      "[1,   212] loss: 1.86060, train_accuracy: 34.38\n",
      "[1,   213] loss: 1.74004, train_accuracy: 34.38\n",
      "[1,   214] loss: 1.63515, train_accuracy: 45.31\n",
      "[1,   215] loss: 1.86714, train_accuracy: 32.81\n",
      "[1,   216] loss: 1.77411, train_accuracy: 34.38\n",
      "[1,   217] loss: 1.96924, train_accuracy: 32.81\n",
      "[1,   218] loss: 1.73266, train_accuracy: 41.41\n",
      "[1,   219] loss: 1.69015, train_accuracy: 44.53\n",
      "[1,   220] loss: 2.00189, train_accuracy: 28.91\n",
      "[1,   221] loss: 1.58994, train_accuracy: 43.75\n",
      "[1,   222] loss: 1.86273, train_accuracy: 35.94\n",
      "[1,   223] loss: 1.81558, train_accuracy: 36.72\n",
      "[1,   224] loss: 2.03158, train_accuracy: 40.62\n",
      "[1,   225] loss: 1.73190, train_accuracy: 32.81\n",
      "[1,   226] loss: 1.86462, train_accuracy: 35.94\n",
      "[1,   227] loss: 1.67037, train_accuracy: 35.94\n",
      "[1,   228] loss: 2.12523, train_accuracy: 27.34\n",
      "[1,   229] loss: 1.81042, train_accuracy: 39.06\n",
      "[1,   230] loss: 1.66622, train_accuracy: 39.06\n",
      "[1,   231] loss: 1.80205, train_accuracy: 38.28\n",
      "[1,   232] loss: 1.62383, train_accuracy: 40.62\n",
      "[1,   233] loss: 1.81445, train_accuracy: 37.50\n",
      "[1,   234] loss: 1.93744, train_accuracy: 33.59\n",
      "[1,   235] loss: 1.83284, train_accuracy: 27.34\n",
      "[1,   236] loss: 1.80628, train_accuracy: 35.94\n",
      "[1,   237] loss: 1.82720, train_accuracy: 42.19\n",
      "[1,   238] loss: 1.50854, train_accuracy: 43.75\n",
      "[1,   239] loss: 1.68632, train_accuracy: 40.62\n",
      "[1,   240] loss: 1.77980, train_accuracy: 39.06\n",
      "[1,   241] loss: 1.75289, train_accuracy: 32.81\n",
      "[1,   242] loss: 1.70805, train_accuracy: 34.38\n",
      "[1,   243] loss: 1.71466, train_accuracy: 35.16\n",
      "[1,   244] loss: 1.90564, train_accuracy: 34.38\n",
      "[1,   245] loss: 1.88392, train_accuracy: 32.81\n",
      "[1,   246] loss: 1.77926, train_accuracy: 31.25\n",
      "[1,   247] loss: 2.32371, train_accuracy: 28.91\n",
      "[1,   248] loss: 1.75089, train_accuracy: 41.41\n",
      "[1,   249] loss: 1.70412, train_accuracy: 35.94\n",
      "[1,   250] loss: 1.68799, train_accuracy: 43.75\n",
      "[1,   251] loss: 1.64390, train_accuracy: 38.28\n",
      "[1,   252] loss: 1.62211, train_accuracy: 35.94\n",
      "[1,   253] loss: 1.78479, train_accuracy: 32.03\n",
      "[1,   254] loss: 1.66014, train_accuracy: 37.50\n",
      "[1,   255] loss: 2.51242, train_accuracy: 28.91\n",
      "[1,   256] loss: 1.60465, train_accuracy: 39.84\n",
      "[1,   257] loss: 2.06279, train_accuracy: 28.91\n",
      "[1,   258] loss: 1.80497, train_accuracy: 45.31\n",
      "[1,   259] loss: 1.68927, train_accuracy: 35.94\n",
      "[1,   260] loss: 1.70424, train_accuracy: 38.28\n",
      "[1,   261] loss: 1.68660, train_accuracy: 41.41\n",
      "[1,   262] loss: 1.59733, train_accuracy: 38.28\n",
      "[1,   263] loss: 1.49927, train_accuracy: 37.50\n",
      "[1,   264] loss: 1.61486, train_accuracy: 44.53\n",
      "[1,   265] loss: 1.75341, train_accuracy: 47.66\n",
      "[1,   266] loss: 1.68540, train_accuracy: 40.62\n",
      "[1,   267] loss: 1.44102, train_accuracy: 48.44\n",
      "[1,   268] loss: 2.02694, train_accuracy: 36.72\n",
      "[1,   269] loss: 1.65201, train_accuracy: 44.53\n",
      "[1,   270] loss: 1.75962, train_accuracy: 45.31\n",
      "[1,   271] loss: 1.71867, train_accuracy: 36.72\n",
      "[1,   272] loss: 1.92507, train_accuracy: 33.59\n",
      "[1,   273] loss: 1.74827, train_accuracy: 46.09\n",
      "[1,   274] loss: 1.69993, train_accuracy: 40.62\n",
      "[1,   275] loss: 1.57668, train_accuracy: 43.75\n",
      "[1,   276] loss: 1.77866, train_accuracy: 46.09\n",
      "[1,   277] loss: 1.70899, train_accuracy: 42.97\n",
      "[1,   278] loss: 1.69150, train_accuracy: 39.84\n",
      "[1,   279] loss: 1.69962, train_accuracy: 43.75\n",
      "[1,   280] loss: 1.66010, train_accuracy: 41.41\n",
      "[1,   281] loss: 1.57288, train_accuracy: 42.97\n",
      "[1,   282] loss: 1.42349, train_accuracy: 51.56\n",
      "[1,   283] loss: 1.77374, train_accuracy: 39.84\n",
      "[1,   284] loss: 1.48005, train_accuracy: 42.97\n",
      "[1,   285] loss: 1.57865, train_accuracy: 43.75\n",
      "[1,   286] loss: 1.79693, train_accuracy: 41.41\n",
      "[1,   287] loss: 1.55482, train_accuracy: 46.09\n",
      "[1,   288] loss: 1.71918, train_accuracy: 45.31\n",
      "[1,   289] loss: 1.59756, train_accuracy: 35.16\n",
      "[1,   290] loss: 1.61553, train_accuracy: 46.88\n",
      "[1,   291] loss: 1.65074, train_accuracy: 42.97\n",
      "[1,   292] loss: 1.74505, train_accuracy: 39.84\n",
      "[1,   293] loss: 1.58798, train_accuracy: 47.66\n",
      "[1,   294] loss: 1.47453, train_accuracy: 44.53\n",
      "[1,   295] loss: 1.56288, train_accuracy: 49.22\n",
      "[1,   296] loss: 1.57787, train_accuracy: 43.75\n",
      "[1,   297] loss: 1.75187, train_accuracy: 46.09\n",
      "[1,   298] loss: 1.42399, train_accuracy: 44.53\n",
      "[1,   299] loss: 1.60141, train_accuracy: 39.06\n",
      "[1,   300] loss: 1.53985, train_accuracy: 45.31\n",
      "[1,   301] loss: 1.53675, train_accuracy: 50.78\n",
      "[1,   302] loss: 1.58761, train_accuracy: 45.31\n",
      "[1,   303] loss: 1.59317, train_accuracy: 40.62\n",
      "[1,   304] loss: 1.60594, train_accuracy: 44.53\n",
      "[1,   305] loss: 1.68916, train_accuracy: 38.28\n",
      "[1,   306] loss: 1.95250, train_accuracy: 35.94\n",
      "[1,   307] loss: 1.61689, train_accuracy: 43.75\n",
      "[1,   308] loss: 2.06131, train_accuracy: 33.59\n",
      "[1,   309] loss: 1.62351, train_accuracy: 46.88\n",
      "[1,   310] loss: 2.06022, train_accuracy: 36.72\n",
      "[1,   311] loss: 1.75888, train_accuracy: 32.81\n",
      "[1,   312] loss: 1.94834, train_accuracy: 28.91\n",
      "[1,   313] loss: 1.94603, train_accuracy: 35.16\n",
      "[1,   314] loss: 2.01099, train_accuracy: 33.59\n",
      "[1,   315] loss: 1.67557, train_accuracy: 44.53\n",
      "[1,   316] loss: 1.72802, train_accuracy: 39.06\n",
      "[1,   317] loss: 1.90480, train_accuracy: 34.38\n",
      "[1,   318] loss: 1.58902, train_accuracy: 39.06\n",
      "[1,   319] loss: 1.49982, train_accuracy: 41.41\n",
      "[1,   320] loss: 1.62768, train_accuracy: 37.50\n",
      "[1,   321] loss: 1.75117, train_accuracy: 34.38\n",
      "[1,   322] loss: 1.85043, train_accuracy: 39.84\n",
      "[1,   323] loss: 1.68939, train_accuracy: 42.19\n",
      "[1,   324] loss: 1.57216, train_accuracy: 39.06\n",
      "[1,   325] loss: 1.68086, train_accuracy: 42.19\n",
      "[1,   326] loss: 1.51147, train_accuracy: 44.53\n",
      "[1,   327] loss: 1.87395, train_accuracy: 37.50\n",
      "[1,   328] loss: 1.50077, train_accuracy: 48.44\n",
      "[1,   329] loss: 1.66953, train_accuracy: 40.62\n",
      "[1,   330] loss: 1.59906, train_accuracy: 42.97\n",
      "[1,   331] loss: 1.55376, train_accuracy: 47.66\n",
      "[1,   332] loss: 1.69004, train_accuracy: 36.72\n",
      "[1,   333] loss: 1.82578, train_accuracy: 42.19\n",
      "[1,   334] loss: 1.44506, train_accuracy: 46.88\n",
      "[1,   335] loss: 1.41466, train_accuracy: 46.88\n",
      "[1,   336] loss: 1.81528, train_accuracy: 39.06\n",
      "[1,   337] loss: 1.40802, train_accuracy: 46.88\n",
      "[1,   338] loss: 1.72323, train_accuracy: 41.41\n",
      "[1,   339] loss: 1.96215, train_accuracy: 41.41\n",
      "[1,   340] loss: 1.66033, train_accuracy: 33.59\n",
      "[1,   341] loss: 1.67432, train_accuracy: 39.84\n",
      "[1,   342] loss: 1.61017, train_accuracy: 36.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   343] loss: 1.39060, train_accuracy: 50.00\n",
      "[1,   344] loss: 1.48784, train_accuracy: 44.53\n",
      "[1,   345] loss: 1.52151, train_accuracy: 47.66\n",
      "[1,   346] loss: 1.54286, train_accuracy: 42.19\n",
      "[1,   347] loss: 1.61188, train_accuracy: 36.72\n",
      "[1,   348] loss: 2.10970, train_accuracy: 36.72\n",
      "[1,   349] loss: 1.57273, train_accuracy: 47.66\n",
      "[1,   350] loss: 2.04256, train_accuracy: 34.38\n",
      "[1,   351] loss: 1.81987, train_accuracy: 29.69\n",
      "[1,   352] loss: 1.75799, train_accuracy: 39.84\n",
      "[1,   353] loss: 1.57756, train_accuracy: 38.28\n",
      "[1,   354] loss: 1.77935, train_accuracy: 35.94\n",
      "[1,   355] loss: 1.68459, train_accuracy: 44.53\n",
      "[1,   356] loss: 1.68506, train_accuracy: 38.28\n",
      "[1,   357] loss: 1.53355, train_accuracy: 46.88\n",
      "[1,   358] loss: 1.80312, train_accuracy: 39.06\n",
      "[1,   359] loss: 1.86189, train_accuracy: 37.50\n",
      "[1,   360] loss: 1.58711, train_accuracy: 42.19\n",
      "[1,   361] loss: 1.62852, train_accuracy: 40.62\n",
      "[1,   362] loss: 1.92040, train_accuracy: 38.28\n",
      "[1,   363] loss: 1.71332, train_accuracy: 41.41\n",
      "[1,   364] loss: 1.67481, train_accuracy: 35.94\n",
      "[1,   365] loss: 1.47830, train_accuracy: 39.06\n",
      "[1,   366] loss: 1.56779, train_accuracy: 43.75\n",
      "[1,   367] loss: 1.51556, train_accuracy: 44.53\n",
      "[1,   368] loss: 1.50166, train_accuracy: 42.19\n",
      "[1,   369] loss: 1.56130, train_accuracy: 38.28\n",
      "[1,   370] loss: 1.73284, train_accuracy: 42.19\n",
      "[1,   371] loss: 1.76766, train_accuracy: 33.59\n",
      "[1,   372] loss: 1.60328, train_accuracy: 42.19\n",
      "[1,   373] loss: 1.63823, train_accuracy: 43.75\n",
      "[1,   374] loss: 1.64588, train_accuracy: 40.62\n",
      "[1,   375] loss: 1.40069, train_accuracy: 50.78\n",
      "[1,   376] loss: 1.70995, train_accuracy: 36.72\n",
      "[1,   377] loss: 1.53234, train_accuracy: 46.88\n",
      "[1,   378] loss: 1.60841, train_accuracy: 45.31\n",
      "[1,   379] loss: 1.35169, train_accuracy: 54.69\n",
      "[1,   380] loss: 1.44480, train_accuracy: 48.44\n",
      "[1,   381] loss: 1.64690, train_accuracy: 41.41\n",
      "[1,   382] loss: 1.54090, train_accuracy: 44.53\n",
      "[1,   383] loss: 1.56848, train_accuracy: 46.09\n",
      "[1,   384] loss: 1.51484, train_accuracy: 47.66\n",
      "[1,   385] loss: 1.37128, train_accuracy: 54.69\n",
      "[1,   386] loss: 1.67373, train_accuracy: 42.19\n",
      "[1,   387] loss: 1.64100, train_accuracy: 43.75\n",
      "[1,   388] loss: 1.79408, train_accuracy: 46.09\n",
      "[1,   389] loss: 1.57683, train_accuracy: 45.31\n",
      "[1,   390] loss: 1.65315, train_accuracy: 41.41\n",
      "[1,   391] loss: 1.46322, train_accuracy: 48.75\n",
      "duration: 142 s - train loss: 2.49616 - train accuracy: 33.35 - validation loss: 1.56 - validation accuracy: 44.33 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs_trained': 0,\n",
       " 'avg_time_per_epoch': 142.11310338974,\n",
       " 'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'hist': {'train_loss': [2.4961614459371932],\n",
       "  'train_accuracy': [33.35078324808184],\n",
       "  'validation_loss': [1.5624872204623645],\n",
       "  'validation_accuracy': [44.33]},\n",
       " 'val_accuracy': 44.33}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CifarResNet().to(device)\n",
    "model.fit(train_loader, test_loader, 1, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Jitter only - 139 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "[1,     1] loss: 2.72934, train_accuracy: 10.16\n",
      "[1,     2] loss: 32.79873, train_accuracy: 10.16\n",
      "[1,     3] loss: 35.51935, train_accuracy: 16.41\n",
      "[1,     4] loss: 31.12176, train_accuracy: 14.84\n",
      "[1,     5] loss: 27.37873, train_accuracy: 10.16\n",
      "[1,     6] loss: 18.06026, train_accuracy: 13.28\n",
      "[1,     7] loss: 18.00992, train_accuracy: 4.69\n",
      "[1,     8] loss: 23.75197, train_accuracy: 14.06\n",
      "[1,     9] loss: 9.95253, train_accuracy: 7.03\n",
      "[1,    10] loss: 11.40526, train_accuracy: 15.62\n",
      "[1,    11] loss: 9.17352, train_accuracy: 11.72\n",
      "[1,    12] loss: 8.48862, train_accuracy: 13.28\n",
      "[1,    13] loss: 9.06450, train_accuracy: 19.53\n",
      "[1,    14] loss: 13.53641, train_accuracy: 12.50\n",
      "[1,    15] loss: 7.33773, train_accuracy: 14.06\n",
      "[1,    16] loss: 9.71513, train_accuracy: 9.38\n",
      "[1,    17] loss: 5.32476, train_accuracy: 10.94\n",
      "[1,    18] loss: 8.41257, train_accuracy: 9.38\n",
      "[1,    19] loss: 6.59242, train_accuracy: 10.16\n",
      "[1,    20] loss: 7.11621, train_accuracy: 11.72\n",
      "[1,    21] loss: 8.25448, train_accuracy: 11.72\n",
      "[1,    22] loss: 4.13783, train_accuracy: 17.97\n",
      "[1,    23] loss: 4.73735, train_accuracy: 10.16\n",
      "[1,    24] loss: 4.31715, train_accuracy: 15.62\n",
      "[1,    25] loss: 3.54441, train_accuracy: 17.97\n",
      "[1,    26] loss: 3.53787, train_accuracy: 17.97\n",
      "[1,    27] loss: 3.95668, train_accuracy: 14.84\n",
      "[1,    28] loss: 3.49802, train_accuracy: 21.88\n",
      "[1,    29] loss: 3.95023, train_accuracy: 10.16\n",
      "[1,    30] loss: 2.96231, train_accuracy: 21.09\n",
      "[1,    31] loss: 5.72173, train_accuracy: 12.50\n",
      "[1,    32] loss: 3.66913, train_accuracy: 14.06\n",
      "[1,    33] loss: 4.70996, train_accuracy: 14.84\n",
      "[1,    34] loss: 4.17833, train_accuracy: 11.72\n",
      "[1,    35] loss: 3.49982, train_accuracy: 14.84\n",
      "[1,    36] loss: 4.19981, train_accuracy: 15.62\n",
      "[1,    37] loss: 5.39870, train_accuracy: 17.19\n",
      "[1,    38] loss: 4.04471, train_accuracy: 23.44\n",
      "[1,    39] loss: 5.88341, train_accuracy: 14.06\n",
      "[1,    40] loss: 2.90820, train_accuracy: 22.66\n",
      "[1,    41] loss: 3.19660, train_accuracy: 29.69\n",
      "[1,    42] loss: 3.31327, train_accuracy: 24.22\n",
      "[1,    43] loss: 3.53379, train_accuracy: 24.22\n",
      "[1,    44] loss: 3.62996, train_accuracy: 25.00\n",
      "[1,    45] loss: 3.77340, train_accuracy: 24.22\n",
      "[1,    46] loss: 3.93099, train_accuracy: 14.84\n",
      "[1,    47] loss: 2.93771, train_accuracy: 21.09\n",
      "[1,    48] loss: 2.92075, train_accuracy: 17.19\n",
      "[1,    49] loss: 3.18392, train_accuracy: 23.44\n",
      "[1,    50] loss: 2.50785, train_accuracy: 28.91\n",
      "[1,    51] loss: 2.84150, train_accuracy: 14.84\n",
      "[1,    52] loss: 4.58304, train_accuracy: 12.50\n",
      "[1,    53] loss: 2.21505, train_accuracy: 23.44\n",
      "[1,    54] loss: 2.40187, train_accuracy: 17.97\n",
      "[1,    55] loss: 2.49292, train_accuracy: 19.53\n",
      "[1,    56] loss: 2.53009, train_accuracy: 16.41\n",
      "[1,    57] loss: 2.45730, train_accuracy: 24.22\n",
      "[1,    58] loss: 2.19255, train_accuracy: 26.56\n",
      "[1,    59] loss: 2.76195, train_accuracy: 19.53\n",
      "[1,    60] loss: 2.58508, train_accuracy: 28.12\n",
      "[1,    61] loss: 2.59409, train_accuracy: 23.44\n",
      "[1,    62] loss: 2.08364, train_accuracy: 20.31\n",
      "[1,    63] loss: 2.29738, train_accuracy: 28.12\n",
      "[1,    64] loss: 3.05985, train_accuracy: 28.91\n",
      "[1,    65] loss: 2.33526, train_accuracy: 24.22\n",
      "[1,    66] loss: 2.27192, train_accuracy: 29.69\n",
      "[1,    67] loss: 2.17411, train_accuracy: 26.56\n",
      "[1,    68] loss: 2.36333, train_accuracy: 29.69\n",
      "[1,    69] loss: 2.51865, train_accuracy: 22.66\n",
      "[1,    70] loss: 2.26648, train_accuracy: 22.66\n",
      "[1,    71] loss: 2.59847, train_accuracy: 13.28\n",
      "[1,    72] loss: 2.17796, train_accuracy: 20.31\n",
      "[1,    73] loss: 2.49586, train_accuracy: 14.84\n",
      "[1,    74] loss: 2.08245, train_accuracy: 22.66\n",
      "[1,    75] loss: 3.28331, train_accuracy: 28.91\n",
      "[1,    76] loss: 2.20732, train_accuracy: 22.66\n",
      "[1,    77] loss: 2.02275, train_accuracy: 25.78\n",
      "[1,    78] loss: 2.00879, train_accuracy: 27.34\n",
      "[1,    79] loss: 2.03666, train_accuracy: 32.03\n",
      "[1,    80] loss: 3.32377, train_accuracy: 21.88\n",
      "[1,    81] loss: 2.29431, train_accuracy: 20.31\n",
      "[1,    82] loss: 2.40312, train_accuracy: 25.00\n",
      "[1,    83] loss: 2.87463, train_accuracy: 26.56\n",
      "[1,    84] loss: 2.85147, train_accuracy: 18.75\n",
      "[1,    85] loss: 2.22037, train_accuracy: 20.31\n",
      "[1,    86] loss: 3.00535, train_accuracy: 24.22\n",
      "[1,    87] loss: 3.55112, train_accuracy: 25.00\n",
      "[1,    88] loss: 2.54103, train_accuracy: 17.97\n",
      "[1,    89] loss: 2.58562, train_accuracy: 28.12\n",
      "[1,    90] loss: 2.48002, train_accuracy: 22.66\n",
      "[1,    91] loss: 2.44138, train_accuracy: 27.34\n",
      "[1,    92] loss: 2.59171, train_accuracy: 24.22\n",
      "[1,    93] loss: 2.67831, train_accuracy: 30.47\n",
      "[1,    94] loss: 2.85600, train_accuracy: 25.00\n",
      "[1,    95] loss: 2.47232, train_accuracy: 25.78\n",
      "[1,    96] loss: 3.17994, train_accuracy: 18.75\n",
      "[1,    97] loss: 2.54257, train_accuracy: 25.00\n",
      "[1,    98] loss: 2.69504, train_accuracy: 21.09\n",
      "[1,    99] loss: 2.47417, train_accuracy: 21.88\n",
      "[1,   100] loss: 2.70222, train_accuracy: 33.59\n",
      "[1,   101] loss: 2.73522, train_accuracy: 23.44\n",
      "[1,   102] loss: 2.82014, train_accuracy: 21.09\n",
      "[1,   103] loss: 2.60606, train_accuracy: 16.41\n",
      "[1,   104] loss: 2.06982, train_accuracy: 25.78\n",
      "[1,   105] loss: 2.29667, train_accuracy: 23.44\n",
      "[1,   106] loss: 1.92221, train_accuracy: 33.59\n",
      "[1,   107] loss: 2.25996, train_accuracy: 27.34\n",
      "[1,   108] loss: 2.29832, train_accuracy: 35.16\n",
      "[1,   109] loss: 2.79363, train_accuracy: 25.00\n",
      "[1,   110] loss: 2.58418, train_accuracy: 20.31\n",
      "[1,   111] loss: 2.32872, train_accuracy: 31.25\n",
      "[1,   112] loss: 2.19709, train_accuracy: 24.22\n",
      "[1,   113] loss: 2.07003, train_accuracy: 25.78\n",
      "[1,   114] loss: 1.94770, train_accuracy: 27.34\n",
      "[1,   115] loss: 2.30291, train_accuracy: 16.41\n",
      "[1,   116] loss: 2.40951, train_accuracy: 24.22\n",
      "[1,   117] loss: 2.19647, train_accuracy: 24.22\n",
      "[1,   118] loss: 2.39097, train_accuracy: 24.22\n",
      "[1,   119] loss: 2.04295, train_accuracy: 28.12\n",
      "[1,   120] loss: 2.16995, train_accuracy: 25.78\n",
      "[1,   121] loss: 1.89337, train_accuracy: 25.78\n",
      "[1,   122] loss: 2.04738, train_accuracy: 29.69\n",
      "[1,   123] loss: 2.02677, train_accuracy: 21.09\n",
      "[1,   124] loss: 2.22485, train_accuracy: 30.47\n",
      "[1,   125] loss: 2.18189, train_accuracy: 25.78\n",
      "[1,   126] loss: 1.81170, train_accuracy: 32.81\n",
      "[1,   127] loss: 1.95839, train_accuracy: 39.06\n",
      "[1,   128] loss: 2.09739, train_accuracy: 32.03\n",
      "[1,   129] loss: 1.79983, train_accuracy: 28.91\n",
      "[1,   130] loss: 1.96786, train_accuracy: 35.94\n",
      "[1,   131] loss: 2.03823, train_accuracy: 38.28\n",
      "[1,   132] loss: 2.46947, train_accuracy: 26.56\n",
      "[1,   133] loss: 2.48542, train_accuracy: 27.34\n",
      "[1,   134] loss: 2.45960, train_accuracy: 34.38\n",
      "[1,   135] loss: 2.21116, train_accuracy: 24.22\n",
      "[1,   136] loss: 1.93394, train_accuracy: 31.25\n",
      "[1,   137] loss: 2.19007, train_accuracy: 26.56\n",
      "[1,   138] loss: 1.67918, train_accuracy: 34.38\n",
      "[1,   139] loss: 1.72698, train_accuracy: 35.94\n",
      "[1,   140] loss: 2.09458, train_accuracy: 30.47\n",
      "[1,   141] loss: 2.00429, train_accuracy: 30.47\n",
      "[1,   142] loss: 1.90429, train_accuracy: 32.81\n",
      "[1,   143] loss: 1.95208, train_accuracy: 34.38\n",
      "[1,   144] loss: 1.98620, train_accuracy: 31.25\n",
      "[1,   145] loss: 1.84240, train_accuracy: 29.69\n",
      "[1,   146] loss: 1.87001, train_accuracy: 25.78\n",
      "[1,   147] loss: 2.07318, train_accuracy: 25.78\n",
      "[1,   148] loss: 1.73498, train_accuracy: 32.81\n",
      "[1,   149] loss: 1.80750, train_accuracy: 32.81\n",
      "[1,   150] loss: 1.88626, train_accuracy: 30.47\n",
      "[1,   151] loss: 1.95778, train_accuracy: 32.81\n",
      "[1,   152] loss: 1.85468, train_accuracy: 30.47\n",
      "[1,   153] loss: 2.11838, train_accuracy: 24.22\n",
      "[1,   154] loss: 1.75463, train_accuracy: 34.38\n",
      "[1,   155] loss: 1.93373, train_accuracy: 25.78\n",
      "[1,   156] loss: 1.81910, train_accuracy: 33.59\n",
      "[1,   157] loss: 1.76786, train_accuracy: 33.59\n",
      "[1,   158] loss: 2.07340, train_accuracy: 32.03\n",
      "[1,   159] loss: 2.31961, train_accuracy: 29.69\n",
      "[1,   160] loss: 1.90276, train_accuracy: 29.69\n",
      "[1,   161] loss: 1.69187, train_accuracy: 34.38\n",
      "[1,   162] loss: 1.90313, train_accuracy: 36.72\n",
      "[1,   163] loss: 1.81186, train_accuracy: 32.81\n",
      "[1,   164] loss: 1.89413, train_accuracy: 28.91\n",
      "[1,   165] loss: 1.88317, train_accuracy: 27.34\n",
      "[1,   166] loss: 1.91344, train_accuracy: 34.38\n",
      "[1,   167] loss: 2.06536, train_accuracy: 33.59\n",
      "[1,   168] loss: 1.68183, train_accuracy: 32.03\n",
      "[1,   169] loss: 1.94789, train_accuracy: 31.25\n",
      "[1,   170] loss: 1.74674, train_accuracy: 35.16\n",
      "[1,   171] loss: 2.08259, train_accuracy: 35.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   172] loss: 1.70902, train_accuracy: 45.31\n",
      "[1,   173] loss: 2.03106, train_accuracy: 31.25\n",
      "[1,   174] loss: 1.77800, train_accuracy: 34.38\n",
      "[1,   175] loss: 1.68846, train_accuracy: 35.16\n",
      "[1,   176] loss: 1.85306, train_accuracy: 32.81\n",
      "[1,   177] loss: 1.82075, train_accuracy: 35.16\n",
      "[1,   178] loss: 2.27571, train_accuracy: 29.69\n",
      "[1,   179] loss: 1.78031, train_accuracy: 38.28\n",
      "[1,   180] loss: 1.74826, train_accuracy: 36.72\n",
      "[1,   181] loss: 1.54893, train_accuracy: 39.84\n",
      "[1,   182] loss: 1.70221, train_accuracy: 42.19\n",
      "[1,   183] loss: 1.78268, train_accuracy: 39.06\n",
      "[1,   184] loss: 1.82487, train_accuracy: 42.19\n",
      "[1,   185] loss: 1.86772, train_accuracy: 34.38\n",
      "[1,   186] loss: 1.87836, train_accuracy: 32.81\n",
      "[1,   187] loss: 1.63919, train_accuracy: 39.84\n",
      "[1,   188] loss: 1.74640, train_accuracy: 36.72\n",
      "[1,   189] loss: 1.75531, train_accuracy: 34.38\n",
      "[1,   190] loss: 1.67848, train_accuracy: 43.75\n",
      "[1,   191] loss: 1.87277, train_accuracy: 33.59\n",
      "[1,   192] loss: 1.75054, train_accuracy: 34.38\n",
      "[1,   193] loss: 1.52792, train_accuracy: 45.31\n",
      "[1,   194] loss: 1.78951, train_accuracy: 39.06\n",
      "[1,   195] loss: 1.67200, train_accuracy: 39.84\n",
      "[1,   196] loss: 1.90799, train_accuracy: 36.72\n",
      "[1,   197] loss: 1.71214, train_accuracy: 33.59\n",
      "[1,   198] loss: 1.75991, train_accuracy: 38.28\n",
      "[1,   199] loss: 1.71963, train_accuracy: 35.94\n",
      "[1,   200] loss: 1.45740, train_accuracy: 43.75\n",
      "[1,   201] loss: 1.62801, train_accuracy: 35.94\n",
      "[1,   202] loss: 1.59441, train_accuracy: 39.06\n",
      "[1,   203] loss: 1.49149, train_accuracy: 46.09\n",
      "[1,   204] loss: 1.66877, train_accuracy: 41.41\n",
      "[1,   205] loss: 1.71298, train_accuracy: 44.53\n",
      "[1,   206] loss: 1.61520, train_accuracy: 43.75\n",
      "[1,   207] loss: 1.54397, train_accuracy: 44.53\n",
      "[1,   208] loss: 1.82486, train_accuracy: 35.94\n",
      "[1,   209] loss: 1.74048, train_accuracy: 35.94\n",
      "[1,   210] loss: 1.58665, train_accuracy: 40.62\n",
      "[1,   211] loss: 1.54331, train_accuracy: 41.41\n",
      "[1,   212] loss: 1.61015, train_accuracy: 41.41\n",
      "[1,   213] loss: 1.73497, train_accuracy: 39.84\n",
      "[1,   214] loss: 1.65118, train_accuracy: 42.97\n",
      "[1,   215] loss: 1.52173, train_accuracy: 39.06\n",
      "[1,   216] loss: 1.80300, train_accuracy: 40.62\n",
      "[1,   217] loss: 1.53791, train_accuracy: 40.62\n",
      "[1,   218] loss: 1.86420, train_accuracy: 37.50\n",
      "[1,   219] loss: 1.59884, train_accuracy: 42.19\n",
      "[1,   220] loss: 1.57550, train_accuracy: 42.19\n",
      "[1,   221] loss: 1.68376, train_accuracy: 38.28\n",
      "[1,   222] loss: 1.91673, train_accuracy: 35.94\n",
      "[1,   223] loss: 1.53601, train_accuracy: 46.88\n",
      "[1,   224] loss: 1.52055, train_accuracy: 53.91\n",
      "[1,   225] loss: 1.72449, train_accuracy: 40.62\n",
      "[1,   226] loss: 1.76296, train_accuracy: 32.03\n",
      "[1,   227] loss: 1.55085, train_accuracy: 39.84\n",
      "[1,   228] loss: 1.48311, train_accuracy: 49.22\n",
      "[1,   229] loss: 1.61890, train_accuracy: 39.84\n",
      "[1,   230] loss: 1.81081, train_accuracy: 41.41\n",
      "[1,   231] loss: 1.69249, train_accuracy: 40.62\n",
      "[1,   232] loss: 1.59608, train_accuracy: 48.44\n",
      "[1,   233] loss: 1.85292, train_accuracy: 39.84\n",
      "[1,   234] loss: 1.82260, train_accuracy: 30.47\n",
      "[1,   235] loss: 1.69876, train_accuracy: 35.16\n",
      "[1,   236] loss: 1.41649, train_accuracy: 42.19\n",
      "[1,   237] loss: 1.69937, train_accuracy: 47.66\n",
      "[1,   238] loss: 1.46462, train_accuracy: 41.41\n",
      "[1,   239] loss: 1.45620, train_accuracy: 46.88\n",
      "[1,   240] loss: 1.55959, train_accuracy: 49.22\n",
      "[1,   241] loss: 1.49957, train_accuracy: 41.41\n",
      "[1,   242] loss: 1.54322, train_accuracy: 46.88\n",
      "[1,   243] loss: 1.45600, train_accuracy: 42.97\n",
      "[1,   244] loss: 1.64302, train_accuracy: 35.94\n",
      "[1,   245] loss: 1.54878, train_accuracy: 43.75\n",
      "[1,   246] loss: 1.69705, train_accuracy: 39.84\n",
      "[1,   247] loss: 1.75194, train_accuracy: 38.28\n",
      "[1,   248] loss: 1.79377, train_accuracy: 43.75\n",
      "[1,   249] loss: 1.74249, train_accuracy: 36.72\n",
      "[1,   250] loss: 1.51783, train_accuracy: 45.31\n",
      "[1,   251] loss: 1.57463, train_accuracy: 44.53\n",
      "[1,   252] loss: 1.68939, train_accuracy: 42.97\n",
      "[1,   253] loss: 1.61041, train_accuracy: 46.09\n",
      "[1,   254] loss: 1.55554, train_accuracy: 41.41\n",
      "[1,   255] loss: 1.46769, train_accuracy: 50.00\n",
      "[1,   256] loss: 1.52060, train_accuracy: 46.09\n",
      "[1,   257] loss: 1.61384, train_accuracy: 41.41\n",
      "[1,   258] loss: 1.80204, train_accuracy: 35.16\n",
      "[1,   259] loss: 1.88500, train_accuracy: 42.19\n",
      "[1,   260] loss: 1.71951, train_accuracy: 41.41\n",
      "[1,   261] loss: 1.85942, train_accuracy: 28.12\n",
      "[1,   262] loss: 1.93816, train_accuracy: 41.41\n",
      "[1,   263] loss: 1.75761, train_accuracy: 35.94\n",
      "[1,   264] loss: 1.53300, train_accuracy: 46.88\n",
      "[1,   265] loss: 1.76304, train_accuracy: 35.16\n",
      "[1,   266] loss: 1.70058, train_accuracy: 39.06\n",
      "[1,   267] loss: 1.67852, train_accuracy: 36.72\n",
      "[1,   268] loss: 1.38937, train_accuracy: 49.22\n",
      "[1,   269] loss: 1.66344, train_accuracy: 41.41\n",
      "[1,   270] loss: 1.66241, train_accuracy: 36.72\n",
      "[1,   271] loss: 1.71733, train_accuracy: 42.19\n",
      "[1,   272] loss: 1.56558, train_accuracy: 42.19\n",
      "[1,   273] loss: 1.61828, train_accuracy: 42.97\n",
      "[1,   274] loss: 1.68951, train_accuracy: 39.84\n",
      "[1,   275] loss: 1.50860, train_accuracy: 50.00\n",
      "[1,   276] loss: 1.58492, train_accuracy: 37.50\n",
      "[1,   277] loss: 1.59750, train_accuracy: 38.28\n",
      "[1,   278] loss: 1.55811, train_accuracy: 42.97\n",
      "[1,   279] loss: 1.50458, train_accuracy: 44.53\n",
      "[1,   280] loss: 1.46673, train_accuracy: 46.88\n",
      "[1,   281] loss: 1.67270, train_accuracy: 38.28\n",
      "[1,   282] loss: 1.62477, train_accuracy: 43.75\n",
      "[1,   283] loss: 1.61443, train_accuracy: 42.97\n",
      "[1,   284] loss: 1.40691, train_accuracy: 46.09\n",
      "[1,   285] loss: 1.60544, train_accuracy: 39.84\n",
      "[1,   286] loss: 1.52012, train_accuracy: 44.53\n",
      "[1,   287] loss: 1.57298, train_accuracy: 42.97\n",
      "[1,   288] loss: 1.43100, train_accuracy: 42.97\n",
      "[1,   289] loss: 1.57916, train_accuracy: 39.06\n",
      "[1,   290] loss: 1.61649, train_accuracy: 39.84\n",
      "[1,   291] loss: 1.61505, train_accuracy: 39.84\n",
      "[1,   292] loss: 1.68469, train_accuracy: 42.97\n",
      "[1,   293] loss: 1.54472, train_accuracy: 44.53\n",
      "[1,   294] loss: 1.63326, train_accuracy: 39.06\n",
      "[1,   295] loss: 1.68912, train_accuracy: 38.28\n",
      "[1,   296] loss: 1.39651, train_accuracy: 46.09\n",
      "[1,   297] loss: 1.51156, train_accuracy: 46.09\n",
      "[1,   298] loss: 1.69681, train_accuracy: 40.62\n",
      "[1,   299] loss: 1.67160, train_accuracy: 37.50\n",
      "[1,   300] loss: 1.49973, train_accuracy: 45.31\n",
      "[1,   301] loss: 1.61276, train_accuracy: 48.44\n",
      "[1,   302] loss: 1.66339, train_accuracy: 39.84\n",
      "[1,   303] loss: 1.59093, train_accuracy: 46.88\n",
      "[1,   304] loss: 1.42941, train_accuracy: 46.09\n",
      "[1,   305] loss: 1.67165, train_accuracy: 47.66\n",
      "[1,   306] loss: 1.65547, train_accuracy: 40.62\n",
      "[1,   307] loss: 1.47045, train_accuracy: 48.44\n",
      "[1,   308] loss: 1.49088, train_accuracy: 46.09\n",
      "[1,   309] loss: 1.50079, train_accuracy: 43.75\n",
      "[1,   310] loss: 1.68715, train_accuracy: 42.19\n",
      "[1,   311] loss: 1.57144, train_accuracy: 48.44\n",
      "[1,   312] loss: 1.80991, train_accuracy: 38.28\n",
      "[1,   313] loss: 1.38811, train_accuracy: 46.09\n",
      "[1,   314] loss: 1.52839, train_accuracy: 46.09\n",
      "[1,   315] loss: 1.41061, train_accuracy: 47.66\n",
      "[1,   316] loss: 1.70463, train_accuracy: 42.97\n",
      "[1,   317] loss: 1.44164, train_accuracy: 42.97\n",
      "[1,   318] loss: 1.38607, train_accuracy: 48.44\n",
      "[1,   319] loss: 1.60253, train_accuracy: 42.97\n",
      "[1,   320] loss: 1.41793, train_accuracy: 40.62\n",
      "[1,   321] loss: 1.39792, train_accuracy: 47.66\n",
      "[1,   322] loss: 1.47811, train_accuracy: 42.97\n",
      "[1,   323] loss: 1.55383, train_accuracy: 46.09\n",
      "[1,   324] loss: 1.69063, train_accuracy: 38.28\n",
      "[1,   325] loss: 1.57121, train_accuracy: 37.50\n",
      "[1,   326] loss: 1.40720, train_accuracy: 52.34\n",
      "[1,   327] loss: 1.64325, train_accuracy: 46.88\n",
      "[1,   328] loss: 1.48354, train_accuracy: 42.97\n",
      "[1,   329] loss: 1.43113, train_accuracy: 46.88\n",
      "[1,   330] loss: 1.51220, train_accuracy: 47.66\n",
      "[1,   331] loss: 1.43798, train_accuracy: 50.00\n",
      "[1,   332] loss: 1.47855, train_accuracy: 50.78\n",
      "[1,   333] loss: 1.45551, train_accuracy: 52.34\n",
      "[1,   334] loss: 1.66452, train_accuracy: 45.31\n",
      "[1,   335] loss: 1.53701, train_accuracy: 41.41\n",
      "[1,   336] loss: 1.46026, train_accuracy: 51.56\n",
      "[1,   337] loss: 1.61574, train_accuracy: 41.41\n",
      "[1,   338] loss: 1.50146, train_accuracy: 39.84\n",
      "[1,   339] loss: 1.31311, train_accuracy: 49.22\n",
      "[1,   340] loss: 1.46365, train_accuracy: 52.34\n",
      "[1,   341] loss: 1.49985, train_accuracy: 42.97\n",
      "[1,   342] loss: 1.49941, train_accuracy: 50.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   343] loss: 1.36201, train_accuracy: 52.34\n",
      "[1,   344] loss: 1.59376, train_accuracy: 45.31\n",
      "[1,   345] loss: 1.26007, train_accuracy: 56.25\n",
      "[1,   346] loss: 1.39269, train_accuracy: 44.53\n",
      "[1,   347] loss: 1.56342, train_accuracy: 42.19\n",
      "[1,   348] loss: 1.36589, train_accuracy: 50.78\n",
      "[1,   349] loss: 1.35425, train_accuracy: 52.34\n",
      "[1,   350] loss: 1.47593, train_accuracy: 42.19\n",
      "[1,   351] loss: 1.44143, train_accuracy: 47.66\n",
      "[1,   352] loss: 1.46895, train_accuracy: 46.88\n",
      "[1,   353] loss: 1.35691, train_accuracy: 51.56\n",
      "[1,   354] loss: 1.41540, train_accuracy: 45.31\n",
      "[1,   355] loss: 1.36098, train_accuracy: 57.03\n",
      "[1,   356] loss: 1.56229, train_accuracy: 41.41\n",
      "[1,   357] loss: 1.47370, train_accuracy: 46.88\n",
      "[1,   358] loss: 1.41152, train_accuracy: 49.22\n",
      "[1,   359] loss: 1.28601, train_accuracy: 50.78\n",
      "[1,   360] loss: 1.52733, train_accuracy: 44.53\n",
      "[1,   361] loss: 1.38292, train_accuracy: 46.88\n",
      "[1,   362] loss: 1.40253, train_accuracy: 43.75\n",
      "[1,   363] loss: 1.49416, train_accuracy: 46.09\n",
      "[1,   364] loss: 1.70107, train_accuracy: 40.62\n",
      "[1,   365] loss: 1.33027, train_accuracy: 50.78\n",
      "[1,   366] loss: 1.31303, train_accuracy: 50.78\n",
      "[1,   367] loss: 1.28902, train_accuracy: 52.34\n",
      "[1,   368] loss: 1.30336, train_accuracy: 53.12\n",
      "[1,   369] loss: 1.31202, train_accuracy: 51.56\n",
      "[1,   370] loss: 1.27270, train_accuracy: 53.12\n",
      "[1,   371] loss: 1.32575, train_accuracy: 49.22\n",
      "[1,   372] loss: 1.58324, train_accuracy: 46.09\n",
      "[1,   373] loss: 1.77651, train_accuracy: 34.38\n",
      "[1,   374] loss: 1.61874, train_accuracy: 47.66\n",
      "[1,   375] loss: 1.48022, train_accuracy: 46.09\n",
      "[1,   376] loss: 1.36323, train_accuracy: 50.00\n",
      "[1,   377] loss: 1.41147, train_accuracy: 44.53\n",
      "[1,   378] loss: 1.43028, train_accuracy: 46.88\n",
      "[1,   379] loss: 1.57121, train_accuracy: 42.19\n",
      "[1,   380] loss: 1.26307, train_accuracy: 53.12\n",
      "[1,   381] loss: 1.48742, train_accuracy: 45.31\n",
      "[1,   382] loss: 1.37253, train_accuracy: 52.34\n",
      "[1,   383] loss: 1.45839, train_accuracy: 45.31\n",
      "[1,   384] loss: 1.43418, train_accuracy: 49.22\n",
      "[1,   385] loss: 1.19204, train_accuracy: 55.47\n",
      "[1,   386] loss: 1.40757, train_accuracy: 49.22\n",
      "[1,   387] loss: 1.45005, train_accuracy: 49.22\n",
      "[1,   388] loss: 1.53477, train_accuracy: 47.66\n",
      "[1,   389] loss: 1.23526, train_accuracy: 58.59\n",
      "[1,   390] loss: 1.31462, train_accuracy: 49.22\n",
      "[1,   391] loss: 1.60412, train_accuracy: 31.25\n",
      "duration: 139 s - train loss: 2.65741 - train accuracy: 34.67 - validation loss: 1.40 - validation accuracy: 49.11 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs_trained': 0,\n",
       " 'avg_time_per_epoch': 139.21841287612915,\n",
       " 'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'hist': {'train_loss': [2.657406526758238],\n",
       "  'train_accuracy': [34.67071611253197],\n",
       "  'validation_loss': [1.396858785725847],\n",
       "  'validation_accuracy': [49.11]},\n",
       " 'val_accuracy': 49.11}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CifarResNet().to(device)\n",
    "model.fit(train_loader, test_loader, 1, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Horizontal Flip only - 110s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "[1,     1] loss: 3.24445, train_accuracy: 10.16\n",
      "[1,     2] loss: 33.16906, train_accuracy: 10.94\n",
      "[1,     3] loss: 34.40232, train_accuracy: 10.94\n",
      "[1,     4] loss: 20.02533, train_accuracy: 26.56\n",
      "[1,     5] loss: 28.19654, train_accuracy: 17.19\n",
      "[1,     6] loss: 19.47647, train_accuracy: 14.84\n",
      "[1,     7] loss: 27.65862, train_accuracy: 8.59\n",
      "[1,     8] loss: 22.47031, train_accuracy: 9.38\n",
      "[1,     9] loss: 14.05315, train_accuracy: 17.97\n",
      "[1,    10] loss: 17.44954, train_accuracy: 14.84\n",
      "[1,    11] loss: 20.48391, train_accuracy: 8.59\n",
      "[1,    12] loss: 10.64860, train_accuracy: 19.53\n",
      "[1,    13] loss: 9.74438, train_accuracy: 16.41\n",
      "[1,    14] loss: 17.34064, train_accuracy: 5.47\n",
      "[1,    15] loss: 5.64611, train_accuracy: 10.94\n",
      "[1,    16] loss: 7.96084, train_accuracy: 14.84\n",
      "[1,    17] loss: 7.32646, train_accuracy: 23.44\n",
      "[1,    18] loss: 3.86598, train_accuracy: 15.62\n",
      "[1,    19] loss: 6.71867, train_accuracy: 17.97\n",
      "[1,    20] loss: 4.52591, train_accuracy: 11.72\n",
      "[1,    21] loss: 4.43484, train_accuracy: 12.50\n",
      "[1,    22] loss: 4.75086, train_accuracy: 18.75\n",
      "[1,    23] loss: 4.98416, train_accuracy: 16.41\n",
      "[1,    24] loss: 5.51813, train_accuracy: 21.09\n",
      "[1,    25] loss: 5.90701, train_accuracy: 14.84\n",
      "[1,    26] loss: 3.58390, train_accuracy: 13.28\n",
      "[1,    27] loss: 3.68017, train_accuracy: 11.72\n",
      "[1,    28] loss: 3.35966, train_accuracy: 20.31\n",
      "[1,    29] loss: 3.46005, train_accuracy: 17.19\n",
      "[1,    30] loss: 4.19758, train_accuracy: 17.97\n",
      "[1,    31] loss: 3.61843, train_accuracy: 21.88\n",
      "[1,    32] loss: 3.38678, train_accuracy: 17.19\n",
      "[1,    33] loss: 4.01906, train_accuracy: 14.06\n",
      "[1,    34] loss: 2.53924, train_accuracy: 19.53\n",
      "[1,    35] loss: 2.51232, train_accuracy: 17.97\n",
      "[1,    36] loss: 4.91710, train_accuracy: 14.06\n",
      "[1,    37] loss: 4.18734, train_accuracy: 17.19\n",
      "[1,    38] loss: 2.46908, train_accuracy: 24.22\n",
      "[1,    39] loss: 3.21616, train_accuracy: 17.97\n",
      "[1,    40] loss: 2.30751, train_accuracy: 25.78\n",
      "[1,    41] loss: 2.47151, train_accuracy: 17.97\n",
      "[1,    42] loss: 2.52447, train_accuracy: 17.19\n",
      "[1,    43] loss: 2.27482, train_accuracy: 25.78\n",
      "[1,    44] loss: 2.38213, train_accuracy: 22.66\n",
      "[1,    45] loss: 3.21360, train_accuracy: 22.66\n",
      "[1,    46] loss: 3.16074, train_accuracy: 22.66\n",
      "[1,    47] loss: 2.57298, train_accuracy: 23.44\n",
      "[1,    48] loss: 2.23652, train_accuracy: 17.19\n",
      "[1,    49] loss: 3.33638, train_accuracy: 24.22\n",
      "[1,    50] loss: 3.89892, train_accuracy: 17.19\n",
      "[1,    51] loss: 2.58322, train_accuracy: 17.19\n",
      "[1,    52] loss: 2.68473, train_accuracy: 21.88\n",
      "[1,    53] loss: 2.78054, train_accuracy: 15.62\n",
      "[1,    54] loss: 3.65241, train_accuracy: 26.56\n",
      "[1,    55] loss: 2.21828, train_accuracy: 25.00\n",
      "[1,    56] loss: 2.82282, train_accuracy: 21.88\n",
      "[1,    57] loss: 2.67206, train_accuracy: 30.47\n",
      "[1,    58] loss: 3.65048, train_accuracy: 29.69\n",
      "[1,    59] loss: 2.76625, train_accuracy: 26.56\n",
      "[1,    60] loss: 3.03794, train_accuracy: 26.56\n",
      "[1,    61] loss: 2.10126, train_accuracy: 35.94\n",
      "[1,    62] loss: 2.19001, train_accuracy: 30.47\n",
      "[1,    63] loss: 2.38765, train_accuracy: 21.88\n",
      "[1,    64] loss: 2.74659, train_accuracy: 23.44\n",
      "[1,    65] loss: 2.07889, train_accuracy: 22.66\n",
      "[1,    66] loss: 2.51260, train_accuracy: 19.53\n",
      "[1,    67] loss: 3.17051, train_accuracy: 18.75\n",
      "[1,    68] loss: 2.09769, train_accuracy: 25.78\n",
      "[1,    69] loss: 2.70529, train_accuracy: 19.53\n",
      "[1,    70] loss: 2.38527, train_accuracy: 25.00\n",
      "[1,    71] loss: 2.11182, train_accuracy: 26.56\n",
      "[1,    72] loss: 2.04696, train_accuracy: 30.47\n",
      "[1,    73] loss: 2.46540, train_accuracy: 25.00\n",
      "[1,    74] loss: 2.38397, train_accuracy: 26.56\n",
      "[1,    75] loss: 2.30673, train_accuracy: 25.78\n",
      "[1,    76] loss: 3.63409, train_accuracy: 22.66\n",
      "[1,    77] loss: 2.04138, train_accuracy: 27.34\n",
      "[1,    78] loss: 2.14662, train_accuracy: 25.78\n",
      "[1,    79] loss: 3.21724, train_accuracy: 19.53\n",
      "[1,    80] loss: 2.53450, train_accuracy: 24.22\n",
      "[1,    81] loss: 2.05097, train_accuracy: 25.00\n",
      "[1,    82] loss: 1.87531, train_accuracy: 32.81\n",
      "[1,    83] loss: 3.30239, train_accuracy: 23.44\n",
      "[1,    84] loss: 2.21875, train_accuracy: 17.97\n",
      "[1,    85] loss: 2.07088, train_accuracy: 27.34\n",
      "[1,    86] loss: 2.56876, train_accuracy: 33.59\n",
      "[1,    87] loss: 1.97611, train_accuracy: 29.69\n",
      "[1,    88] loss: 2.89963, train_accuracy: 21.88\n",
      "[1,    89] loss: 2.24028, train_accuracy: 27.34\n",
      "[1,    90] loss: 2.10619, train_accuracy: 25.78\n",
      "[1,    91] loss: 4.10326, train_accuracy: 31.25\n",
      "[1,    92] loss: 2.11867, train_accuracy: 32.03\n",
      "[1,    93] loss: 2.57917, train_accuracy: 21.88\n",
      "[1,    94] loss: 2.22628, train_accuracy: 19.53\n",
      "[1,    95] loss: 2.11544, train_accuracy: 27.34\n",
      "[1,    96] loss: 2.54421, train_accuracy: 20.31\n",
      "[1,    97] loss: 2.37183, train_accuracy: 26.56\n",
      "[1,    98] loss: 1.81593, train_accuracy: 36.72\n",
      "[1,    99] loss: 1.82487, train_accuracy: 34.38\n",
      "[1,   100] loss: 2.09498, train_accuracy: 28.91\n",
      "[1,   101] loss: 1.97421, train_accuracy: 26.56\n",
      "[1,   102] loss: 2.20811, train_accuracy: 27.34\n",
      "[1,   103] loss: 2.58284, train_accuracy: 31.25\n",
      "[1,   104] loss: 1.92187, train_accuracy: 28.91\n",
      "[1,   105] loss: 2.95587, train_accuracy: 26.56\n",
      "[1,   106] loss: 2.63197, train_accuracy: 28.12\n",
      "[1,   107] loss: 2.33184, train_accuracy: 28.91\n",
      "[1,   108] loss: 2.47717, train_accuracy: 25.00\n",
      "[1,   109] loss: 2.13159, train_accuracy: 30.47\n",
      "[1,   110] loss: 2.41466, train_accuracy: 26.56\n",
      "[1,   111] loss: 2.81529, train_accuracy: 28.91\n",
      "[1,   112] loss: 2.24551, train_accuracy: 28.12\n",
      "[1,   113] loss: 2.53617, train_accuracy: 22.66\n",
      "[1,   114] loss: 2.16382, train_accuracy: 27.34\n",
      "[1,   115] loss: 2.28432, train_accuracy: 35.16\n",
      "[1,   116] loss: 2.09120, train_accuracy: 27.34\n",
      "[1,   117] loss: 1.92226, train_accuracy: 30.47\n",
      "[1,   118] loss: 2.14949, train_accuracy: 28.91\n",
      "[1,   119] loss: 2.24957, train_accuracy: 20.31\n",
      "[1,   120] loss: 2.22475, train_accuracy: 29.69\n",
      "[1,   121] loss: 1.80390, train_accuracy: 32.03\n",
      "[1,   122] loss: 1.93364, train_accuracy: 25.78\n",
      "[1,   123] loss: 1.96487, train_accuracy: 32.81\n",
      "[1,   124] loss: 2.03820, train_accuracy: 24.22\n",
      "[1,   125] loss: 1.81168, train_accuracy: 32.03\n",
      "[1,   126] loss: 2.15824, train_accuracy: 30.47\n",
      "[1,   127] loss: 1.74330, train_accuracy: 39.06\n",
      "[1,   128] loss: 2.06506, train_accuracy: 29.69\n",
      "[1,   129] loss: 2.25318, train_accuracy: 27.34\n",
      "[1,   130] loss: 1.75387, train_accuracy: 37.50\n",
      "[1,   131] loss: 1.79087, train_accuracy: 32.81\n",
      "[1,   132] loss: 1.69744, train_accuracy: 32.81\n",
      "[1,   133] loss: 2.48574, train_accuracy: 34.38\n",
      "[1,   134] loss: 2.21082, train_accuracy: 30.47\n",
      "[1,   135] loss: 2.21379, train_accuracy: 33.59\n",
      "[1,   136] loss: 2.01973, train_accuracy: 24.22\n",
      "[1,   137] loss: 1.94681, train_accuracy: 32.03\n",
      "[1,   138] loss: 1.91516, train_accuracy: 32.03\n",
      "[1,   139] loss: 2.02169, train_accuracy: 31.25\n",
      "[1,   140] loss: 1.74256, train_accuracy: 38.28\n",
      "[1,   141] loss: 1.87989, train_accuracy: 39.84\n",
      "[1,   142] loss: 2.07117, train_accuracy: 28.12\n",
      "[1,   143] loss: 1.81095, train_accuracy: 39.84\n",
      "[1,   144] loss: 1.81822, train_accuracy: 33.59\n",
      "[1,   145] loss: 2.13581, train_accuracy: 32.81\n",
      "[1,   146] loss: 1.68077, train_accuracy: 35.94\n",
      "[1,   147] loss: 1.66052, train_accuracy: 44.53\n",
      "[1,   148] loss: 1.62411, train_accuracy: 42.97\n",
      "[1,   149] loss: 1.66197, train_accuracy: 40.62\n",
      "[1,   150] loss: 1.71377, train_accuracy: 30.47\n",
      "[1,   151] loss: 1.72704, train_accuracy: 38.28\n",
      "[1,   152] loss: 1.90798, train_accuracy: 35.94\n",
      "[1,   153] loss: 2.01079, train_accuracy: 35.16\n",
      "[1,   154] loss: 1.74807, train_accuracy: 35.94\n",
      "[1,   155] loss: 1.83894, train_accuracy: 35.16\n",
      "[1,   156] loss: 1.86487, train_accuracy: 34.38\n",
      "[1,   157] loss: 1.72838, train_accuracy: 38.28\n",
      "[1,   158] loss: 1.67543, train_accuracy: 44.53\n",
      "[1,   159] loss: 1.81394, train_accuracy: 37.50\n",
      "[1,   160] loss: 2.13192, train_accuracy: 27.34\n",
      "[1,   161] loss: 1.66810, train_accuracy: 39.06\n",
      "[1,   162] loss: 1.89689, train_accuracy: 38.28\n",
      "[1,   163] loss: 2.01072, train_accuracy: 32.81\n",
      "[1,   164] loss: 1.90618, train_accuracy: 25.78\n",
      "[1,   165] loss: 1.63775, train_accuracy: 39.84\n",
      "[1,   166] loss: 2.01537, train_accuracy: 28.91\n",
      "[1,   167] loss: 1.95036, train_accuracy: 28.91\n",
      "[1,   168] loss: 1.70891, train_accuracy: 33.59\n",
      "[1,   169] loss: 1.70074, train_accuracy: 36.72\n",
      "[1,   170] loss: 1.85857, train_accuracy: 35.94\n",
      "[1,   171] loss: 1.82101, train_accuracy: 33.59\n",
      "[1,   172] loss: 1.80625, train_accuracy: 31.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   173] loss: 1.91208, train_accuracy: 32.03\n",
      "[1,   174] loss: 1.67884, train_accuracy: 38.28\n",
      "[1,   175] loss: 1.83381, train_accuracy: 38.28\n",
      "[1,   176] loss: 1.88408, train_accuracy: 33.59\n",
      "[1,   177] loss: 1.75106, train_accuracy: 35.16\n",
      "[1,   178] loss: 1.85911, train_accuracy: 28.91\n",
      "[1,   179] loss: 1.70352, train_accuracy: 33.59\n",
      "[1,   180] loss: 1.63405, train_accuracy: 45.31\n",
      "[1,   181] loss: 1.86403, train_accuracy: 32.81\n",
      "[1,   182] loss: 2.07888, train_accuracy: 33.59\n",
      "[1,   183] loss: 1.93041, train_accuracy: 36.72\n",
      "[1,   184] loss: 1.70821, train_accuracy: 31.25\n",
      "[1,   185] loss: 1.95670, train_accuracy: 30.47\n",
      "[1,   186] loss: 1.70071, train_accuracy: 37.50\n",
      "[1,   187] loss: 2.05051, train_accuracy: 43.75\n",
      "[1,   188] loss: 3.23305, train_accuracy: 25.78\n",
      "[1,   189] loss: 1.70504, train_accuracy: 32.03\n",
      "[1,   190] loss: 1.97098, train_accuracy: 34.38\n",
      "[1,   191] loss: 1.82051, train_accuracy: 32.81\n",
      "[1,   192] loss: 1.72065, train_accuracy: 38.28\n",
      "[1,   193] loss: 1.87525, train_accuracy: 38.28\n",
      "[1,   194] loss: 2.40456, train_accuracy: 42.19\n",
      "[1,   195] loss: 1.84817, train_accuracy: 32.81\n",
      "[1,   196] loss: 1.99254, train_accuracy: 35.16\n",
      "[1,   197] loss: 1.69174, train_accuracy: 33.59\n",
      "[1,   198] loss: 1.91852, train_accuracy: 32.81\n",
      "[1,   199] loss: 1.83399, train_accuracy: 37.50\n",
      "[1,   200] loss: 1.55166, train_accuracy: 42.97\n",
      "[1,   201] loss: 2.01720, train_accuracy: 38.28\n",
      "[1,   202] loss: 2.75662, train_accuracy: 32.81\n",
      "[1,   203] loss: 1.62942, train_accuracy: 36.72\n",
      "[1,   204] loss: 1.73268, train_accuracy: 44.53\n",
      "[1,   205] loss: 1.49336, train_accuracy: 45.31\n",
      "[1,   206] loss: 1.79136, train_accuracy: 37.50\n",
      "[1,   207] loss: 1.93562, train_accuracy: 31.25\n",
      "[1,   208] loss: 2.12751, train_accuracy: 41.41\n",
      "[1,   209] loss: 2.07646, train_accuracy: 41.41\n",
      "[1,   210] loss: 1.86739, train_accuracy: 32.03\n",
      "[1,   211] loss: 1.61730, train_accuracy: 39.06\n",
      "[1,   212] loss: 1.75075, train_accuracy: 36.72\n",
      "[1,   213] loss: 1.57191, train_accuracy: 40.62\n",
      "[1,   214] loss: 1.84785, train_accuracy: 38.28\n",
      "[1,   215] loss: 1.77965, train_accuracy: 34.38\n",
      "[1,   216] loss: 1.82889, train_accuracy: 39.06\n",
      "[1,   217] loss: 1.57962, train_accuracy: 38.28\n",
      "[1,   218] loss: 1.93953, train_accuracy: 35.94\n",
      "[1,   219] loss: 1.72433, train_accuracy: 40.62\n",
      "[1,   220] loss: 1.87159, train_accuracy: 35.16\n",
      "[1,   221] loss: 1.70953, train_accuracy: 31.25\n",
      "[1,   222] loss: 1.73197, train_accuracy: 31.25\n",
      "[1,   223] loss: 1.79763, train_accuracy: 31.25\n",
      "[1,   224] loss: 2.04281, train_accuracy: 27.34\n",
      "[1,   225] loss: 1.74632, train_accuracy: 36.72\n",
      "[1,   226] loss: 1.50005, train_accuracy: 42.97\n",
      "[1,   227] loss: 1.63619, train_accuracy: 34.38\n",
      "[1,   228] loss: 1.88890, train_accuracy: 35.16\n",
      "[1,   229] loss: 1.67556, train_accuracy: 35.94\n",
      "[1,   230] loss: 1.87573, train_accuracy: 29.69\n",
      "[1,   231] loss: 1.75657, train_accuracy: 34.38\n",
      "[1,   232] loss: 1.77994, train_accuracy: 33.59\n",
      "[1,   233] loss: 1.90648, train_accuracy: 30.47\n",
      "[1,   234] loss: 1.61362, train_accuracy: 43.75\n",
      "[1,   235] loss: 1.63487, train_accuracy: 40.62\n",
      "[1,   236] loss: 1.90076, train_accuracy: 37.50\n",
      "[1,   237] loss: 2.21075, train_accuracy: 42.19\n",
      "[1,   238] loss: 1.69588, train_accuracy: 35.94\n",
      "[1,   239] loss: 1.87918, train_accuracy: 35.94\n",
      "[1,   240] loss: 1.71822, train_accuracy: 42.19\n",
      "[1,   241] loss: 1.72302, train_accuracy: 30.47\n",
      "[1,   242] loss: 1.59896, train_accuracy: 36.72\n",
      "[1,   243] loss: 1.50991, train_accuracy: 40.62\n",
      "[1,   244] loss: 1.54149, train_accuracy: 40.62\n",
      "[1,   245] loss: 1.55573, train_accuracy: 39.06\n",
      "[1,   246] loss: 1.59555, train_accuracy: 37.50\n",
      "[1,   247] loss: 1.57044, train_accuracy: 42.19\n",
      "[1,   248] loss: 1.83811, train_accuracy: 44.53\n",
      "[1,   249] loss: 1.78059, train_accuracy: 39.84\n",
      "[1,   250] loss: 1.49873, train_accuracy: 41.41\n",
      "[1,   251] loss: 1.43206, train_accuracy: 50.78\n",
      "[1,   252] loss: 1.70797, train_accuracy: 41.41\n",
      "[1,   253] loss: 1.57084, train_accuracy: 42.97\n",
      "[1,   254] loss: 1.54212, train_accuracy: 43.75\n",
      "[1,   255] loss: 1.58688, train_accuracy: 45.31\n",
      "[1,   256] loss: 1.53597, train_accuracy: 40.62\n",
      "[1,   257] loss: 1.54426, train_accuracy: 42.19\n",
      "[1,   258] loss: 1.61058, train_accuracy: 40.62\n",
      "[1,   259] loss: 1.53251, train_accuracy: 44.53\n",
      "[1,   260] loss: 1.48981, train_accuracy: 42.19\n",
      "[1,   261] loss: 1.53981, train_accuracy: 42.97\n",
      "[1,   262] loss: 1.39476, train_accuracy: 47.66\n",
      "[1,   263] loss: 1.89404, train_accuracy: 37.50\n",
      "[1,   264] loss: 1.58739, train_accuracy: 42.19\n",
      "[1,   265] loss: 1.59428, train_accuracy: 41.41\n",
      "[1,   266] loss: 1.56180, train_accuracy: 46.88\n",
      "[1,   267] loss: 1.65591, train_accuracy: 43.75\n",
      "[1,   268] loss: 1.52623, train_accuracy: 39.84\n",
      "[1,   269] loss: 1.50611, train_accuracy: 46.09\n",
      "[1,   270] loss: 1.75387, train_accuracy: 42.19\n",
      "[1,   271] loss: 1.66640, train_accuracy: 35.94\n",
      "[1,   272] loss: 1.51859, train_accuracy: 48.44\n",
      "[1,   273] loss: 1.65084, train_accuracy: 44.53\n",
      "[1,   274] loss: 1.41034, train_accuracy: 50.78\n",
      "[1,   275] loss: 1.63600, train_accuracy: 45.31\n",
      "[1,   276] loss: 1.67712, train_accuracy: 36.72\n",
      "[1,   277] loss: 1.65542, train_accuracy: 44.53\n",
      "[1,   278] loss: 1.90820, train_accuracy: 35.16\n",
      "[1,   279] loss: 1.50371, train_accuracy: 40.62\n",
      "[1,   280] loss: 1.69219, train_accuracy: 38.28\n",
      "[1,   281] loss: 1.65246, train_accuracy: 40.62\n",
      "[1,   282] loss: 1.67365, train_accuracy: 42.97\n",
      "[1,   283] loss: 1.55009, train_accuracy: 39.06\n",
      "[1,   284] loss: 1.59800, train_accuracy: 42.97\n",
      "[1,   285] loss: 1.60321, train_accuracy: 45.31\n",
      "[1,   286] loss: 1.70183, train_accuracy: 34.38\n",
      "[1,   287] loss: 1.45535, train_accuracy: 41.41\n",
      "[1,   288] loss: 1.65102, train_accuracy: 40.62\n",
      "[1,   289] loss: 1.66509, train_accuracy: 43.75\n",
      "[1,   290] loss: 1.55040, train_accuracy: 49.22\n",
      "[1,   291] loss: 1.64480, train_accuracy: 39.06\n",
      "[1,   292] loss: 1.73852, train_accuracy: 42.97\n",
      "[1,   293] loss: 1.54076, train_accuracy: 50.00\n",
      "[1,   294] loss: 1.65910, train_accuracy: 39.06\n",
      "[1,   295] loss: 1.59821, train_accuracy: 46.09\n",
      "[1,   296] loss: 1.70269, train_accuracy: 35.16\n",
      "[1,   297] loss: 1.62011, train_accuracy: 45.31\n",
      "[1,   298] loss: 1.55474, train_accuracy: 42.19\n",
      "[1,   299] loss: 1.56907, train_accuracy: 43.75\n",
      "[1,   300] loss: 1.42804, train_accuracy: 42.19\n",
      "[1,   301] loss: 1.33827, train_accuracy: 48.44\n",
      "[1,   302] loss: 1.67625, train_accuracy: 37.50\n",
      "[1,   303] loss: 1.30738, train_accuracy: 57.03\n",
      "[1,   304] loss: 1.50394, train_accuracy: 42.19\n",
      "[1,   305] loss: 1.46579, train_accuracy: 51.56\n",
      "[1,   306] loss: 1.71257, train_accuracy: 37.50\n",
      "[1,   307] loss: 1.51735, train_accuracy: 42.97\n",
      "[1,   308] loss: 1.74512, train_accuracy: 41.41\n",
      "[1,   309] loss: 1.36897, train_accuracy: 47.66\n",
      "[1,   310] loss: 1.35291, train_accuracy: 48.44\n",
      "[1,   311] loss: 1.63883, train_accuracy: 46.09\n",
      "[1,   312] loss: 1.35525, train_accuracy: 52.34\n",
      "[1,   313] loss: 1.38696, train_accuracy: 44.53\n",
      "[1,   314] loss: 1.50452, train_accuracy: 46.88\n",
      "[1,   315] loss: 1.43523, train_accuracy: 50.78\n",
      "[1,   316] loss: 1.50242, train_accuracy: 48.44\n",
      "[1,   317] loss: 1.55983, train_accuracy: 44.53\n",
      "[1,   318] loss: 1.49101, train_accuracy: 50.78\n",
      "[1,   319] loss: 1.54700, train_accuracy: 48.44\n",
      "[1,   320] loss: 1.36262, train_accuracy: 50.00\n",
      "[1,   321] loss: 1.53250, train_accuracy: 52.34\n",
      "[1,   322] loss: 1.71337, train_accuracy: 43.75\n",
      "[1,   323] loss: 1.34279, train_accuracy: 46.88\n",
      "[1,   324] loss: 1.53099, train_accuracy: 39.84\n",
      "[1,   325] loss: 1.93053, train_accuracy: 45.31\n",
      "[1,   326] loss: 1.46067, train_accuracy: 51.56\n",
      "[1,   327] loss: 1.46940, train_accuracy: 52.34\n",
      "[1,   328] loss: 1.64914, train_accuracy: 49.22\n",
      "[1,   329] loss: 1.76682, train_accuracy: 32.81\n",
      "[1,   330] loss: 1.18605, train_accuracy: 54.69\n",
      "[1,   331] loss: 1.49142, train_accuracy: 45.31\n",
      "[1,   332] loss: 1.42357, train_accuracy: 40.62\n",
      "[1,   333] loss: 1.41393, train_accuracy: 47.66\n",
      "[1,   334] loss: 1.59116, train_accuracy: 42.97\n",
      "[1,   335] loss: 1.36688, train_accuracy: 53.91\n",
      "[1,   336] loss: 1.48357, train_accuracy: 45.31\n",
      "[1,   337] loss: 1.68217, train_accuracy: 41.41\n",
      "[1,   338] loss: 1.68413, train_accuracy: 40.62\n",
      "[1,   339] loss: 1.51714, train_accuracy: 47.66\n",
      "[1,   340] loss: 1.63552, train_accuracy: 41.41\n",
      "[1,   341] loss: 1.56738, train_accuracy: 42.19\n",
      "[1,   342] loss: 1.46143, train_accuracy: 39.06\n",
      "[1,   343] loss: 1.51395, train_accuracy: 45.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   344] loss: 1.55973, train_accuracy: 39.06\n",
      "[1,   345] loss: 1.52950, train_accuracy: 45.31\n",
      "[1,   346] loss: 1.73210, train_accuracy: 42.19\n",
      "[1,   347] loss: 1.42356, train_accuracy: 50.78\n",
      "[1,   348] loss: 1.46716, train_accuracy: 48.44\n",
      "[1,   349] loss: 1.46108, train_accuracy: 49.22\n",
      "[1,   350] loss: 1.48588, train_accuracy: 50.00\n",
      "[1,   351] loss: 1.52567, train_accuracy: 46.88\n",
      "[1,   352] loss: 1.47676, train_accuracy: 47.66\n",
      "[1,   353] loss: 1.66771, train_accuracy: 45.31\n",
      "[1,   354] loss: 1.30189, train_accuracy: 47.66\n",
      "[1,   355] loss: 1.56412, train_accuracy: 38.28\n",
      "[1,   356] loss: 1.52990, train_accuracy: 50.78\n",
      "[1,   357] loss: 1.34111, train_accuracy: 49.22\n",
      "[1,   358] loss: 1.43493, train_accuracy: 47.66\n",
      "[1,   359] loss: 1.47432, train_accuracy: 41.41\n",
      "[1,   360] loss: 1.55403, train_accuracy: 45.31\n",
      "[1,   361] loss: 1.32644, train_accuracy: 51.56\n",
      "[1,   362] loss: 1.36354, train_accuracy: 50.00\n",
      "[1,   363] loss: 1.47405, train_accuracy: 38.28\n",
      "[1,   364] loss: 1.52511, train_accuracy: 43.75\n",
      "[1,   365] loss: 1.49061, train_accuracy: 50.00\n",
      "[1,   366] loss: 1.34166, train_accuracy: 56.25\n",
      "[1,   367] loss: 1.48954, train_accuracy: 46.88\n",
      "[1,   368] loss: 1.44483, train_accuracy: 51.56\n",
      "[1,   369] loss: 1.19771, train_accuracy: 53.91\n",
      "[1,   370] loss: 1.33967, train_accuracy: 51.56\n",
      "[1,   371] loss: 1.46330, train_accuracy: 48.44\n",
      "[1,   372] loss: 1.35295, train_accuracy: 48.44\n",
      "[1,   373] loss: 1.34957, train_accuracy: 53.12\n",
      "[1,   374] loss: 1.40385, train_accuracy: 50.78\n",
      "[1,   375] loss: 1.50371, train_accuracy: 51.56\n",
      "[1,   376] loss: 1.32646, train_accuracy: 49.22\n",
      "[1,   377] loss: 1.35408, train_accuracy: 57.03\n",
      "[1,   378] loss: 1.37309, train_accuracy: 48.44\n",
      "[1,   379] loss: 1.45686, train_accuracy: 45.31\n",
      "[1,   380] loss: 1.50215, train_accuracy: 44.53\n",
      "[1,   381] loss: 1.23591, train_accuracy: 53.91\n",
      "[1,   382] loss: 1.45960, train_accuracy: 46.88\n",
      "[1,   383] loss: 1.29692, train_accuracy: 53.12\n",
      "[1,   384] loss: 1.58228, train_accuracy: 43.75\n",
      "[1,   385] loss: 1.24788, train_accuracy: 47.66\n",
      "[1,   386] loss: 1.20511, train_accuracy: 51.56\n",
      "[1,   387] loss: 1.44384, train_accuracy: 45.31\n",
      "[1,   388] loss: 1.32504, train_accuracy: 51.56\n",
      "[1,   389] loss: 1.39692, train_accuracy: 48.44\n",
      "[1,   390] loss: 1.31684, train_accuracy: 50.78\n",
      "[1,   391] loss: 1.39399, train_accuracy: 47.50\n",
      "duration: 110 s - train loss: 2.67223 - train accuracy: 35.15 - validation loss: 1.40 - validation accuracy: 49.13 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs_trained': 0,\n",
       " 'avg_time_per_epoch': 110.8130419254303,\n",
       " 'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'hist': {'train_loss': [2.672231035464255],\n",
       "  'train_accuracy': [35.14585997442455],\n",
       "  'validation_loss': [1.3972952728030048],\n",
       "  'validation_accuracy': [49.13]},\n",
       " 'val_accuracy': 49.13}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CifarResNet().to(device)\n",
    "model.fit(train_loader, test_loader, 1, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Rotation only - 112 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "[1,     1] loss: 3.01800, train_accuracy: 16.41\n",
      "[1,     2] loss: 39.64801, train_accuracy: 11.72\n",
      "[1,     3] loss: 56.67356, train_accuracy: 10.16\n",
      "[1,     4] loss: 35.74637, train_accuracy: 9.38\n",
      "[1,     5] loss: 24.94523, train_accuracy: 9.38\n",
      "[1,     6] loss: 20.45514, train_accuracy: 13.28\n",
      "[1,     7] loss: 18.60504, train_accuracy: 10.94\n",
      "[1,     8] loss: 18.22313, train_accuracy: 7.81\n",
      "[1,     9] loss: 8.29266, train_accuracy: 10.16\n",
      "[1,    10] loss: 10.27006, train_accuracy: 12.50\n",
      "[1,    11] loss: 17.30413, train_accuracy: 17.19\n",
      "[1,    12] loss: 14.97085, train_accuracy: 11.72\n",
      "[1,    13] loss: 5.05954, train_accuracy: 14.84\n",
      "[1,    14] loss: 6.53913, train_accuracy: 21.88\n",
      "[1,    15] loss: 3.46858, train_accuracy: 20.31\n",
      "[1,    16] loss: 6.09013, train_accuracy: 14.84\n",
      "[1,    17] loss: 5.78682, train_accuracy: 13.28\n",
      "[1,    18] loss: 3.57312, train_accuracy: 17.19\n",
      "[1,    19] loss: 5.53199, train_accuracy: 16.41\n",
      "[1,    20] loss: 5.39329, train_accuracy: 5.47\n",
      "[1,    21] loss: 4.00430, train_accuracy: 14.84\n",
      "[1,    22] loss: 6.80322, train_accuracy: 17.97\n",
      "[1,    23] loss: 4.81120, train_accuracy: 21.88\n",
      "[1,    24] loss: 4.43244, train_accuracy: 14.06\n",
      "[1,    25] loss: 6.30122, train_accuracy: 18.75\n",
      "[1,    26] loss: 3.76638, train_accuracy: 16.41\n",
      "[1,    27] loss: 2.86662, train_accuracy: 8.59\n",
      "[1,    28] loss: 2.74629, train_accuracy: 18.75\n",
      "[1,    29] loss: 2.68768, train_accuracy: 15.62\n",
      "[1,    30] loss: 2.80887, train_accuracy: 12.50\n",
      "[1,    31] loss: 3.97347, train_accuracy: 16.41\n",
      "[1,    32] loss: 7.63593, train_accuracy: 14.84\n",
      "[1,    33] loss: 3.12871, train_accuracy: 19.53\n",
      "[1,    34] loss: 4.28476, train_accuracy: 17.97\n",
      "[1,    35] loss: 3.94508, train_accuracy: 21.09\n",
      "[1,    36] loss: 4.30580, train_accuracy: 17.97\n",
      "[1,    37] loss: 5.22299, train_accuracy: 22.66\n",
      "[1,    38] loss: 2.74265, train_accuracy: 17.97\n",
      "[1,    39] loss: 2.99041, train_accuracy: 21.09\n",
      "[1,    40] loss: 5.23182, train_accuracy: 17.19\n",
      "[1,    41] loss: 3.50104, train_accuracy: 17.97\n",
      "[1,    42] loss: 2.77544, train_accuracy: 19.53\n",
      "[1,    43] loss: 2.36038, train_accuracy: 18.75\n",
      "[1,    44] loss: 2.49479, train_accuracy: 20.31\n",
      "[1,    45] loss: 3.11115, train_accuracy: 15.62\n",
      "[1,    46] loss: 2.53414, train_accuracy: 14.84\n",
      "[1,    47] loss: 2.50099, train_accuracy: 14.06\n",
      "[1,    48] loss: 3.09944, train_accuracy: 22.66\n",
      "[1,    49] loss: 2.67706, train_accuracy: 17.97\n",
      "[1,    50] loss: 2.40335, train_accuracy: 24.22\n",
      "[1,    51] loss: 2.49829, train_accuracy: 15.62\n",
      "[1,    52] loss: 2.95743, train_accuracy: 14.06\n",
      "[1,    53] loss: 2.50971, train_accuracy: 21.09\n",
      "[1,    54] loss: 2.78229, train_accuracy: 21.88\n",
      "[1,    55] loss: 2.96166, train_accuracy: 16.41\n",
      "[1,    56] loss: 2.04589, train_accuracy: 32.81\n",
      "[1,    57] loss: 2.54222, train_accuracy: 21.09\n",
      "[1,    58] loss: 2.26034, train_accuracy: 21.09\n",
      "[1,    59] loss: 2.35119, train_accuracy: 21.09\n",
      "[1,    60] loss: 3.38605, train_accuracy: 23.44\n",
      "[1,    61] loss: 2.55394, train_accuracy: 14.84\n",
      "[1,    62] loss: 2.62661, train_accuracy: 15.62\n",
      "[1,    63] loss: 2.30536, train_accuracy: 20.31\n",
      "[1,    64] loss: 2.58831, train_accuracy: 25.78\n",
      "[1,    65] loss: 1.81862, train_accuracy: 32.03\n",
      "[1,    66] loss: 2.54585, train_accuracy: 19.53\n",
      "[1,    67] loss: 2.82143, train_accuracy: 14.84\n",
      "[1,    68] loss: 2.12277, train_accuracy: 28.91\n",
      "[1,    69] loss: 2.06881, train_accuracy: 31.25\n",
      "[1,    70] loss: 2.98516, train_accuracy: 26.56\n",
      "[1,    71] loss: 1.99845, train_accuracy: 24.22\n",
      "[1,    72] loss: 2.09163, train_accuracy: 23.44\n",
      "[1,    73] loss: 2.26986, train_accuracy: 26.56\n",
      "[1,    74] loss: 3.27283, train_accuracy: 24.22\n",
      "[1,    75] loss: 2.53039, train_accuracy: 20.31\n",
      "[1,    76] loss: 2.36645, train_accuracy: 25.78\n",
      "[1,    77] loss: 2.40646, train_accuracy: 26.56\n",
      "[1,    78] loss: 2.09255, train_accuracy: 28.12\n",
      "[1,    79] loss: 2.20455, train_accuracy: 28.91\n",
      "[1,    80] loss: 2.72325, train_accuracy: 32.03\n",
      "[1,    81] loss: 1.95087, train_accuracy: 29.69\n",
      "[1,    82] loss: 2.18906, train_accuracy: 26.56\n",
      "[1,    83] loss: 2.19142, train_accuracy: 28.91\n",
      "[1,    84] loss: 1.90708, train_accuracy: 31.25\n",
      "[1,    85] loss: 2.29786, train_accuracy: 29.69\n",
      "[1,    86] loss: 2.35129, train_accuracy: 22.66\n",
      "[1,    87] loss: 2.45771, train_accuracy: 24.22\n",
      "[1,    88] loss: 2.39512, train_accuracy: 31.25\n",
      "[1,    89] loss: 1.99425, train_accuracy: 28.12\n",
      "[1,    90] loss: 2.10163, train_accuracy: 34.38\n",
      "[1,    91] loss: 1.87025, train_accuracy: 28.12\n",
      "[1,    92] loss: 2.14509, train_accuracy: 27.34\n",
      "[1,    93] loss: 1.94103, train_accuracy: 29.69\n",
      "[1,    94] loss: 1.93000, train_accuracy: 26.56\n",
      "[1,    95] loss: 2.64331, train_accuracy: 27.34\n",
      "[1,    96] loss: 1.95372, train_accuracy: 22.66\n",
      "[1,    97] loss: 2.82712, train_accuracy: 29.69\n",
      "[1,    98] loss: 2.37428, train_accuracy: 29.69\n",
      "[1,    99] loss: 2.48541, train_accuracy: 32.03\n",
      "[1,   100] loss: 2.26254, train_accuracy: 29.69\n",
      "[1,   101] loss: 1.99223, train_accuracy: 25.00\n",
      "[1,   102] loss: 2.10016, train_accuracy: 27.34\n",
      "[1,   103] loss: 2.12335, train_accuracy: 30.47\n",
      "[1,   104] loss: 2.30635, train_accuracy: 29.69\n",
      "[1,   105] loss: 2.89751, train_accuracy: 23.44\n",
      "[1,   106] loss: 1.89109, train_accuracy: 32.81\n",
      "[1,   107] loss: 2.06690, train_accuracy: 19.53\n",
      "[1,   108] loss: 1.94176, train_accuracy: 28.91\n",
      "[1,   109] loss: 2.15982, train_accuracy: 25.78\n",
      "[1,   110] loss: 1.95997, train_accuracy: 29.69\n",
      "[1,   111] loss: 2.91275, train_accuracy: 23.44\n",
      "[1,   112] loss: 1.97159, train_accuracy: 35.16\n",
      "[1,   113] loss: 1.87776, train_accuracy: 34.38\n",
      "[1,   114] loss: 2.57897, train_accuracy: 30.47\n",
      "[1,   115] loss: 2.14183, train_accuracy: 27.34\n",
      "[1,   116] loss: 1.96233, train_accuracy: 38.28\n",
      "[1,   117] loss: 2.25312, train_accuracy: 28.91\n",
      "[1,   118] loss: 2.27148, train_accuracy: 26.56\n",
      "[1,   119] loss: 2.04513, train_accuracy: 29.69\n",
      "[1,   120] loss: 1.83849, train_accuracy: 32.81\n",
      "[1,   121] loss: 2.03953, train_accuracy: 32.03\n",
      "[1,   122] loss: 1.89475, train_accuracy: 35.16\n",
      "[1,   123] loss: 1.90723, train_accuracy: 28.12\n",
      "[1,   124] loss: 1.82822, train_accuracy: 37.50\n",
      "[1,   125] loss: 1.89608, train_accuracy: 32.03\n",
      "[1,   126] loss: 1.89807, train_accuracy: 28.91\n",
      "[1,   127] loss: 2.43063, train_accuracy: 32.03\n",
      "[1,   128] loss: 1.77006, train_accuracy: 32.03\n",
      "[1,   129] loss: 2.37779, train_accuracy: 30.47\n",
      "[1,   130] loss: 1.98017, train_accuracy: 32.81\n",
      "[1,   131] loss: 1.91896, train_accuracy: 32.81\n",
      "[1,   132] loss: 2.03969, train_accuracy: 26.56\n",
      "[1,   133] loss: 2.05185, train_accuracy: 33.59\n",
      "[1,   134] loss: 2.34154, train_accuracy: 28.12\n",
      "[1,   135] loss: 2.14637, train_accuracy: 26.56\n",
      "[1,   136] loss: 1.93136, train_accuracy: 31.25\n",
      "[1,   137] loss: 2.37844, train_accuracy: 25.78\n",
      "[1,   138] loss: 2.03273, train_accuracy: 31.25\n",
      "[1,   139] loss: 2.08269, train_accuracy: 28.12\n",
      "[1,   140] loss: 2.16128, train_accuracy: 18.75\n",
      "[1,   141] loss: 1.88976, train_accuracy: 32.03\n",
      "[1,   142] loss: 2.02014, train_accuracy: 17.97\n",
      "[1,   143] loss: 2.28018, train_accuracy: 32.81\n",
      "[1,   144] loss: 1.95017, train_accuracy: 33.59\n",
      "[1,   145] loss: 2.02558, train_accuracy: 31.25\n",
      "[1,   146] loss: 1.82491, train_accuracy: 38.28\n",
      "[1,   147] loss: 1.92984, train_accuracy: 27.34\n",
      "[1,   148] loss: 1.96467, train_accuracy: 32.03\n",
      "[1,   149] loss: 2.01604, train_accuracy: 28.12\n",
      "[1,   150] loss: 2.45987, train_accuracy: 25.00\n",
      "[1,   151] loss: 2.03246, train_accuracy: 23.44\n",
      "[1,   152] loss: 1.80666, train_accuracy: 27.34\n",
      "[1,   153] loss: 1.86805, train_accuracy: 35.16\n",
      "[1,   154] loss: 2.19630, train_accuracy: 37.50\n",
      "[1,   155] loss: 2.21284, train_accuracy: 32.81\n",
      "[1,   156] loss: 1.92968, train_accuracy: 35.16\n",
      "[1,   157] loss: 2.10158, train_accuracy: 26.56\n",
      "[1,   158] loss: 1.85863, train_accuracy: 34.38\n",
      "[1,   159] loss: 1.92496, train_accuracy: 32.03\n",
      "[1,   160] loss: 1.84841, train_accuracy: 38.28\n",
      "[1,   161] loss: 1.81004, train_accuracy: 35.16\n",
      "[1,   162] loss: 2.13286, train_accuracy: 30.47\n",
      "[1,   163] loss: 1.97732, train_accuracy: 35.16\n",
      "[1,   164] loss: 1.92799, train_accuracy: 32.81\n",
      "[1,   165] loss: 1.97034, train_accuracy: 26.56\n",
      "[1,   166] loss: 1.92190, train_accuracy: 29.69\n",
      "[1,   167] loss: 1.80321, train_accuracy: 33.59\n",
      "[1,   168] loss: 1.97046, train_accuracy: 27.34\n",
      "[1,   169] loss: 1.82720, train_accuracy: 30.47\n",
      "[1,   170] loss: 2.28511, train_accuracy: 25.78\n",
      "[1,   171] loss: 1.85501, train_accuracy: 31.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   172] loss: 1.72704, train_accuracy: 38.28\n",
      "[1,   173] loss: 2.03732, train_accuracy: 24.22\n",
      "[1,   174] loss: 1.84323, train_accuracy: 28.12\n",
      "[1,   175] loss: 1.79470, train_accuracy: 34.38\n",
      "[1,   176] loss: 1.91841, train_accuracy: 27.34\n",
      "[1,   177] loss: 1.67188, train_accuracy: 34.38\n",
      "[1,   178] loss: 1.92275, train_accuracy: 32.81\n",
      "[1,   179] loss: 1.55924, train_accuracy: 44.53\n",
      "[1,   180] loss: 1.87209, train_accuracy: 35.16\n",
      "[1,   181] loss: 1.64117, train_accuracy: 40.62\n",
      "[1,   182] loss: 1.95828, train_accuracy: 28.91\n",
      "[1,   183] loss: 1.70472, train_accuracy: 39.06\n",
      "[1,   184] loss: 1.77927, train_accuracy: 39.06\n",
      "[1,   185] loss: 1.88685, train_accuracy: 39.06\n",
      "[1,   186] loss: 1.77597, train_accuracy: 31.25\n",
      "[1,   187] loss: 1.79334, train_accuracy: 45.31\n",
      "[1,   188] loss: 1.59424, train_accuracy: 39.06\n",
      "[1,   189] loss: 1.54767, train_accuracy: 41.41\n",
      "[1,   190] loss: 2.15524, train_accuracy: 35.16\n",
      "[1,   191] loss: 1.65596, train_accuracy: 35.94\n",
      "[1,   192] loss: 1.97502, train_accuracy: 33.59\n",
      "[1,   193] loss: 1.66956, train_accuracy: 35.94\n",
      "[1,   194] loss: 2.18329, train_accuracy: 31.25\n",
      "[1,   195] loss: 1.72101, train_accuracy: 38.28\n",
      "[1,   196] loss: 1.67013, train_accuracy: 43.75\n",
      "[1,   197] loss: 1.91792, train_accuracy: 33.59\n",
      "[1,   198] loss: 1.58155, train_accuracy: 42.97\n",
      "[1,   199] loss: 1.83458, train_accuracy: 29.69\n",
      "[1,   200] loss: 1.76503, train_accuracy: 37.50\n",
      "[1,   201] loss: 1.74224, train_accuracy: 36.72\n",
      "[1,   202] loss: 1.69250, train_accuracy: 38.28\n",
      "[1,   203] loss: 1.76654, train_accuracy: 35.94\n",
      "[1,   204] loss: 1.73019, train_accuracy: 35.16\n",
      "[1,   205] loss: 1.57877, train_accuracy: 39.84\n",
      "[1,   206] loss: 1.75114, train_accuracy: 36.72\n",
      "[1,   207] loss: 1.66378, train_accuracy: 34.38\n",
      "[1,   208] loss: 1.63511, train_accuracy: 41.41\n",
      "[1,   209] loss: 1.81234, train_accuracy: 32.81\n",
      "[1,   210] loss: 1.77818, train_accuracy: 27.34\n",
      "[1,   211] loss: 1.53532, train_accuracy: 46.09\n",
      "[1,   212] loss: 1.67968, train_accuracy: 40.62\n",
      "[1,   213] loss: 1.60868, train_accuracy: 39.84\n",
      "[1,   214] loss: 1.73349, train_accuracy: 38.28\n",
      "[1,   215] loss: 1.74103, train_accuracy: 39.84\n",
      "[1,   216] loss: 1.95166, train_accuracy: 37.50\n",
      "[1,   217] loss: 1.81948, train_accuracy: 34.38\n",
      "[1,   218] loss: 1.78902, train_accuracy: 30.47\n",
      "[1,   219] loss: 1.90684, train_accuracy: 29.69\n",
      "[1,   220] loss: 1.57391, train_accuracy: 45.31\n",
      "[1,   221] loss: 1.84383, train_accuracy: 32.03\n",
      "[1,   222] loss: 1.76442, train_accuracy: 43.75\n",
      "[1,   223] loss: 1.80285, train_accuracy: 32.03\n",
      "[1,   224] loss: 1.58678, train_accuracy: 46.09\n",
      "[1,   225] loss: 1.61683, train_accuracy: 43.75\n",
      "[1,   226] loss: 1.73729, train_accuracy: 32.81\n",
      "[1,   227] loss: 1.65249, train_accuracy: 38.28\n",
      "[1,   228] loss: 1.66928, train_accuracy: 41.41\n",
      "[1,   229] loss: 1.77280, train_accuracy: 40.62\n",
      "[1,   230] loss: 1.60536, train_accuracy: 37.50\n",
      "[1,   231] loss: 1.45837, train_accuracy: 48.44\n",
      "[1,   232] loss: 1.69146, train_accuracy: 37.50\n",
      "[1,   233] loss: 1.59829, train_accuracy: 44.53\n",
      "[1,   234] loss: 1.59430, train_accuracy: 49.22\n",
      "[1,   235] loss: 1.68880, train_accuracy: 42.19\n",
      "[1,   236] loss: 1.62809, train_accuracy: 36.72\n",
      "[1,   237] loss: 1.88980, train_accuracy: 32.03\n",
      "[1,   238] loss: 2.08127, train_accuracy: 35.94\n",
      "[1,   239] loss: 1.86643, train_accuracy: 32.03\n",
      "[1,   240] loss: 1.69835, train_accuracy: 36.72\n",
      "[1,   241] loss: 1.73101, train_accuracy: 27.34\n",
      "[1,   242] loss: 1.88850, train_accuracy: 29.69\n",
      "[1,   243] loss: 1.64654, train_accuracy: 35.16\n",
      "[1,   244] loss: 1.63752, train_accuracy: 36.72\n",
      "[1,   245] loss: 1.73894, train_accuracy: 35.16\n",
      "[1,   246] loss: 1.82358, train_accuracy: 29.69\n",
      "[1,   247] loss: 1.68523, train_accuracy: 35.16\n",
      "[1,   248] loss: 1.63579, train_accuracy: 50.78\n",
      "[1,   249] loss: 1.54002, train_accuracy: 38.28\n",
      "[1,   250] loss: 1.60319, train_accuracy: 34.38\n",
      "[1,   251] loss: 1.55544, train_accuracy: 46.09\n",
      "[1,   252] loss: 1.94480, train_accuracy: 28.91\n",
      "[1,   253] loss: 1.48578, train_accuracy: 46.09\n",
      "[1,   254] loss: 1.63436, train_accuracy: 43.75\n",
      "[1,   255] loss: 1.73302, train_accuracy: 39.06\n",
      "[1,   256] loss: 1.91138, train_accuracy: 41.41\n",
      "[1,   257] loss: 1.49788, train_accuracy: 49.22\n",
      "[1,   258] loss: 1.79037, train_accuracy: 45.31\n",
      "[1,   259] loss: 1.65892, train_accuracy: 38.28\n",
      "[1,   260] loss: 1.55423, train_accuracy: 46.09\n",
      "[1,   261] loss: 1.56525, train_accuracy: 43.75\n",
      "[1,   262] loss: 1.56465, train_accuracy: 39.84\n",
      "[1,   263] loss: 1.71620, train_accuracy: 31.25\n",
      "[1,   264] loss: 1.62659, train_accuracy: 42.19\n",
      "[1,   265] loss: 1.41723, train_accuracy: 46.09\n",
      "[1,   266] loss: 1.57145, train_accuracy: 47.66\n",
      "[1,   267] loss: 1.75672, train_accuracy: 33.59\n",
      "[1,   268] loss: 1.53707, train_accuracy: 42.19\n",
      "[1,   269] loss: 1.61829, train_accuracy: 42.19\n",
      "[1,   270] loss: 1.48104, train_accuracy: 43.75\n",
      "[1,   271] loss: 1.72257, train_accuracy: 36.72\n",
      "[1,   272] loss: 1.87493, train_accuracy: 36.72\n",
      "[1,   273] loss: 1.74643, train_accuracy: 36.72\n",
      "[1,   274] loss: 1.90280, train_accuracy: 36.72\n",
      "[1,   275] loss: 1.86782, train_accuracy: 40.62\n",
      "[1,   276] loss: 1.76191, train_accuracy: 32.03\n",
      "[1,   277] loss: 1.86285, train_accuracy: 34.38\n",
      "[1,   278] loss: 1.53134, train_accuracy: 43.75\n",
      "[1,   279] loss: 1.64751, train_accuracy: 33.59\n",
      "[1,   280] loss: 1.88575, train_accuracy: 35.16\n",
      "[1,   281] loss: 1.69738, train_accuracy: 38.28\n",
      "[1,   282] loss: 1.83037, train_accuracy: 26.56\n",
      "[1,   283] loss: 1.63920, train_accuracy: 38.28\n",
      "[1,   284] loss: 1.43493, train_accuracy: 50.00\n",
      "[1,   285] loss: 1.48100, train_accuracy: 42.97\n",
      "[1,   286] loss: 1.64626, train_accuracy: 37.50\n",
      "[1,   287] loss: 1.64588, train_accuracy: 46.88\n",
      "[1,   288] loss: 1.63246, train_accuracy: 39.06\n",
      "[1,   289] loss: 1.71519, train_accuracy: 36.72\n",
      "[1,   290] loss: 1.66995, train_accuracy: 39.84\n",
      "[1,   291] loss: 1.45344, train_accuracy: 44.53\n",
      "[1,   292] loss: 1.69142, train_accuracy: 35.94\n",
      "[1,   293] loss: 1.68226, train_accuracy: 36.72\n",
      "[1,   294] loss: 1.85490, train_accuracy: 35.16\n",
      "[1,   295] loss: 1.50531, train_accuracy: 43.75\n",
      "[1,   296] loss: 1.63471, train_accuracy: 38.28\n",
      "[1,   297] loss: 1.33064, train_accuracy: 46.09\n",
      "[1,   298] loss: 1.54386, train_accuracy: 41.41\n",
      "[1,   299] loss: 1.61498, train_accuracy: 43.75\n",
      "[1,   300] loss: 1.73247, train_accuracy: 38.28\n",
      "[1,   301] loss: 1.68187, train_accuracy: 39.06\n",
      "[1,   302] loss: 1.86133, train_accuracy: 38.28\n",
      "[1,   303] loss: 1.58403, train_accuracy: 51.56\n",
      "[1,   304] loss: 1.47877, train_accuracy: 50.00\n",
      "[1,   305] loss: 1.54329, train_accuracy: 40.62\n",
      "[1,   306] loss: 1.42988, train_accuracy: 50.78\n",
      "[1,   307] loss: 1.53782, train_accuracy: 41.41\n",
      "[1,   308] loss: 1.70567, train_accuracy: 40.62\n",
      "[1,   309] loss: 1.78049, train_accuracy: 39.06\n",
      "[1,   310] loss: 1.54013, train_accuracy: 43.75\n",
      "[1,   311] loss: 1.76199, train_accuracy: 41.41\n",
      "[1,   312] loss: 1.69506, train_accuracy: 43.75\n",
      "[1,   313] loss: 1.46627, train_accuracy: 45.31\n",
      "[1,   314] loss: 1.42743, train_accuracy: 50.00\n",
      "[1,   315] loss: 1.73453, train_accuracy: 36.72\n",
      "[1,   316] loss: 1.66648, train_accuracy: 39.06\n",
      "[1,   317] loss: 1.58098, train_accuracy: 42.97\n",
      "[1,   318] loss: 1.36501, train_accuracy: 46.09\n",
      "[1,   319] loss: 1.64492, train_accuracy: 37.50\n",
      "[1,   320] loss: 1.67111, train_accuracy: 41.41\n",
      "[1,   321] loss: 1.32215, train_accuracy: 48.44\n",
      "[1,   322] loss: 1.53981, train_accuracy: 47.66\n",
      "[1,   323] loss: 1.60776, train_accuracy: 49.22\n",
      "[1,   324] loss: 1.76179, train_accuracy: 41.41\n",
      "[1,   325] loss: 1.59290, train_accuracy: 44.53\n",
      "[1,   326] loss: 1.61965, train_accuracy: 42.97\n",
      "[1,   327] loss: 1.66631, train_accuracy: 33.59\n",
      "[1,   328] loss: 1.87971, train_accuracy: 39.06\n",
      "[1,   329] loss: 1.80241, train_accuracy: 36.72\n",
      "[1,   330] loss: 1.47082, train_accuracy: 49.22\n",
      "[1,   331] loss: 1.48907, train_accuracy: 48.44\n",
      "[1,   332] loss: 1.52535, train_accuracy: 45.31\n",
      "[1,   333] loss: 1.47882, train_accuracy: 47.66\n",
      "[1,   334] loss: 1.72000, train_accuracy: 37.50\n",
      "[1,   335] loss: 1.49487, train_accuracy: 50.00\n",
      "[1,   336] loss: 1.87676, train_accuracy: 35.16\n",
      "[1,   337] loss: 1.65019, train_accuracy: 40.62\n",
      "[1,   338] loss: 1.53852, train_accuracy: 43.75\n",
      "[1,   339] loss: 1.65230, train_accuracy: 37.50\n",
      "[1,   340] loss: 1.49453, train_accuracy: 42.19\n",
      "[1,   341] loss: 1.72272, train_accuracy: 41.41\n",
      "[1,   342] loss: 1.62247, train_accuracy: 41.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   343] loss: 1.68676, train_accuracy: 33.59\n",
      "[1,   344] loss: 1.77895, train_accuracy: 35.16\n",
      "[1,   345] loss: 1.47791, train_accuracy: 48.44\n",
      "[1,   346] loss: 1.53743, train_accuracy: 46.88\n",
      "[1,   347] loss: 1.64767, train_accuracy: 39.84\n",
      "[1,   348] loss: 1.56099, train_accuracy: 38.28\n",
      "[1,   349] loss: 1.47818, train_accuracy: 46.88\n",
      "[1,   350] loss: 1.51973, train_accuracy: 39.06\n",
      "[1,   351] loss: 1.50908, train_accuracy: 46.88\n",
      "[1,   352] loss: 1.59868, train_accuracy: 38.28\n",
      "[1,   353] loss: 1.53806, train_accuracy: 46.09\n",
      "[1,   354] loss: 1.82435, train_accuracy: 39.06\n",
      "[1,   355] loss: 1.54157, train_accuracy: 41.41\n",
      "[1,   356] loss: 1.58506, train_accuracy: 44.53\n",
      "[1,   357] loss: 1.48275, train_accuracy: 44.53\n",
      "[1,   358] loss: 1.50395, train_accuracy: 46.09\n",
      "[1,   359] loss: 1.60244, train_accuracy: 42.97\n",
      "[1,   360] loss: 1.73872, train_accuracy: 38.28\n",
      "[1,   361] loss: 1.38962, train_accuracy: 54.69\n",
      "[1,   362] loss: 1.46892, train_accuracy: 50.00\n",
      "[1,   363] loss: 1.65700, train_accuracy: 35.94\n",
      "[1,   364] loss: 1.49256, train_accuracy: 42.19\n",
      "[1,   365] loss: 1.68367, train_accuracy: 42.97\n",
      "[1,   366] loss: 1.63473, train_accuracy: 33.59\n",
      "[1,   367] loss: 1.45370, train_accuracy: 43.75\n",
      "[1,   368] loss: 1.34640, train_accuracy: 47.66\n",
      "[1,   369] loss: 1.64863, train_accuracy: 42.19\n",
      "[1,   370] loss: 1.33836, train_accuracy: 45.31\n",
      "[1,   371] loss: 1.39975, train_accuracy: 50.78\n",
      "[1,   372] loss: 1.35547, train_accuracy: 52.34\n",
      "[1,   373] loss: 1.56597, train_accuracy: 37.50\n",
      "[1,   374] loss: 1.38181, train_accuracy: 53.12\n",
      "[1,   375] loss: 1.41425, train_accuracy: 46.88\n",
      "[1,   376] loss: 1.45299, train_accuracy: 46.88\n",
      "[1,   377] loss: 1.50227, train_accuracy: 41.41\n",
      "[1,   378] loss: 1.50719, train_accuracy: 48.44\n",
      "[1,   379] loss: 1.45871, train_accuracy: 48.44\n",
      "[1,   380] loss: 1.58077, train_accuracy: 46.88\n",
      "[1,   381] loss: 1.40606, train_accuracy: 46.88\n",
      "[1,   382] loss: 1.47169, train_accuracy: 46.09\n",
      "[1,   383] loss: 1.38438, train_accuracy: 45.31\n",
      "[1,   384] loss: 1.45734, train_accuracy: 44.53\n",
      "[1,   385] loss: 1.57675, train_accuracy: 47.66\n",
      "[1,   386] loss: 1.36454, train_accuracy: 46.09\n",
      "[1,   387] loss: 1.40768, train_accuracy: 46.09\n",
      "[1,   388] loss: 1.31427, train_accuracy: 51.56\n",
      "[1,   389] loss: 1.30893, train_accuracy: 51.56\n",
      "[1,   390] loss: 1.46255, train_accuracy: 54.69\n",
      "[1,   391] loss: 1.58568, train_accuracy: 46.25\n",
      "duration: 112 s - train loss: 2.68332 - train accuracy: 33.57 - validation loss: 1.41 - validation accuracy: 49.41 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs_trained': 0,\n",
       " 'avg_time_per_epoch': 112.65657949447632,\n",
       " 'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'hist': {'train_loss': [2.6833220775170092],\n",
       "  'train_accuracy': [33.56817455242967],\n",
       "  'validation_loss': [1.4091312885284424],\n",
       "  'validation_accuracy': [49.41]},\n",
       " 'val_accuracy': 49.41}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CifarResNet().to(device)\n",
    "model.fit(train_loader, test_loader, 1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Resize only - 119 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying layers\n",
      "[1,     1] loss: 3.10206, train_accuracy: 12.50\n",
      "[1,     2] loss: 25.93526, train_accuracy: 13.28\n",
      "[1,     3] loss: 31.89803, train_accuracy: 8.59\n",
      "[1,     4] loss: 18.16910, train_accuracy: 11.72\n",
      "[1,     5] loss: 31.91439, train_accuracy: 11.72\n",
      "[1,     6] loss: 26.85158, train_accuracy: 11.72\n",
      "[1,     7] loss: 14.83936, train_accuracy: 10.94\n",
      "[1,     8] loss: 11.17216, train_accuracy: 7.81\n",
      "[1,     9] loss: 13.76136, train_accuracy: 14.84\n",
      "[1,    10] loss: 16.65985, train_accuracy: 12.50\n",
      "[1,    11] loss: 10.80370, train_accuracy: 11.72\n",
      "[1,    12] loss: 9.83598, train_accuracy: 12.50\n",
      "[1,    13] loss: 20.68222, train_accuracy: 12.50\n",
      "[1,    14] loss: 10.29360, train_accuracy: 14.84\n",
      "[1,    15] loss: 7.84886, train_accuracy: 10.94\n",
      "[1,    16] loss: 8.45962, train_accuracy: 10.94\n",
      "[1,    17] loss: 6.59555, train_accuracy: 12.50\n",
      "[1,    18] loss: 5.21252, train_accuracy: 14.06\n",
      "[1,    19] loss: 9.12383, train_accuracy: 8.59\n",
      "[1,    20] loss: 4.50371, train_accuracy: 17.19\n",
      "[1,    21] loss: 7.84279, train_accuracy: 13.28\n",
      "[1,    22] loss: 4.23504, train_accuracy: 18.75\n",
      "[1,    23] loss: 4.53443, train_accuracy: 17.19\n",
      "[1,    24] loss: 5.23010, train_accuracy: 21.09\n",
      "[1,    25] loss: 4.53877, train_accuracy: 15.62\n",
      "[1,    26] loss: 6.92002, train_accuracy: 18.75\n",
      "[1,    27] loss: 4.02334, train_accuracy: 17.19\n",
      "[1,    28] loss: 4.39608, train_accuracy: 19.53\n",
      "[1,    29] loss: 4.40984, train_accuracy: 16.41\n",
      "[1,    30] loss: 3.00530, train_accuracy: 16.41\n",
      "[1,    31] loss: 3.22904, train_accuracy: 13.28\n",
      "[1,    32] loss: 4.13040, train_accuracy: 15.62\n",
      "[1,    33] loss: 3.59792, train_accuracy: 13.28\n",
      "[1,    34] loss: 4.26010, train_accuracy: 15.62\n",
      "[1,    35] loss: 4.08642, train_accuracy: 13.28\n",
      "[1,    36] loss: 3.78341, train_accuracy: 14.84\n",
      "[1,    37] loss: 2.43883, train_accuracy: 17.97\n",
      "[1,    38] loss: 4.42764, train_accuracy: 13.28\n",
      "[1,    39] loss: 3.75086, train_accuracy: 9.38\n",
      "[1,    40] loss: 3.48847, train_accuracy: 14.84\n",
      "[1,    41] loss: 4.39001, train_accuracy: 17.97\n",
      "[1,    42] loss: 2.80130, train_accuracy: 18.75\n",
      "[1,    43] loss: 2.77217, train_accuracy: 18.75\n",
      "[1,    44] loss: 2.49822, train_accuracy: 17.97\n",
      "[1,    45] loss: 3.77955, train_accuracy: 21.88\n",
      "[1,    46] loss: 2.46782, train_accuracy: 14.06\n",
      "[1,    47] loss: 2.45597, train_accuracy: 14.06\n",
      "[1,    48] loss: 3.06384, train_accuracy: 21.09\n",
      "[1,    49] loss: 3.40253, train_accuracy: 11.72\n",
      "[1,    50] loss: 3.07311, train_accuracy: 17.97\n",
      "[1,    51] loss: 3.16502, train_accuracy: 16.41\n",
      "[1,    52] loss: 2.70062, train_accuracy: 23.44\n",
      "[1,    53] loss: 3.21626, train_accuracy: 17.19\n",
      "[1,    54] loss: 2.63869, train_accuracy: 21.09\n",
      "[1,    55] loss: 2.80567, train_accuracy: 15.62\n",
      "[1,    56] loss: 2.30209, train_accuracy: 19.53\n",
      "[1,    57] loss: 2.89215, train_accuracy: 19.53\n",
      "[1,    58] loss: 2.52188, train_accuracy: 21.09\n",
      "[1,    59] loss: 2.60082, train_accuracy: 21.88\n",
      "[1,    60] loss: 3.62434, train_accuracy: 14.84\n",
      "[1,    61] loss: 2.94717, train_accuracy: 17.19\n",
      "[1,    62] loss: 3.13146, train_accuracy: 20.31\n",
      "[1,    63] loss: 3.36753, train_accuracy: 17.19\n",
      "[1,    64] loss: 2.66441, train_accuracy: 21.88\n",
      "[1,    65] loss: 2.89400, train_accuracy: 21.09\n",
      "[1,    66] loss: 2.75455, train_accuracy: 23.44\n",
      "[1,    67] loss: 2.83079, train_accuracy: 24.22\n",
      "[1,    68] loss: 2.62375, train_accuracy: 22.66\n",
      "[1,    69] loss: 3.34874, train_accuracy: 15.62\n",
      "[1,    70] loss: 2.98542, train_accuracy: 10.94\n",
      "[1,    71] loss: 3.27993, train_accuracy: 19.53\n",
      "[1,    72] loss: 2.66129, train_accuracy: 26.56\n",
      "[1,    73] loss: 2.89114, train_accuracy: 20.31\n",
      "[1,    74] loss: 2.28055, train_accuracy: 17.97\n",
      "[1,    75] loss: 2.62717, train_accuracy: 20.31\n",
      "[1,    76] loss: 2.45122, train_accuracy: 23.44\n",
      "[1,    77] loss: 3.53864, train_accuracy: 20.31\n",
      "[1,    78] loss: 2.28619, train_accuracy: 19.53\n",
      "[1,    79] loss: 2.15282, train_accuracy: 27.34\n",
      "[1,    80] loss: 2.31944, train_accuracy: 14.06\n",
      "[1,    81] loss: 2.31936, train_accuracy: 16.41\n",
      "[1,    82] loss: 2.47734, train_accuracy: 21.88\n",
      "[1,    83] loss: 2.39809, train_accuracy: 25.78\n",
      "[1,    84] loss: 2.30205, train_accuracy: 22.66\n",
      "[1,    85] loss: 2.48135, train_accuracy: 19.53\n",
      "[1,    86] loss: 2.41831, train_accuracy: 20.31\n",
      "[1,    87] loss: 2.50515, train_accuracy: 23.44\n",
      "[1,    88] loss: 2.23784, train_accuracy: 30.47\n",
      "[1,    89] loss: 2.34082, train_accuracy: 19.53\n",
      "[1,    90] loss: 2.55204, train_accuracy: 22.66\n",
      "[1,    91] loss: 2.59166, train_accuracy: 20.31\n",
      "[1,    92] loss: 2.90236, train_accuracy: 21.88\n",
      "[1,    93] loss: 2.37924, train_accuracy: 22.66\n",
      "[1,    94] loss: 2.41513, train_accuracy: 21.09\n",
      "[1,    95] loss: 2.23224, train_accuracy: 23.44\n",
      "[1,    96] loss: 2.76010, train_accuracy: 18.75\n",
      "[1,    97] loss: 2.21972, train_accuracy: 24.22\n",
      "[1,    98] loss: 2.59457, train_accuracy: 21.09\n",
      "[1,    99] loss: 2.73333, train_accuracy: 24.22\n",
      "[1,   100] loss: 2.17765, train_accuracy: 19.53\n",
      "[1,   101] loss: 2.55504, train_accuracy: 24.22\n",
      "[1,   102] loss: 2.38622, train_accuracy: 25.00\n",
      "[1,   103] loss: 2.25541, train_accuracy: 29.69\n",
      "[1,   104] loss: 2.02236, train_accuracy: 21.88\n",
      "[1,   105] loss: 2.27032, train_accuracy: 24.22\n",
      "[1,   106] loss: 2.23989, train_accuracy: 26.56\n",
      "[1,   107] loss: 2.43915, train_accuracy: 21.09\n",
      "[1,   108] loss: 2.31221, train_accuracy: 21.88\n",
      "[1,   109] loss: 2.50116, train_accuracy: 21.88\n",
      "[1,   110] loss: 2.89841, train_accuracy: 21.88\n",
      "[1,   111] loss: 2.50400, train_accuracy: 17.97\n",
      "[1,   112] loss: 2.48970, train_accuracy: 18.75\n",
      "[1,   113] loss: 2.37939, train_accuracy: 20.31\n",
      "[1,   114] loss: 2.27065, train_accuracy: 19.53\n",
      "[1,   115] loss: 2.27668, train_accuracy: 21.88\n",
      "[1,   116] loss: 1.95005, train_accuracy: 25.00\n",
      "[1,   117] loss: 2.09947, train_accuracy: 23.44\n",
      "[1,   118] loss: 2.07213, train_accuracy: 24.22\n",
      "[1,   119] loss: 2.30441, train_accuracy: 32.03\n",
      "[1,   120] loss: 1.84055, train_accuracy: 36.72\n",
      "[1,   121] loss: 2.26306, train_accuracy: 21.09\n",
      "[1,   122] loss: 2.52969, train_accuracy: 17.97\n",
      "[1,   123] loss: 2.01629, train_accuracy: 25.78\n",
      "[1,   124] loss: 2.07215, train_accuracy: 25.78\n",
      "[1,   125] loss: 2.06213, train_accuracy: 24.22\n",
      "[1,   126] loss: 2.10956, train_accuracy: 25.78\n",
      "[1,   127] loss: 2.10006, train_accuracy: 23.44\n",
      "[1,   128] loss: 1.93982, train_accuracy: 25.00\n",
      "[1,   129] loss: 2.10277, train_accuracy: 28.91\n",
      "[1,   130] loss: 2.27131, train_accuracy: 29.69\n",
      "[1,   131] loss: 1.99158, train_accuracy: 21.09\n",
      "[1,   132] loss: 2.33390, train_accuracy: 26.56\n",
      "[1,   133] loss: 1.99021, train_accuracy: 28.91\n",
      "[1,   134] loss: 1.97226, train_accuracy: 20.31\n",
      "[1,   135] loss: 2.03085, train_accuracy: 20.31\n",
      "[1,   136] loss: 2.00599, train_accuracy: 25.78\n",
      "[1,   137] loss: 2.01456, train_accuracy: 26.56\n",
      "[1,   138] loss: 2.12785, train_accuracy: 21.09\n",
      "[1,   139] loss: 2.27831, train_accuracy: 31.25\n",
      "[1,   140] loss: 2.06044, train_accuracy: 28.12\n",
      "[1,   141] loss: 1.85642, train_accuracy: 25.00\n",
      "[1,   142] loss: 2.13511, train_accuracy: 21.09\n",
      "[1,   143] loss: 1.81916, train_accuracy: 33.59\n",
      "[1,   144] loss: 2.17950, train_accuracy: 32.03\n",
      "[1,   145] loss: 2.01352, train_accuracy: 27.34\n",
      "[1,   146] loss: 1.85153, train_accuracy: 31.25\n",
      "[1,   147] loss: 1.93629, train_accuracy: 37.50\n",
      "[1,   148] loss: 2.16354, train_accuracy: 18.75\n",
      "[1,   149] loss: 1.97536, train_accuracy: 28.12\n",
      "[1,   150] loss: 2.09344, train_accuracy: 24.22\n",
      "[1,   151] loss: 1.82739, train_accuracy: 31.25\n",
      "[1,   152] loss: 1.96943, train_accuracy: 31.25\n",
      "[1,   153] loss: 1.81516, train_accuracy: 32.81\n",
      "[1,   154] loss: 2.03616, train_accuracy: 28.12\n",
      "[1,   155] loss: 1.93806, train_accuracy: 23.44\n",
      "[1,   156] loss: 1.84608, train_accuracy: 29.69\n",
      "[1,   157] loss: 1.77390, train_accuracy: 32.03\n",
      "[1,   158] loss: 2.18771, train_accuracy: 25.00\n",
      "[1,   159] loss: 1.94102, train_accuracy: 33.59\n",
      "[1,   160] loss: 1.89403, train_accuracy: 22.66\n",
      "[1,   161] loss: 1.99955, train_accuracy: 26.56\n",
      "[1,   162] loss: 2.22157, train_accuracy: 32.81\n",
      "[1,   163] loss: 2.02466, train_accuracy: 32.03\n",
      "[1,   164] loss: 2.00086, train_accuracy: 26.56\n",
      "[1,   165] loss: 2.02451, train_accuracy: 23.44\n",
      "[1,   166] loss: 2.26152, train_accuracy: 23.44\n",
      "[1,   167] loss: 1.88951, train_accuracy: 32.03\n",
      "[1,   168] loss: 1.99095, train_accuracy: 28.91\n",
      "[1,   169] loss: 1.88994, train_accuracy: 21.09\n",
      "[1,   170] loss: 2.30534, train_accuracy: 28.12\n",
      "[1,   171] loss: 2.02121, train_accuracy: 25.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   172] loss: 1.86145, train_accuracy: 32.03\n",
      "[1,   173] loss: 1.98888, train_accuracy: 28.12\n",
      "[1,   174] loss: 2.30943, train_accuracy: 27.34\n",
      "[1,   175] loss: 2.12598, train_accuracy: 24.22\n",
      "[1,   176] loss: 2.05125, train_accuracy: 28.12\n",
      "[1,   177] loss: 1.78808, train_accuracy: 32.81\n",
      "[1,   178] loss: 2.00980, train_accuracy: 30.47\n",
      "[1,   179] loss: 1.95519, train_accuracy: 37.50\n",
      "[1,   180] loss: 1.93661, train_accuracy: 28.12\n",
      "[1,   181] loss: 1.78854, train_accuracy: 31.25\n",
      "[1,   182] loss: 2.13988, train_accuracy: 29.69\n",
      "[1,   183] loss: 1.91985, train_accuracy: 25.78\n",
      "[1,   184] loss: 2.05615, train_accuracy: 35.94\n",
      "[1,   185] loss: 1.84890, train_accuracy: 28.12\n",
      "[1,   186] loss: 1.85268, train_accuracy: 33.59\n",
      "[1,   187] loss: 1.82027, train_accuracy: 31.25\n",
      "[1,   188] loss: 1.95259, train_accuracy: 28.12\n",
      "[1,   189] loss: 1.94362, train_accuracy: 28.12\n",
      "[1,   190] loss: 2.03577, train_accuracy: 28.12\n",
      "[1,   191] loss: 1.82528, train_accuracy: 26.56\n",
      "[1,   192] loss: 1.79208, train_accuracy: 32.03\n",
      "[1,   193] loss: 1.70137, train_accuracy: 35.16\n",
      "[1,   194] loss: 1.86247, train_accuracy: 28.91\n",
      "[1,   195] loss: 1.86218, train_accuracy: 36.72\n",
      "[1,   196] loss: 1.93734, train_accuracy: 25.00\n",
      "[1,   197] loss: 2.21324, train_accuracy: 30.47\n",
      "[1,   198] loss: 1.92193, train_accuracy: 29.69\n",
      "[1,   199] loss: 1.88560, train_accuracy: 33.59\n",
      "[1,   200] loss: 2.12847, train_accuracy: 28.12\n",
      "[1,   201] loss: 1.92197, train_accuracy: 27.34\n",
      "[1,   202] loss: 1.92431, train_accuracy: 28.12\n",
      "[1,   203] loss: 1.94509, train_accuracy: 32.03\n",
      "[1,   204] loss: 1.94293, train_accuracy: 27.34\n",
      "[1,   205] loss: 1.72852, train_accuracy: 32.03\n",
      "[1,   206] loss: 2.00389, train_accuracy: 29.69\n",
      "[1,   207] loss: 1.83151, train_accuracy: 32.03\n",
      "[1,   208] loss: 1.85447, train_accuracy: 33.59\n",
      "[1,   209] loss: 2.00627, train_accuracy: 25.00\n",
      "[1,   210] loss: 1.83393, train_accuracy: 32.81\n",
      "[1,   211] loss: 2.03132, train_accuracy: 27.34\n",
      "[1,   212] loss: 1.98195, train_accuracy: 29.69\n",
      "[1,   213] loss: 1.99660, train_accuracy: 32.81\n",
      "[1,   214] loss: 1.86481, train_accuracy: 28.91\n",
      "[1,   215] loss: 1.99293, train_accuracy: 27.34\n",
      "[1,   216] loss: 1.95836, train_accuracy: 27.34\n",
      "[1,   217] loss: 2.13789, train_accuracy: 19.53\n",
      "[1,   218] loss: 1.77808, train_accuracy: 33.59\n",
      "[1,   219] loss: 1.88760, train_accuracy: 32.03\n",
      "[1,   220] loss: 1.86034, train_accuracy: 39.06\n",
      "[1,   221] loss: 2.07047, train_accuracy: 26.56\n",
      "[1,   222] loss: 1.93741, train_accuracy: 31.25\n",
      "[1,   223] loss: 1.83264, train_accuracy: 36.72\n",
      "[1,   224] loss: 2.09722, train_accuracy: 25.78\n",
      "[1,   225] loss: 1.80383, train_accuracy: 35.16\n",
      "[1,   226] loss: 1.95271, train_accuracy: 30.47\n",
      "[1,   227] loss: 1.90963, train_accuracy: 31.25\n",
      "[1,   228] loss: 1.77852, train_accuracy: 34.38\n",
      "[1,   229] loss: 2.13477, train_accuracy: 35.94\n",
      "[1,   230] loss: 1.89195, train_accuracy: 32.03\n",
      "[1,   231] loss: 2.15798, train_accuracy: 27.34\n",
      "[1,   232] loss: 1.89493, train_accuracy: 31.25\n",
      "[1,   233] loss: 1.92308, train_accuracy: 33.59\n",
      "[1,   234] loss: 1.95603, train_accuracy: 28.12\n",
      "[1,   235] loss: 1.79225, train_accuracy: 33.59\n",
      "[1,   236] loss: 2.26274, train_accuracy: 19.53\n",
      "[1,   237] loss: 2.03753, train_accuracy: 28.12\n",
      "[1,   238] loss: 1.83194, train_accuracy: 29.69\n",
      "[1,   239] loss: 1.96533, train_accuracy: 25.00\n",
      "[1,   240] loss: 1.91288, train_accuracy: 29.69\n",
      "[1,   241] loss: 2.10448, train_accuracy: 30.47\n",
      "[1,   242] loss: 1.84981, train_accuracy: 30.47\n",
      "[1,   243] loss: 2.08370, train_accuracy: 29.69\n",
      "[1,   244] loss: 1.99297, train_accuracy: 25.78\n",
      "[1,   245] loss: 1.98637, train_accuracy: 25.00\n",
      "[1,   246] loss: 1.96380, train_accuracy: 31.25\n",
      "[1,   247] loss: 1.92791, train_accuracy: 28.91\n",
      "[1,   248] loss: 2.07455, train_accuracy: 26.56\n",
      "[1,   249] loss: 1.84181, train_accuracy: 35.94\n",
      "[1,   250] loss: 1.96424, train_accuracy: 29.69\n",
      "[1,   251] loss: 1.88133, train_accuracy: 28.91\n",
      "[1,   252] loss: 1.67651, train_accuracy: 43.75\n",
      "[1,   253] loss: 1.72757, train_accuracy: 36.72\n",
      "[1,   254] loss: 2.07129, train_accuracy: 35.16\n",
      "[1,   255] loss: 1.95428, train_accuracy: 23.44\n",
      "[1,   256] loss: 2.18419, train_accuracy: 30.47\n",
      "[1,   257] loss: 1.88785, train_accuracy: 35.16\n",
      "[1,   258] loss: 1.73312, train_accuracy: 37.50\n",
      "[1,   259] loss: 1.85964, train_accuracy: 35.94\n",
      "[1,   260] loss: 1.70832, train_accuracy: 39.06\n",
      "[1,   261] loss: 1.78686, train_accuracy: 32.81\n",
      "[1,   262] loss: 1.97186, train_accuracy: 35.94\n",
      "[1,   263] loss: 1.92593, train_accuracy: 25.00\n",
      "[1,   264] loss: 1.72026, train_accuracy: 35.94\n",
      "[1,   265] loss: 1.70901, train_accuracy: 38.28\n",
      "[1,   266] loss: 1.69635, train_accuracy: 38.28\n",
      "[1,   267] loss: 1.90478, train_accuracy: 28.12\n",
      "[1,   268] loss: 1.65246, train_accuracy: 41.41\n",
      "[1,   269] loss: 2.07590, train_accuracy: 28.91\n",
      "[1,   270] loss: 1.94928, train_accuracy: 36.72\n",
      "[1,   271] loss: 1.89051, train_accuracy: 33.59\n",
      "[1,   272] loss: 1.61214, train_accuracy: 46.09\n",
      "[1,   273] loss: 1.90584, train_accuracy: 34.38\n",
      "[1,   274] loss: 1.84596, train_accuracy: 32.03\n",
      "[1,   275] loss: 1.82274, train_accuracy: 34.38\n",
      "[1,   276] loss: 1.78041, train_accuracy: 31.25\n",
      "[1,   277] loss: 1.86391, train_accuracy: 32.81\n",
      "[1,   278] loss: 1.78243, train_accuracy: 35.16\n",
      "[1,   279] loss: 1.74224, train_accuracy: 33.59\n",
      "[1,   280] loss: 1.74443, train_accuracy: 32.81\n",
      "[1,   281] loss: 1.82201, train_accuracy: 39.84\n",
      "[1,   282] loss: 1.78773, train_accuracy: 33.59\n",
      "[1,   283] loss: 1.93697, train_accuracy: 34.38\n",
      "[1,   284] loss: 1.95183, train_accuracy: 32.03\n",
      "[1,   285] loss: 1.67647, train_accuracy: 36.72\n",
      "[1,   286] loss: 1.72647, train_accuracy: 39.06\n",
      "[1,   287] loss: 2.01659, train_accuracy: 27.34\n",
      "[1,   288] loss: 1.90645, train_accuracy: 29.69\n",
      "[1,   289] loss: 1.98759, train_accuracy: 31.25\n",
      "[1,   290] loss: 1.86101, train_accuracy: 32.03\n",
      "[1,   291] loss: 1.75102, train_accuracy: 34.38\n",
      "[1,   292] loss: 1.99460, train_accuracy: 28.12\n",
      "[1,   293] loss: 1.70384, train_accuracy: 40.62\n",
      "[1,   294] loss: 1.81406, train_accuracy: 35.16\n",
      "[1,   295] loss: 1.84162, train_accuracy: 35.94\n",
      "[1,   296] loss: 1.98556, train_accuracy: 32.81\n",
      "[1,   297] loss: 1.86374, train_accuracy: 31.25\n",
      "[1,   298] loss: 2.05258, train_accuracy: 27.34\n",
      "[1,   299] loss: 1.87500, train_accuracy: 31.25\n",
      "[1,   300] loss: 2.20738, train_accuracy: 32.81\n",
      "[1,   301] loss: 1.99104, train_accuracy: 28.12\n",
      "[1,   302] loss: 1.86154, train_accuracy: 37.50\n",
      "[1,   303] loss: 1.89949, train_accuracy: 28.91\n",
      "[1,   304] loss: 1.89824, train_accuracy: 32.03\n",
      "[1,   305] loss: 1.96088, train_accuracy: 26.56\n",
      "[1,   306] loss: 1.71713, train_accuracy: 38.28\n",
      "[1,   307] loss: 1.86620, train_accuracy: 33.59\n",
      "[1,   308] loss: 1.64037, train_accuracy: 39.84\n",
      "[1,   309] loss: 1.95223, train_accuracy: 25.00\n",
      "[1,   310] loss: 1.64018, train_accuracy: 36.72\n",
      "[1,   311] loss: 1.66652, train_accuracy: 39.06\n",
      "[1,   312] loss: 1.81844, train_accuracy: 36.72\n",
      "[1,   313] loss: 1.97958, train_accuracy: 34.38\n",
      "[1,   314] loss: 1.74227, train_accuracy: 32.03\n",
      "[1,   315] loss: 1.69553, train_accuracy: 42.97\n",
      "[1,   316] loss: 1.67165, train_accuracy: 35.16\n",
      "[1,   317] loss: 1.78665, train_accuracy: 36.72\n",
      "[1,   318] loss: 1.73483, train_accuracy: 36.72\n",
      "[1,   319] loss: 1.94124, train_accuracy: 36.72\n",
      "[1,   320] loss: 1.98021, train_accuracy: 25.00\n",
      "[1,   321] loss: 2.16783, train_accuracy: 26.56\n",
      "[1,   322] loss: 1.87837, train_accuracy: 39.06\n",
      "[1,   323] loss: 1.89041, train_accuracy: 35.94\n",
      "[1,   324] loss: 1.78709, train_accuracy: 35.16\n",
      "[1,   325] loss: 1.87891, train_accuracy: 34.38\n",
      "[1,   326] loss: 1.87060, train_accuracy: 31.25\n",
      "[1,   327] loss: 2.21268, train_accuracy: 33.59\n",
      "[1,   328] loss: 1.87473, train_accuracy: 35.94\n",
      "[1,   329] loss: 2.12383, train_accuracy: 28.12\n",
      "[1,   330] loss: 1.87538, train_accuracy: 33.59\n",
      "[1,   331] loss: 1.95725, train_accuracy: 39.84\n",
      "[1,   332] loss: 1.97895, train_accuracy: 25.00\n",
      "[1,   333] loss: 1.76431, train_accuracy: 33.59\n",
      "[1,   334] loss: 1.73117, train_accuracy: 42.97\n",
      "[1,   335] loss: 1.92565, train_accuracy: 25.00\n",
      "[1,   336] loss: 1.80493, train_accuracy: 36.72\n",
      "[1,   337] loss: 1.75543, train_accuracy: 41.41\n",
      "[1,   338] loss: 1.64444, train_accuracy: 37.50\n",
      "[1,   339] loss: 1.87420, train_accuracy: 32.81\n",
      "[1,   340] loss: 1.91847, train_accuracy: 25.78\n",
      "[1,   341] loss: 1.94808, train_accuracy: 34.38\n",
      "[1,   342] loss: 2.06651, train_accuracy: 30.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   343] loss: 1.84307, train_accuracy: 26.56\n",
      "[1,   344] loss: 1.81446, train_accuracy: 32.03\n",
      "[1,   345] loss: 1.67665, train_accuracy: 36.72\n",
      "[1,   346] loss: 1.80287, train_accuracy: 42.19\n",
      "[1,   347] loss: 1.91096, train_accuracy: 35.16\n",
      "[1,   348] loss: 1.82605, train_accuracy: 32.81\n",
      "[1,   349] loss: 1.81246, train_accuracy: 37.50\n",
      "[1,   350] loss: 1.79717, train_accuracy: 35.94\n",
      "[1,   351] loss: 1.79764, train_accuracy: 32.03\n",
      "[1,   352] loss: 1.92872, train_accuracy: 28.91\n",
      "[1,   353] loss: 1.89364, train_accuracy: 32.03\n",
      "[1,   354] loss: 1.79667, train_accuracy: 39.84\n",
      "[1,   355] loss: 1.74719, train_accuracy: 32.81\n",
      "[1,   356] loss: 1.88280, train_accuracy: 32.81\n",
      "[1,   357] loss: 1.75367, train_accuracy: 32.03\n",
      "[1,   358] loss: 1.82737, train_accuracy: 31.25\n",
      "[1,   359] loss: 1.80144, train_accuracy: 34.38\n",
      "[1,   360] loss: 1.94088, train_accuracy: 35.94\n",
      "[1,   361] loss: 1.78906, train_accuracy: 36.72\n",
      "[1,   362] loss: 1.85187, train_accuracy: 32.03\n",
      "[1,   363] loss: 1.76019, train_accuracy: 35.94\n",
      "[1,   364] loss: 1.73137, train_accuracy: 34.38\n",
      "[1,   365] loss: 1.79400, train_accuracy: 33.59\n",
      "[1,   366] loss: 1.95089, train_accuracy: 32.81\n",
      "[1,   367] loss: 1.75049, train_accuracy: 37.50\n",
      "[1,   368] loss: 1.75811, train_accuracy: 35.94\n",
      "[1,   369] loss: 1.77632, train_accuracy: 32.03\n",
      "[1,   370] loss: 2.02415, train_accuracy: 34.38\n",
      "[1,   371] loss: 1.96944, train_accuracy: 31.25\n",
      "[1,   372] loss: 1.69162, train_accuracy: 37.50\n",
      "[1,   373] loss: 2.02087, train_accuracy: 29.69\n",
      "[1,   374] loss: 1.71534, train_accuracy: 42.19\n",
      "[1,   375] loss: 1.98285, train_accuracy: 31.25\n",
      "[1,   376] loss: 1.68821, train_accuracy: 34.38\n",
      "[1,   377] loss: 1.76450, train_accuracy: 33.59\n",
      "[1,   378] loss: 1.81199, train_accuracy: 32.03\n",
      "[1,   379] loss: 1.82750, train_accuracy: 32.03\n",
      "[1,   380] loss: 1.86935, train_accuracy: 30.47\n",
      "[1,   381] loss: 1.74365, train_accuracy: 32.03\n",
      "[1,   382] loss: 1.67199, train_accuracy: 38.28\n",
      "[1,   383] loss: 1.73508, train_accuracy: 30.47\n",
      "[1,   384] loss: 1.72417, train_accuracy: 36.72\n",
      "[1,   385] loss: 1.66516, train_accuracy: 39.84\n",
      "[1,   386] loss: 1.88668, train_accuracy: 29.69\n",
      "[1,   387] loss: 1.87812, train_accuracy: 25.78\n",
      "[1,   388] loss: 1.87997, train_accuracy: 32.03\n",
      "[1,   389] loss: 1.60988, train_accuracy: 38.28\n",
      "[1,   390] loss: 1.78018, train_accuracy: 39.84\n",
      "[1,   391] loss: 1.75039, train_accuracy: 36.25\n",
      "duration: 119 s - train loss: 2.81919 - train accuracy: 27.55 - validation loss: 1.66 - validation accuracy: 39.16 \n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs_trained': 0,\n",
       " 'avg_time_per_epoch': 119.81687951087952,\n",
       " 'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'hist': {'train_loss': [2.819187433518412],\n",
       "  'train_accuracy': [27.552349744245525],\n",
       "  'validation_loss': [1.6579050897042962],\n",
       "  'validation_accuracy': [39.16]},\n",
       " 'val_accuracy': 39.16}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CifarResNet().to(device)\n",
    "model.fit(train_loader, test_loader, 1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
